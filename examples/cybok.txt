Chapter 1 Introduction Andrew Martin University of Oxford Awais Rashid University of Bristol Howard Chivers University of York George Danezis University College London Steve Schneider University of Surrey Emil Lupu Imperial College London 1 The Cyber Security Body Of Knowledge www.cybok.org Cyber security is becoming an important element in curricula at all education levels .
However , the foundational knowledge on which the ﬁeld of cyber security is being developed is fragmented , and as a result , it can be difﬁcult for both students and educators to map coherent paths of progression through the subject .
By comparison , mature scientiﬁc disciplines like mathematics , physics , chemistry , and biology have established foundational knowledge and clear learning pathways .
Within software engineering , the IEEE Software Engineering Body of Knowledge [ 3 ] codiﬁes key foundational knowledge on which a range of educational programmes may be built .
There are a number of previous and current efforts on establishing skills frameworks , key topic areas , and curricular guidelines for cyber security .
However , a consensus has not been reached on what the diverse community of researchers , educators , and practitioners sees as established foundational knowledge in cyber security .
The Cyber Security Body of Knowledge ( CyBOK ) aims to codify the foundational and generally recognised knowledge on cyber security .
In the same fashion as SWEBOK , CyBOK is meant to be a guide to the body of knowledge ; the knowledge that it codiﬁes already exists in literature such as textbooks , academic research articles , technical reports , white papers , and standards .
Our focus is , therefore , on mapping established knowledge and not fully replicating everything that has ever been written on the subject .
Educational programmes ranging from secondary and undergraduate education to postgraduate and continuing professional development programmes can then be developed on the basis of CyBOK .
Each KA assumes a baseline agreement on the overall vocabulary , goals , and approaches to cyber security , and here we provide that common material which underpins the whole body of knowledege .
We begin with an overview of cyber security as a topic , and some basic deﬁnitions , before introducing the knowledge areas .
The KAs and their groupings into categories are , of course , not orthogonal and there are a number of dependencies across the KAs which are cross-referenced and also separately captured visually on the CyBOK web site ( https : //www.cybok.org ) .
We then discuss how the knowledge in the KAs can be deployed to understand the means and objectives of cyber security , mitigate against failures and incidents , and manage risks .
Although we have necessarily divided the CyBOK into a number of discrete Knowledge Areas ( KAs ) , it is clear that there are many inter-relationships among them .
Those with professional responsibility for one area must typically have at least a moderate grasp of the adjacent topics ; someone responsible for architecting a secure system must understand many .
There are a number of unifying principles and crosscutting themes — security economics ; veriﬁcation and formal methods ; and security architecture and lifecycle — that underpin the development of systems that satisfy particular security properties .
We conclude the introduction by discussing such principles and themes .
1.1 CYBER SECURITY DEFINITION The CyBOK Knowledge Areas assume a common vocabulary and core understanding of a number of topics central to the ﬁeld .
Whilst this Body of Knowledge is descriptive of existing knowledge ( rather than seeking to innovate , or constrain ) , it is evident that use of widelyshared terminology in an established concept map is crucial to the development of the discipline as a whole .
Since our main aim is to provide a guide to the Body of Knowledge , we will provide references to other deﬁnitions , rather than introducing our own .
Cyber security has become an encompassing term , as our working deﬁnition illustrates : KA Introduction | October 2019 Page 2 The Cyber Security Body Of Knowledge www.cybok.org Deﬁnition : Cyber security refers to the protection of information systems ( hardware , software and associated infrastructure ) , the data on them , and the services they provide , from unauthorised access , harm or misuse .
This includes harm caused intentionally by the operator of the system , or accidentally , as a result of failing to follow security procedures .
UK National Cyber Security Strategy [ 4 ] This is a succinct deﬁnition but expresses the breadth of coverage within the topic .
The consideration of human behaviours is a crucial element of such a deﬁnition—but arguably still missing is a mention of the impact on them from loss of information or reduced safety , or of how security and privacy breaches impact trust in connected systems and infrastructures .
Moreover , security must be balanced with other risks and requirements—from a human factors perspective there is a need not to disrupt the primary task .
A large contributor to the notion of cyber security is Information Security , widely regarded as comprised of three main elements : Deﬁnition : Information security .
Through the developing digital age other ‘ securities ’ have had prominence , including Computer Security and Network Security ; related notions include Information Assurance , and Systems Security — perhaps within the context of Systems Engineering or Security Engineering .
These terms are easily confused , and it seems that often one term is used when another is meant .
Many of those terms were subject to the criticism that they place an over-reliance on technical controls , and focus almost exclusively on information .
Stretching them to relate to cyberphysical systems may be taking them too far : indeed , our working deﬁnition above privileges the notion of information ( whilst also mentioning services ) — whereas in the case of networkconnected actuators , the pressing challenge is to prevent unwanted physical actions .
Moreover , in some accounts of the topic , cyberspace is best understood as a ‘ place ’ in which business is conducted , human communications take place , art is made and enjoyed , relationships are formed and developed , and so on .
Taken as a whole , the CyBOK delineates a large range of topics which appear to be within the broad scope of cyber security , even if a succinct reduction of those into a short deﬁnition remains elusive .
The full scope of CyBOK may serve as an extended deﬁnition of the topic—as summarised next .
Clearly , other possible categorisations of these KAs may be equally valid , and ultimately some of the structure is relatively arbitrary .
The CyBOK Preface describes the process by which these KAs were identiﬁed and chosen .
Our categories are not entirely orthogonal .
These are intended to capture knowledge relating to cyber security per se : in order to make sense of some of that knowledge , auxiliary and background knowledge is needed — whether in the design of hardware and software , or in diverse other ﬁelds , such as law .
Risk Management & Governance Law & Regulation International and national statutory and regulatory requirements , compliance obligations , and security ethics , including data protection and developing doctrines on cyber warfare .
Human Factors Usable security , social & behavioural factors impacting security , security culture and awareness as well as the impact of security controls on user behaviours .
Privacy & Online Rights Techniques for protecting personal information , including communications , applications , and inferences from databases and data processing .
It also includes other systems supporting online rights touching on censorship and circumvention , covertness , electronic elections , and privacy in payment and identity systems .
Attacks and Defences Technical details of exploits and distributed malicious systems , together with associated discovery and analysis approaches .
Security Operations & Incident Management The conﬁguration , operation and maintenance of secure systems including the detection of and response to security incidents and the collection and use of threat intelligence .
Forensics The collection , analysis , & reporting of digital evidence in support of incidents or criminal events .
Systems Security Core primitives of cryptography as presently practised & emerging algorithms , techniques for analysis of these , and the protocols that use them .
Cryptography Operating Systems & Virtualisation Security Operating systems protection mechanisms , implementing secure abstraction of hardware , and sharing of resources , including isolation in multiuser systems , secure virtualisation , and security in database systems .
Authentication , Authorisation , & Accountability All aspects of identity management and authentication technologies , and architectures and tools to support authorisation and accountability in both isolated and distributed systems .
Software and Platform Security Known categories of programming errors resulting in security bugs , & techniques for avoiding these errors—both through coding practice and improved language design—and tools , techniques , and methods for detection of such errors in existing systems .
Software Security Web & Mobile Security Issues related to web applications and services distributed across devices and frameworks , including the diverse programming paradigms and protection models .
Secure Software Lifecycle The application of security software engineering techniques in the whole systems development lifecycle resulting in software that is secure by default .
Infrastructure Security Security aspects of networking & telecommunication protocols , including the security of routing , network security elements , and speciﬁc cryptographic protocols used for network security .
Network Security Hardware Security Security in the design , implementation , & deployment of general-purpose and specialist hardware , including trusted computing technologies and sources of randomness .
Physical Layer & Telecommunications Security Security concerns and limitations of the physical layer including aspects of radio frequency encodings and transmission techniques , unintended radiation , and interference .
Figure 1.2 : Short descriptions of CyBOK Knowledge Areas The Cyber Security Body Of Knowledge www.cybok.org 1.3 DEPLOYING CYBOK KNOWLEDGE TO ADDRESS SECURITY ISSUES 1.3.1 Means and objectives of cyber security Implicit in the deﬁnitions above is that cyber security entails protection against an adversary or , possibly , against some other physical or random process .
The latter implies some overlap between the notions of safety and security , although it is arguably possible to have either without the other .
Within the security domain , if our modelling accounts for malice , it will necessarily encompass accidents and random processes .
Therefore , core to any consideration of security is the modelling of these adversaries : their motives for attack , the threats they pose and the capabilities they may utilise .
In considering those threats , cyber security is often expressed in terms of instituting a number of controls affecting people , process , and technology .
Some of these will focus on the prevention of bad outcomes , whereas others are better approached through detection and reaction .
Equally , security requires an analysis of vulnerabilities within the system under consideration : a ( hypothetical ) system without vulnerabilities would be impervious to all threats ; a highly vulnerable system placed in totally benign circumstances ( no threats ) would have no security incidents , either .
The intended use of security controls gives rise to its own questions about whether they are deployed appropriately , and whether they are effective : these belong to the domain of security assurance , which has processes and controls of its own .
These will involve residual risk analysis ( see below , and the Risk Management & Governance Knowledge Area ( Chapter 2 ) ) which includes an attempt to measure and quantify the presence of vulnerabilities .
1.3.2 Failures and Incidents When adversaries achieve their goal ( wholly or partially ) — when attacks succeed — the collection of security controls may be said to have failed .
Alternatively , we may say that insufﬁcient or ineffective controls were in place .
Operationally speaking , one or more failures may give rise to a security incident .
Typically such incidents may be described in terms of the harm to which they give rise : according to our deﬁnition of cyber security , these typically amount to harm from theft or damage of information , devices , services , or networks .
A recurrent theme in security analysis is that it is not sufﬁcient to deﬁne good security controls solely within a particular abstraction or frame of reference : it is necessary also to consider what may happen if an adversary chooses to ignore that abstraction or frame .
This arises , for example , in communication side channels , where an adversary may infer much from capturing radio frequency emissions from a cable , say , without needing to tap that cable physically .
Similar eavesdropping effects have been observed against cryptography implemented on smartcards : simple analysis of the power consumption of the processor as it addresses each bit in turn can be sufﬁcient to disclose the cryptographic key ( see Cryptography , Hardware Security and Software Security Knowledge Areas ) .
These problems occur at every level in the system design .
In software , the SQL injection attack arises ( see Software Security and Web & Mobile Security Knowledge Areas ) because a string of characters intended to be interpreted as a database entry is forced to become a database command .
Files holding secrets written by one application may give up those secrets when read by another , or by a general-purpose debugger or dump program .
Mathematical theories of reﬁnement ( and software development contracts ) explore the relationship of an ‘ abstract ’ expression of an algorithm and a more ‘ concrete ’ version which is implemented : but security properties proven of the one may not be true of the other ( for example , reducing uncertainty can increase information content and lead to the leak of information such as a cryptographic key ) , so great care must be taken in the construction of the theories .
‘ Black-box testing ’ relies on the same notion and , since it can not possibly test every input , may easily miss the particular combination of circumstances which — by accident or design — destroys the security of the program .
Operational security of a system may be predicated upon the operators following a particular procedure or avoiding particular dangerous circumstances : there is an assumption that if people are told in a professional context ( not ) to do something , then they will ( not ) do it .
These — and an endless array of other — security problems arise because it is necessary to think ( and design systems ) using abstractions .
Not only can no individual comprehend every detail of the operation of a networked computing system ( from the device physics upwards ) , even if they had the requisite knowledge they must work in abstractions in order to make progress and avoid being overwhelmed with detail .
But , for the majority of security controls , the abstraction is no more than a thinking tool : and so the adversary is able to disregard it entirely .
Since abstractions are usually built in layers ( and computing systems are usually explicitly designed in that way ) , this is sometimes known as the ‘ layer below ’ problem [ 7 ] because the adversary often attacks the layer below the one in which the abstraction deﬁning the control sits ( see , for example , the threats and attacks discussed in the Operating Systems & Virtualisation Knowledge Area ( Chapter 11 ) and the Hardware Security Knowledge Area ( Chapter 18 ) ) .
KA Introduction | October 2019 Page 7 The Cyber Security Body Of Knowledge www.cybok.org 1.3.3 Risk There is no limit in principle to the amount of effort or money that might be expended on security controls .
In order to balance these with the available resources and the harms and opportunities that might arise from emerging threats to security , a common over-arching approach to security analysis is a process of Risk Assessment — and selection of controls , a process of Risk Management .
As with any process of risk management , a key calculation relates to expected impact , being calculated from some estimate of likelihood of events that may lead to impact , and an estimate of the impact arising from those events .
The likelihood has two elements : the presence of vulnerabilities ( known or unknown—the latter not always being capable of being mitigated ) , and the nature of the threat .
The management response to the risk assessment may take many forms , including additional controls to reduce the impact or likelihood of a threat , accepting the risk , or transferring/sharing it with a third party ( e.g .
, insurance ) , or in some cases deciding not to proceed because all of these outcomes are unacceptable .
Security management encompasses all the management and security actions necessary to maintain the security of a system during its lifetime .
Important in this context , but outside of the scope of the CyBOK , are quality management practices .
Such practices are longestablished in industry , essentially requiring that all work follows documented processes , and that the processes provide metrics which are , in turn , reviewed and used to correct processes that are not ﬁt for purpose ( ‘ nonconformities ’ ) .
The analogy between quality management and security is not perfect because the threat environment is not static ; however , the trend is for security management standards such as ISO/IEC 27001 to embody standard quality management processes which are then specialised for security .
The primary specialisation is the periodic use of risk management ( see the Risk Management & Governance Knowledge Area ( Chapter 2 ) ) , which must also take account of the changing threat environment .
It is necessary to supplement periodic risk management with continuous measures of the effectiveness of the security processes .
For example , system patching and maintenance can be continuously reviewed via vulnerability scanning , logs relating to failed access attempts , user lock-outs or password resets can provide indicators of the usability of security features .
The functions within a security management system can be grouped into Physical , Personnel , Information Systems and Incident Management and are a mixture of standard IT system management functions and those that are speciﬁc to cyber security .
Physical security includes physical protection of the system , including access control , asset management and the handling and protection of data storage media .
These aspects are outside the scope of the CyBOK .
It also includes formal human-resource management elements such as the selection and vetting of staff , terms and conditions of acceptable usage for IT systems ( see the Law & Regulation Knowledge Area ( Chapter 3 ) ) and disciplinary sanctions for security breaches .
Management of the information system also involves standard IT functions such as backup and recovery , and the management of supplier relationships .
1.4 PRINCIPLES Sound thinking and good practice in security has been codiﬁed by a number of authors .
The principles they describe touch many different KAs , and taken together help to develop a holistic approach to the design , development , and deployment of secure systems .
These were proposed in the context of engineering secure multi-user operating systems supporting conﬁdentiality properties for use in government and military organisations .
This motivation does bias them in some ways , however they have also stood the test of time in being applicable to the design of security controls much more broadly .
The design of security controls should remain as simple as possible , to ensure high assurance .
Simpler designs are easier to reason about formally or informally , to argue correctness .
Further , simpler designs have simpler implementations that are easier to manually audit or verify for high assurance .
This principle underlies the notion of Trusted Computing Base ( TCB ) — namely the collection of all software and hardware components on which a security mechanism or policy relies .
It implies that the TCB of a system should remain small to ensure that it maintain the security properties expected .
Security controls need to deﬁne and enable operations that can positively be identiﬁed as being in accordance with a security policy , and reject all others .
In particular , Saltzer and Schroeder warn against mechanisms that determine access by attempting to identify and reject malicious behaviour .
Malicious behaviour , as it is under the control of the adversary and will therefore adapt , is difﬁcult to enumerate and identify exhaustively .
As a result basing controls on exclusion of detected violation , rather than inclusion of known good behaviour , is error prone .
It is notable that some modern security controls violate this principle including signature based anti-virus software and intrusion detection .
All operations on all objects in a system should be checked to ensure that they are in accordance with the security policy .
Such checks would usually involve ensuring that the subject that initiated the operation is authorised to perform it , presuming a robust mechanism for authentication .
The security of the control must not rely on the secrecy of how it operates , but only on well speciﬁed secrets or passwords .
This principle underpins cyber security as a ﬁeld of open study : it allows scholars , engineers , auditors , and regulators to examine how security controls operate to ensure their correctness , or identify ﬂaws , without undermining their security .
The opposite approach , often called ‘ security by obscurity ’ , is fragile as it restricts who may audit a security control , and is ineffective against insider threats or controls that can be reverse engineered .
Security controls that rely on multiple subjects to authorise an operation , provide higher assurance than those relying on a single subject .
This principle is embodied in traditional banking systems , and carries forward to cyber security controls .
However , while it is usually the case that increasing the number of authorities involved in authorising an operation increases assurance around integrity properties , it usually also decreases assurance around availability properties .
The principle also has limits , relating to over diluting responsibility leading to a ‘ tragedy of the security commons ’ in which no authority has incentives to invest in security assuming the others will .
Subjects and the operations they perform in a system should be performed using the fewest possible privileges .
For example , if an operation needs to only read some information , it should not also be granted the privileges to write or delete this information .
Granting the minimum set of privileges ensures that , if the subject is corrupt or software incorrect , the damage they may do to the security properties of the system is diminished .
Deﬁning security architectures heavily relies on this principle , and consists of separating large systems into components , each with the least privileges possible — to ensure that partial compromises can not affect , or have a minimal effect on , the overall security properties of a whole system .
It is preferable to minimise sharing of resources and system mechanisms between different parties .
This principle is heavily inﬂuenced by the context of engineering secure multi-user systems .
are vectors for potential leaks of conﬁdential information from one user to the other , as well as potential interference from one user into the operations of another .
Yet , the principle has limits when it comes to using shared infrastructures ( such as the Internet ) , or shared computing resources ( such as multi-user operating systems , that naturally share CPUs and other resources ) .
The security control should be naturally usable so that users ‘ routinely and automatically ’ apply the protection .
Saltzer and Schroeder , speciﬁcally state that ‘ to the extent that the user ’ s mental image of his protection goals matches the mechanisms he must use , mistakes will be minimised ’ .
Saltzer and Schroeder also provide two further principles , but warn that those are only imperfectly applicable to cyber security controls : • Work factor .
Good security controls require more resources to circumvent than those available to the adversary .
In some cases , such as the cost of brute forcing a key , the work factor may be computed and designers can be assured that adversaries can not be sufﬁciently endowed to try them all .
For other controls , however , this work factor is harder to compute accurately .
For example , it is hard to estimate the cost of a corrupt KA Introduction | October 2019 Page 10 The Cyber Security Body Of Knowledge www.cybok.org insider , or the cost of ﬁnding a bug in software .
It is sometimes suggested that reliable records or logs , that allow detection of a compromise , may be used instead of controls that prevent a compromise .
Most systems do log security events , and security operations heavily rely on such reliable logs to detect intrusions .
Kerchoff highlights that cryptographic systems must be practically secure , without requiring the secrecy of how they operate ( open design ) .
He also highlights that keys should be short and memorable , the equipment must be easy to use , and applicable to telecommunications — all of which relate to the psychological acceptability of the designs .
They incorporate and extend the principles from Saltzer and Schroeder .
As such those principles speciﬁcally refer to security architecture , speciﬁc controls , as well as engineering process management .
A number of the NIST principles map directly to those by Saltzer and Schroeder , such as Least Common Mechanism , Efﬁciently Mediated Access , Minimised Sharing , Minimised Security Elements , Reduced Complexity , Least Privilege , Secure Defaults and Predicate Permission , and Acceptable Security .
Notably , new principles deal with the increased complexity of modern computing systems and emphasise clean modular design , i.e .
Other principles recognise that not all components in a secure system may operate at the same level of assurance , and call for those to beneﬁt from a Hierarchical Trust structure , in which the security failure of some components does not endanger all properties in the system .
The principle of Inverse Modiﬁcation Threshold states that those components that are the most critical to security , should also be the most protected against unauthorised modiﬁcation or tampering .
Hierarchical protection states that least critical security components need not be protected from more critical ones .
The NIST framework also recognises that modern systems are interconnected , and provides principles of how to secure them .
These should be networked using Trusted Communication Channels .
They should enjoy Secure Distributed Composition , meaning that if two systems that enforce the same policy are composed , their composition should also at least enforce the same policy .
Finally , the principle of Self-Reliant Trustworthiness states that a secure system should remain secure even if disconnected from other remote components .
The NIST principles expand on what types of security mechanisms are acceptable for realworld systems .
In particular the principles of Economic Security , Performance Security , Human Factored Security , and Acceptable Security state that security controls should not be overly expensive , overly degrade performance , or be unusable or otherwise unacceptable to users .
This is a recognition that security controls support functional properties of systems KA Introduction | October 2019 Page 11 The Cyber Security Body Of Knowledge www.cybok.org and are not a goal in themselves .
Besides principles , NIST also outlines three key security architecture strategies .
The Reference Monitor Concept is an abstract control that is sufﬁcient to enforce the security properties of a system .
Defence in Depth describes a security architecture composed on multiple overlapping controls .
Isolation is a strategy by which different components are physically or logically separated to minimise interference or information leakage .
Both NIST , as well as Saltzer and Schroeder , highlight that principles provide guidance only , and need to be applied with skill to speciﬁc problems at hand to design secure architectures and controls .
Deviation from a principle does not automatically lead to any problems , but such deviations need to be identiﬁed to ensure that any issues that may arise have been mitigated appropriately .
1.4.3 Latent Design Conditions As more and more cyber-physical systems are connected to other systems and the Internet , the inherent complexity emerging from such large-scale connectivity and the safety critical nature of some of the cyber-physical systems means other principles also become highly relevant .
One such principle is that of Latent Design Conditions from research in the safetycritical systems domain by James Reason [ 11 ] .
They often remain hidden ( or unconsidered ) and only come to the fore when certain events or settings align — in the case of cyber-physical systems security vulnerabilities being exposed as they become connected to other systems or the Internet .
Reason refers to this as the Swiss Cheese model where different holes in the slices align .
The key point to note is that we can no longer just consider information loss as a potential consequence of cyber security breaches — but must also consider safety implications .
Furthermore , security by design is not always a possibility and , as legacy systems become connected to other networked environments , one must consider the latent ( insecure ) design conditions that may be manifested and how to mitigate their impact .
1.4.4 The Precautionary Principle As the participatory data economy leads to a range of innovative products and services , there are also growing concerns about privacy and potential misuse of data as has been highlighted by recent cases of interference in democratic processes .
As such the Precautionary Principle — reﬂecting on the potential harmful effect of design choices before technological innovations are put into large-scale deployment — also becomes relevant .
Designers must consider the security and privacy implications of their choices from conception , through to modelling , implementation , maintenance , evolution and also decommissioning of large-scale connected systems and infrastructures on which society increasingly relies .
Function creep as the system evolves over its lifetime and its impact on the society-at-large must also be considered [ 12 ] .
KA Introduction | October 2019 Page 12 The Cyber Security Body Of Knowledge www.cybok.org 1.5 CROSSCUTTING THEMES A number of topics and themes recur across various KAs — implicitly or explicitly — and provide a context or uniﬁcation of ideas across those KAs which cuts across the structure chosen for the CyBOK .
In a different decomposition of the CyBOK they might have been KAs in their own right .
These are an important part of the body of knowledge , and so we document here the most substantial of them .
1.5.1 Security Economics Economics of information security is a synthesis between computer and social science .
For example , Van Eeten and Bauer studied the incentives of legitimate market players — such as Internet Service Providers ( ISPs ) and software vendors — when confronted with malware1 and how the actions driven by such incentives lead to optimal or sub-optimal security for the wider interconnected system .
Security economics is , therefore , of high relevance across the various attacks and countermeasures discussed within the different KAs within CyBOK .
It also plays a key role in understanding the cost of security to legitimate users of the system and to the cybercriminals — the strength of such a socio-technical approach is its acknowledgement that security is very much a human problem , and the cost versus beneﬁts trade-offs are key to increasing our understanding of the decisions of defenders and attackers to respectively secure their systems or optimise attacks [ 13 ] .
1.5.2 Veriﬁcation and Formal Methods Human frailty means that ﬂaws frequently arise in system design or coding , and these often give rise to security vulnerabilities .
The Software Engineering discipline has expended much effort in attempting to minimise the introduction of such faults , and to aid their early detection when they arise .
By its nature , such testing can never be complete or exhaustive on any realistic system , and it will necessarily be poor at ﬁnding deliberate ﬂaws or systemic design failures .
Approaches to veriﬁcation and modelling seek to reason about designs and implementations in order to prove mathematically that they have the required security properties .
Formal methods are approaches to modelling and veriﬁcation based on the use of formal 1 http : //www.oecd.org/internet/ieconomy/40722462.pdf KA Introduction | October 2019 Page 13 The Cyber Security Body Of Knowledge www.cybok.org languages , logic and mathematics to express system and software speciﬁcations , and to model designs of protocols and systems .
For security modelling and veriﬁcation the adversary model is also incorporated into the reasoning , so that designs can be veriﬁed with respect to their security requirements in the context of particular classes of threat .
Rigorous proofs establish that no attack of a particular class is possible , establishing security of the design against particular kinds of adversary .
The computational modelling approach [ 22 ] is close to the real system : it is a formal methodology at a more fundamental mathematical level , where messages are bitstrings , cryptographic functions are deﬁned as functions on bitstrings , system participants are generally interactive Turing machines , and security parameters give asymptotic metrics to this methodology : the length of keys , complexity of algorithms , or measure of probabilities , vary with the security parameter .
The adversary is considered to be a probabilistic polynomial time Turing machine .
Precise deﬁnitions of cryptographic functions can be captured and analysed within the model .
Security requirements are expressed as properties on the model including the adversary , and a security property is generally considered to hold if the probability that it does not hold is negligible in the security parameter .
Formal modelling has been used within the ﬁeld of security for some decades , across many of the KAs classiﬁed in CyBOK under Systems Security , Infrastructure Security , and Software & Platform Security .
For example , in the area of access control , the Bell-LaPadula model [ 23 ] provides an abstract model of the rules determining whether a subject with a certain security clearance should have a particular kind of access to an object with a given security classiﬁcation .
The aim of this model is to prevent data declassiﬁcation ; later work generalized this to methods for preventing certain information ﬂows .
Formal methods enable key security properties to be expressed and proven in the formal model .
Non-interference properties have been formalised [ 26 ] in terms of executions using transition systems , and system descriptions with transition system semantics can be evaluated against such properties .
The symbolic modelling approach is more abstract than the computational approach , and has been applied in a variety of ﬂavours to the modelling and analysis of security protocols — sequences of interactions between agents to achieve a security goal such as authentication or key-exchange .
Logic-based approaches such as the BAN logic [ 27 ] provide a language for expressing requirements such as conﬁdentiality and authentication , facts around the sending and receiving of protocol messages , and inference rules to enable reasoning about correctness .
Security properties are expressed in terms of what must be true for every execution in the model , e.g .
, if Bob believes at the end of a protocol run that he shares a session key with Alice , then the adversary is not also in possession of that session key .
Although the foundations of formal approaches are mature , the challenge has been in making them practical .
The application of formal approaches requires the careful management of intricate detail , which in practice requires tool support to enable mechanised veriﬁcation and to check proofs .
Veriﬁcation using the computational modelling approaches have been more mathematical in nature , though tools such as CryptoVerif [ 35 ] and EasyCrypt [ 36 ] have now been developed to support computational proofs .
The symbolic and computational approaches may be used together : an attack in a symbolic model will typically give rise to an attack in the computational model , so it is valuable to carry out a symbolic analysis of a system ﬁrst in order to check for and design out any identiﬁed attacks .
Once a symbolic model is veriﬁed , then some additional work is needed to establish security in the computational model .
This can either be carried out directly , or through the application of general techniques such as computational soundness [ 37 ] which give conditions for symbolic results to apply to the computational model .
These tools are now becoming strong enough to verify deployed protocols such as TLS1.3 , which has been veriﬁed using a combination of both approaches [ 38 ] , but they still require expert guidance .
Further development of the tool support is an active research area .
1.5.3 Security Architecture and Lifecycle The word ‘ architecture ’ is used at all levels of detail within a system ; here we are concerned with the high-level design of a system from a security perspective , in particular how the primary security controls are motivated and positioned within the system .
This , in turn , is bound up with an understanding of the systems lifecycle , from conception to decommissioning .
Within this , the secure software lifecycle is crucial ( the subject of the Secure Software Lifecycle Knowledge Area ) .
The fundamental design decision is how a system is compartmentalised — how users , data , and services are organised to ensure that the highest risk potential interactions are protected by the simplest and most self-contained security mechanisms ( see Section 1.4 ) .
For example , a network may be divided into front-ofﬁce/back-ofﬁce compartments by a network router or ﬁrewall that permits no inward connections from the front to the back .
Such a mechanism is simpler and more robust than one that uses access controls to separate the two functions in a shared network .
The ﬁrst step is to review the proposed use of the system .
The business processes to be supported should identify the interactions between the users , data or services in the system .
Potential high risk interactions between users ( see the Adversarial Behaviours Knowledge Area ( Chapter 7 ) and data should then be identiﬁed with an outline risk assessment ( see the Risk Management & Governance Knowledge Area ( Chapter 2 ) ) which will also need to take account of external requirements such as compliance ( see the Law & Regulation Knowledge Area ( Chapter 3 ) ) and contractual obligations .
If users with a legitimate need to access speciﬁc data items also pose a high risk to those items , or if any user has unconstrained authority to effect an undesired security outcome , the business process itself must be revised .
The next step is to group users and data into broad categories using role-access requirements , together with formal data classiﬁcation and user clearance .
Such categories are potential system compartments , for example , Internet users and public data , or engineers and design data .
Compartments should ensure that the highest risk user-data interactions cross compartment boundaries , and that common user-data interactions do not .
CyBOK provides important foundation knowledge in these areas , but neither this nor risk assessment are sufﬁcient to motivate the detailed implementation of infrastructure ; they need to be complemented by current good practice .
Orthogonal to these concerns are a number of topics which relate to the context of the system development and operation .
It is increasingly clear that a code of conduct , as prescribed by many professional bodies , offers a valuable framework for system designers and those who explore weaknesses and vulnerabilities within such systems .
Initiatives around responsible research and innovation are gaining ground .
The discovery of vulnerabilities necessitates a disclosure policy — and the parameters of responsible disclosure have prompted much debate , together with the role of this in a security equities process .
The former term is often applied to detailed practices in software engineering , such as input checking , to avoid buffer overﬂows and the like ( see the Secure Software Lifecycle Knowledge Area ( Chapter 16 ) ) .
More generally , consideration of security throughout the lifecycle , including in the default conﬁguration ‘ out of the box ’ ( although not much software is delivered in boxes these days ) , demonstrably leads to less insecurity in deployed systems .
We invite the readers to read the detailed descriptions captured in the 19 Knowledge Areas that follow and utilise the methods , tools , techniques and approaches discussed therein when tackling the challenges of cyber security in the increasingly connected digital world that we inhabit .
The authors thank Erik van de Sandt for permission to use text from his PhD thesis [ 19 ] in the section on Security Economics .
KA Introduction | October 2019 Page 16 I Human , Organisational & Regulatory Aspects 17 Chapter 2 Risk Management and Governance Pete Burnap Cardiff University 19 The Cyber Security Body Of Knowledge www.cybok.org 2.1 INTRODUCTION This Knowledge Area will explain the fundamental principles of cyber risk assessment and management and their role in risk governance , expanding on these to cover the knowledge required to gain a working understanding of the topic and its sub-areas .
We begin by discussing the relationship between everyday risk and why this is important in today ’ s interconnected digital world .
We explain why , as humans , we need effective risk assessment and management principles to support the capture and communication of factors that may impact our values .
We then move on to describe different perspectives on cyber risk assessment – from individual assets , to whole-system goals and objectives .
We unpick some of the major risk assessment methods and highlight their main uses and limitations , as well as providing pointers to more detailed information .
Security metrics are an ongoing topic of debate in the risk assessment and management domain : which system features to measure for risk , how to measure risk , and why measure risk at all ?
These questions are framed in the context of existing literature on this topic .
This links into risk governance , which explains why effective governance is important to uphold cyber security and some of the social and cultural factors that are essential to consider when developing governance frameworks .
Almost all systems still include a human element of control , which must be considered from the outset .
Finally , even with well deﬁned and executed risk assessment and management plans , it is still possible that a risk will turn into reality .
We discuss the importance of incident response and its link to the risk governance process .
From a child making a decision to jump out of a tree to an investment decision by the CEO of a multi-billion dollar company , we all make decisions that potentially impact us as individuals , and impact our broader social networks and surroundings .
Renn ’ s working deﬁnition of risk is the possibility that human actions or events lead to consequences that have an impact on what humans value .
This fundamentally grounds risk in human value , which applies to both the child and CEO examples .
It also applies to cyber security contexts in a world where people and technology are intrinsically linked .
The failure of one to support the success of the other can lead to social , economic and technical disaster .
The working deﬁnition of impact on values raises a further question of how to deﬁne the value and capture indicators that can be used to measure and manage the risk .
Renn deﬁnes three basic abstract elements required for this : outcomes that have an impact on what humans value , possibility of occurrence ( uncertainty ) , and a formula to combine both elements .
These elements are at the core of most risk assessment methods .
Such methods aim to provide a structured approach to capturing the entities of value and the likelihood of unwanted outcomes affecting the entities , while also bearing in mind that even something with very low probability may be realised and may have signiﬁcant impact on a value .
We , therefore , use Renn ’ s working deﬁnition of risk for discussion in this KA in the context of cyber risk .
KA Risk Management and Governance | October 2019 Page 20 The Cyber Security Body Of Knowledge www.cybok.org A key challenge with risk assessment and management is making assumptions explicit and ﬁnding the balance between subjective risk perceptions and objective evidence .
Risk assessment is , therefore , a process of collating observations and perceptions of the world that can be justiﬁed by logical reasoning or comparisons with actual outcomes [ 41 ] .
Risk management , on the other hand , is the process of developing and evaluating options to address the risks in a manner that is agreeable to people whose values may be impacted , bearing in mind agreement on how to address risk may involve a spectrum of ( in ) tolerance – from acceptance to rejection .
Risk Governance is an overarching set of ongoing processes and principles that aims to ensure an awareness and education of the risks faced when certain actions occur , and to instil a sense of responsibility and accountability to all involved in managing it .
This Knowledge Area explores all these topics and provides insights into risk assessment , management and governance from a cyber security science perspective that is accessible to individuals , SMEs and large organisations alike .
Identiﬁcation relates to the establishment of events and subsequent outcomes , while estimation is related to the relative strength of the outcome .
The fundamental concept of risk assessment is to use analytic and structured processes to capture information , perceptions and evidence relating what is at stake , the potential for desirable and undesirable events , and a measure of the likely outcomes and impact .
Without any of this information we have no basis from which to understand our exposure to threats nor devise a plan to manage them .
An often overlooked part of the risk assessment process is concern assessment .
This stems from public risk perception literature but is also important for cyber security risk assessment as we will discuss later in the document .
In addition to the more evidential , scientiﬁc aspects of risk , concern assessment includes wider stakeholder perceptions of : hazards , repercussions of risk effects , fear and dread , personal or institutional control over risk management and trust in the risk managers .
The risk management process involves reviewing the information collected as part of the risk ( and concern ) assessments .
This information forms the basis of decisions leading to three outcomes for each perceived risk [ 41 ] : • Intolerable : the aspect of the system at risk needs to be abandoned or replaced , or if not possible , vulnerabilities need to be reduced and exposure limited .
Furthermore , risk can also be used to pursue opportunities ( also known as ‘ upside risk ’ ) , thus the outcome may be to accept and embrace the risk rather than reduce it .
Beyond this decision framework Renn deﬁnes four types of risk that require different risk management plans [ 41 ] .
Statistics and relevant data are provided , desirable outcomes and limits of acceptability are deﬁned , and risk reduction measures are implemented and enforced .
Renn gives examples of car accidents and safety devices .
Scientiﬁc dissent such as drug treatment effects or climate change are examples of this .
A precautionary approach should be taken with a continual and managed approach to system development whereby negative side effects can be contained and rolled-back .
Resilience to uncertain outcomes is key here .
, different viewpoints exist or lack of agreement on management controls ) , risk management needs to address the causes for the differing views .
Renn uses the example of genetically modiﬁed foods where well-being concerns conﬂict with sustainability options .
In this instance , risk management must enable participatory decision-making , with discursive measures aiming to reduce the ambiguity to a number of manageable options that can be further assessed and evaluated .
Without effective consideration of the acceptability of risk and an appropriate risk reduction plan , it is likely that the response to adverse outcomes will be disorganised , ineffective , and likely lead to further spreading of undesirable outcomes .
Effective risk management through structured assessment methods is particularly important because , although our working deﬁnition of risk is grounded in consequences of interest to people , we ( as a society ) are not very good at assessing this risk .
, nuclear accidents ) are ranked highest risk by lay people , but much lower by domain experts who understand the evidence relating to safety limitations and controls for such systems .
Expert risk ranking tends to follow KA Risk Management and Governance | October 2019 Page 22 The Cyber Security Body Of Knowledge www.cybok.org expected or recorded undesirable outcomes such as deaths , while lay people are inﬂuenced more by their intuitive judgment ( a nuclear accident could impact my whole family ) .
This is also why concern assessment is important in the risk management process alongside risk assessment .
For instance , we feel safe walking down a street next to our house but on edge when arriving in a new city .
As a society , we rarely study statistics when making decisions ; they are based on perceptions of exposure to threat , our perceived control over threats , and their possible impact .
Risk assessment helps us capture quantitative and qualitative aspects of the world that enable us to put a realistic estimate of how certain we can be that adverse events will come to pass , and how they will impact on what we value most .
We need to capture our goals , understand what could lead to the failure to achieve them , and put processes in place to align realistic measures to reduce harms inﬂicted upon our objectives .
When done well , risk assessment and management enables decision makers , who are responsible , to ensure that the system operates to achieve the desired goals as deﬁned by its stakeholders .
It can also ensure the system is not manipulated ( intentionally or otherwise ) to produce undesired outcomes , as well as having processes in place that minimise the impact should undesirable outcomes occur .
Risk assessment and management is also about presenting information in a transparent , understandable and easily interpreted way to different audiences , so that accountable stakeholders are aware of the risks , how they are being managed , who is responsible for managing them , and are in agreement on what is the acceptable limit of risk exposure .
This is absolutely crucial to successfully managing risk because , if the risks are not presented clearly to decision makers ( be they technical , social , economic or otherwise ) , the impact of not managing them will be overlooked , and the system will remain exposed .
Likewise , if the purpose of risk management is not made clear to the people at the operational level , alongside their own responsibilities and accountability for risk impacts , they will not buy in to the risk management plan and the system will remain exposed .
, civil society ) are not heard or there is lack of conﬁdence in the risk management plan , there could be widespread rejection of the planned system being proposed .
As important as it is to convey risks clearly to stakeholders , it is equally as important to stress that risks can not always be removed .
There is likely to be some residual risk to the things we value , so discussions must be held between decision makers and those who are involved with the operations of a system .
Ultimately , decision makers , who will be held to account for failure to manage risk , will determine the level of risk tolerance – whether risk is accepted , avoided , mitigated , shared , or transferred .
However , it is possible that wider stakeholders , such as those involved with system operations , may have differing views on how to manage risk , given they are likely to have different values they are trying to protect .
For people working within the system it may be speed of process or ease of carrying out daily tasks .
The purpose of risk assessment and management is to communicate these values and ensure decisions are taken to minimise the risks to an agreed set of values by managing them appropriately , while KA Risk Management and Governance | October 2019 Page 23 The Cyber Security Body Of Knowledge www.cybok.org maximising ‘ buy in ’ to the risk management process .
In the broader health and safety risk context , this concept relates to the notion of ALARP ( as low as reasonably practicable ) [ 44 ] – being able to demonstrate that signiﬁcant efforts and computation have been made to calculate the balance between risk acceptance and mitigation , in the favour of security and safety .
Again it is important to highlight here that concern assessment is an important part of risk assessment to ensure the risk assessment policy ( the agreed approach to risk assessment ) is informed by those responsible for , and impacted by risk , and those who are required to act in a way that upholds the management plan day-to-day .
Crucially , it must be recognised that the impact of single events can often extend beyond direct harms and spread far wider into supply chains .
As Slovic puts it , the results of an event act like ripples from a stone dropped into a pond , ﬁrst directly within the company or system in which it occurred , and then into sub-systems and interdependent companies and components [ 40 ] .
One of the major drivers for risk assessment and management is to demonstrate compliance .
This can be a result of the need to have audited compliance approval from international standards bodies in order to gain commercial contracts ; to comply with legal or regulatory demands ( e.g .
This can sometimes lead to ‘ tick-box ’ risk assessment whereby the outcome is less focused on managing the risk , and more about achieving compliance .
This can result in a false sense of security and leave the organisation exposed to risks .
These examples focus on managing risk of failing compliance with various policy positions , and as a result , they may neglect the broader focus on impact on values held by wider organisational , societal or economic stakeholders .
The context and scope of risk management must take this broader outcomes-view in order to be a useful and valuable exercise that improves preparedness and resilience to adverse outcomes .
It is something that , when done well , has the potential to signiﬁcantly improve the resilience of a system .
When done badly ( or not at all ) it can lead to confusion , reputational damage , and serious impact on system functionality .
It is a process that is sometimes perceived to be unimportant before one needs it , but critical for business continuity in a time of crisis .
Throughout the process of risk assessment we must remain aware that risk perception varies signiﬁcantly based on a variety of factors , and that despite objective evidence , it will not change .
To use an example from [ 40 ] , providing evidence that the annual risk from living next to a nuclear power plant is equivalent to the risk of riding an extra 3 miles in an automobile , does not necessarily reduce the perception of risk given the differences surrounding the general perception of the different scenarios .
Intuitively , communication and a respect for qualitative and quantitative measures of risk assessment are core to its practice .
There will always be a need for subjective human judgment to determine relevance and management plans [ 50 ] , which in itself comes with its own limitations such as lack of expert knowledge and cognitive bias [ 51 ] .
[ 52 ] The introductory sections have made the case for risk assessment and management more generally , but the main focus of this document is to frame risk assessment and management in a cyber security context .
Digital technology is becoming evermore pervasive and underpins almost every facet of our daily lives .
Cyber security risk assessment and management is , therefore , a fundamental special case that everyone living and working within the digital domain should understand and be a participant in it .
There are a number of global standards that aim to formalise and provide a common framework for cyber risk assessment and management , and , in this section , we will study some of them .
We will begin with high level deﬁnitions of some of the foremost positions on risk .
Importantly , the NCSC is clear that there is no one-size-ﬁts-all for risk assessment and management .
Indeed conducting risk assessment and management as a tick-box exercise produces a false sense of security , which potentially increases the Vulnerability of the people impacted by risk because they are not properly prepared .
Cyber security is such a rapidly evolving domain that we must accept that we can not be fully cyber secure .
Risk assessment and developing mitigation principles to manage risk is only likely to be effective where a coordinated and well communicated governance policy is put in place within the system being managed .
• Decisionistic : where risk evaluation and policy are developed using inputs beyond science alone .
There is a ﬁne balance between the knowledge and ﬁndings of scientiﬁc experts , and perceptions of the lay public .
While the technocratic approach may seem logical to some risk owners who work on the basis of reasoning using evidence , it is absolutely crucial for effective risk governance to include the wider stakeholder view .
These factors are not particularly scientiﬁc , structured or evidence-based but , as noted by Fischoff et al .
[ 59 ] , such forms of deﬁning probabilities are countered by the strength of belief people have about the likelihood of an undesirable event impacting their own values .
Ultimately , from a governance perspective , the more inclusive and transparent the policy development , the more likely the support and buy-in from the wider stakeholder group – including lay people as well as operational staff – for the risk management policies and principles .
There are several elements that are key to successful risk governance .
Like much of the risk assessment process , there is no one-size solution for all endeavours .
Cyber risk is as important as health and safety , ﬁnancial processes , and human resources .
When travelling overseas , employees will always consult the ﬁnancial constraints and processes for travel .
Cyber security should be thought of in the same way – a clear set of processes that reduce the risk of harm to individuals and the business .
Everyone involved in the daily running of the system in question must understand that , for security to be effective , it must be part of everyday operational culture .
The cyber risk governance approach is key to this cultural adoption .
2.5.2 The human factor and risk communication Sasse and Flechais [ 60 ] identiﬁed human factors that can impact security governance , including people : having problems using security tools correctly ; not understanding the importance of data , software , and systems for their organisation ; not believing that the assets are at risk ( i.e .
, that they would be attacked ) ; or not understanding that their behaviour puts the system at risk .
This highlights that risk can not be mitigated with technology alone , and that concern assessment is important .
If risk perception is such that there is a widely held view that people do not believe their assets will be attacked ( as noted by [ 60 ] ) , despite statistics showing cyber security breaches are on the rise year-on-year , then there is likely to be a problem with the cyber security culture in the organisation .
Educating people within an organisation is vital KA Risk Management and Governance | October 2019 Page 26 The Cyber Security Body Of Knowledge www.cybok.org to ensuring cultural adoption of the principles deﬁned in the risk management plan and associated security governance policy .
People will generally follow the path of least resistance to get a job done , or seek the path of highest reward .
As Sasse and Flechais note , people fail to follow the required security behaviour for one of two reasons : ( 1 ) they are unable to behave as required ( one example being that it is not technically possible to do so ; another being that the security procedures and policies available to them are large , difﬁcult to digest , or unclear ) , ( 2 ) they do not want to behave in the way required ( an example of this may be that they ﬁnd it easier to work around the proposed low-risk but time consuming policy ; another being that they disagree with the proposed policy ) .
Weirich and Sasse studied compliance with password rules as an example of compliance with security policy [ 61 ] and found that a lack of compliance was associated with people not believing that they were personally at risk and or that they would be held accountable for failure to follow security rules .
There is thus a need to ensure a sense of responsibility and process for accountability , should there be a breach of policy .
This must , of course , be mindful of legal and ethical implications , as well as the cultural issues around breaching rules , which is a balancing act .
Risk communication , therefore , plays an important role in governance [ 62 ] [ 39 ] including aspects , such as : • Education : particularly around risk awareness and day-to-day handling of risks , including risk and concern assessment and management ; • Training and inducement of behaviour change : taking the awareness provided by education and changing internal practices and processes to adhere to security policy ; • Creation of conﬁdence : both around organisational risk management and key individuals – develop trust over time , and maintain this through strong performance and handling of risks .
• Involvement : particularly in the risk decision-making process – giving stakeholders an opportunity to take part in risk and concern assessment and partake in conﬂict resolution .
Finally , leading by example is of paramount importance in the risk communication process .
People are likely to be resentful if it appears that senior management are not abiding by the same risk management rules and principles .
Visible senior engagement in an important cultural aspect of risk communication .
He proposes the need to change the way in which we think about accountability so that it becomes compatible with learning and improving the security posture of an organisation .
It is important that people feel able to report issues and concerns , particularly if they think they may be at fault .
Accountability needs to be intrinsically linked to helping the organisation , without concern of being stigmatised and penalised .
There is often an issue where those responsible for security governance have limited awareness and understanding of what it means to practise it in the operational world .
In these cases there needs to be an awareness that there is possibly no clear right or wrong , and that poorly thought-out processes and practices are likely to have been behind the security breach , as opposed to malicious human behaviour .
If this is the case , these need to be addressed and the person at fault needs to feel supported by their peers and free of anxiety .
One suggestion Dekker KA Risk Management and Governance | October 2019 Page 27 The Cyber Security Body Of Knowledge www.cybok.org makes is to have an independent team to handle security breach reports so people do not have to go through their line manager .
If people are aware of the pathways and outcomes following security breaches it will reduce anxiety about what will happen and , therefore , lead to a more open security culture .
Given that security awareness and education is such an important factor in effective governance , Jaquith [ 64 ] links security awareness with security metrics through a range of questions that may be considered as useful pointers for improving security culture : • Are employees acknowledging their security responsibilities as users of information systems ?
• Are employees receiving training at intervals consistent with company policies ?
• Do security staff members possess sufﬁcient skills and professional certiﬁcations ?
• Are security staff members acquiring new skills at rates consistent with management objectives ?
• Are security awareness and training efforts leading to measurable results ?
( Metrics : By business unit or ofﬁce , correlation of password strength with the elapsed time since training classes ; by business unit or ofﬁce , correlation of tailgating rate with training latency ) .
Metrics may be a crude way to capture adherence to security policy , but when linked to questions that are related to the initial risk assessment , they can provide an objective and measurable way to continually monitor and report on the security of a system to the decision makers , as well as those responsible for its governance in an understandable and meaningful way .
However , it is worth noting the complexity of metrics here with the use of the term ‘ acknowledging ’ in the ﬁrst bullet point .
It does not necessarily mean the person will acknowledge their responsibilities merely by completing awareness training .
This reinforces the points already made about the importance of human factors and security culture , and the following section on enacting security policy .
2.5.4 Enacting Security Policy Overall , effective cyber risk governance will be underpinned by a clear and enactable security policy .
This section focuses on the elements of risk assessment and management that are relevant to achieving this .
From the initial phase of the risk assessment there should be a clear focus on the purpose and scope of the risk assessment exercise .
During this phase , for more complex systems or whole system security , there should be a focus on identifying the objectives and goals of the system .
These should be achievable with clear links from objectives to the processes that underpin them .
Risks should be articulated as clear statements that capture the interdependencies between the vulnerabilities , threats , likelihoods and outcomes ( e.g .
Risk management decisions will be taken to mitigate threats identiﬁed for these processes , and these should be linked to the security policy , which will clearly articulate the required actions and activities taken ( and by whom ) , often along with a clear timeline , to mitigate the risks .
This should also include what is expected to happen as a consequence of this risk becoming a reality .
Often heat maps and risk matrices are used to visualise the risks .
Attention should , therefore , be paid to the purpose of the visualisation and the accuracy of the evidence it represents for the goal of developing security policy decisions .
As discussed , people fail to follow the required security behaviour because they are unable to behave as required , or they do not want to behave in the way required [ 60 ] .
A set of rules dictating how security risk management should operate will almost certainly fail unless the necessary actions are seen as linked to broader organisational governance , and therefore security policy , in the same way HR and ﬁnance policy requires .
People must be enabled to operate in a secure way and not be the subject of a blame culture when things fail .
It is highly likely that there will be security breaches , but the majority of these will not be intentional .
Therefore , the security policy must be reﬂective and reactive to issues , responding to the Just Culture agenda and creating a policy of accountability for learning , and using mistakes to reﬁne the security policy and underpinning processes – not blame and penalise people .
Security education should be a formal part of all employees ’ continual professional development , with reinforced messaging around why cyber security is important to the organisation , and the employee ’ s role and duties within this .
Principles of risk communication are an important aspect of the human factor in security education .
We have discussed the need for credible and trustworthy narratives and stakeholder engagement in the risk management KA Risk Management and Governance | October 2019 Page 29 The Cyber Security Body Of Knowledge www.cybok.org process .
There are additional principles to consider such as early and frequent communication , tailoring the message to the audience , pretesting the message and considering existing risk perceptions that should be part of the planning around security education .
Extensive discussion of such risk communication principles that are particularly relevant for messaging regarding risk can be found in [ 67 ] .
Part of the ﬁnal risk assessment and management outcomes should be a list of accepted risks with associated owners who have oversight for the organisational goals and assets underpinning the processes at risk .
These individuals should be tightly coupled with review activity and should be clearly identiﬁable as responsible and accountable for risk management .
Figure 2.1 summarises the core elements of the risk governance process as discussed so far .
The governance process is iterative , always seeking awareness of new problems and evolving threats , and continually reﬂecting on best practice to manage new risks .
A major difference between the two is that component-driven approaches tend to focus on the speciﬁc risk to an individual component ( e.g .
As illustrated in Figure 2.2 , the goals and purposes of the system can be considered at the higher level .
These are important to design into the system and , if omitted , lead to having to retroﬁt cyber security into a system that has already been deployed .
The lower levels then consider capabilities and functionality needed to achieve the overarching goals .
System-driven approaches can help to better understand the complexity between sub-components and their components .
These may include people , technology , and organisational processes for which the interactions and dependencies are non-trivial .
The NCSC guidance provides a summary table ( reproduced here as Figure 2.3 ) that is helpful in guiding the selection of component-driven or system-driven methods based on the kind of risk management problem being addressed .
The major differentiator is that the component view is individual asset-based , where complexity is well-understood and expected functionality is clear .
The system view supports an analysis of risk in situations of greater complexity , before physical function is agreed and implemented , and to support discussions by key stakeholders on what the system should and should not do .
These discussions are crucial in ﬁnding the balance between component-level and system-level failure and how best to manage the risk .
Systems-level risk is likely to be more important to higher-level managers who have a vested interest in the strategic direction of the system .
For them a component further down the value/supply chain may not be perceived to be important , while for the operational employee it ’ s the number one risk .
The challenge is to work with both perspectives to develop a representation of risk and an associated risk management policy enacted by all parties .
2.6.2 Elements of Risk While it is useful to avoid creating a universal deﬁnition of risk , to support inclusivity of different views and perspectives , it is important to have agreed deﬁnitions of the concepts that underpin risk assessment and management .
This ensures a common language throughout the process and avoids talking at cross purposes .
There are four concepts that are core to a risk assessment in most models – vulnerability , threat , likelihood and impact .
A Vulnerability is something open to attack or misuse that could lead to an undesirable outcome .
If the vulnerability were to be exploited it could lead to an impact on a process or system .
System-driven methods • Exploring security breaches which emerge out of the complex interaction of many parts of your system .
• Analysing security breaches which can not be tracked back to a single point of failure .
Threats are also socio-technical and could include hackers , disgruntled or poorly trained employees , poorly designed software , a poorly articulated or understood operational process etc .
To give a concrete example that differentiates vulnerabilities from threats – a software interface has a vulnerability in that malicious input could cause the software to behave in an undesirable manner ( e.g .
Likelihood represents a measure capturing the degree of possibility that a threat will exploit a vulnerability , and therefore produce an undesirable outcome affecting the values at the core of the system .
Impact is the result of a threat exploiting a vulnerability , which has a negative effect on the success of the objectives for which we are assessing the risk .
From a systems view this could be the failure to manufacture a new product on time , while from a component view it could be the failure of a speciﬁc manufacturing production component .
KA Risk Management and Governance | October 2019 Page 32 The Cyber Security Body Of Knowledge www.cybok.org 2.6.3 Risk assessment and management methods The purpose of capturing these four elements of risk is for use in dialogue that aims to represent how best to determine the exposure of a system to cyber risk , and how to manage it .
There are a range of methods , some of which have been established as international standards and guidelines , that provide a structured means to transform vulnerability , threat , likelihood and impact into a ranked list in order to be able to prioritise and treat them .
While each method has its own particular approach to risk assessment and management , there are some features common to a number of the most widely used methods that are useful for framing risk assessment and management activities , which can be mapped back to Renn ’ s seminal work on risk governance [ 41 ] as discussed in earlier sections .
The International Risk Governance Council ( IRGC ) capture these in its risk governance framework ( developed by an expert group chaired by Renn ) , summarised in Figure 2.1 , which includes four core areas and crosscutting components .
Pre-assessment includes the framing of risk , identiﬁcation of relevant actors and stakeholders , and captures perspectives on risk .
Cutting across all four is communication , engagement and context setting through open and inclusive dialogue .
A step-by-step detailed guide can be found in the full document , but we summarise the actions here .
It also involves deﬁning assumptions and constraints on elements such as resources required and predisposing conditions that need to inform the risk assessment .
The assessment approach and tolerances for risk are also deﬁned at this stage along with identifying sources of information relating to threats , vulnerabilities and impact .
Conduct is the phase where threats , vulnerabilities , likelihood and impact are identiﬁed .
There are a range of ways that this can be conducted , and this will vary depending on the nature of the system being risk assessed and the results of the prepare stage .
NIST has a very speciﬁc set of tasks to be performed .
These may not be relevant to all systems , but there are some useful tasks that generalise across multiple system perspectives , including identifying : threat sources and adversary capability , intent and targets ; threat events and relevance to the system in question ; vulnerabilities and predisposing conditions ; likelihood that the threats identiﬁed will exploit the vulnerabilities ; and the impacts and affected assets .
Note that the ordering of actions in the NIST approach puts threat identiﬁcation before vulnerabilities , which presupposes that all threats can be identiﬁed and mapped to vulnerabilities .
It is worth highlighting that risk assessment must also be effective in situations where threats are less obvious or yet to be mainstream ( e.g .
, IoT Botnets ) and , therefore , some organisations that are particularly ingrained in digital adoption may also wish to consider conducting a vulnerability assessment independently or prior to the identiﬁcation of likely threats to avoid making KA Risk Management and Governance | October 2019 Page 33 The Cyber Security Body Of Knowledge www.cybok.org Figure 2.4 : NIST SP-800-30 Risk Assessment Process assumptions on what or who the threats actors may be .
Communicate is one of the most important phases , and one often overlooked .
Conducting the risk assessment gives one the data to be able to inform actions that will improve the security of the system .
However , it is crucial this is communicated using an appropriate method .
Executive boards will expect and need information to be presented in a different way to operational team members , and general organisational staff will need educating and guiding in an entirely different way .
The results and evidence of the risk assessment must be communicated in a manner accessible to each stakeholder and in a way that is likely to engage them in risk management planning and execution .
Maintain is an ongoing phase that is essential to continually update the risk assessment in the light of changes to the system environment and conﬁguration .
Security postures change regularly in digital environments .
This kind of rapid integration of devices into corporate IT systems is likely to change the exposure to risk and , therefore , the scope would need to be reﬁned , new risk assessments carried out , and action taken and communicated to all stakeholders to ensure that the new risk is managed .
This scenario indicates that ( i ) risk assessment maintenance must be proactive and undertaken much more regularly than an annual basis , and ( ii ) conducting risk assessment for compliance purposes ( possibly only once a year ) will leave the organisation wide open to new technological threats unless the maintain phase is taken seriously .
, changes in technology KA Risk Management and Governance | October 2019 Page 34 The Cyber Security Body Of Knowledge www.cybok.org Figure 2.5 : IoT Devices Use Figures : Source : [ 53 ] use within the system ) , frequency of risk factor monitoring should be agreed , and changetriggered reviews should revisit and reﬁne the scope , purpose and assumptions of the risk assessment—remembering to communicate the results each time new risks are identiﬁed .
It includes an Establish Context phase , which is broadly aimed at achieving the outcomes of the Prepare phase of NIST and the IRGC Preassessment phase .
ISO 27005 also has Risk Communication and Risk Monitoring and Review phases , which relate broadly to the aims of the NIST Communicate and Maintain phases , and IRGC ’ s crosscutting communication , context and engagement phases .
ISO/IEC 27005 has additional elements that explicitly capture risk management decision processes but it is not prescriptive on how to implement them .
The inclusion of the treatment and acceptance phases linked to communication and review capture some of the fundamental management aspects , offering the choice of treatment or acceptance as part of the assessment process .
The take-away message from this comparison is that , while the risk assessment methods may differ at the risk assessment phase ( depending on the type of system being analysed and the scope of the study ) , the preparation , communication , and continual monitoring phases are must-haves in both widely-used international guidelines , as are the important decisions around risk tolerance .
ISO/IEC 27005 is less prescriptive than NIST so offers the option to include a range of assessment and management approaches within the overall process .
The list also includes a brief description , an overview of how they work , who should use it , and an indication of cost and prerequisites .
While not wishing to reproduce the whole list here , we provide an overview for the purposes of comparison .
It does not prescribe a speciﬁc risk assessment technique but does have a component-driven focus and requires vulnerabilities , threats and impact to be speciﬁed .
They have a strong regulatory focus , which may not be relevant for countries other than the US , but they have a clear set of guiding steps to support the whole risk assessment and management process from establishing context to risk tolerance , and effective controls , including determining likelihood of impact .
They are freely available and consistent with ISO standards ( which are not free but are low cost ) .
• The Information Security Forum ( ISF ) produced the IRAM 2 risk management methodology that uses a number of phases to identify , evaluate and treat risks using the vulnerability , threats and impact measures .
It is provided to ( paid up ) members of the ISF and requires information risk management expertise to use it effectively , which may come at additional cost .
Threat surface can be considered very broad and there is a clear focus on loss event frequency , threat capability , control strength and loss magnitude .
It also breaks ﬁnancial loss factors into multiple levels and supports a scenario model to build comparable loss proﬁles .
• Octave Allegro is oriented towards operational risk and security practices rather than technology .
Qualitative risk assessment is linked with organisational goals .
Real-world scenarios are used to identify risks through threat and impact analysis .
The risks are then prioritised and mitigation is planned .
The approach is designed for workshop style risk assessment and could be performed in-house possibly resulting in a lower cost than a consultant-led risk assessment .
Threats can be considered for multiple interactions on the same threat target in the system and can include people , process and technology .
Threat modelling , of course , can not guarantee that all failures can be predicted , but the iterative process supports continual assessment of evolving threats if time and resources allow .
Like STRIDE , attack trees are required to be iterative , continually considering pruning the tree and checking for completeness .
Attack libraries such as Common Vulnerabilities and Exposuress ( CVEs ) and Open Web Application Security Project ( OWASP ) can be used to augment internal knowledge of evolving threats and attacks .
While core principles of risk based around vulnerability , threat and impact exist across all methods , there are individual attributes ( we refer to as strengths ) of each method , as well as resource and reporting differences , that may make them a better ﬁt to an organisation depending on what the risk stakeholders require as evidence of exposure .
other methods in this list could be used to manage risk ) but covers threats , vulnerabilities , and impacts .
Intended to target higher level management and decision makers .
Clear focus on people - internal and external Strength : Socio-technical Aims to include a range of relevant backgrounds in the assessment ( covering people , process and tech ) and applicable across varying sizes of organisation .
Typically externally led due to size and complexity in large organisations , which comes at a cost in addition to the cost of purchasing the documentation .
Smaller organisations with less complexity can also follow the principles in-house .
Documentation covers all security controls NIST SP80030/39 Focused on technical risk management of IT systems with a prescriptive approach .
Strength : Technology-driven Includes roles and should be usable by organisations of all sizes ( albeit it is very US focused ) .
Checklist reports for operational , management and technical security ISF Broad business impact assessment , practitioner led .
Threat , vulnerability and impact based Strength : Business impact-driven Only available to members at cost and requires a team with expertise in risk assessment Information required on impact of losses .
Scenario driven with very well deﬁned measures on economic impact .
People are part of the method , both internal business and external threat actors Strength : Economic impact-driven Well-deﬁned method could be used by a small internal team .
OpenFAIR standard available via the Open Group Information sources may vary depending who hold the necessary information .
Reports on ﬁnancial loss magnitudes KA Risk Management and Governance | October 2019 Page 38 The Cyber Security Body Of Knowledge www.cybok.org Methodology Assessment Team and Cost Information Gathering and Reporting Octave Allegro Covers people , technology and physical security .
Self-directed methods intended for internal use , including qualitative management and evaluation workshops linked to identiﬁcation of organisational goals and related assets .
Followed by threat identiﬁcation and mitigation .
reputation , productivity ) have relative impact scores ( low , medium , high multiplied by categorical risk score ) to support prioritisation Strength : Qualitative goaloriented focus Collaborative assessment team from within and across business including management , staff and IT .
Documentation states it is targeted at organisations with 300+ employees Workshops and questionnaires .
Baseline reports proﬁle of practices , threat proﬁle , and vulnerabilities STRIDE Threat assessment method .
Well documented and clear approach based on threats , mitigation ( including tolerance levels for risk ) , and mitigation including who signs off on risk .
Strength : Threat-driven Small threat modelling team from within and across business including management and IT .
Graphical threat models and tables capturing STRIDE analysis for systems elements and interactions .
Attack Trees Similar threat assessment to STRIDE , but more attack-speciﬁc , focusing on key details of attack methods .
Openly accessible method Attack modelling workshops .
Attack trees and quantitative measures of likelihood of attack with associated impact .
Below we provide an overview and identify the attributes that can act as differentiators based on the core focus of each method .
These all focus on system-level risk and , as such , may require signiﬁcant human resource effort depending on the size of the organisation .
The main objective of these methods is to capture interactions and interdependent aspects of the system and thus requires extensive engagement with process owners and seeking the ‘ right ’ people with knowledge of sub-systems .
The method uses a feedback loop with a controller and a controlled process linked via actuation and feedback .
It is based on systems thinking and involves : identiﬁcation of system purpose , unacceptable losses , hazards , and constraints ; development of a hierarchical control structure ; identiﬁcation of unsafe control actions ; and the analysis of causal scenarios that lead to these unsafe control actions .
This can be supplemented by a timeline or sequence of events .
The concept of an enterprise in this context encompasses all the business activities and capabilities , information , and technology that make up the entire infrastructure and governance activities of the enterprise .
If this extends into partners , suppliers , and customers , as well as internal business units , then the model can also encompass this aspect .
Risk assessment in TOGAF is based on a qualitative approach combining effect and frequency labels to produce an overall impact assessment .
Strength : Linked to structured architectural representation of the enterprise .
The method then iterates the questions until a tree of dependencies is created .
Goals are abstract so not dependent on actual processes , and allow a connectionist view of an enterprise , its suppliers , and customers to be developed .
Recent work has developed tools to support the capturing of dependencies in a workshop setting and apply quantitative probabilities to goals , underpinning Bayesian analysis and modelling cascading failure [ 85 ] .
Strength : Capturing interdependencies between abstract goals that sit above , and are linked to , actual business processes .
The ﬁrst phase identiﬁes the risk associated with achieving objectives so mitigation plans can be identiﬁed .
The output then feeds into the design phase that determines the security management processes and how they will be used .
The third phase implements , deploys and tests the management processes by the operations teams .
The ﬁnal phase relates to management and measurement , which collects security information and reports to the governance stakeholders .
The method is enacted by decomposing business processes at different architectural layers , from high-level capabilities ( context and concept ) down to logical and physical aspects , technology components and activities .
Risk is addressed at every layer in a top-down approach to managing risk through activities in all layers , and ﬁltering security requirements from top to bottom to ensure cyber risk is considered throughout .
They also underpin complex manufacturing systems where processes are too heavy-duty , monotonous , or dangerous for human involvement .
As a result , OT risks will more often involve a safety or reliability context due to the nature of failure impacting worker and general public safety and livelihood by having a direct impact in the physical world .
Taking this view can bridge the security and safety perspective and support discussion on how to best mitigate risk with shared system-level objectives in mind .
Efforts to continually monitor and control OT remotely have led to increasing convergence of OT with IT , linking the business ( and its associated risks ) to its safety critical systems .
Technology such as Supervisory Control and Data Acquisition ( SCADA ) provides capability to continually monitor and control OT but must be suitably designed to prevent risks from IT impacting OT .
Recent additions to this debate include the uptake and adoption of IoT devices , including , for example , smart tools on manufacturing shop-ﬂoors .
These are a more recent example of an interface to safety critical systems that could offer a window for attackers to breach systems security .
IoT security is in its infancy and the approach to risk management is yet to be completely understood .
The cyber security of cyber-physical systems , including vulnerabilities , attacks and countermeasures is beyond the scope of this KA and is discussed in detail in the Cyber-Physical Systems Security Knowledge Area ( Chapter 19 ) .
2.6.5 Security Metrics Security metrics is a long-standing area of contention within the risk community as there is debate over the value of measuring security .
It is often difﬁcult to quantify – with conﬁdence – how secure an organisation is , or could be .
Qualitative representations such as low , medium , high or red , amber , green are typically used in the absence of trusted quantitative data , but there is often a concern that such values are subjective and mean different things to different stakeholders .
Some metrics may be related to risk levels , some to system performance , and others related to service provision or reliability .
Jaquith provides some useful pointers on what constitutes good and bad metrics to help KA Risk Management and Governance | October 2019 Page 41 The Cyber Security Body Of Knowledge www.cybok.org select appropriate measures [ 64 ] .
• Do not express results with cardinal numbers and units of measure .
There are examples of metrics that could provide utility in domains such as healthcare , privacy and national security .
The perspective on metrics is grounded in the understanding that we can not be completely secure , so measuring actual security against necessary security is arguably a defensible approach , and the metrics described are tailored towards measuring the effectiveness of vulnerability management .
Essentially , is it possible to quantify whether the risk management plan and associated controls are ﬁt for purpose based on the threats identiﬁed , and do the metrics provide evidence that these controls are appropriate ?
Furthermore , are the controls put in place likely to add more value in the savings they produce than the cost of their implementation ?
This point is particularly pertinent in the current era of Artiﬁcial Intelligence technology being marketed widely at an international level to protect digital infrastructure .
With a large price tag there is a question mark over an evidence-based understanding of the actual added-value of such security mechanisms and the cost-effectiveness of such solutions in the light of potential savings .
For instance , nation state threats are based on metrics such as population , literacy and cultural factors ; terrorist groups on technical expertise , level of education and history of activity ; and pressure groups are ranked on spread of membership , number of activists , and funding .
The framework provides a perspective on how to capture measures that ground threat metrics in information that can support discursive , intelligence-led and culturally-grounded risk assessment .
In an article with President Obama on the complications and failures KA Risk Management and Governance | October 2019 Page 42 The Cyber Security Body Of Knowledge www.cybok.org of risk management in the state of Libya , he notes that the US analytical teams underestimated the attacker proﬁle ( particularly socio-cultural aspects ) , which led to failure in risk management [ 88 ] .
Assuming knowledge of the adversary can be very risky , but metrics to proﬁle possible threats and attacks ( while explicitly accepting our limitations in knowledge ) can be used as part of a threat modelling approach such as STRIDE [ 75 ] or Attack Trees [ 79 ] .
While quantitative metrics framed in this way appear preferable to qualitative metrics , it is not always a trivial process to collect consistently measured data , either manually or automated .
This brings us back to the point around communication and agreeing common language in the risk assessment phase .
While metrics may be limited in their accessibility and consistent collection , agreeing the upper and lower bounds , or speciﬁc meaning of qualitative labels also provides a degree of value to measuring the security of a system through well-deﬁned links between threats and their relationship to vulnerabilities and impact .
2.7 BUSINESS CONTINUITY : INCIDENT RESPONSE AND RECOVERY PLANNING [ 90 , 91 ] Ultimately , despite all best efforts of accountable individuals or boards within a company who have understood and managed the risk they face , it is likely that at some point cyber security defences will be breached .
An essential part of the risk assessment , management and governance process includes consideration and planning of the process of managing incidents and rapidly responding to cyber attacks .
The aim is to understand the impact on the system and minimise it , develop and implement a remediation plan , and use this understanding to improve defences to better protect against successful exploitation of vulnerabilities in future ( feedback loop ) .
This is still a nascent area of cyber security maturity .
Organisations typically prefer to keep information about cyber security breaches anonymous to prevent reputational damage and cover up lapses in security .
However , it is likely that other organisations , including competitors will succumb to the same fate in the future , and could beneﬁt from prior knowledge of the incident that occurred .
At a broad scale , this is something that needs to be addressed , especially given the offensive side of cyber security will communicate and collaborate to share intelligence about opportunities and vulnerabilities for exploiting systems .
Certain industries such as ﬁnancial and pharmaceutical sectors have arrangements for sharing such intelligence but it is yet to become commonplace for all types of organisations .
Large public consortia such as Cyber Defence Alliance Limited ( CDA ) , Cyber Information Sharing Partnership ( CISP ) , and the Open Web Application Security Project ( OWASP ) are all aiming to support the community in sharing and providing access to intelligence on the latest threats to cyber security .
It expands on the aforementioned ISO/IEC 27005 model and includes steps for incident response , including : • Plan and Prepare : including the deﬁnition of an incident management policy and establishing a team to deal with incidents .
• Assessment and Decision : determining the presence ( or otherwise ) and associated severity of the incident and taking decisive action on steps to handle it .
• Learning : a key part of incident management is learning – making improvements to the system defences to reduce the likelihood of future breaches .
This should include reporting incidents and managing any regulatory expectations .
• Roles : assign duties to individuals to handle incidents and empower them to respond to incidents in line with a clear action plan – and make sure this person is well known to people who may be likely to identify an incident .
• Recovery : particularly for data and critical applications , make sure a backup is physically separated from the system – and test the ability to restore from backup .
• Test : play out scenarios to test out the recovery plans ; these should be reﬁned based on practical and timely restoration under different attack scenarios .
• Report : ensure that information is shared with the appropriate personnel internally to improve risk management and security controls , plus externally to ensure legal or regulatory requirements are met .
• Gather evidence : forensic response may be crucial following an incident – the preservation of evidence could be critical to legal proceedings or , at a minimum , understanding the events that led to the breach .
• Develop : take note of the actions taken as part of the incident response .
What worked and what did not ?
Where could the process be improved ?
As well as defences , the response plan may also beneﬁt from reﬁnement .
Security policies , training , and communication may all help reduce the impact of future breaches .
• Awareness : continue to remind employees of their responsibilities and accountability regarding cyber security – remind them of how to report incidents and what to look out for .
Vigilance is key whether it involves reporting suspicious behaviour or a known personal error that has led to a breach .
As a ﬁnal word on business continuity we highlight the signiﬁcance of supply chains .
Incident management approaches along with systems-level risk assessment methods are designed to enable the capture of risks relating to interactions and interdependent aspects of the system , which , of course , can and should include supply chains , but will only do so if due atten- KA Risk Management and Governance | October 2019 Page 44 The Cyber Security Body Of Knowledge www.cybok.org tion is given this aspect of risk .
2.8 CONCLUSION We have explained the fundamental concepts of risk , using a working deﬁnition of the possibility that human actions or events may lead to consequences that have an impact on what humans value , and placed this in the context of cyber risk management and governance .
Using academic foundations that have been widely adopted in international practice , we have explained the links between pre-assessment and context setting , risk and concern assessment , characterisation and evaluation , management , and governance .
Risk governance is the overarching set of ongoing processes and principles that underpin collective decisionmaking and encompasses both risk assessment and management , including consideration of the legal , social , organisational and economic contexts in which risk is evaluated .
We have deﬁned some of the core terminology used as part of the structured processes that capture information , perceptions and evidence relating to what is at stake , the potential for desirable and undesirable events , and measures of likely outcomes and impact – whether they be qualitative or quantitative .
A major aspect of risk is human perception and tolerance of risk and we have framed these in the extant literature to argue their signiﬁcance in risk governance aligned with varying types of risk – routine , complex , uncertain and ambiguous .
We have particularly drawn on factors that inﬂuence the perception of risk and discussed how these link to the human factors of cyber security in the context of security culture .
Training , behaviour change , creation of conﬁdence and trust , and stakeholder involvement in the risk governance process have been highlighted as crucial success factors .
This is based on well-established literature that people ’ s intuition and bias will often outweigh evidence about risk likelihood if they believe the management of the risk is not trustworthy , does not apply to them , or is beyond their control .
We need people to buy into risk governance rather than impose it upon them .
Accordingly , we introduced the concept of balancing accountability with learning , proposing that failures in the risk governance process should lead to feedback and improvement where individuals that may have breached risk management policies should feel able to bring this to the attention of risk managers without fear of stigmatisation .
A number of well-established risk management methods from the systems and component perspectives were analysed with core strengths of each highlighted and some insights into how the methods function , the resources ( human and economic ) required , and information gathering/reporting requirements .
While the core principles of risk – based around vulnerability , threat and impact – exist across all methods , there are individual attributes ( we referred to as strengths ) of each method that may make them a better ﬁt to an organisation depending on what the risk stakeholders require as evidence of exposure .
We reﬂected brieﬂy on the context of safety in risk assessment for operational technology , which also included the growth of IoT and the need to consider additional directives for critical national infrastructure risk .
Measuring security and the limitations of metrics were discussed in the context of possible options for security metrics , as well as differing views in the community on the beneﬁts and limitations of metricised risk .
Finally , we linked to incident response and recovery , which KA Risk Management and Governance | October 2019 Page 45 The Cyber Security Body Of Knowledge www.cybok.org should provide a feedback loop to risk management planning within the risk governance process .
Even with the best laid plans , it is likely a breach of cyber security defences will occur at some point and , in addition to the cultural aspects of learning and improvements of staff , we highlighted a number of key steps from international standards that are required to be considered as part of the governance process .
Risk governance is a cyclical and iterative process , and not something that can be performed once .
The crosscutting aspects of communication , stakeholder engagement and context bind the risk assessment and management processes and are core to the continual reﬂection and review of risk governance practices .
Incidents , when they occur , must inform risk management policy to improve cyber security in future – and we must accept that we will likely never be completely secure .
In line with this , human factors and security culture must respond to the ever changing need to manage cyber risk , enabling and instilling continual professional development through education and Just Culture where lessons can be learned and governance methods improved .
The work is presented as an educational aid for cyber security practitioners .
Opinions expressed are solely those of the author .
This work does not represent ofﬁcial policy or opinion of the NCSC , the government of the United Kingdom , any state , any persons involved in its production or review , or any of their staff , employers , funders , or other persons afﬁliated with any of them .
INTRODUCTION The purpose of this knowledge area is to provide a snapshot of legal and regulatory topics that merit consideration when conducting various activities in the ﬁeld of cyber security such as : security management , risk assessment , security testing , forensic investigation , research , product and service development , and cyber operations ( defensive and offensive ) .
The hope is to provide a framework that shows the cyber security practitioner the most common categories of legal and regulatory risk that apply to these activities , and to highlight ( where possible ) some sources of legal authority and scholarship .
The nature and breadth of the subject matter addressed renders this knowledge area , and the sources cited , a mere starting rather than ending point .
The reader is assumed to hold no formal qualiﬁcation or training in the subject of law .
The audience is further assumed to be multinational .
To make the material practically accessible to such a diverse body of cyber security domain specialists , subjects are presented at a level that would be considered introductory for those who are already well educated in law or public policy .
The rules of mathematics and physical sciences are both immutable and identical around the world .
The foundation of the world ’ s legal and regulatory systems has for many centuries been based on the principle of territorial sovereignty .
Various international efforts to harmonise differences in laws and regulations have met with variable degrees of success .
In practice , this means that laws and regulations differ – sometimes signiﬁcantly – from state to state .
This knowledge area , however , addresses a multinational audience of practitioners who will be called upon to conduct their activities under laws and regulations imposed by different states - both the home state in which they practice , and foreign states with which they make contact .
While respecting the reality that legal details vary by state , this knowledge area will attempt to identify some widely shared norms among various systems of domestic law and regulation , and some aspects of public international law , that may ( or should ) inﬂuence the work of the security practitioner .
In the search for generalisable norms that retain utility for the practitioner , this knowledge area focuses primarily on substantive law .
Procedural rules are mostly excluded from coverage .
Procedural rules tend to focus on managing the dispute resolution process or specifying methods of communication with a state KA Law & Regulation | October 2019 Page 50 The Cyber Security Body Of Knowledge www.cybok.org authority .
Examples include civil procedure,1 criminal procedure,2 and rules of evidence.3 Although these are signiﬁcant to the administration of justice , they are often parochial in nature and bound up with quirks of local practice .
Cyber security practitioners who need to become familiar with the details of these rules ( e.g .
, forensic investigators , law enforcement ofﬁcers , expert witnesses , and others who collect or present evidence to tribunals ) invariably require specialist guidance or training from relevant local legal practitioners who understand the procedural rules of a given tribunal.4 As with many efforts at legal taxonomy , the difference between substance and procedure is imprecise at the boundary .
The test for inclusion in this knowledge area is less to do with divining the boundary between substance and procedure , and springs instead from the desire to make normative statements that remain useful to practitioners in a multinational context .
Section 3.1 starts the knowledge area with an introduction to principles of law and legal research , contrasting the study of law and science and explaining the role of evidence and proof .
Section 3.2 then explores various aspects of jurisdiction in an online environment .
Sections 3.3 and 3.4 discuss general principles of privacy law ( including interception of communications ) and the more detailed regulatory regime of data protection law .
Section 3.5 presents an outline of computer crime laws , and more speciﬁcally crimes against information systems .
Sections 3.6 and 3.7 provide an introduction to principles of contract and tort law of interest to practitioners .
Section 3.8 provides a general introduction to relevant topics in intellectual property , while Section 3.9 provides an overview of laws that reduce liability of content intermediaries .
Sections 3.10 and 3.11 address a few specialist topics , with an exploration of rights and responsibilities in trust services systems and a brief survey of other topics of interest such as export restrictions on cryptography products .
The author of this knowledge area is trained in the common law5 ( nearly ubiquitous in anglophone territories ) and experienced in international commercial legal practice conducted in London .
Examples of legal norms are therefore drawn from common law ( as interpreted by different states ) , various anglophone statutes and case decisions , European Union law , and public international law.6 The author welcomes thoughtful correspondence conﬁrming , further qualifying , or challenging the normative status of issues presented .
’ Alice ’ and ’ Bob ’ and similar terms are used in an effort to present ideas in a form likely to be familiar to security practitioners .
There is one signiﬁcant difference in how these terms are used .
Notes are used for a variety of purposes , including providing speciﬁc examples , further explanation of issues , and additional argument in support of or against a given a proposition .
In some circumstances notes have been used to suggest potential future legal developments , subjects worthy of further study , or to provide other comments.8 KA Law & Regulation | October 2019 Page 51 The Cyber Security Body Of Knowledge www.cybok.org CONTENT 3.1 INTRODUCTORY PRINCIPLES OF LAW AND LEGAL RESEARCH Cyber security practitioners and researchers come from an incredibly wide array of educational backgrounds .
Experience teaching legal and regulatory subjects to cyber security postgraduate students , and providing legal advice to cyber security practitioners , suggests that much of this knowledge area ’ s content will be novel to those whose education is based in science , technology , engineering , mathematics , many social sciences , and many of the humanities .
These introductory observations are offered as an aid for those who are approaching the subject without signiﬁcant experience .
3.1.1 The nature of law and legal analysis Although the reader is assumed to have some degree of familiarity with the process of law making and law enforcement , a review of some of the most common sources of law should help to orient those who are unfamiliar with legal research and analysis .
Law should be analysed with rigorous logic .
Unlike scientiﬁc disciplines such as physics or mathematics , however , the study of law is not conceptualised as an effort to discover immutable principles of our world .
Society inﬂuences the development and interpretation of law even as law inﬂuences the behaviour of members of society .
Changes to law and to methods of interpreting law tend to follow.9 This creates a number of challenges for legal scholarship,10 as the topic under study continues to change.11 Perhaps as a result the study of law is often presented in the form of historical dialectic : examining the evolution of law and its interpretation over time , often through case studies .
This method provides all-important context , aids in the interpretation of law as it exists , and often suggests the direction of future developments .
The study of law endeavours to share at least one characteristic with the sciences : the ability to predict outcomes .
While sciences like chemistry predict the outcome of events such as the introduction of solid sodium to liquid water , the study of law attempts to predict the outcome of disputes submitted to a suitably expert legal tribunal .
Although the study of law can never predict outcomes of dispute with 100 % certainty , in states with well-developed systems of law and well-qualiﬁed adjudicators , it is possible to achieve a degree of predictability of outcome that is sufﬁciently high to maintain conﬁdence in the system as a whole.12 Legal studies often begin with a mechanistic review of the governance processes surrounding the adoption and enforcement of law .
Understanding different governance structures adopted by states to manage these three processes requires an examination of comparative constitutional law which is beyond the scope of this knowledge area .
Most legal research and analysis proceeds on the basis of argument from authority , drawn from an analysis of historical texts that embody expressions of law .
There follow a few observations about differing sources of legal authority and how these vary in different contexts .
No KA Law & Regulation | October 2019 Page 52 The Cyber Security Body Of Knowledge www.cybok.org standards body exists to harmonise the deﬁnition of legal terms of art as they are used by different states .
Confusion over legal terminology is therefore commonplace in a multinational context .
In both common law13 and civil law14 jurisdictions , primary legislation ( typically a statute such as an Act of Parliament in the UK , or an Act of Congress in the US ) is the most easily understood embodiment of ’ the law ’ .
Sometime a degree of law-making authority is delegated by a senior legislative body ( such as the UK Parliament or the US Congress ) to some other agency of the state ( such as the Foreign Minister of the UK or the US Commerce Department ) .
Delegation is often made for reasons of technical expertise , or the need for frequent periodic review of adopted rules .
Laws promulgated by such subordinate agencies are generally termed secondary legislation .
The term ’ regulation ’ is sometimes used colloquially to refer to secondary legislation as distinct from primary legislation .
Each member state is required to examine the terms of the Directive , and then to implement these terms within its own domestic law within a speciﬁed time frame .
Directives are normally said to lack ’ direct effect ’ in member state law , with some exceptions .
In common law jurisdictions , the published decisions of domestic courts that interpret the law tend to constitute signiﬁcant and binding interpretative authority depending upon the seniority and jurisdiction of the court .
Decisions by the courts of foreign states may constitute persuasive authority , or indeed their interpretation of the law may be ignored entirely.19 In civil law jurisdictions , the decisions of judges are generally accorded less interpretive authority than similar decisions in a common law jurisdiction .
Although restatements are not normally considered a source of mandatory authority , as carefully considered expressions of expert opinion they are often extremely inﬂuential.24 Treaties .
Treaties are instruments of agreement among and between states .
In some states , the legal terms of a treaty are automatically carried into operation of a contracting state ’ s domestic law once the state has fully acceded to the treaty .
In others , domestic law is not amended unless and until the domestic legislature acts to amend domestic law in accordance with the treaty requirements .
Within common law jurisdictions , scholarly articles written by legal academics can constitute a type of persuasive , albeit weak , authority .
Judges typically adopt the arguments of legal scholars only to the extent that the scholar ’ s work persuades a jurist to KA Law & Regulation | October 2019 Page 53 The Cyber Security Body Of Knowledge www.cybok.org adopt their view .
In many civil law systems , by contrast , scholarly articles by leading legal academics may be accorded signiﬁcant deference by tribunals who are called upon to interpret the law .
3.1.2 Applying law to cyberspace and information technologies The birth of cyberspace caused a great deal of anxiety with regard to the application of laws and regulations to this new domain .
Two prevailing schools of thought emerged .
The ﬁrst school posited that cyberspace is so radically different from anything in human experience , that old laws were unsuitable and should be widely inapplicable to actions taken using this new domain .
Law makers and judges were encouraged by this school to re-examine all doctrines afresh and to abandon large swathes of precedent when considering disputes .
Radical proponents of this view went so far as to deny the authority of sovereign states to enforce laws and regulations in the context of Internet-related activities [ 97 ] .
The second school held instead that the Internet is , like so many tools developed in human history , merely an instrumentality of human action .
The practitioner is confronted with the reality that existing laws , some centuries old and some amended or born anew each year , are applied by states , their law makers , judges , police and defence forces to cyberspace-related activity whether or not cyberspace was expressly contemplated by those same laws.26 One must be cautious when attempting to map legal rules onto activities .
While lawyers and legal scholars divide the law into neat categories , real-life and cyber operations do not always ﬁt neatly within a single category .
For example , a single data processing action that does not infringe copyright and is not defamatory may still constitute a violation of data protection rights .
Any given action should be assessed by reference to whatever laws or regulations present risk .
The problem of conﬂicting obligations that can arise as a result of multi-state regulation is introduced in Section 3.2 .
Practitioners increasingly ask questions concerning the application of law to artiﬁcial intelligence .
Laws are generally framed to inﬂuence and respond to the behaviours of persons , or to address the disposition or use of property .
Instances of artiﬁcial intelligence are not currently deﬁned as persons under the law.27 Therefore an AI , as such , can not be guilty of a crime , enter into a contract , own property , or be liable for a tort .
If an object controlled by an AI causes harm , the law would normally be expected to look beyond the AI to the persons who created or made use of it and the responsibility of such persons would be assessed using existing legal standards .
This subject is explored brieﬂy in Section 3.7.2 , which touches upon circumstances where persons could become strictly liable for AI-related actions which cause death or personal injury.28 KA Law & Regulation | October 2019 Page 54 The Cyber Security Body Of Knowledge www.cybok.org 3.1.3 3.1.3.1 Distinguishing criminal and civil law Criminal law Criminal law is the body of law that prohibits behaviour generally abhorred by society .
Criminal law is normally enforced by an agency of the state .
Examples include prohibitions against bank fraud and computer hacking .
These terms should not be used when referring to outcomes of civil actions .
Punishments available in criminal law include custodial prison sentences , criminal ﬁnes normally remitted to the state , seizure and forfeiture of criminal proceeds , and ﬁnancial or other restitution remitted to victims .
There is often no requirement for an accused to have understood that their actions were deﬁned as criminal , although states normally must prove that the accused intended to take those actions .
Some crimes are deﬁned in a fashion that guilt only attaches if the state can prove that the accused was aware that they were doing something ’ wrong ’ .29 An accused , therefore , may not be able to escape criminal liability by suggesting , or even proving , that an act was undertaken with good intentions or otherwise ’ in the public interest ’ .30 3.1.3.2 Civil ( non-criminal ) law Civil law31 is the area of law that regulates private relationships among and between persons .
Examples include the laws of contract and negligence .
A person injured as a result of breach of civil law can normally bring legal action against the responsible party .
Remedies available under civil law ( depending on the circumstances ) may include some combination of : • an order for the liable party to pay compensation to the injured party ; • an order to terminate some legal relationship between the parties ; • an order for the liable party to discontinue harmful activity ; or • an order for the liable party to take some type of afﬁrmative act ( e.g .
The principles of civil law are often crafted in an effort to redress negative externalities of behaviour in a modern economy .
This makes civil law especially interesting in cyber security , as poor security in the development of ICT products and services is a sadly recurring negative externality that often falls short of criminal behaviour [ 105 ] .
Policy makers hope that people KA Law & Regulation | October 2019 Page 55 The Cyber Security Body Of Knowledge www.cybok.org who become aware that certain types of risk-taking carry an associated liability for resulting harm will alter their behaviour for the better .
3.1.3.3 One act : two types of liability & two courts A single act or series of connected acts can create liability simultaneously under both criminal and civil law .
Her actions in turn cause Bob ’ s LAN and related infrastructure to fail .
The two types of legal action would normally be contested in two separate tribunals , and subject to two different standards of proof ( see Section 3.1.4 ) .32 The purpose of the criminal case is to protect the interests of society as a whole , while the purpose of the civil case is to compensate Bob .
3.1.4 The nature of evidence and proof The concept of ’ proof ’ in law is different from the term as it is used in the ﬁeld of mathematics or logic .
This can create confusion in discussions of cyber security topics and the law .
In law , to ’ prove ’ something means simply to use permissible evidence in an effort to demonstrate the truth of contested events to a fact ﬁnder to a prescribed degree of certainty .
This factual narrative is then subjected to analysis under relevant law .
A person who brings a legal action is said to carry the burden of proof with respect to the elements that deﬁne their right of action .
This is also known as proving the claiming party ’ s prima facie case .
An accused then bears the burden to prove afﬁrmative defences which might serve to reduce or eliminate their liability.35 The applicable standard of proof , which is to say the degree of certainty that must be achieved by the fact ﬁnder to reach a ﬁnding on a given contested issue , depends upon the issue under consideration .
A non-exhaustive sample of different standards of proof used in various legal contexts is presented in Table 3.1 .
KA Law & Regulation | October 2019 Page 56 The Cyber Security Body Of Knowledge www.cybok.org 3.1.5 A more holistic approach to legal risk analysis Those who approach the study of law for the ﬁrst time often fall victim to seeing only one aspect of the law : ’ the rules ’ .
More speciﬁcally , the elemental framework from a given law which deﬁnes the evidentiary burden to be met by a person seeking to prove the guilt or liability of a second person .
This ignores other factors that must be taken into account when analysing legal risk .
Consider a circumstance in which Alice has some right of action against Bob .
( Alice could be a state considering prosecution of Bob for a crime or Alice could be a person considering a civil law suit against Bob for breach of contract or tort . ) .
If Alice pursues legal action against Bob , she might win the action or she might lose .
Bob must take different factors into consideration when analysing the relevant risk of Alice taking legal action .
The purpose of the function above is merely to highlight that legal risk analysis involves more than consideration of ’ the rules ’ .36 Thus , the discussions of substantive law in this knowledge area ( e.g .
In assessing each of these factors , one must also consider the probative value of available evidence as well as the relevant standard of proof to be met in each element ( see Section 3.1.4 ) .
Some areas of risk , such as risks related to transaction costs including mechanisms that may shift some transaction costs from winner to loser ( which also fall within X ) , are highly individualised and process-oriented and beyond the scope of this knowledge area .
The issues introduced here signiﬁcantly underpin the observations concerning legal risk management in Section 3.14 .
No other reasonable explanation exists to make sense of the evidence .
States are most often required to meet this , or a similar standard , in proving the elements of a crime for a fact ﬁnder to hold an accused person guilty .
This higher standard is heavily inﬂuenced by notions of human rights law because individual life and liberty are at stake .
This standard of proof is used in US law , for example , Much more than simply when a court is asked to invalidate a previously granted ’ probable ’ .
The burden of proof placed upon the person seeking to invalidate the patent is set high because this would deprive a rights-holder of property previously granted by the patent ofﬁce .
This phrase is also used to describe the standard to be met by prisoners who challenge the validity of their criminal conviction in US federal courts using a habeas corpus petition long after normal routes of appeal have been exhausted .
In this circumstance , the higher standard is required as a means of preserving the integrity of the original criminal justice process ( including the original appeals ) while not foreclosing all possibility of post-conviction review.37 Preponderance of evidence .
The most common formulations of the standard of proof required to prevail in a civil case .
When weighed on the scales of justice , the evidence on one side is at least a feather-weight greater than the other .
The evidence suggests that the target of an investigation has committed a crime , although evidence is not yet conclusive .
The standard required in the US to persuade a judicial ofﬁcer to issue a search warrant or arrest warrant .
This standard serves to ﬁlter out trivial or unsubstantiated requests to intrude into privacy or detain a suspect .
The standard typically required in the US to justify a police ofﬁcer temporarily stopping and questioning a person .
This lower standard is often justiﬁed on policy grounds of minimising threats to the safety of police ofﬁcers .
This phrase has also been suggested by the United Nations High Commissioner for Human Rights on the right to privacy in the digital age as a threshold for justifying state electronic surveillance [ 106 ] .
Those who face a potential threat of enforcement by a person in a foreign state must consider a few threshold questions before the relevant legal risk can be analysed : jurisdiction and conﬂict of law .
Jurisdiction describes scope of state authority and the mechanisms used by a state to assert power .
Private international law , or conﬂict of law , examines how to determine which domestic state law ( s ) will be applied to resolve certain aspects of a given dispute .
This section of the knowledge area discusses jurisdiction .
Conﬂict of law is addressed separately in the context of individual substantive headings of law .
Many of the principles concerning jurisdiction and conﬂict of law are not new .
What has changed are the larger numbers of people who beneﬁt from considering these principles now that persons are facing cross-border legal responsibilities at increased rates .
3.2.1 Territorial jurisdiction The term ’ jurisdiction ’ is often used in a rather informal manner to refer to a state , or any political sub-division of a state , that has the authority to make or enforce laws or regulations.38 In this sense , the term is nearly synonymous with the territory of that state or its political subdivision .
The purpose of this section , however , is to focus more speciﬁcally on the territorial extent of a state ’ s power – its territorial jurisdiction.39 When reviewing legal risks from multi-state activities conducted via cyberspace , it may be helpful to consider three different aspects of jurisdiction : prescriptive jurisdiction , juridical jurisdiction , and enforcement jurisdiction .
Prescriptive jurisdiction describes the scope of authority claimed by a state to regulate the activities of persons or take possession of property .
Law makers normally adopt laws for the purpose of protecting the residents of their home state and may declare their desire to regulate the actions of foreign-resident persons to the extent that such actions are prejudicial to home state-resident persons .
Juridical jurisdiction describes the authority of a tribunal to decide a case or controversy .
The rules of such jurisdiction vary widely from tribunal to tribunal .
In civil cases , courts usually demand a minimum degree of contact between the residential territory of the court and the property or person against which legal action is taken .
Such minimum contact might involve obvious examples such as the presence of a branch ofﬁce .
It might be extremely minimal , indeed , resting upon little more than correspondence soliciting business from a resident of the court ’ s territory.40 In the context of criminal prosecutions , courts normally demand the physical presence of an accused before proceedings commence .
Some states allow courts to make exceptions to this rule and are prepared to conduct a criminal trial in absentia if the defendant can not be found within the territorial jurisdiction of the court .
Enforcement jurisdiction describes the authority of a state to enforce law .
This is sometimes described as police power , power to arrest and detain , authority to use force against persons , etc .
In civil matters , this may describe other methods used to project force over persons or property resident in a territory , such as seizing plant and equipment , evicting tenants from KA Law & Regulation | October 2019 Page 59 The Cyber Security Body Of Knowledge www.cybok.org property , garnishing wages , seizing funds on deposit with a bank , etc .
In practice , enforcement jurisdiction is limited by the ability of the state and its agents to project power over the objects of enforcement.41 3.2.2 Prescriptive jurisdiction It has long been commonplace for states to exert a degree of prescriptive and juridical jurisdiction over non-resident persons who solicit business relationships with residents .
A theory often espoused is that non-resident persons who remotely solicit or enter into business relationships with residents avail themselves of the beneﬁts of the domestic market and , therefore , become amenable to the rules of that market .
This principle long predates the Internet .
More controversial are cases where a non-resident person is not soliciting business from a state resident but may nonetheless be acting in a fashion which somehow harms state residents .
In this meeting the cartel members conspire to ﬁx the wholesale prices of a given commodity .
This kind of offshore price-ﬁxing conspiracy , which would be disallowed if it took place within the state ’ s territory , eventually results in inﬂated prices inside the state as well .
The only communication between the prohibited act ( price ﬁxing ) and the state is the price inﬂation in the overseas ( exporting ) market , which in turn causes inﬂation of domestic ( importing ) market prices .
The growth of international trade in the modern economy , however , caused courts to reconsider this position .
US courts decided in 1945 that extending prescriptive jurisdiction to foreign price-ﬁxing activity was justiﬁed due to the consequential harm to the domestic market and the sovereign interest in protecting the functioning of that market [ 113 ] .
Although these jurisdictional theories have been criticised , they are now exercised routinely .
States also claim prescriptive jurisdiction over some actions taken by their own nationals while present in a foreign state even if no express ’ effect ’ is claimed within the territory of the home state .
States may also claim prescriptive jurisdiction over violent acts committed against a state ’ s own nationals outside of the state ’ s territory by any person , especially in cases of terrorism.42 Instances where more than one state claims jurisdiction over a single act or occurrence are not uncommon .
Claims of prescriptive jurisdiction tend to be founded on notions of protecting the interests of a state and its residents .
Some of the rules of jurisdiction have been adopted with a view to reducing instances where persons might face irreconcilable conﬂict between the mandates of two states .
Although such irreconcilable conﬂicts are less common than some might believe , they still arise from time to time .
In cases where a person faces an irreconcilable conﬂict of mandates imposed by two states , the person is required to make hard choices .
For businesses , these choices often involve changing business processes , structure or governance to avoid or limit the potential for such conﬂicts .
KA Law & Regulation | October 2019 Page 60 The Cyber Security Body Of Knowledge www.cybok.org 3.2.2.1 Prescriptive jurisdiction over online content Numerous court decisions around the world have conﬁrmed the willingness of states to assert prescriptive jurisdiction over actions where criminal or tortious content originates from outside of the state ’ s territory , is transferred via the internet , and displayed within the state ’ s territory .
These exercises of jurisdiction do not necessarily rest on the more attenuated ’ effects doctrine ’ used in competition law .
Courts seem willing to interpret domestic law in a fashion which asserts prescriptive jurisdiction , and then to assert their own juridical jurisdiction on the basis that content is visible to persons within the state irrespective of the location of the server from which it originates .
3.2.2.2 Prescriptive jurisdiction over computer crime States adopting computer crime laws often legislate to include cross-border acts .
As a result , it is common for a state with such laws on their books to exercise prescriptive jurisdiction over persons – no matter where they are located – who take actions directed to computer equipment located within the state .
When a hacker who is physically present in one state directs offensive activity to a computer in another state , that hacker may violate the criminal law of both states .
If the relevant hacking activity does not constitute a crime in the ﬁrst state for whatever reason,43 it may still constitute a crime under the law of the second state where the target computer is located [ 120 , 121 ] .
GDPR , in common with its predecessor 1995 legislation , applies ﬁrst to any ’ processing of personal data in the context of the activities of an establishment of a controller or a processor in the Union , regardless of whether the processing takes place in the Union or not ’ ( Art .
The term ’ establishment of a controller ’ as used in EU data protection law generally , is extraordinarily broad when compared with other commonly understood legal principles .
Creating or maintaining an establishment in the territory of the EU merely means the ability to direct business affairs or activities .
This deﬁnition is not restricted by the usual niceties of corporate or international tax law .
Thus , legal persons that have no ’ permanent establishment ’ or ’ taxable presence ’ in the EU for purposes of analysing direct tax liability may nonetheless KA Law & Regulation | October 2019 Page 61 The Cyber Security Body Of Knowledge www.cybok.org be deemed to be carrying out data processing in the context of an ’ establishment ’ in the EU for the purposes of analysing GDPR liability .
GDPR now also asserts prescriptive jurisdiction over the personal data processing activities of any person , anywhere in the world , related to offering goods or services to data subjects in the EU ( Art .
Prescriptive jurisdiction is believed to extend only to circumstances when the supplier volitionally offers such goods or services to data subjects in the EU .
Finally , GDPR applies to any person who monitors the behaviour of data subjects located in the EU , to the extent that this monitored behaviour ’ takes place in ’ the EU ( Art .
This heading of jurisdiction appears to have been motivated primarily by the emergence of services which monitor and analyse a variety of human behaviours including actions performed by persons using web browsers , or physical movement patterns exhibited by persons on the ground such as shopping behaviour .
Persons located outside the EU , who are nonetheless subject to the prescriptive jurisdiction of GDPR because they offer goods or services to , or monitor the behaviour of , persons resident in the EU , are often required to appoint a representative in the EU ( Art 27 ; Recital 80 ) .
Interpreting the scope of GDPR ’ s territorial jurisdictional can be difﬁcult , especially given the rapid emergence of new forms of online services .
3.2.3 Enforcement jurisdiction While it is relatively easy to imagine a state exercising broad prescriptive and juridical jurisdiction over activities and controversies , more difﬁcult questions arise with respect to enforcement jurisdiction : how a state practically enforces its rules .
As a general proposition , one state has no right under public international law to exercise enforcement jurisdiction within the territory of another state ( [ 104 ] at R.11 ) .44 This section considers some of the more common enforcement mechanisms used by states in a cyber security context .
Enforcing the law tends to turn on three different mechanisms of state power : power over persons ( in personum jurisdiction ) , power over property ( in rem jurisdiction ) , and requests or demands for international assistance .
3.2.3.1 Asset seizure and forfeiture generally It is common to assert in rem jurisdiction over the property or other legal rights that are present within a state ’ s territory and amenable to that state ’ s police powers .
The state might seize such property in an effort to compel attendance at court proceedings , or eventually sell the property to meet the ﬁnancial obligations of an absent person .
Examples of objects seized for this purpose include immovable property such as ofﬁce buildings or factories , movable property such as plant and equipment , trucks , maritime vessels , or merchandise in transit , and intangibles such as intellectual property rights or rights to withdraw funds on deposit with a bank .
KA Law & Regulation | October 2019 Page 62 The Cyber Security Body Of Knowledge www.cybok.org 3.2.3.2 Seizure and forfeiture of servers , domain names , and registries When a server located in a state is used to conduct activity that constitutes a crime in that state , seizing the server as an enforcement mechanism might be considered .
Moving beyond the server , however , US law enforcement authorities have also used in rem jurisdiction for seizure and forfeiture of domain names where the domain TLD registry is maintained in the US .
Actions for infringement of trademark rights have used similar in rem powers for domain name seizure and forfeiture .
Similar in rem powers have been asserted by various states to regulate the administration of the ccTLD registry associated with their state , or to forcibly transfer the administration and operation of the ccTLD to a different in-state administrator [ 127 ] .45 3.2.3.3 Territorial location of the right to demand repayment of bank deposits Efforts to enforce laws that freeze or otherwise restrict depositor access to funds on deposit have raised difﬁcult questions about the territorial scope of state enforcement authority .
Asset freeze orders directed to enemy states or their citizens are not unusual , especially at times of international conﬂict .
A case highlighting limits of this power arose from the 1986 order issued by the United States mandating the freeze of assets held by the state of Libya .
This order by the Reagan administration was unusual .
In addition to mandating the freeze of money on deposit in the United States , it also ordered any US person who maintained effective control over any bank account anywhere in the world to freeze money on deposit in any of these global bank accounts .
The Libyan Arab Foreign Bank ( a state-owned Libyan bank ) took legal action against US banks in the courts of England demanding the repayment of deposits ( denominated in US dollars ) held in London branches .
The resulting English court judgment makes for interesting reading , as the court discussed at length the extensive role of electronic funds transfer systems in international banking at that time .
Having looked at the question , however , the dematerialised nature of funds transfers ultimately had almost no impact on the outcome of the case .
The court held that money deposited with the London branch of a bank constitutes a legal right for the depositor to demand payment of that money in England [ 128 , 129 ] .46 In other words , a bank account may be conceptualised as being situated within the territory of the state in which the branch to which the deposit is made is located .
This analysis continues to apply if the relationship is carried out entirely through online interactions , and indeed even if the depositor remains offshore and never attends the branch in person .
KA Law & Regulation | October 2019 Page 63 The Cyber Security Body Of Knowledge www.cybok.org 3.2.3.4 Foreign recognition and enforcement of civil judgments A civil judgment issued by the court of one state may under certain circumstances be enforced by the courts of a friendly second state .
This is normally achieved when the prevailing party transmits the judgment to the courts of the second state where the adverse party has assets , requesting enforcement of the judgment against those assets .
Foreign recognition and enforcement of civil judgments is often granted under the principle of comity : a doctrine which can be expressed in this context as , ’ We will enforce your civil judgments because , as a friendly state , we anticipate you will enforce ours .
Requests for civil enforcement are sometimes rejected for policy reasons .
Nonetheless , this remains a relatively common mechanism in the context of judgments for money damages arising from many contract and tort disputes .
3.2.3.5 The arrest of natural persons in state territory It is normally straightforward for police ofﬁcers to arrest persons present within their state ’ s territory .
When a criminal suspect is outside the state ’ s territory , ofﬁcials are sometimes able to arrest that suspect when they subsequently appear in state – whether or not it was an intended destination .
Law enforcement ofﬁcers can normally arrest the accused upon their arrival in state territory.48 State authorities can normally exercise the power of arrest on any seagoing vessel within the state ’ s territorial waters , as well as vessels registered under the ﬂag of the arresting state when in international waters .
Extradition is normally governed by bilateral extradition treaties , and is normally only allowed when the alleged criminal act constitutes a crime in both states ( the requirement of dual criminality ) .
If two states that are contracting parties to the Budapest Convention ( see Section 3.5.1 ) maintain a bilateral extradition treaty between them , the Convention obliges them to incorporate within their extradition procedures those computer crimes mandated by the Convention .
Extradition requests for accused cyber criminals might be denied by another state for a number of reasons : lack of an extradition treaty between the two states , lack of dual criminality , public policy concerns over the severity of punishment to be imposed by the requesting state , and concerns for the health or welfare of the accused , are all reasons that have been cited for refusal to grant the extradition of persons accused of cybercrime [ 107 ] .
KA Law & Regulation | October 2019 Page 64 The Cyber Security Body Of Knowledge www.cybok.org 3.2.3.7 Technological content ﬁltering Technological intervention can be adopted as a practical expression of state power – either by a state directly ordering such intervention , or by other persons adopting a technical intervention to avoid or limit liability .
Content ﬁltering is merely one type of technological intervention that can be used to enforce law or to reduce the risk of adverse enforcement activity .
This approach ﬁts generally within the concept explored by Lawrence Lessig and expressed with the phrase , ’ code is law ’ [ 98 ] .49 An enforcing state can direct an enforcement order to a person mandating that they ﬁlter content at the point of origination , whether the content is hosted on an in-state or out-of-state server [ 119 ] .
Such an order carries with it the implicit or explicit threat that failure to implement the order could result in the use of other , more aggressive , enforcement mechanisms directed to in-state persons or property .
If an out-of-state person who originates or hosts offending online content from out-of-state infrastructure fails or refuses to ﬁlter it , the enforcing state might look to other technologicallybased enforcement methods .
Although such technical mechanisms are far from perfect ( as is the case with any border enforcement technology ) , they may be sufﬁciently effective to accomplish the purpose of the enforcing state .
Filtering efforts are also initiated in the absence of speciﬁc state enforcement activity .
Persons create and impose their own ﬁlters at point of origin to limit content transfers to states where ﬁltered content might result in liability.50 Filtering efforts can be conducted collaboratively between private and public sector actors.51 3.2.3.8 Orders to in-state persons directing production of data under their control whether held on domestic or foreign IT systems States may also order state-resident persons to produce data under their control , irrespective of the territorial location of data storage .
Such orders are especially common under court procedural rules that govern disclosure ( a.k.a .
Those who ﬁnd themselves party to a dispute that is subject to the jurisdiction of a foreign court must quickly become familiar with that court ’ s rules of mandated disclosure .
Courts normally do not feel constrained by the location of potential evidence – only that the parties to the dispute disclose it as required according to forum court rules .
More controversial are cases where a state , often in the context of a criminal investigation or intelligence gathering operation , demands the production of data under the control of a state-resident person who is not the target of ( criminal ) investigation or a party to ( civil ) legal action .
Critics claim that such demands are inappropriate and the state should be limited to submitting requests for international legal assistance ( see Section 3.2.3.9 ) .
Supporters argue that such demands represent a legitimate exercise of state enforcement jurisdiction against persons present within state territory .
An early example involved a previously secret program in which the United States demanded lawful access to banking transaction records held by SWIFT .
The orders to produce data were addressed to US-resident SWIFT ofﬁces .
Failure to comply with the US demands could have resulted in criminal prosecution of US-resident persons under US law .
This diplomatic issue was eventually resolved through negotiation and agreement concerning the scope of future investigatory operations [ 132 ] .
Another well-known example involved a request made by an unknown agency of the US government under the Stored Communications Act .
The government asked the US court to issue an order to the Microsoft Corporation in the US demanding the production of the contents of an email account maintained by Microsoft on behalf of an unnamed customer who was not resident in the US .
The US court issued the order to Microsoft in the US , although the email account itself was maintained on a server in a data centre in Dublin , Ireland .
US-resident staff of Microsoft had the technological ability to access the contents of the Dublin server , and the act of producing the requested data would have been technologically trivial .
Microsoft asked the court to quash ( invalidate ) this order , generally on the grounds that the relevant US law did not authorise an order of this type with respect to data stored offshore .
After multiple skirmishes in the District court , the US Court of Appeals ( 2nd Circuit ) eventually quashed the order against Microsoft on the extremely narrow basis that the Stored Communications Act ( adopted in 1986 ) did not expressly and unambiguously claim prescriptive jurisdiction over data stored on equipment located outside the territorial United States [ 133 , 134 , 135 ] .52 This decision was appealed to the US Supreme Court where it was fully briefed and argued .
Following argument but before judgment , the US Congress in 2018 adopted the CLOUD Act .
This legislation amended the Stored Communications Act to bring data stored on foreign servers expressly into the prescriptive jurisdiction of that Act , and the US government immediately requested a replacement warrant under the revised law .
The Supreme Court then dismissed the pending appeal without issuing a substantive judgment , as the new law had resolved any dispute about the scope of prescriptive jurisdiction claimed by the US Congress [ 136 ] .53 3.2.3.9 International legal assistance States can make requests for assistance from persons outside of their territory to gather evidence in support of criminal investigation .
Traditionally , such requests are made pursuant to a mutual legal assistance treaty and are transmitted by the authorities of a ﬁrst state to the designated authority of a second state for consideration and possible action .
Such requests can also be made in the absence of a treaty , although the second state retains discretion over how it chooses to respond in the absence of international legal obligation .
The Convention also sets a series of requirements concerning preservation of electronic evidence , including metadata .
Although there are many examples of successful international cooperation in the investigation of cybercrime , it has been observed that ’ the use of formal cooperation mechanisms occurs on a timescale of months , rather than days ’ [ 137 ] .
There are some options available to gather cross-border evidence that do not involve seeking permission from the state in which evidence resides .
The Budapest Convention provides two additional methods .
Convention State A is also said to be allowed to use a computer in the territory of State A to access data from a closed source in Convention State B if State A ’ obtains the lawful and voluntary consent of the person who has the lawful authority to disclose the data ’ [ 120 ] at Article 32b .
An ad hoc subgroup of this Committee set out an extensive discussion of issues arising and speciﬁc examples in which use of this authority might be considered [ 139 ] .
If State A is unable to demonstrate that a proposed evidence gathering activity complies with Article 32b this only means that the activity is not expressly authorised by the Budapest Convention .
Article 32 of the Convention would not prohibit the proposed activity , although some other features of public international law might .
Critics argue that Article 32b constitutes an unwelcome intrusion into state sovereignty .
Another cross-border investigation method in the absence of consent by the second state is described in Section 3.2.3.8 .
3.2.4 The problem of data sovereignty The phrase ’ data sovereignty ’ is sometimes used to struggle with the various jurisdictional demands outlined above .
The extremely low technological cost of storing and then retrieving data outside the territory of a state , raises concerns about the number of states that might seek to compel some form of intervention with respect to such data .
The location of a service provider ’ s infrastructure and the location of persons who maintain effective control over that infrastructure are both important for understanding which states might be able to assert enforcement jurisdiction mandating some type of intervention with respect to such data [ 142 ] .55 Users of cloud services have become increasingly aware that locating a data storage facility in any given state increases that state ’ s opportunity to exercise enforcement jurisdiction over such facilities .
Practitioners should also consider enforcement jurisdiction opportunities presented to a state when persons within its territory have technical or organisational ability to access or otherwise interfere with data held on infrastructure physically outside that state .
Enforcement risk can arise from the geo-location of data storage equipment , or the geo-location of persons able to access such data.56 Some states have responded to potential jurisdictional conﬂicts by mandating local storage and processing ( localisation ) for some types of data .
Indeed , under its data protection laws the European Union has long imposed an EEA localisation requirement ( in the form of a rule KA Law & Regulation | October 2019 Page 67 The Cyber Security Body Of Knowledge www.cybok.org prohibiting export ) for personal data although in practice there are multiple mechanisms available to enable exports from the EEA ( see Section 3.4.6 ) .
Some states within the EEA have imposed single-state data localisation rules for certain types of sensitive data , prohibiting exports even to fellow member states of the EEA .
Possibly in response to this single state localisation trend , the European Union adopted a Regulation in 2018 that prohibits member state legal restrictions on the free movement of non-personal data within the Union .
This Regulation also includes multiple exceptions for member states that wish to impose localisation requirements for reasons of important public policy [ 148 ] .57 3.3 PRIVACY LAWS IN GENERAL AND ELECTRONIC INTERCEPTION The concept of ’ privacy ’ is both widely cited and challenging to articulate .
In this context , privacy has been described simply as the right for a person58 to be free from intrusion by others into personal affairs or the ’ right to be left alone ’ .
In the work of a cyber security practitioner , the issue of privacy most often arises in the context of electronic surveillance and related investigatory activity , which is the focus of this section .
This area of law can be expected to continue to evolve quickly in response to new use cases enabled by cloud data processing services .
Data protection law is addressed in Section 3.4 and crimes against information systems are considered in Section 3.5 .
Most of these areas of law stem from or are related to privacy concepts .
3.3.1 law International norms : foundations from international human rights Privacy is widely recognised internationally as a human right , although not an absolute right.59 The right to privacy is conditional – subject to limitations and exceptions .
Similar expressions , with similar qualiﬁcations , can be found in Article 8 of the European Convention on Human Rights and again in Article 7 of the Charter of Fundamental Rights of the European Union [ 151 ] .60 In the more narrow context of limiting government authority , the Fourth Amendment of the US Constitution adopted in 1791 states , ’ The right of the people to be secure in their persons , houses , papers , and effects , against unreasonable searches and seizures , shall not be violated , and no warrants [ authorizing search or seizure ] shall issue , but upon probable cause .
The application of these principles to intangible data evolved signiﬁcantly during the twentieth century .
Four decades later , after electronic communication had become a ubiquitous feature of everyday life , the Court changed its position and re-interpreted the Fourth Amendment to protect persons from unwarranted intrusion into electronic communications .
The privacy right expressed in the European Convention on Human Rights has long been understood to apply to electronic communications [ 155 ] .
By the early twenty-ﬁrst century it appears to have become a widely accepted international norm that privacy rights ( however they are interpreted ) apply to intangible expressions of information as well as physical space [ 156 ] .
While the principles described above are widely accepted in the international community , the interpretation and implementation of these principles remains subject to signiﬁcant divergence .
Some laws extend a general right of privacy into almost every situation , while others focus solely on limiting the power of the state to intrude into private affairs.61 A given person ’ s expectation of privacy may vary by reference to the nature of their relationship with the party who seeks to intrude .
For example , there tend to be few restrictions imposed by any state ’ s laws with respect to intrusion by a parent into the affairs of their minor children .
By contrast , states vary signiﬁcantly when considering when it is appropriate for employers to intrude into the affairs of their employees .
Expectations of privacy can also vary signiﬁcantly between different societies .
An intrusion viewed by one society as relatively innocuous and to be expected might be viewed by another society as a breach of human rights .
As persons rely on cloud services to manage increasingly intimate aspects of their lives , expectations of privacy over the variety of data processed using these systems will continue to evolve.62 Policy makers , service providers , and civil society organisations , regularly seek to explain or to adjust expectations of privacy through education and advocacy .
An additional aspect of privacy relates to limits imposed upon the degree of permitted intrusion .
In cases of state-warranted lawful interception , for example , warrants may be narrowly drawn to limit interception to named places , speciﬁed equipment , speciﬁed persons , or speciﬁed categories of persons .
Privacy laws often treat metadata differently from content data , usually based on the theory that persons have a lower expectation of privacy in metadata [ 158 ] .63 This distinction is increasingly criticised , and policy makers and courts are under pressure to reconsider the nature of metadata given : • the private quality of some information disclosed by modern metadata such as URLs,64 • the incredible growth in the volume and types of metadata available in the age of ubiquitous personal mobile data communications ; 65 and • the growing volume of otherwise-private information that can be inferred from metadata using modern trafﬁc analysis and visualisation techniques.66 KA Law & Regulation | October 2019 Page 69 The Cyber Security Body Of Knowledge www.cybok.org 3.3.2 Interception by a state State intrusion into electronic communication for purposes of law enforcement or state security is often treated under specialist legal regimes that are highly heterogenous .
There is broad agreement in public international law dating to the mid-nineteenth century that each state has the right to intercept or interrupt electronic communications in appropriate circumstances [ 159 ] .
Although legal governance processes and standards adopted to authorise state interception have evolved signiﬁcantly , these legal processes and standards differ signiﬁcantly from state to state .
Some states require a prior examination of each request for state interception by an independent judicial ofﬁcer ; some delegate this decision-making authority broadly with limited oversight ; and others adopt mechanisms that fall anywhere between these extremes .
Although there does not yet appear to be any obvious international harmonisation of legal standards and procedures concerning lawful interception , there are examples of recommended practice for states that wish to place their legal procedures onto a robust and predictable foundation [ 162 ] .
These technical standards make it possible for product and service developers to design lawful access technologies to a common multinational standard , while leaving substantive decision-making about their use in the hands of domestic authorities.67 Practitioners who work in a police or state security environment must become familiar with the rules that apply to their interception activity .
Some state organisations employ large teams of lawyers dedicated solely to assessing the legality of various intelligence-gathering and investigation activities .
Those who work for communication service providers must also become familiar with obligations imposed on them by applicable laws to assist in state interception activity .
This can be especially challenging for multinational communication service providers , as they are normally subject to the prescriptive jurisdiction of each state where their service is supplied.68 Service providers often localise responsibility for compliance with lawful interception by domestic authorities in each state where they supply services .
State regulations concerning lawful interception tend to impose a combination of obligations upon the providers of public communications services , such as : • procuring and maintaining facilities designed to facilitate lawful interception within the service provider ’ s domain ( this obligation may be imposed under telecommunication regulation as a condition of telecommunications licensing , especially for those that operate in-state physical infrastructure such as PSTN operators ) ; • providing technical assistance in response to lawful interception requests ; and • maintaining the secrecy of the content of lawful interception requests , especially the identity of investigation targets .
KA Law & Regulation | October 2019 Page 70 The Cyber Security Body Of Knowledge www.cybok.org Some states impose additional legal obligations to maintain secrecy over the existence , nature , or frequency , of lawful interception requests , the location or operation of interception facilities , etc .
Communication service providers that wish to report publicly about the nature and frequency of state interception requests ( a.k.a .
transparency reports ) must be careful to conduct this reporting in compliance with applicable law.69 As easy-to-use cryptographic technologies have become ubiquitous , and larger volumes of message trafﬁc are transmitted as ciphertext , states conducting lawful access activity face increasing difﬁculty obtaining access to plaintext messages [ 161 ] .
States have attempted to recover plaintext by using a variety of creative legal mechanisms including warrants for the physical search and seizure of end point devices and requests for technical assistance from device manufacturers or third-party analysts .
Efforts to compel an end user to decrypt ciphertext or to disclose relevant passwords or keys also face a variety of legal challenges [ 165 , 166 ] .70 Some states have adopted laws that speciﬁcally address compelled disclosure of plaintext or keys that enable decipherment.71 The emergence of virtual communication service providers ( i.e .
These service providers remain subject to the jurisdiction of states in which their service is supplied , as states show a clear sovereign interest in services provided to persons within their territory.72 States have , however , taken different approaches when choosing how and when to exercise jurisdiction over these providers .
Enforcement actions by states against such persons have included orders to facilitate in-territory lawful interception at the risk of a variety of sanctions including : prohibiting the service provider from entering into business relationships with in-state residents , or ordering third-party state-resident service providers to block or ﬁlter such services at the PSTN or IP layer , thus making it inaccessible to ( many or most ) in-state residents .
Changes in enforcement practices are likely as this subject continues to develop .
3.3.3 Interception by persons other than states Laws concerning interception activity by non-state actors are also highly heterogenous .
This might be framed legally as a restriction imposed only on providers of these public services , or a more general restriction limiting the ability of any person to intercept communications on public networks .
The interception of communications by a person during the course of transmission over its own non-public network , such as interception on a router , bridge or IMAP server operated by that person on their own LAN for purposes other than providing a public communications service , presents other challenges to analysis .
This type of interception activity would not normally expect to fall foul of traditional computer crime legislation , as the relevant person is normally authorised to gain entry to the relevant computer ( see Section 3.5 ) .
From an evidentiary perspective , a person whose privacy rights have been violated might never learn that a violation has occurred .
Some legal rules serve , among other things , to redress this knowledge imbalance .
These include breach notiﬁcation requirements which reveal inappropriate disclosures of personal data to the effected person ( see Section 3.4.7 ) , criminal procedure rules that require the disclosure of prosecutorial evidence to the accused which in turn reveals intrusive investigatory techniques,73 and civil procedure rules which require similar disclosures in civil legal actions ( e.g .
Remedies available to persons whose privacy rights have been violated might include the ability to bring a tort action against the violator claiming monetary compensation ( see Section 3.7.4 ) .
These individual tort remedies are a regular feature of data protection laws as well as various US privacy laws .
The US criminal courts also employ an exclusionary rule prohibiting the introduction of evidence gathered in violation of the US Constitutional privacy rights of the accused [ 168 ] .74 Finally , some violations of privacy – especially unwarranted interception of communications during the course of transmission on a public network or unauthorised intrusions into data at rest – are deﬁned as and may be prosecuted as crimes [ 169 ] .
This generalisation can be a bit misleading , however , as data protection law has evolved to address a number of related issues that arise from modern data processing techniques that might not traditionally have been deﬁned as ’ privacy ’ .
Data protection is of signiﬁcant interest to cyber security practitioners , as it includes numerous obligations related to data security .
Data protection law is not , however , a generalised system of regulations that address every aspect of cyber security .
The focus remains on speciﬁc principles adopted to support individual rights in a data processing context .
Data protection law has developed primarily from European legislative initiatives .
European Union law has been tremendously inﬂuential around the world through various mechanisms , including states seeking ’ adequacy determinations ’ from the European Union , which enable exports of personal data , and private law contract requirements imposed upon non-EU resident data processors [ 172 ] .
This international impact continues to grow as the EU now expressly claims prescriptive jurisdiction over personal data processing activity anywhere in the world that relates to data subjects present in the EU ( see discussion in Section 3.2.2.3 ) .
Practitioners engaged by a state in conduct related to investigation or prosecution of crime must be aware of the modiﬁed obligations that apply to that activity described by Directive 2016/680 as transposed into member state law [ 174 , 175 ] . ) .
.76 Data protection law accomplishes this by regulating acts of controllers and processors when processing data that incorporates personal data .
Any such processing activity activates the application of data protection law .
Each of these terms is considered in this section .
GDPR does not apply to personal data of deceased natural persons , although member states may individually adopt such protections if they wish ( GDPR at Recital 27 ) .
Because the deﬁnition of data subject extends to persons who are identiﬁed or identiﬁable , data can incorporate personal data even when the data include no obvious information identifying a data subject .
It is sufﬁcient that a data subject is capable of being identiﬁed , by anyone , through analysing the data or by applying additional information known to any person - even if this additional information is unknown and inaccessible to the person controlling or processing data .
The Court of Justice of the European Union has held that a server log with IP address numbers incorporates personal data , as it remains possible for third parties ( telecommunications service providers ) to match static or dynamic IP numbers to individual customer premises and from there to a living person .
The fact that the holder of the server logs did not have access to the IP number allocation or customer identiﬁcation data was irrelevant .
As de-anonymisation and similar analysis techniques increase the capability to identify living persons from data that has no obvious personal identiﬁers , it becomes increasingly difﬁcult to maintain data sets that are truly devoid of personal data [ 177 , 178 ] .77 The term ’ personal data ’ is often confused in practice with ’ personally identiﬁable information ’ ( PII ) .
This confusion arises because of the ubiquity of the term ’ PII ’ in cyber security as well as signiﬁcant variance in its deﬁnition .
Although it is arguable whether the ISO and KA Law & Regulation | October 2019 Page 73 The Cyber Security Body Of Knowledge www.cybok.org NIST deﬁnitions of PII are contiguous with the legal deﬁnition of personal data , both technical standards clearly conclude that data containing no obvious personal identiﬁers may nonetheless constitute PII .
Complicating matters further , the phrase ’ personally identiﬁable information ’ is used in a variety of US federal statutes and regulations , either without statutory deﬁnition , or with deﬁnitions speciﬁcally addressed to individual use cases [ 181 ] .78 In this speciﬁc context , some US courts have interpreted this phrase narrowly to include only obvious personal identiﬁers .
Thus some US courts have held that data such as MAC codes and IP numbers do not fall within the meaning of ’ personally identiﬁable information ’ as that phrase is used in some US statutes [ 182 , 183 , 184 ] .79 As explained above , these same identiﬁers often constitute ’ personal data ’ as that term is deﬁned in European law .
Irrespective of how one deﬁnes PII , European data protection law contains a clear and broad deﬁnition of ’ personal data ’ .
It is this deﬁnition of personal data , not PII , that triggers the application of European data protection law.80 3.4.1.2 Processing In data protection law , the term processing is deﬁned as : any operation or set of operations which is performed on personal data or on sets of personal data , whether or not by automated means , such as collection , recording , organisation , structuring , storage , adaptation or alteration , retrieval , consultation , use , disclosure by transmission , dissemination or otherwise making available , alignment or combination , restriction , erasure or destruction ( GDPR , Art 4 ( 2 ) ) Processing therefore incorporates almost any action one can imagine taking with respect to personal data .
3.4.1.3 Controller and processor In data protection law , the term controller is deﬁned as : the natural or legal person , public authority , agency or other body which , alone or jointly with others , determines the purposes and means of the processing of personal data ; where the purposes and means of such processing are determined by Union or Member State law , the controller or the speciﬁc criteria for its nomination may be provided for by Union or Member State law ( GDPR , Art 4 ( 7 ) ) In data protection law , the term processor is deﬁned as : a natural or legal person , public authority , agency or other body which processes personal data on behalf of the controller ( GDPR , Art 4 ( 8 ) ) These deﬁnitions make clear the relationship between controller and processor .
In the history of data protection law , many policy makers originally believed that the most effective way to protect individual rights was to focus regulation on persons who operated and maintained computer equipment – processors .
The focus was on the machine .
As the PC revolution changed our social relationship with computers , KA Law & Regulation | October 2019 Page 74 The Cyber Security Body Of Knowledge www.cybok.org however , policy makers began to appreciate that the focus should be turned to persons in a position to command and control how the machines were used – controllers .
As between these two persons , Directive 95/46 tended to place the heaviest regulatory burden on controllers .
Processors were advised that their obligation consisted primarily of following directions provided by controllers .
There are many valid reasons for placing primary compliance responsibility on data controllers , especially because they are most often able to communicate and manage relationships with the relevant data subjects .
This regulatory distinction started to break down as cloud services became ubiquitous – especially SaaS .
A typical SaaS provider might spend an enormous amount of time and effort designing their system and user interfaces , and then present the operational characteristics of that system to controller-customers in a service level agreement on a ’ take it or leave it ’ basis .
As a technical matter , the SaaS provider might be keen to demonstrate that they are acting only in the capacity of a processor and that their customers are acting as controllers – shifting the burden of assessing compliance to individual controllers .
In the revisions to data protection law embodied in GDPR , policy makers have responded by generally increasing the regulatory responsibility of processors .
Compliance responsibility under GDPR is now more evenly shared by controllers and processors , although their responsibilities depend upon their respective area of competence .
Practitioners should be especially alert to the presence of certain types of sensitive personal data in any system with which they are involved .
Sensitive personal data triggers a series of additional protections and generally increased levels of regulatory scrutiny , as improper use of such data often presents a disproportional risk to the interests of the data subject .
As a threshold matter , data subject consent is not always required when processing personal data .
There may be multiple lawful grounds for processing personal data other than consent depending upon context .
A series of conditions that apply to consent are set out in GDPR , Art 7 ( and Art 8 relating to children ’ s consent ) .81 3.4.3 Investigation and prevention of crime , and similar activities Practitioners engaged by a state beneﬁt from certain reductions in data protection obligations when processing personal data related to criminal investigation and prosecution .
These reduced obligations are described in general in Directive 2016/680 and then transposed into member state law .
Practitioners who conduct activities with similar goals , but are not engaged by a state , remain subject to GDPR .
GDPR also provides member states with the option to adopt in their domestic laws reduced data protection obligations for non-state actors when conducting activities designed to prevent , investigate , detect , or prosecute crime , etc .
Compliance requires that both components are appropriate .
Compliance requires a consideration of the state of the art and an assessment of costs of various measures in comparison with risks presented .
Assessing this obligation to take appropriate security measures might therefore be aided by analogy with the law of negligence which presents various frameworks used to assess ’ reasonable ’ care ( see discussion in Section 3.7.1.2 ) .
GDPR has expanded signiﬁcantly the discussion of security measures to provide examples of measures that might assist in creating appropriate security .
This includes many past practices that developed organically such as pseudonymisation and encryption of personal data , assuring ongoing conﬁdentiality , integrity , availability and resilience of systems , and robust incident recovery plans .
To be clear , GDPR does not expressly mandate encryption of all personal data .
It simply highlights encryption as a technical measure that can be adopted to enhance security .
As encryption methods or other security technologies become standardised and costs fall , however , it becomes increasingly difﬁcult to justify why such technologies are not adopted .
Organisational methods used to protect the security of personal data may include contract obligations with supply chain partners and others .
KA Law & Regulation | October 2019 Page 76 The Cyber Security Body Of Knowledge www.cybok.org 3.4.5 Assessment and design of processing systems Sometimes , the most effective way to prevent violations of data protection law is to design a system that minimises the ability of persons to take inappropriate action .
GDPR , therefore , has adopted an obligation to implement data protection strategies by design , and by default .
As with the general security principle , this obligation extends to both technological and organisation measures and is assessed on a risk balancing basis .
If a new personal data processing activity presents signiﬁcant risk of harm to data subjects , especially in the context of developing or migrating to systems that process large volumes of data , the controller is required to undertake a data protection impact assessment ( GDPR , Art 35 , Recital 91 , et al . ) .
If the assessment reveals signiﬁcant risks , the controller is further required to consult with the relevant supervisory authority about the proposed processing activity ( GDPR , Art 36 ) .
3.4.6 International data transfer European data protection law imposes a general prohibition on the transfer of personal data to any state outside the European Economic Area or to any international governmental organisation ( GDPR , Art 44 ) .
Such transfers remain commonplace , however , when enabled by an appropriate export compliance mechanism .
3.4.6.1 Adequacy determinations and Privacy Shield Transfers of personal data can be made to territories in accordance with an adequacy decision : a ﬁnding by the European Commission that the receiving territory ( or IGO ) has established adequate legal protections concerning personal data ( GDPR , Art 45 ) .
The process of obtaining an adequacy decision is instigated at the request of the proposed receiving state and often requires years of technical evaluation and diplomatic negotiation [ 172 ] .
Adequacy determinations fall into two categories : decisions that a receiving territory ’ s laws are generally adequate to protect personal data , and decisions that a receiving territory ’ s laws are adequate provided that special conditions are met .
Decisions concerning Canada and the United States both fall into the second category .
In the case of Canada , adequacy is only assured with respect to transfers to the commercial for-proﬁt sector , as the relevant Canadian laws do not apply to processing by governments or charities .
The US has nothing like the EU ’ s generalised legal protections concerning processing personal data .
To enable transfers of data , the US and the EU have negotiated speciﬁc agreements to support an adequacy ﬁnding .
This agreement enables most US businesses , if they wish , to opt in to a regulatory system that provides adequacy .
This regulatory system is then enforced by agencies of the US state against opted-in US businesses .
It was quickly replaced by the EU-US Privacy Shield regime in 2016 , which operates in a fashion similar to Safe Harbour with enhanced protections for data subjects .
The most common safeguards normally encountered are binding corporate rules , and approved data protection clauses in contracts between exporters and importers .
Binding corporate rules are governance procedures normally adopted by multinational enterprises in an effort to demonstrate to data protection authorities that they will comply with data protection principles ( GDPR , Art 47 ) .
To be effective for data transfer compliance , such rules must be approved by relevant public authorities .
This can take years to negotiate .
While such rules were originally developed as a tool to enable sharing of personal data among the members of a multinational data controller enterprise that operates both inside and outside the EEA , they have more recently been adopted by non-resident cloud service providers as a compliance tool to facilitate business from customers in the EEA .
Practitioners may be called upon to assist in drafting or negotiating binding corporate rules , as they have a signiﬁcant impact on IT services , security architectures and governance procedures .
Approved contract clauses are simply contract obligations between a data exporter and importer that serve to protect the interests of data subjects .
Although the Commission-approved clauses are standardised , to be effective the parties to the relevant contract are required to incorporate a signiﬁcant amount of operational detail about the nature of the personal data to be transferred , the purposes of the data processing to be undertaken , etc .
3.4.6.3 Transfers pursuant to international mutual legal assistance treaty Transfers of personal data that are otherwise prohibited by GDPR can be made in circumstances such as requests for assistance by a foreign state police agency pursuant to the terms of a mutual legal assistance treaty ( GDPR , Art 48 ) .
3.4.6.4 Derogations allowing transfers In the absence of any other mechanism allowing a transfer , exports from the EEA are still allowed under certain limited circumstances such as : • the data subject provides knowing informed express consent to the transfer ; • the transfer is necessary in order to perform a contract with the data subject , or a contract with a third party adopted in the interests of the data subject ; • the transfer serves an important public interest ; • the transfer is connected to the pursuit or defence of a legal claim ; or • the transfer is necessary to protect the life or welfare of the data subject , who is physically unable to consent .
In a pattern that is curiously the reverse of the development of data protection laws generally , EU notiﬁcation requirements arose ﬁrst in narrowly deﬁned subject matter areas while US states ( beginning with California ) imposed a more general duty to notify effected persons of personal data breaches.83 GDPR marked the emergence in Europe of a general duty placed on processors and controllers of personal data to make certain notiﬁcations following a ’ personal data breach ’ , which is deﬁned as ’ a breach of security leading to the accidental or unlawful destruction , loss , alteration , unauthorised disclosure of , or access to , personal data transmitted , stored or otherwise processed ’ ( GDPR , Art 4 ( 12 ) ) .
Thus , events as diverse as personal data exﬁltration , the unauthorised modiﬁcation of personal data and ransomware can all constitute personal data breaches .
There is a limited exception to the controller ’ s duty to notify a supervisory authority if the breach is ’ unlikely to result in a risk to the rights and freedoms of natural persons ’ .
Whether or not notiﬁed to the supervisory authority , the controller is required to document all such breach events and these records are subject to periodic review by the supervisory authority .
Communication to the data subjects can be avoided if the controller has implemented methods that limit the harm that might be caused by such a breach , such as encrypting data that was then exﬁltrated as ciphertext .
While such ciphertext remains personal data for legal purposes , the encrypted state of the data reduces the potential harm to data subject to some degree ( depending upon the type of encryption , etc . ) .
This ability to avoid communication to data subjects when harm is unlikely is a useful feature of GDPR .
Many US state notiﬁcation laws originally demanded notifying data subjects irrespective of the relevant risks presented by the breach.84 Supervisory authorities retain the right to compel communication to data subjects about the breach if they disagree with the controller ’ s risk assessment .
Various states around the world continue to adopt mandatory breach disclosure laws , each with their own unique characteristics [ 192 ] .
KA Law & Regulation | October 2019 Page 79 The Cyber Security Body Of Knowledge www.cybok.org 3.4.8 Enforcement and penalties Egregious violations of data protection law can be prosecuted as crimes under member state domestic law .
Data protection laws also enable data subjects to bring tort claims for violation of data protection rights .
Such claims implicate the risk of vicarious liability for employee misdeeds , especially if a large group of data subjects are able to bring a claim as a group or class .
( See the discussion of the Morrisons case at Section 3.7.5.1 ) Public enforcement authorities are also given powers to serve enforcement notices , demanding changes in processing behaviour to achieve compliance with the law ( GDPR , Art 58 . ) .
In particularly egregious cases , public authorities might serve a notice prohibiting large categories of processing activity .
Breaching such an enforcement notice is an independent cause for more severe enforcement action .
Perhaps the greatest change to legal risk presented by EU data protection law in the past few decades has been the steady and accelerating increase in the size of penalties assessed by public authorities .
Historically , civil or administrative ﬁnes imposed by public authorities for violation of data protection law were perceived in some member states as relatively minor .
The disparity in approach among member states to data protection law was a motivating factor for the adoption of the original 1995 Directive , which tended to increase data protection rights in most member states .
Following the 1995 Directive , increasingly larger ﬁnes started to emerge as state authorities began to increase enforcement pressure .
By the time GDPR was adopted in 2016 , administrative ﬁnes in the region of e500,000 were not uncommon for signiﬁcant violations of the law .
Violations of some of the more procedural or operational requirements of GDPR , including the requirement to adopt appropriate security measures , can incur administrative ﬁnes of up to e10,000,000 , or 2 % of an undertaking ’ s annual worldwide turnover , whichever is greater .
Violations of more fundamental principles of GDPR , such as failure to respect the rights of data subjects , processing personal data without lawful authority , or exporting data in violation of the law , can incur administrative ﬁnes of up to e20,000,000 , or 4 % of an undertaking ’ s annual worldwide turnover , whichever is greater .
Authorities are instructed to calculate ﬁnes at a level to make them ’ effective , proportionate and dissuasive ’ in individual circumstances .
The emergence in GDPR of the potential for ’ eight ﬁgure ’ and ’ nine ﬁgure ’ ﬁnes , together with the increased scope of territorial jurisdiction , instantly promoted data protection law into the category of a signiﬁcant risk to be assessed and managed at senior leadership levels – a position that this law had rarely occupied prior to these changes .
Some persons who provide online information services from outside the EU ( who presumably fear that their business models are not compatible with GDPR compliance ) responded by withdrawing from the European market by using geographic ﬁltering mechanisms ( see Section 3.2.3.7 ) .
Other offshore service providers have embraced the change and worked to comply with the rules ( presumably as they value their ongoing contact with the European market ) .
KA Law & Regulation | October 2019 Page 80 The Cyber Security Body Of Knowledge www.cybok.org In July 2019 , the Information Commissioner ’ s Ofﬁce of the United Kingdom issued two notices of their intention to issue large ﬁnes under GDPR : a proposed ﬁne of GB£183.39 million to British Airways85 and a proposed ﬁne of GB£99.2 million to Marriott International , Inc.86 At time of writing , both companies have expressed their intention to contest the ﬁnes .
This section is addressed solely to the last category , computer crimes or crimes against information systems .
These tend to be of concern as they are of interest to those who work for state enforcement authorities , as well as those who manage cyber security risk , research cyber security technologies , and develop cyber security products and services .
Although some practitioners are engaged by states in the investigation and prosecution of crimes where cyberspace is an instrumentality of crime , it is difﬁcult to draw out generalisable statements about those crimes that remain useful in a multinational context .
Crimes based on message content are especially problematic , as these rest upon widely diverging opinion from different societies about what constitutes ’ illegitimate ’ content worthy of criminal prosecution.87 ( One area in which there appears to be growing international consensus for criminalising message content concerns child exploitation materials [ 110 , 120 , 194 ] .
Even with this subject matter , where high level normative principles may be quickly agreed , attempting to translate these principles into widely agreed legal standards remains challenging [ 111 ] . ) .
3.5.1 Crimes against information systems In the 1980s and 1990s , many states confronted the problem that an emerging set of antisocial behaviours related to cyberspace infrastructure were not clearly identiﬁed as crimes.88 The UK Parliament responded by adopting the Computer Misuse Act 1990 , which deﬁned a series of computer-related criminal offences .
In 1984 , the US Congress adopted the Computer Fraud and Abuse Act , which has also been regularly amended [ 196 , 197 ] .89 Many US states have additionally adopted their own statutes to prosecute computer crime.90 The US landscape is especially complex , as a variety of federal and state law enforcement agencies have varying subject matter jurisdiction over computer crimes [ 110 ] .
Similar laws have been adopted by many , but not all , states around the world .
This mandates that member states modify their criminal laws to address commonly recognised computer crimes which the Directive describes as crimes ’ against information systems ’ [ 121 ] .
This introductory section on crimes against information systems is inﬂuenced by the taxonomy adopted by the Budapest Convention and further reﬂected in Directive 2013/40 .
Although these two international legal instruments are cited repeatedly , practitioners should keep in mind that they are instruments of public international law and relevant crimes are deﬁned by , and prosecuted under , the domestic law of individual states.91 3.5.1.1 Improper access to a system Improper system access laws criminalise the act of accessing a computer system ( in whole or in part ) without the right to do so , colloquially known as hacking.92 ( Budapest Convention at Art .
The UK Computer Misuse Act 1990 at s.1 , for example , deﬁnes as criminal an action by a person which causes a computer to perform an act with the intent to secure unauthorised access to any program or data [ 195 ] .
Thus , the mere act of entering a password into a system without authorisation in an effort to access that system constitutes a crime under the UK statute whether or not access is successfully achieved .
Some debate persists concerning how to distinguish rightful from wrongful action in cases where an otherwise-authorised person exceeds the scope of permission granted to them .
Critics argue that an overly-broad interpretation of statutory terms like ’ unauthorised access ’ can produce criminal prosecution based only on breaching an acceptable use policy or website terms and conditions .
These laws can be used to prosecute actions such as release or installation of malware , including ransomware .
3.5.1.3 Improper interference with systems Early computer crime laws tended to focus on the act of intrusion into a computer system , or improperly modifying the contents of those systems .
With the emergence of DoS and DDoS attacks , some of these early criminal laws were found to be inadequate to address this new threatening behaviour .
These laws now more commonly include a prohibition against acts that cause a material degradation in the performance of an information system .
KA Law & Regulation | October 2019 Page 82 The Cyber Security Body Of Knowledge www.cybok.org 3.5.1.4 Improper interception of communication Often as a corollary to various rights of privacy , many legal systems deﬁne the act of wrongfully intercepting electronic communications as a crime .
The rules and penalties tend to be most restrictive in the context of intercepting communications during the course of their conveyance on public networks .
3.5.1.5 Producing hacking tools with improper intentions Many states also deﬁne as crimes the production or distribution of tools with the intention that they are used to facilitate other crimes against information systems .
These laws can create challenges for those who produce or distribute security testing tools , as discussed in Section 3.5.5 .
3.5.2 De minimis exceptions to crimes against information systems Some laws may limit the deﬁnition of computer crime to acts which are somehow signiﬁcant .
The concept of a ’ minor ’ act against a system is discussed in Recital 11 to the Directive , which suggests that states might deﬁne this by reference to the relative insigniﬁcance of any risk created or damage caused by the given act [ 121 ] .
This type of de minimis exception to the deﬁnition of computer crime is far from universal .
EU member states remain free to criminalise such de minimis acts .
At the time of writing , the UK legislation contains no such de minimis exception.93 The very idea of a de minimis exception to crimes against information systems raises a recurring debate over the nature of the harm that these types of laws seek to redress .
It is not always clear how to assess the relative damage or risk caused by any given act against information systems .
For some criminal acts such as remote intrusion into a chemical plant industrial control system the risk presented or harm caused is clear to see , as the attack is concentrated against a single and volatile target .
In others , such as controlling the actions of a multinational botnet comprising tens of thousands of suborned machines , the risk created or harm caused may be widely diffused among the bots and more difﬁcult to quantify.94 3.5.3 The enforcement of and penalties for crimes against information systems States normally have absolute discretion to decide whether or not to investigate alleged crimes .
Having investigated , states normally have absolute discretion regarding the decision to prosecute a criminal matter.95 Some states have set out guidance to explain how this discretion is exercised [ 203 ] .
Penalties for committing a crime against information systems vary widely .
In criminal cases custodial sentences are often bounded in law by a maximum , and occasionally by a minimum , length of term .
Within these policy-imposed limits judges are usually given a wide degree of discretion to decide an appropriate sentence .
Under the UK Computer Misuse Act , for example , a custodial sentence for the crime of improper system access is normally limited to a maximum of two years , while the crime of KA Law & Regulation | October 2019 Page 83 The Cyber Security Body Of Knowledge www.cybok.org interfering with data or system integrity is normally limited to a maximum of ﬁve years .
Prosecution and sentencing history both suggest that actual sentences issued under the UK legislation for these crimes are rarely , if ever , this severe .
By contrast , in the US , both federal and state laws have consistently provided for longer maximum custodial sentences of 20 years or more for unlawful intrusion or unlawful interference with data.96 The question of appropriate punishment for crimes against information systems remains the subject of review and debate .
The emergence of the Internet of Things arguably increases the risk that these crimes might pose to life and property.97 EU Directive 2013/40 , for example , requires that member states provide for the possibility of longer custodial sentences when attacks are directed against critical national infrastructure or when they actually cause signiﬁcant damage ( Art 9 ( b ) - ( c ) ) .
The UK amended its Computer Misuse Act in 2015 ( s.3ZA ) to increase the maximum available custodial sentence if criminals are proven to have created signiﬁcant risk or caused serious damage .
Arguments continue over appropriate punishments for crimes against information systems .
This debate is complicated by difﬁculties in understanding or quantifying the degree of risk or the degree of harm caused by these criminal acts .
3.5.4 Warranted state activity When actions related to investigation of crime or in defence of state security are conducted with state authorisation such as a warrant , the person using the warranted technique is often expressly exempted from that state ’ s criminal liability for intrusion into information systems to the extent that the intrusion conforms with expressly warranted activity .
In other words , actions in compliance with a warrant issued pursuant to the 2016 legislation will not constitute a crime against information systems under the Computer Misuse Act 1990 etc.98 State-sponsored acts of remote investigation into cyberspace infrastructure located in foreign states are considered in Section 3.12.4 .
3.5.5 sons Research and development activities conducted by non-state per- Those who research cyber security issues and develop security products and services outside of the domain of state-sponsored activity can face difﬁculties if their planned activities constitute a crime against information systems .
Examples that may lead to difﬁculties include : • uninvited remote analysis of security methods employed on third-party servers or security certiﬁcate infrastructures ; • uninvited remote analysis of third-party WiFi equipment ; • uninvited analysis of third-party LAN infrastructure ; KA Law & Regulation | October 2019 Page 84 The Cyber Security Body Of Knowledge www.cybok.org • invited stress testing of live WAN environments , to the extent that this degrades performance of infrastructure operated by third parties who are unaware of the testing plan ; • analysing malware and testing anti-malware methods ; • analysing botnet components and performance ; • producing or distributing security testing tools ; and • various covert intelligence-gathering techniques .
With respect to testing tools speciﬁcally , the law tends to criminalise production or distribution only when the state can prove an intent to facilitate other violations of the law .
This criminal act may have less to do with the operational characteristics of the testing tool than the subjective intention of the person who is producing or distributing it.99 In some states , researchers might be able to demonstrate a lack of criminal responsibility for these acts under some type of de minimis exception , if one is available ( see the discussion in Section 3.5.2 ) .100 Some may rest on the belief that ’ legitimate ’ researchers will be saved from criminal liability as a result of state discretion to refrain from investigating or prosecuting de mimimis criminal acts , judicial or jury intervention to ﬁnd accused parties not guilty , or if found guilty , through the imposition of only a token punishment .
This situation is rather unsatisfactory for practitioners who attempt to assess potential criminal liability arising from an otherwise carefully risk-managed research or development effort.101 Even if practitioners ﬁnd appropriate exceptions under relevant laws concerning crimes against information systems , they must also be careful to consider whether their actions would constitute crimes under other laws such as generalised privacy or data protection laws .
A routinely cited example is the re-possession of movable property by a secured lender from a borrower in default of payment of obligations .
Public policy is generally suspicious of self-help mechanisms , as they involve non-state actors exercising powers normally considered to be the exclusive province of the state .
Laws that enable such actions often impose multiple conditions that limit the actor .
In the context of cyber security , practitioners have occasionally designed or adopted methods that might be classiﬁed as self-help .
These actions come with the risk of potentially violating criminal law .
Implementing a system that clearly discloses to a user that operation requires the prior entry of a unique activation key is normally non-contentious , and is actively encouraged by certain aspects of copyright law ( see Section 3.8.2.1 ) .
Similarly , SaaS providers usually do not face any sanctions when suspending access to a customer who terminates the service relationship or fails to pay their service fees.102 Problems arise when a supplier ( for whatever reason , including non-payment of promised license or maintenance fees ) installs a lock mechanism into a software product after the fact without customer agreement .
Also problematic are instances where software sold as a product contains an undisclosed time-lock device which later suspends functionality ( in the event of non-payment or otherwise ) .
These types of undisclosed or post-facto interventions have a history of being prosecuted as crimes against information systems and are otherwise criticised as being against public policy , whether or not the vendor in question held a legitimate right of action against the end user for non-payment of licence fees [ 204 , 205 ] .
This strategy is often considered in the context of an attack which appears to originate from a foreign state , and cooperation from the foreign state is deemed unlikely or untimely .
Such an action might be prosecuted as a crime by the state where the person conducting the hack-back is located , the states where the machines used to conduct the hack-back are located , or the state in which the hack-back target is located .
In addition to the risk of criminal prosecution , a hack-back ( if sufﬁciently aggressive ) could serve as the basis under international law for the state of the hack-back target to take sovereign countermeasures against the person conducting the hack-back or against other infrastructure used to conduct the hack-back operation – even if the hack-back itself is not directly attributable to host state ( see Section 3.12 ) .
This section will discuss a few contract topics of recurring interest to cyber security practitioners .
3.6.1 Online contracts : time of contract and receipt of contractual communication The deﬁnition of ’ contract ’ above immediately begs a follow-up question : how does one distinguish a legally enforceable promise from other types of communication ?
Although different legal systems have varying approaches to deﬁning a contract , the elements required by law can be classiﬁed into two categories : sufﬁciency of communication , and indicia of enforceability .
As an example , under the law of England a contract usually exists only when the parties have communicated an offer and an acceptance ( collectively constituting sufﬁciency of communication ) , supported by consideration and an intention to create legal relations ( collectively constituting indicia of enforceability ) .
Sufﬁciency of contract communication is a recurring issue when designing and implementing online transaction systems .
System designers should consider four successive moments in the contract communication process : 1. the time at which Alice transmits her offer105 to Bob ; 2. the time at which Bob receives Alice ’ s offer ; 3. the time at which Bob transmits his acceptance to Alice ; 4. the time at which Alice receives Bob ’ s acceptance .
Most common law systems would , by default , place the time of contract formation for online transactions into the last of these four times – the moment that Alice receives Bob ’ s acceptance .
Practitioners are urged not to conﬂate these four distinct moments in time , even when they appear to be instantaneous .
System designers should consider the impact of a lost or interrupted transmission and , accordingly , technical design should be carefully mapped onto relevant business process.106 A perennial question in the design of online systems concerns the precise point in time at which it can be said that Alice or Bob has ’ received ’ a communication .
3.6.2 Encouraging security standards via contract Contracts can serve as a mechanism to encourage the implementation of security standards .
This can arise in a wide variety of contractual relationships .
3.6.2.1 Supply chain A common contract technique is to incorporate terms within a procurement agreement that attempt to mandate some form of compliance by a supply chain partner with speciﬁed security standards : whether published standards such as ISO 27001 , or sui generis standards adopted by the contracting parties .
the general principle is that these contract terms have become a common mechanism that is used in an attempt to inﬂuence the security behaviour of supply chain partners .
The value of these clauses in managing supply chain behaviour , however , is worth a closer examination .
In a legal action for breach of contract , the enforcing party normally remains responsible for proving that the breach caused ﬁnancial harm , as well as the quantum of ﬁnancial harm suffered by the enforcing party as a result of the breach ( see Section 3.6.5 ) .
In the case of a breaching party ’ s failure to comply with an obligation to maintain a third-party security certiﬁcation , for example , it might be difﬁcult or impossible for the enforcing party to prove that any ﬁnancial harm ﬂows from such a breach ( thus effectively reducing the Q term to zero ) .
A sometimes-overlooked value of these contractual clauses arises well before the agreement is made .
The process of inserting and then negotiating these clauses can operate as a due diligence technique .
A negotiating party obtains information about the maturity and operational capability of the proposed supply chain partner during negotiations .
3.6.2.2 Closed trading and payment systems Many high-value or high-volume electronic trading or payment platforms109 require persons to enter into participation contracts prior to using the platform .
These systems may be generally referred to as ’ closed ’ systems : they constitute a club that must be joined contractually to enable members to trade with one another .
These membership contracts typically adopt comprehensive rules concerning forms of communication , connected equipment , and the timing for ﬁnality of transactions .
They also typically specify the adoption of certain security standards , authentication protocols , etc .
The membership contract is thus a private law mechanism that is used to enforce certain security standards among the members .
Breaching the terms of the membership contract might jeopardise the subject matter of the agreement itself – the ﬁnality of trades or the ability to collect payment .
As an example , a merchant collecting payment via payment card that fails to comply with the authentication procedures mandated by its merchant acquirer contract might face a loss of payment for a transaction even though it has delivered ( expensive ) goods into the hands of a person who KA Law & Regulation | October 2019 Page 88 The Cyber Security Body Of Knowledge www.cybok.org has committed card fraud .
Faced with such drastic ﬁnancial consequences , the contracting parties may work exceptionally hard to meet the mandated authentication standards .
Perhaps the most well-known example of a widespread standard implemented using contract is PCI DSS adopted by the payment card industry .
While there is some debate about the degree to which this standard has been effective , it is difﬁcult to deny that it has had some impact on raising the standard of security practices employed by many merchants when handling card transaction data – especially those that previously seemed to approach the subject with a cavalier attitude .
3.6.2.3 Freedom of contract and its limitations When considering using a contract as a means of regulating security behaviour , one must consider that the law can and does interfere with or otherwise limit the enforceability of some contract terms .
When considering PCI DSS standards , for example , the US Fair and Accurate Credit Transactions Act of 2003 [ 211 ] in Section 113 mandates speciﬁc truncation rules concerning payment card numbers displayed on printed receipts provided at the point of sale.110 Thus , merchants subject to US law must consider these public law requirements as well as PCI DSS , and those who wish to modify the PCI DSS standards should do so in a manner that is sympathetic to the external requirements imposed on these merchants by US law .
( Some states have taken the additional step of adopting the terms of PCI DSS into their law . ) .
In the case of funds transfer services , public law also establishes a framework to balance the rights and responsibilities of providers and users of payment services which includes considering the adequacy of authentication mechanisms .
Limitations on the freedom of parties to deviate from public law norms in contract are further discussed in Sections 3.6.3 and 3.6.4 .
The contract laws of individual states normally imply certain minimum warranties into contracts concerning the quality of the goods and services supplied .
The types of quality warranty most commonly imposed include : • Objective quality of goods .
The product vendor promises that the goods delivered will be objectively satisfactory to a normal purchaser given all of the circumstances of the transaction.112 • Subjective quality of goods .
The product vendor promises that the goods delivered will be sufﬁcient to meet the subjective purpose of an individual purchaser , whether or not the goods were originally manufactured for that intended purpose.113 For this warranty to apply , the purchaser is normally required to disclose the purchaser ’ s speciﬁc purpose KA Law & Regulation | October 2019 Page 89 The Cyber Security Body Of Knowledge www.cybok.org in advance to the vendor .
As a result , this term is rarely discussed in the context of standard online commerce systems , which often do not allow unstructured communication between vendor and purchaser concerning intended use cases .
The service provider promises that it will exercise due care in the process of service delivery .
Upon consideration , a signiﬁcant distinction emerges between the quality of goods and services warranties .
Compliance with the goods warranties is assessed by examining the goods supplied .
A warranty that goods will be objectively satisfactory is breached if the goods are poor – without regard to the care taken by the vendor in manufacturing , sourcing , or inspecting goods .
It is possible for a service provider to comply with a warranty of due care and yet produce a deliverable which is demonstrably poor or inaccurate .
( The basis of this distinction between product and service is becoming increasingly difﬁcult as persons place greater reliance on cloud services as a substitute for products .
Although various laws imply these standard warranties into contracts as a matter of course , it is commonplace – nearly universal – for suppliers of information and communications technologies and services to attempt to exclude these terms by express agreement .
Efforts to exclude these baseline warranty protections are viewed with suspicion under the contract laws of various states .
As a general proposition , it is more difﬁcult and often impossible to exclude these baseline protections from standard form contracts with consumers .
In the context of B2B contracts , however , the rules allowing these exclusions tend to be more liberal .
Information and communications technology vendors normally exclude these baseline implied warranties and replace them with narrowly drawn express warranties concerning the quality of deliverables.114 The relative utility of these express warranties provided by ICT vendors is questioned with some regularity , especially as regards commercial off-the-shelf software or hardware .
It remains an open question to what degree these warranty standards encourage or discourage developer behaviours in addressing security-related aspects of ICT products and services [ 105 ] .
3.6.4 Limitations of liability and exclusions of liability Parties to contracts often use the contract to impose both limitations and exclusions of liability that arise from the contracting relationship .
An exclusion of liability refers to a contractual term that seeks to avoid ﬁnancial responsibility for entire categories of ﬁnancial loss arising as a result of breach of contract , such as consequential loss , loss of proﬁt , loss of business opportunity , value of wasted management time , etc .
A limitation of liability , on the other hand , seeks to limit overall ﬁnancial liability by reference to a ﬁxed sum or ﬁnancial formula .
The possibility of imposing and enforcing contractual limitations and exclusions of liability creates a powerful incentive for vendors to draft and introduce express terms into their contractual relationships with customers .
As a result , these exclusions and limitations are ubiquitous in contracts for ICT goods and services .
As with the exclusion of implied warranty terms , limitations and exclusions of liability are viewed with suspicion under most systems of contract law .
Once again , limitations and exclusions of liability are most heavily disfavoured when contracting with consumers .
Rules allowing these exclusions and limitations tend to be more liberal in B2B arrangements .
KA Law & Regulation | October 2019 Page 90 The Cyber Security Body Of Knowledge www.cybok.org There is a wide variation among and between jurisdictions concerning the enforceability of these limitations and exclusions .
As a general proposition , civil law jurisdictions disfavour these limitations and exclusions more than common law jurisdictions .
It remains an open question to what degree the relative enforceability of these contractual limitations and exclusions encourages or discourages developer behaviours in addressing security-related aspects of ICT products and services [ 105 ] .
3.6.5 Breach of contract & remedies When considering the obligations imposed by contract , it is also important to consider the legal consequences of breaching a contract .
An individual breach of contract might be considered de minimis , moderately serious , very signiﬁcant , etc.115 The severity of breach can and often does result in different remedies for the injured party .
Order the breaching party to pay monetary damages to the non-breaching party that are sufﬁcient to restore the net ﬁnancial expectation that the harmed party can prove was foreseeably lost as a result of the breach .
This is the most common remedy available .
A non-breaching party is often obliged to take steps to mitigate ﬁnancial harm , and failure to mitigate can serve to reduce an award of damages accordingly .
Declare that the contract is at an end and excuse the non-breaching party from further performance .
This is a more extreme remedy , normally reserved for cases in which the breach is very severe .
Alternatively , the terms of the contract might specifically legislate for the remedy of recision under deﬁned circumstances.117 • Speciﬁc performance .
This is also considered an extreme remedy .
This remedy is often reserved for situations when the breaching party can take a relatively simple action that is highly signiﬁcant to the non-breaching party ( e.g .
The contract itself may specify available remedies , such as service credits or liquidated damages .
Courts often treat these remedies with suspicion .
The law concerning enforceability of private remedies is complex and varies signiﬁcantly from jurisdiction to jurisdiction .
The remedies described above are normally cumulative in nature .
KA Law & Regulation | October 2019 Page 91 The Cyber Security Body Of Knowledge www.cybok.org 3.6.6 Effect of contract on non-contracting parties One potential limitation of the utility of contracts is that enforcement may be limited to the contracting parties alone .
In the context of seeking a remedy for breach , the rule of privity of contract ( generally found in common law systems ) normally restricts contract enforcement solely to the contacting parties .
If Alice and Bob enter into a contract and Alice breaches , under the doctrine of privity Bob is normally the only person who can take legal action against Alice for breach of contract .
Charlie , as a non-party , can not normally take action against Alice for breach of contract even if Charlie has been harmed as a result of the breach .
In complex supply chains , Bob might be able to assign the beneﬁt of the contract rights ( such as warranties ) to Charlie .
( Even in common law systems , there are circumstances in which parties can expressly vest contract rights in the hands of third parties . ) .
If Alice is a supplier of services and wishes to limit her potential liability to persons who rely on the outputs of these services , a contractual limitation of liability might not be effective against a non-contracting person like Charlie who relies on her service but is not in privity of contract with Alice .
This inability to limit liability to non-contracting parties is a recurring consideration in the development of trust services , in which third parties who rely on trust certiﬁcates may have no direct contract relationship with the certiﬁcate issuer .
3.6.7 Conﬂict of law – contracts Deciding which state ’ s law will apply to various aspects of a contract dispute is normally vested within the jurisdiction of the court deciding the dispute .
The rules used to decide this question can and do vary from state to state .
Individual US states , by contrast , remain free to adopt their own individual rules used to decide whose law should be applied to aspects of contract disputes .
Even with these variations some useful and generalisable principles can be identiﬁed .
It is widely accepted that persons who enter into a contract should have some degree of freedom to choose the law that will be used to interpret it .
Various policy justiﬁcations are available , often built upon notions of freedom of contract .
If parties are free to specify the terms of their contractual relationship , this argument suggests that the same parties should be free to incorporate within the agreement anything that assists to interpret the terms that have been agreed – including the substantive system of contract law used to interpret the agreement .
Absence of an express choice of law by the parties .
When parties connected to different states do not make an express choice of law in their contract , the court is faced with the dilemma of deciding whose law to apply to various aspects of the contract dispute .
In the European Union , rules determining the applicable law in the absence of choice are found in Rome I , Art 4 .
Of particular interest to those who deal with online contracting systems , are the following default rules in the absence of a clear choice by the parties : • A contract for the sale of goods or supply of services will be governed by the law of the place where the seller or service provider has its habitual residence .
KA Law & Regulation | October 2019 Page 92 The Cyber Security Body Of Knowledge www.cybok.org • A contract for the sale of goods by auction shall be governed by the law of the country where the auction takes place , if such a place can be determined .
• A contract concluded within a multilateral system which brings together or facilitates the bringing together of multiple third-party buying and selling interests in ﬁnancial instruments in accordance with non-discretionary rules and governed by a single law , shall be governed by that law .
Thus , we see in European law a baseline policy preference to apply by default the law where the vendor or market maker is resident , over the law where the buyers or bidders may be resident .
When one of the parties to a cross-border contract is a consumer , the rules are generally modiﬁed to provide additional protection for the consumer .
In disputes in a European Union forum court , for example , if the cross-border vendor of products or services pursues their business activity in the place of the consumer ’ s residence , or ’ directs such activities to that country or to several countries including that country ’ , then the following special rules usually apply : • If there is no express choice of law in the contract , the applicable law will be the law of the consumer ’ s habitual residence .
• If some other law has been expressly chosen , that choice of law can not deprive the consumer of legal protections mandated by the law of the consumer ’ s residence .
Although the speciﬁc examples above are drawn from European legislation , they represent principles that regularly occur in other states that face conﬂict of law issues in consumer contract disputes .
This section will address a few of the more common tort doctrines that should be considered by cyber security practitioners .
Two substantive torts of interest ( negligence and product liability ) will be examined in some detail together with a series of more general tort doctrines such as causation and apportionment of liability .
KA Law & Regulation | October 2019 Page 93 The Cyber Security Body Of Knowledge www.cybok.org 3.7.1 Negligence Most legal systems recognise the idea that persons in society owe a certain duty to others in the conduct of their activities .
If a person fails to fulﬁl this duty , and the failure causes harm to a victim , the victim is often given a right to take legal action against the tortfeasor for ﬁnancial compensation .
3.7.1.1 Duty of care : how far does it extend Legal systems implicitly acknowledge that a person is not always responsible to everyone all of the time .
Some limitation on the scope of responsibility is normal .
Alice and Bob are somehow proximate to one another in time and space ; 2. it is reasonably foreseeable to Alice that her action ( or inaction ) could cause harm to persons in a position similar to Bob ; and 3. with respect to Alice ’ s action ( or inaction ) , on the whole it seems fair and reasonable for persons like Alice to be responsible to persons in a position similar to Bob .
Although this three-pronged rule is not presented as a multinational norm , it illustrates the general proposition that the scope of civil responsibility owed to others as a result of negligence is limited.118 ’ Foreseeability ’ of harm is used routinely as a mechanism to limit the scope of liability in negligence law.119 Foreseeability is normally measured by reference to whether or not an objectively reasonable person would have foreseen harm .
A tortfeasor is not excused from liability due to failure of imagination , failure to plan , or an afﬁrmative effort to avoid considering potential victims.120 This raises a number of related questions about possible duties of care in the context of cyber security , some of which are set out in Table 3.2 .
The purpose of Table 3.2 is merely to consider some of the types of relationship that might create a duty of care under existing law .
As harm caused by cyber security failure becomes increasingly foreseeable , it seems likely that courts will increasingly interpret the concept of duty of care to encompass various cyber-security related obligations owed to a broader group of victims [ 216 ] .
The concept of ’ duty of care ’ does not normally depend on the existence of any business or contract relationship between tortfeasor and victim .
As a commonly understood non-security example , automobile drivers are said to owe a duty of care to other drivers , to bicycle riders , to pedestrians , and to others who are expected to use roads and pathways .
One might therefore consider the extent to which those who supply software on a non-commercial basis , such as open source security software , might be found to owe a duty of care to those persons who foreseeably rely upon such software .
KA Law & Regulation | October 2019 Page 94 The Cyber Security Body Of Knowledge www.cybok.org When this potential tortfeasor : Conducts this activity in an unreasonable manner : Consider whether the potential tortfeasor owes a duty of care to these potential victims : Retail chant .
Maintaining security of payment card details supplied by customers at point of sale .
Card holders ; Managing the security of email servers and related services ; Service subscribers ; Making decisions about the types of security to be adopted .
Unrelated third parties suffering harm when malicious actors compromise the enterprise ’ s security measures and use the enterprise ’ s IT to launch onward attacks ; mer- Email service provider .
Merchants that adopt the web server software for online commerce ; SaaS providers that adopt the web server software for the provision of various services to customers ; Customers submitting payment card details ; Business customers that submit sensitive business data to a SaaS provider that adopted the server software ; Business enterprises that adopt the server within their IT or OT infrastructure .
Trust service provider.122 Registering the identity to be bound to a certiﬁcate ; Issuing certiﬁcates ; Customers who purchase certiﬁcates ; Third parties who place reliance on these certiﬁcates ; Third parties who operate equipment which ( without their knowledge ) places reliance on these certiﬁcates .
Selects root trust certiﬁcates for installation into its web browser .
Natural persons who use the web browser .
A typical standard used to assess conduct is to examine whether or not Alice has acted in an objectively reasonable manner .
In classic negligence law persons like Alice are not held to a standard of perfection .
In assessing fault , courts often make use of rhetorical devices such as the objectively ’ reasonable person ’ similarly situated .
As a framework for measuring conduct , the reasonable person standard has proven remarkably resilient and ﬂexible over time .
Cyber security practitioners often converge with opinions on whether a given cyber security-related action ( or inaction ) was objectively reasonable or unreasonable .
can all serve to revise opinions on the deﬁnition of what constitutes ’ reasonable ’ security conduct .
The highly respected US Judge Learned Hand warned of this in two famous decisions from the mid-twentieth Century .
Although the vessel operator conformed with common industry practice of the 1920s , Judge Hand clearly expressed the idea that changes in technology and the surrounding environment should spur re-examination of methods and activities .
Fifteen years later in the 1947 Carroll Towing case , Judge Hand announced a deﬁnition of reasonable conduct that may be helpful in assessing whether or not the time has arrived to adopt a given method of operation .
Using this doctrine , a victim argues that the tortfeasor ’ s conduct should be found to be unreasonable because that conduct violated a public law or widely-adopted technical standard .
This doctrine has already been pleaded together with standard negligence claims in legal action arising from cyber security-related incidents [ 215 ] .
This doctrine may become increasingly useful to victims as a result of increasing standardisation and regulation in the ﬁeld of cyber security.125 The mere act of deﬁning and adopting security standards may therefore inﬂuence courts as they seek technical frames of reference KA Law & Regulation | October 2019 Page 96 The Cyber Security Body Of Knowledge www.cybok.org for assessing the ’ reasonableness ’ of conduct .
Using this doctrine , a victim who might otherwise have difﬁculty proving the precise nature of the action that caused harm , claims that the most appropriate inference to be drawn from the surrounding circumstances is that the accused tortfeasor bears the responsibility .
This doctrine tends to be used against persons who are supposed to maintain control over risky or dangerous processes that otherwise cause harm .
Irrespective of the victim ’ s ability to prove a lapse of caution , the most appropriate inference to be drawn from the circumstances is a lack of due care .
In the ﬁeld of cyber security , one might imagine a case in which this doctrine is applied in a legal action against a person who creates a new form of malware for research purposes , only to lose containment.126 Doctrines similar to negligence per se and res ipsa loquitur might be deﬁned in some legal systems as rules concerning the reasonability of conduct , or they might be deﬁned as rules of evidence – relieving a victim of some or all of their burden to prove unreasonable conduct , or shifting the burden to the alleged tortfeasor to prove reasonable conduct .
Although they are not normally considered under the rubric of negligence law , other laws which inﬂuence cyber security practice deﬁne ’ reasonable ’ conduct within their sphere of competence .
3.7.1.3 The interpretation of ’ fault ’ differs by place and changes over time Although the framework presented above for deﬁning ’ fault ’ is generally well-received by legal systems in most developed economies , this should not be mistaken for agreement on how to interpret or apply these standards .
This should not be surprising , as both concepts are social constructs anchored by opinions about risk and responsibility that prevail in a given society at a given time .
The interpretation of ’ duty of care ’ has ( with some exceptions ) mostly expanded over the past century as the increasingly complicated and interconnected nature of modern life creates more opportunity for the actions of one person to harm others .
These interpretations can be expected to change within the working life of a practitioner , especially as the harm caused by cyber security failure becomes increasingly foreseeable , better understood , and easier to prove with new forensic tools .
Similarly , practitioners are cautioned that potentially tortious acts committed in one state might be assessed by the interpretation of standards of care adopted by another , more demanding , state .
KA Law & Regulation | October 2019 Page 97 The Cyber Security Body Of Knowledge www.cybok.org 3.7.2 Strict liability for defective products In the second half of the twentieth Century , a number of states with developed industrial economies adopted rules of strict liability for defective products.127 This liability regime provides a right of action for those who suffer personal injury , death , or property damage , caused by a defective product .
A product is usually deemed to be defective when it fails to provide the safety that a reasonable person would expect under the circumstances .
Depending on the speciﬁc law in question , strict liability typically attaches to persons who produce , import or sell defective products or component products .
Liability can attach to a tortfeasor who has no pre-existing relationship with the victim .
In this type of liability , the focus of analysis shifts away from any notion of ’ fault ’ by the tortfeasor and moves instead to an examination of the allegedly defective product .
Liability is generally assessed without regard to the degree of reasonableness used in producing , examining , or selecting products for sale .
This type of strict liability is found throughout the laws of the states of the US and is incorporated into EU member states ’ domestic laws as mandated by Directive 85/374 [ 221 , 222 ] .
Most authorities believe that software , as such , does not ﬁt within the various deﬁnitions of ’ product ’ applicable under such laws.128 Even so , under currently-existing product liability law a defect in a software component can be the source of a defect in a product into which it is installed .
Liability of this sort arising from cyber security failures will probably increase as physical control devices are increasingly connected to remote data services , presenting more cyber security-related risks to life and limb .
Thus , strict product liability could be implicated in cases of personal injury or property damage whether the safety of the connected device is compromised through errors in operational decision-making ( e.g .
, an autonomous vehicle chooses to swerve into oncoming trafﬁc after misinterpreting road markings ) or errors in cyber security ( e.g .
This is an area of law that could change signiﬁcantly in the medium-term future .
KA Law & Regulation | October 2019 Page 98 The Cyber Security Body Of Knowledge www.cybok.org 3.7.3 Limiting the scope of liability : legal causation The primary purpose of tort law is to compensate victims for harm suffered .
A victim can normally only bring a legal action against a tortfeasor if the victim can prove that the relevant tortious action was the cause of a legally cognisable harm suffered by the victim .
Put simply , people may act negligently without tort liability – if their behaviour causes no harm .
Causation is one of the more difﬁcult concepts to deﬁne in law .
Different authorities take different views about when it is appropriate to hold a tortfeasor responsible when it is claimed that tortious action A has produced harm B .
, which in turn causes result Xn , which in turn causes harm B.130 As the link between A and B becomes increasingly attenuated , policy makers and judges struggle to deﬁne the limits of responsibility of the person committing the tortious act .
Similar difﬁculties arise when the ’ last cause ’ in a combination of negligent acts causes harm that is signiﬁcantly disproportionate to the individual negligent last act , as a result of more serious lapses of judgment by prior actors .
Approaches adopted to resolve this issue include limiting the responsibility of the tortfeasor to harm that is reasonably foreseeable [ 227 ] .131 The narrower deﬁnition of causation required by tort law may be referred to using terms such as ’ legal causation ’ or ’ proximate causation ’ .
Proving that a speciﬁc harm was caused by a speciﬁc cyber security incident can be extremely challenging .
To take a common example , a natural person whose identiﬁcation data has been compromised may ﬁnd it difﬁcult or impossible to prove that the data lost in a given data breach event are the source of the data subsequently used by malicious actors to carry out fraud through impersonation .
Data breach notiﬁcation laws help to redress the imbalance of evidence available to victims in these cases , but even then , the victim must prove a causal link from a speciﬁc breach to the fraud event .
A notable exception is ﬁnancial loss incurred following a breach of payment card data , as the causation of subsequent fraud losses can be easily inferred from a contemporaneous data breach event .
These cases create other challenges as discussed in Section 3.7.4 .
3.7.4 Quantum of liability Consideration of the impact of tort law on cyber security related activity is incomplete without considering quantum of liability .
Different states have different approaches to deﬁning what constitutes legally cognisable harm for purposes of tort law .
A victim is normally required to prove the ﬁnancial value of harm caused by a tortious act .
In cases involving personal injury , the value of the harm is often calculated by reference to easily understood measures such as : loss of salary suffered by the victim due to their inability to work , costs incurred by the victim for medical treatment , rehabilitation , or nursing care , costs of installing accommodation facilitates for a permanently injured victim , etc .
Some states also allow compensation for harm in personal injury cases that is more difﬁcult to quantify such as pain and suffering , emotional distress , etc .
KA Law & Regulation | October 2019 Page 99 The Cyber Security Body Of Knowledge www.cybok.org A recurring issue in negligence cases concerns whether or not a victim can recover for socalled pure economic loss .
There is a divergence in the law on this question .
A leading case in England concerned the economic loss caused by a poorly considered credit reference provided by a bank to its customer .
Although the loss ( the customer ’ s subsequent inability to collect a trade debt from its insolvent client ) was purely economic in nature , the English court decided it should be recoverable because the bank professed special skill ( ﬁnancial awareness ) , and the victim relied on the ﬂawed statement to its detriment [ 228 ] .132 A growing number of cases have been brought on the basis of negligent cyber security which claim losses other than personal injury or property damage .
Some courts have already exhibited a willingness to award damages under the law of negligence to victims whose losses are purely economic in nature [ 216 ] .133 Other legal actions ( settled by the parties before trial ) have involved substantial claims for economic losses based on negligent cyber security.134 Proving legally cognisable harm can be challenging for some victims who might otherwise wish to take legal action based on cyber security failures .
One example concerns the loss of privacy .
There is a lot of argument about how to quantify ( ﬁnancially ) the harm caused by breach of privacy unless the victim has some business or economic interest that is directly harmed as a result.135 Another common example concerns the loss of conﬁdentiality of ﬁnancial authentication methods such as payment card details .
Card holders would have difﬁculty proving harm to the extent that fraudulent charges are refunded by the issuing bank .
Of course , the issuing bank will then be able to demonstrate ﬁnancial harm as a result of refunding these monies , plus a pro rata portion of the costs incurred issuing replacement cards earlier than planned .
In response to these types of difﬁculties in proving harm , some states have adopted speciﬁc laws that provide a schedule of damages that can be claimed without the need to quantify harm .
An example is found in the State of Illinois Biometric Information Privacy Act , which provides that any party aggrieved by a violation of the act can take legal action and recover US $ 1,000 per violation ( for negligent violations ) or US $ 5,000 per violation ( for intentional violations ) of the law ’ s mandates.136 Similarly , US copyright law allows some rights owners to recover minimum damages using a statutory tariff .
These awards are intended to punish and deter bad behaviour .
These awards can be disproportionate compared to the underlying award for the harm suffered by the victim .
Examples where a court might award punitive damages most commonly include cases where the tortfeasor demonstrates a pattern of repeated poor behaviour , or the tortfeasor has made relevant operational decisions with gross indifference to human life or human suffering .
KA Law & Regulation | October 2019 Page 100 The Cyber Security Body Of Knowledge www.cybok.org 3.7.5 Attributing , apportioning and reducing tort liability This section discusses a few miscellaneous legal doctrines that are important to consider when attempting to assess risks of tort liability .
3.7.5.1 Vicarious liability There are circumstances when the liability of a tortfeasor can be attributed to a second person .
The situation commonly encountered in cyber security is liability for the tortious act of an employee attributed to their employer .
This type of vicarious liability applies when the tort is committed during the course of an employment relationship .
Once a victim proves that the employee committed a tort which caused relevant harm and then proves that the tort was committed within the course of employment , the employer becomes strictly liable for that underlying tort .
Pleas by the employer about taking reasonable precautions , mandating reasonable training , due diligence when hiring or the employee ’ s deviation from employment standards , are generally ineffective against claims of vicarious liability .
The Court of Appeal in England in 2018 afﬁrmed a vicarious liability claim brought in a data protection tort action .
In Wm Morrison Supermarkets PLC vs Various Claimants , the data controller Morrison was sued by various data subjects after a disgruntled internal audit employee published salary data of 100,000 employees in violation of data protection law.137 The secure handling of salary data fell within the ﬁeld of operation with which the employee was entrusted and therefore the tort was committed by the employee within the scope of the employment relationship , thus leading to vicarious liability [ 193 ] .
At time of writing , this decision is pending appeal in The Supreme Court of the United Kingdom.138 The only reliable method to avoid vicarious liability is to encourage employee behaviour that limits or avoids tortious activity .
This is worthy of consideration by those who develop and enforce acceptable use policies , staff security standards , employment policies , etc .
3.7.5.2 Joint and several liability In cases where more than one tortfeasor can be said to have caused harm to a single victim , tort law often imposes joint and several liability .
The doctrine is simple : any jointly responsible tortfeasor could be required to pay 100 % of the damages awarded to a victim .
’ contribution ’ ) from other tortfeasors , this becomes problematic when the joint tortfeasors have no ﬁnancial resources or are resident in foreign states where there is no effective method of enforcing such rights .
Practitioners may wish to consider the impact of this rule when working with supply chain partners or joint venturers that are small , do not have much capital , or are resident in a foreign state where enforcement of domestic judgments may be problematic .
KA Law & Regulation | October 2019 Page 101 The Cyber Security Body Of Knowledge www.cybok.org 3.7.5.3 Afﬁrmative defences Tortfeasors are sometimes able to take advantage of certain afﬁrmative defences to tort claims .
A tortfeasor who is able to prove the relevant elements of these defences can reduce , or sometimes eliminate , their liability .
In this type of defence , the tortfeasor attempts to prove that the victim ’ s own negligence contributed to their harm .
Depending on which state ’ s tort law is applicable to the claim , a successful defence can reduce or eliminate liability to the victim .
Another category of defence that can be useful in various cyber security contexts include ’ assumption of risk ’ or ’ consent ’ .
In this type of defence , the tortfeasor avoids liability by proving that the victim was aware of , or knowingly consented to , the risks that ultimately caused the harm .
This type of defence can be especially useful for those who supply cyber security services that risk damage to client infrastructure , such as penetration testing .
Practitioners often draft commercial engagement documents with a view to attempting to satisfy one of these defences in the event that something goes wrong during the engagement .
Where this defence is allowed , a party can avoid strict liability by proving that a product , although defective , was produced at a time when the technological state of the art would not have enabled discovery of the defect .
It is debatable how this defence might apply to products made defective as a result of cyber security ﬂaws.139 Of greater signiﬁcance , perhaps , is the afﬁrmative defence against strict liability for a defective product available if the defending party can prove that the defect is present due to compliance with laws or regulations concerning product design.140 3.7.6 Conﬂict of law – torts Deciding which state ’ s law applies to various aspects of a tort dispute is normally vested within the juridical jurisdiction of the forum court deciding the dispute .
The rules that are used to decide this question can and do vary from state to state .
Individual US states , by contrast , remain free to adopt their own individual choice of law principles when deciding whose law should be applied to aspects of tort disputes .
Even with these variations some useful and generalisable principles can be identiﬁed .
Broadly speaking , courts that examine tort claims between persons in different states tend to adopt one of two methods most often used to decide whose law to apply : apply the law of the place where the tortious act originated or apply the law of the place where the injury was suffered .
Historically , it might have been difﬁcult to ﬁnd cases where these two events occurred in different states .
Modern commerce , however , has produced a number of cases where the two events can be widely separated by space and time.141 In disputes heard in courts throughout the European Union , the applicable law in a tort action ( with some exceptions ) is the law of the place where the damage was suffered .
In cases of product liability , the rules are slightly more complex and the applicable law might be the place of the injured party ’ s habitual residence , the place where the product was acquired , or the place where the damage occurred .
The above rules provide a reasonable indicator of the risk that cyber security failures occur- KA Law & Regulation | October 2019 Page 102 The Cyber Security Body Of Knowledge www.cybok.org ring due to actions performed in State A , and subsequently causing harm to persons in State B , could easily become amenable to liability analysis under the tort law of State B .
Thus practitioners ( and their employers ) might be held to a higher standard of care imposed by a foreign state where victims of negligent cyber security or defective IoT products are found .
This section will summarise some points where the two ﬁelds intersect .
3.8.1 Understanding intellectual property Intellectual property rights are negative rights – they convey the right to demand that other persons cease a prohibited activity .
The nature of the activity to be prohibited is deﬁned in the law establishing that right .
Ownership of intellectual property normally conveys a right of action against others who transgress one or more acts prohibited by the relevant property right .
Intellectual property rights do not give the afﬁrmative right for the owner to take any action imaginable with the subject matter .
In the ﬁeld of intellectual property law , ’ public domain ’ refers to a work in which no current intellectual property right subsists .
To distinguish these two , if a conﬁdential original written work is subsequently published the contents become publicly known .
This work , however , may still be protected by copyright unless these rights are expressly relinquished .
In contrast , if a person who writes software then declares that they are placing the code ’ in the public domain ’ this statement is often treated as an irretrievable relinquishment of copyright .
The term should be used with care .
KA Law & Regulation | October 2019 Page 103 The Cyber Security Body Of Knowledge www.cybok.org 3.8.2 Catalogue of intellectual property rights This section will describe some of the intellectual property rights most likely to be encountered by cyber security practitioners .
Additional intellectual property rights that may be of interest to practitioners , but which are not addressed in this section , include protections for semiconductor topographies , the EU sui generis right to prevent the extraction or reutilisation of the contents of a database , and registered and unregistered design rights .
In many circumstances , contract rights ( especially licensing agreements ) supplement intellectual property rights and may be treated informally as a type of intellectual property .
To make matters more confusing , persons in business often use the phrase ’ intellectual property ’ in an expansive and colloquial fashion to refer to any work product or process that is the result of intellectual effort - whether or not it incorporates legally recognised and enforceable intellectual property rights .
This section deals only with legal rights , as such .
Copyright subject matter includes literary works , which for this purpose includes software code ( both source and executable code ) .
This makes copyright especially important for the developers and users of security products embodied in software .
The scope of copyright is generally said to be limited to the expression of an idea rather than the idea itself .
Thus , copyright in software code normally protects only the code as written and not the functionality of the resulting software product .
Protection of functionality is usually the province of patent rights .
Literary works are normally protected for the life of the author plus 70 years following their death .
While the term of copyright protection granted to computer software may be less than this , it remains sufﬁciently long that the expiration of the copyright term is unlikely to apply to any relevant software encountered by a security practitioner within their lifetime .
Infringement of copyright normally consists of acts such as copying , transmitting , displaying or translating a signiﬁcant part of the protected work .
Proving that one work infringes the copyright embodied in a second work requires proof of copying .
Copying can be inferred from sufﬁcient points of similarity between the two works – there is no need to prove knowledge of copying by the accused .
A plethora of forensic techniques have been developed over the course of decades to assess infringement of software source code .
These are deﬁned differently from state to state.145 The scope of copyright protection was expanded at the turn of the twenty-ﬁrst century to encompass the right to take legal action against persons who interfere with the technological measures used to protect copyright works [ 230 ] at Art 11.146 This was intended to provide additional legal rights of action against those who circumvent technologies such as digital rights management systems ( see the discussion in Section 3.8.4 . ) .
Patents are meant to protect an invention that is novel and that also includes an additional distinguishing characteristic variously described by states as an ’ inventive step ’ , a ’ non-obvious ’ character , or something similar .
This inventive step requirement is a policy device used to limit patent protection to inventions that are signiﬁcant in some fashion , rather than trivial.148 Novel inventions that would have been obvious to a person skilled in the relevant technical art are normally denied patent protection .
States expressly deﬁne additional subject matter that may not be claimed as a patented invention .
Common exclusions of special interest to security practitioners are software , as such , and an idea or mathematical formula , as such.149 Inventions that embody these , however , can be patentable subject matter in appropriate circumstances .
The US patent system has changed its approach to software patents in the past few decades and is increasingly receptive to them .
Even states that notionally reject the concept of software patents regularly grant patents on inventions that are embodied in software .
The price of a patent is paid in two forms : money and public disclosure .
Applications are expensive to prosecute and expensive to maintain .
The process of navigating international application and examination is sufﬁciently complex that ( expensive ) expert assistance is always advisable , and often critical to success .
In addition to application and examination fees paid to states , those who are granted a patent are then required to pay periodic fees to maintain the patent throughout its life .
Beyond the monetary cost , public disclosure is a core feature of the patent system .
The patent application must disclose how the invention works in a manner that would enable a skilled technical practitioner to replicate it .
The application and the granted patent , together with examination correspondence,150 is normally published to enable future study.151 The term of a patent is normally 20 years from the date of application .
Patents are typically subjected to an examination process which can take years to conclude .
When a patent is granted , the right holder is normally given the right to take legal action retrospectively for infringements that took place after the application but before the grant , even if the infringement happened prior to the publication of the application.152 The validity of a patent can be challenged post-grant and this is a common method of defending against infringement legal actions .
Infringement of a patent normally consists of acts such as manufacturing , distributing , importing , exporting or selling a product or service that embodies the claimed invention .
Proving infringement involves a forensic comparison of the accused device or service with the invention as claimed in the granted patent .
There is no need for a right holder to prove that the invention was copied from the patent or from any product .
The most common trademarks consist either of words or ﬁgures.156 Trademarks are granted within deﬁned use categories , meaning that it is possible for two different persons to have exclusive rights for the use of the same symbol in different lines of business .
The purpose of trademarks is to reduce the possibility of confusion for those who procure goods or services , and to protect investment in the reputation of the enterprise supplying those goods or services .
Trademarks are normally registered for a period of 10 years , although these registrations can be renewed indeﬁnitely.157 Infringement of a registered trademark normally consists of displaying an identical or confusingly similar mark in combination with products or services that fall within the registered scope of exclusivity.158 Proving infringement involves comparing the accused sign with the registered trademark and assessing whether the two are identical or confusingly similar .
There is no requirement to prove that the accused party has actual knowledge of the registered trademark.159 Infringement of trademark can occur through the use of a domain name identical or confusingly similar to a registered mark .
To prove that the use of a domain name constitutes infringement of a registered trademark , a rights owners must normally prove that the domain name is identical or confusingly similar to the mark , and that the domain name is used in the supply of goods or services within the scope of exclusive use deﬁned in the trademark registration .
Certiﬁcation marks are a type of trademark that is used to demonstrate conformity with a given standard.160 These marks are registered by a standards body , which then grants licences to use the mark subject to compliance with the relevant standard .
Any person who supplies relevant goods or services bearing the mark that does not conform with the relevant standard risks legal action for trademark infringement .
A collective mark is a trademark that is used to identify the members of an association , such as a professional society .
Having registered the relevant collective mark , the society can take action against those who use it without authorisation , and revoke authorisation from those whose membership has ceased .
KA Law & Regulation | October 2019 Page 106 The Cyber Security Body Of Knowledge www.cybok.org 3.8.2.4 Trade secrets Trade secrets were traditionally protected under general tort law , giving persons who attempted to keep their secrets the right to take legal action against those who inappropriately obtained , used or disclosed these secrets .
As the twentieth century progressed , a trend emerged to increase the legal protection of trade secrets .
The subject matter of a trade secret is generally regarded as information that is secret , is valuable because it is secret and remains secret due to the reasonable efforts of the secret keeper .
Subject matter can include information as diverse as an ingredients list , a method of manufacture , a customer list , an algorithm or details of a patentable invention prior to patent application and publication .
Examples of current trade secrets in ICT include the ﬁner details of Google ’ s PageRank algorithm and various proprietary cryptographic algorithms .
Trade secrets can be protected indeﬁnitely so long as secrecy is maintained.161 Unfortunately , loss of trade secrets through acts of cyber industrial espionage is believed to be widespread and should be a source of major concern for cyber security practitioners [ 239 ] .
Loss of conﬁdentiality of patentable subject matter can be especially damaging , as publication of inventive details by a third party prior to patent application normally destroys patentability ( as the invention then ceases to be ’ novel ’ ) .
Owners of trade secret rights can normally take legal action against persons who misappropriate their secrets .
3.8.3 Enforcement – remedies Consideration of the impact of intellectual property law is incomplete without also considering remedies available to a successful litigant .
These prosecutions usually require proof that the infringing party was aware of the infringement and are often based on a pattern or practice of infringing these rights , en masse .
These laws can serve as a basis ( not necessarily the only one ) for the criminal prosecution of industrial espionage activity .
Some states do not deﬁne misappropriation of trade secrets as a crime.164 KA Law & Regulation | October 2019 Page 107 The Cyber Security Body Of Knowledge www.cybok.org 3.8.3.2 Civil liability A rights owner is normally able to take legal action against a person for infringement of intellectual property .
Remedies for infringement normally include monetary damages , which may be calculated by reference to a so-called reasonable royalty , a statutory tariff or a demand that the infringer make an account of any proﬁts – a demand to pay to the rights owner the economic beneﬁt gained from the infringement .
Civil remedies may also include orders to seize , and perhaps destroy , products that infringe intellectual property rights .
These orders are especially useful when interdicting shipments of ’ knock-off ’ goods that embody trademark or copyright infringements .
With respect to trade secrets , persons in the US who suffered misappropriation of a trade secret traditionally brought legal action under the relevant law of their individual state .
In 2016 , the US national government adopted the ’ Defend Trade Secrets Act 2016 ’ amending the Economic Espionage Act to authorise private rights of action under federal law for the misappropriation of trade secrets [ 240 ] .
A common civil remedy for the infringement of intellectual property is a court order addressed to the relevant infringing party to cease any ongoing infringing activity .
In the context of patent enforcement , this can be especially devastating as an enterprise ﬁnds itself unable to continue manufacturing or selling an infringing product .
In the context of trade secret misappropriation , this might include an order to cease manufacturing products employing the trade secret or an order prohibiting the publication of the trade secret .
In an online context , such orders might demand that content suppliers or server hosts take down content that infringes copyright or a trademark .
Parties who enforce patents have sought orders to force a service provider to stop the operation of infringing services delivered via an online environment [ 241 ] .
Reverse engineering has historically been viewed as the ﬂip-side of trade secret misappropriation . ) .
, the scientiﬁc study of a device sold and purchased in a public sale in an effort to learn its secrets has generally been viewed as ’ fair game ’ .
If a trade secret is successfully reverse engineered in this fashion and published , it ceases to be a trade secret .
Since the turn of the twenty-ﬁrst century , however , the legal treatment of reverse engineering seems to have shifted following the adoption of laws prohibiting interference with anticircumvention technologies , generally making these activities more difﬁcult [ 244 , 245 ] .
Most difﬁculties arise in the context of reverse engineering software products .
Software licenses often contain onerous restrictions , including some limitations on reverse engineering generally and/or reverse compiling speciﬁcally .
European law generally prohibits any restriction on the ability of an authorised software user to observe and study the functioning of this software , and also grants these users the limited right to reverse compile speciﬁcally for the purpose of gaining interoperability information [ 246 ] .
3.8.4.1 Circumventing copyright technological protection measures Following the expansion of copyright law to prohibit the circumvention of technological protection measures , those who wish to meddle with these measures do so at their peril .
The implementation of these laws provides some exceptions to liability for research in speciﬁed circumstances , although the precise circumstances vary .
Each exception relied upon must be examined with care .
In other words , one of these researchers might face peril under the law if they were to publish details that made it possible for others to circumvent the protection measures .
There is no such general exception in British law for cryptography research involving the circumvention of measures on computer programs ( CPDA s.296 ) .
3.8.4.2 Testing a proprietary cryptographic algorithm Security researchers hoping to test the strength of a cryptographic system normally require access to the relevant algorithm .
A person who wishes to test the security capabilities of an algorithm encounters practical difﬁculties when the manufacturer of the product employs a proprietary algorithm protected by trade secret and does not wish to disclose it for testing .
The testers ( academic researchers ) did not reverse engineer this product , which could have been accomplished using an expensive chip slicing technique .
The researchers intended to publish the results of their analysis , which would have disclosed the algorithm .
Parties who had an interest in the trade secret status of the algorithm brought legal action in the English courts to halt publication .
The English High Court was confronted with a request to prohibit publication of the research pending a full trial on the merits .
The court seemed to accept that if the researchers had recovered the algorithm from the product itself using the chip slicing technique , there would be no case to answer .
But the court found that there was a possibility that the third-party Tango Programmer software may have existed only as a result of trade secret misappropriation , and that the researchers should have been aware of this .
KA Law & Regulation | October 2019 Page 109 The Cyber Security Body Of Knowledge www.cybok.org 3.8.5 International treatment and conﬂict of law The existence of intellectual property rights and assessment of ﬁrst ownership are normally measured by reference to the place where these rights come into existence [ 229 ] .
After creation in one state , the existence of copyright is generally recognised in most states around the world by the operation of various copyright treaties [ 252 ] .
If an author writes some software while resident in State A , the copyright laws of State A are normally viewed as the source of authority for identifying the existence and ﬁrst ownership of that copyright , while treaties oblige most other states to enforce that copyright within their territories ( subject to limitations or exclusions granted by those states ) .
When identical or confusingly similar trademarks are registered in different states to different owners , the rights of each owner are equally valid within their respective registered territory .
Infringement , and defences to infringement , are normally assessed by reference to the law of the place where the intellectual property is infringed [ 229 ] .
The courts are also willing to enforce domestic patents against domestic instantiations of claimed inventions delivered as part of a global service offering [ 241 ] .
The changes were made in response to early cases that held these communication service providers liable under then-existing interpretations of content liability laws including copyright and defamation .
These shields may be structured as afﬁrmative defences , meaning that the use of the shield rests upon the ability of an accused to prove that they are entitled to be treated under the relevant exception .
In the European Union , these exceptions to liability were generally mandated by Articles 12-15 of the Ecommerce Directive .
In US law , various shields from liability arising under copyright , defamation etc .
, have been adopted on a subject-by-subject basis.166 The widest scope of exemption from liability is normally afforded to those whose service consists of acting as a mere conduit for data.167 These carriers are often exempted from liability without exception , although they may be ordered to ﬁlter trafﬁc as part of a courtordered enforcement plan [ 131 ] .
KA Law & Regulation | October 2019 Page 110 The Cyber Security Body Of Knowledge www.cybok.org Those who provide a service that consists of nothing more than hosting data are often exempted from content-related liability , unless and until they have reason to know that their infrastructure is hosting illicit content.168 At this point , they often have an obligation to take down offending content ’ expeditiously ’ .
Confusion over how to implement this obligation resulted in changes to some laws which now specify in detail how take-down notices should be sent to hosting organisations , and how hosting organisations are required to reply to these notices.169 The topic of shielding service intermediaries from liability is not without controversy .
In 2018 , the US Congress amended the main US content liability shield so that it no longer protects any person in cases arising from claims of promoting prostitution or acting in reckless disregard of sex trafﬁcking.170 3.10 DEMATERIALISATION OF DOCUMENTS AND ELECTRONIC TRUST SERVICES As the age of ecommerce developed , concerns grew about how to transpose traditional methods for assuring information authenticity and integrity ( e.g .
Security technology experts responded with an array of new technologies ( often based on PKI ) intended to address these concerns .
This , in turn , prompted a series of legal concerns which potentially interfere with the utility of such technologies .
These broadly ﬁt into three categories .
The ﬁrst relates to the admissibility of electronic documents into evidence in legal proceedings .
The second category are laws that threaten legal enforceability of communications made in electronic form .
The third category relates to uncertainty about rights and responsibilities in the provision and use of identiﬁcation trust services .
3.10.1 Admission into evidence of electronic documents The admissibility171 of electronic data as evidence into legal proceedings , once the subject of much suspicion by courts , has now become commonplace .
Policy makers and judges have become increasingly conﬁdent as practitioners have developed forensic techniques to assure the authenticity and integrity of this data .
Occasionally , local rules mandate special procedures for admitting electronic evidence .
While forensic disputes about the weight to be accorded to this evidence persist , this is conceptually no different from arguments that might arise about any other type of recorded evidence .
KA Law & Regulation | October 2019 Page 111 The Cyber Security Body Of Knowledge www.cybok.org 3.10.2 Requirements of form and the threat of unenforceability A requirement of form is any obligation imposed by applicable law that a given communication will be enforceable if and only if it takes a prescribed form .
A failure to comply with an applicable requirement of form creates the risk that the subject matter of the communication will become unenforceable in whole or in part .
Different states have adopted differing requirements of form over the course of centuries in response to whatever policy issue was ascendant at the time .
As a result , these requirements are remarkably diverse and can arise in a wide variety of circumstances .
the party against whom enforcement is sought ; • certain submissions to a state agency must be made using a speciﬁed form ; • certain contract clauses or notices that seek to restrict liability must be presented in a prominent fashion ( e.g .
, all in uppercase letters , bold or italic font , etc ) to the party against whom they are to be enforced ; • certain contract clauses that seek to restrict liability must be initialled by the party against whom they are to be enforced ; • a last will and testament must be delivered in writing and signed by the testator in the presence of a prescribed number of witnesses , who must also sign the document ; and • a document transferring title to certain types of property must be signed in the presence of a state judicial ofﬁcial , who must then afﬁx an ofﬁcial seal to the document .
The examples above are merely intended to acquaint the practitioner with some of the more common types of requirement adopted within different laws by different states .
Some states and some laws impose relatively few requirements , while others aggressively adopt a variety of such requirements .
Participants enter into written agreements ( with wet-ink-on-paper signatures or following whatever other requirement of form might be imposed on these contracts ) which constitute the foundation of the contractual relationships between participants.172 Newer trading platforms built on open standards , often directed to both businesses and consumers , made early gains by trading in subject matter ( e.g .
, the sale of books and other small consumer goods ) where contracts could be concluded , and payments settled , with few if any challenges based on requirements of form.173 There is a broad international consensus that it should be possible to create and conduct business relationships in an online environment .
Many states around the world contemporaneously adopted a variety of laws and regulations designed to enable the online conduct of various types of transactions , trading relationships , administrative reporting , KA Law & Regulation | October 2019 Page 112 The Cyber Security Body Of Knowledge www.cybok.org court ﬁlings , etc .
Many were adopted in the speciﬁc context of enabling digital signatures and trust services , as discussed in Section 3.10.3 .
The legal enforceablity of communications related to other subject matter , especially topics such as the disposition of a deceased ’ s estate and the transfer of title to immovable property , have been slower to transition to electronic platforms .
These often retain signiﬁcant requirements of form that make the electronic implementation of relevant communications impracticable unless and until states decide to amend their laws .
3.10.3 Electronic signatures and identity trust services The emergence of modern ecommerce was contemporaneous with the emergence of identity trust services , speciﬁcally those that issue digital certiﬁcates that bind the identity of a person with a given public key in a PKI .
As engineering standards for these identity trust services began to emerge , two related legal questions surfaced for consideration by anyone who wished to provide or make use of these services : • the extent to which a digital ’ signature ’ produced using such a system would be accorded legal equivalence with a wet-ink-on-paper signature ; and • the nature of rights and responsibilities of various persons involved in the maintenance and use of these systems .
The question of legal equivalence for signatures is merely a sub-set of the more general problem of requirements of form discussed in Section 3.10.2 .
To the extent that various laws impose a requirement to ’ sign ’ a communication , many states have adopted laws to provide legal equivalence to electronic signatures in most , but not all , circumstances .
The question of rights and responsibilities of persons involved in trust service arrangements is signiﬁcantly more complex [ 259 ] .
Consider ﬁrst the potential liabilities of a certiﬁcate issuer in a standard three-corner operational model.174 The law of negligence ( see Section 3.7.1 ) immediately creates a number of challenges for any person operating as a certiﬁcate issuer , among them : what is the nature of the duty owed to a third party relying on a certiﬁcate ; what are appropriate standards of care in this new operational model ; and what harm is foreseeable when errors occur ?
Speciﬁc liability scenarios range from a system-wide disaster caused by the undetected compromise of a root certiﬁcate or technical ﬂaw in the authentication mechanism , to the occasional ( although recurring and perhaps inevitable ) cases of improperly issuing a certiﬁcate following the misidentiﬁcation of a signatory .
Early policy debate focussed signiﬁcantly on the degree to which signatures should be binding on the relevant signatory – especially when that person may have lost control of the signature creation device .
Much of the policy debate over this issue appears now to be concentrated on the subject-matter laws governing speciﬁc use cases , such as those adopted to regulate electronic payment services [ 212 , 213 ] .
A lack of certainty over these issues has caused certiﬁcate issuers to seek out methods to limit or otherwise rationalise their liability .
Forming a contract between the issuer and the relying person normally requires the communication of offer and acceptance between these persons ( see Section 3.6 ) .
Most systems were designed to enable reliance without the constant intervention of presenting a user with new terms and conditions every time a relying party encountered a new certiﬁcate vendor .
Similarly , certiﬁcate issuers might wish to warn relying parties about the scope of appropriate subject matter for which the certiﬁcates might be used .
The technology development community attempted to address these concerns by incorporating in the certiﬁcates speciﬁc data ﬁelds designed to communicate reliance limits and scope of use limits.175 This strategy faced a different set of legal challenges .
In practice , the certiﬁcates tend to be buried in rarely-accessed segments of the user interface .
Further , a vast number of end users whose machines might be relying on these certiﬁcates would likely fail to comprehend the data presented in them , as certiﬁcate data tends to be presented in a highly technical fashion .
There is some degree of variance between states on how they have chosen to address these issues .
Not all states have adopted all of these interventions .
Many of these interventions are subject to a variety of additional conditions or limitations .
A recurring theme concerns KA Law & Regulation | October 2019 Page 114 The Cyber Security Body Of Knowledge www.cybok.org the unwillingness of law makers to reduce rights otherwise afforded by consumer protection laws .
While some of these laws are general in nature , others are more narrowly drawn to address speciﬁc subject matter .
Any practitioner who hopes to develop a platform in an area where requirements of form are commonplace must research and review applicable laws and regulations to reduce enforceability risk .
While much debate and discussion has focused on certiﬁcate issuers , signatories , and third parties who rely on certiﬁcates , another actor in this domain is more often overlooked : the person who selects which certiﬁcate issuers should be trusted by default .
This is perhaps inevitable , as the vast majority of end users would have no rational method of discriminating between good-quality and poor-quality certiﬁcate issuers .
This raises the question of deﬁning what duty of care these certiﬁcate issuer selectors might owe to end users.178 3.10.4 Conﬂict of law – electronic signatures and trust services The nature of electronic signatures and trust services invariably implicates conﬂicts of law when relevant parties are in different states .
Consider a certiﬁcate issuer located in State A , a signatory located in State B who procures a certiﬁcate and uses it to create digital signatures , and a third party relying on the certiﬁcate located in State C. Assessing the legal equivalence of the signature can become complicated depending on which law imposes a relevant requirement of form that mandates a ’ signature ’ .
In the case of documents that purport to transfer title to immovable property , the legal equivalence question will almost certainly be answered by reference to the law of the state where the immovable property is located without any regard to the location of certiﬁcate issuer , signatory , or third party relying .
, this could be a fourth State D. ) The state where the immovable property is located is , in nearly all circumstances , the only one that can credibly assert enforcement jurisdiction over a title dispute as it is the only sovereign that could seize the property .
In matters of a simple contract between a non-consumer signatory and non-consumer third party , the European courts should be willing to ﬁnd formal validity of the contract if it meets the requirements of validity applied by the law of the state chosen by the parties to govern the contract , the law of State B , the law of State C , or possibly the law of either party ’ s habitual residence if different from any of these ( Rome I , Art 11 ) [ 214 ] .
Where consumers are involved , the European courts would only ﬁnd such a cross-border contract valid if it was deemed valid under the law of the consumer ’ s habitual residence .
Determining the applicable law concerning limitations of liability is similarly complex .
Consider , for example , the ability of a certiﬁcate issuer to rely on a limitation of liability granted under the trust services or digital signature law of State A .
The law of State C may not recognise the liability limitation otherwise granted by State A law , especially in cases where injured persons are acting as consumers .
In other words , the value of any liability exclusion or limit granted by such laws becomes questionable when relationships cross borders .
KA Law & Regulation | October 2019 Page 115 The Cyber Security Body Of Knowledge www.cybok.org 3.11 OTHER REGULATORY MATTERS This section will brieﬂy address additional miscellaneous regulatory topics that a cyber security practitioner might be expected to encounter .
Many ﬁnancial services regulators , for example , in their role as regulators of operational risk in ﬁnancial services , have always had some degree of subject matter jurisdiction over cyber security operations .
Details of cyber security risk management have increased in prominence within ﬁnancial services regulation and can be expected to continue to feature prominently [ 265 ] .
Similarly , within professions that owe legally mandated duties of conﬁdentiality to clients or whose clients enjoy legally mandated privileges prohibiting disclosure of client-professional communications ( e.g .
, lawyers and physicians ) professional regulators have become increasingly attuned to problems of cyber security .
Many of these various regulations include obligations to report or disclose security breaches .
Such disclosure requirements operate in addition to any obligations imposed by data protection law ( see Section 3.4.7 ) .
As states have begun to focus more heavily on cyber security risks , existing regulators have been encouraged to bring cyber security into their supervisory and regulatory frameworks especially in the context of critical national infrastructure .
In the European Union this has been accelerated by the adoption of the EU directive on network and information systems ( NIS Directive ) [ 267 ] .
Article 14 of the Directive requires member states to ensure that ’ operators of essential services ’ : • ’ take appropriate and proportionate technical and organisational measures to manage the risks posed to the security of network and information systems which they use in their operations ’ ; • ’ take appropriate measures to prevent and minimise the impact of incidents affecting the security of the network and information systems used for the provision of such essential services , with a view to ensuring the continuity of those services ’ ; and • ’ notify , without undue delay , the competent authority or the CSIRT of incidents having a signiﬁcant impact on the continuity of the essential services they provide ’ .
The UK implementation devolves responsibility for regulatory oversight to relevant competent authorities - instructing existing industry regulators to adopt and enforce cyber security obligations set out in the Directive [ 268 ] .
Efforts to use regulation to heighten cyber security in society continue to take many different forms .
KA Law & Regulation | October 2019 Page 116 The Cyber Security Body Of Knowledge www.cybok.org 3.11.2 Encouraging increased cyber security for products and services The emergent Internet of Things and the accompanying growth of cloud-based services create increased risks from cyber security breaches to both consumers and business enterprises .
Policy makers have begun to adopt legal frameworks for certiﬁcation of compliance of products and services with various cyber security standards .
In the European Union , certiﬁcation activity is expected to operate within the framework of the EU Cyber Security Act [ 270 ] .
( See also discussion of certiﬁcation marks used by public and private standards bodies in Section 3.8.2.3 . ) .
3.11.3 Restrictions on exporting security technologies States have long imposed restrictions on the export of goods intended for use in armed conﬂict .
These laws grew signiﬁcantly during the Cold War , as Western bloc states sought to restrict the ﬂow of defence technologies to the Eastern bloc.179 These export limitation regimes also apply to ’ dual use ’ goods : sensitive products that have legitimate uses in both peace and war .
Although a surprisingly wide variety of dual use products ( and services ) have been caught under the terms of such restrictions , those that are caught because they embody certain cryptographic functions have been especially contentious in the ﬁeld of cyber security .
Prior to the 1990s , the US ( and other states ) regulated the export of strong cryptographic products with an extremely broad brush .
Export prohibitions were framed in such expansive language that almost any export required prior government licence .
At the beginning of the 1990s , the implementation of strong cryptography in software for general purpose computers , the growing body of non-governmental research work into cryptography , the availability of the Internet as a means to distribute know-how and source code , and the increasing pressure for reliable standards-based cryptographic implementations in support of cyberspace infrastructure , collided with these same export restrictions .
, the First Amendment to the US Constitution ) were brought challenging the validity of export regulations as applied to cryptographic software .
The argument presented proceeds , in essence , as follows : source code is expressive , expressive content is protected speech , therefore source code is speech , the export regulations are therefore a governmental prior restraint on speech , as a prior restraint the regulations must be extremely narrowly tailored to address a clear danger , but the regulations are in fact very broadly drawn and therefore do not meet constitutional muster .
The US courts struggled with the concept of whether source code was protected ’ speech ’ .
Eventually , in Junger v Daley ( 2000 ) , the US Court of Appeals for the 6th Circuit held that source code was speech and found the US export regulations unconstitutionally over-broad [ 273 ] .180 No doubt in response to this and similar legal challenges in other US Circuits , combined with heavy lobbying by the ICT industry , the US government issued revised export regulations to create signiﬁcantly more limited restrictions on cryptographic exports [ 274 ] .
Many states including the US continue to maintain export restrictions on certain dual use products , including some implementations of cryptographic technology .
Anyone engaged in the production of these products should review applicable laws carefully , as violations can be prosecuted as crimes .
KA Law & Regulation | October 2019 Page 117 The Cyber Security Body Of Knowledge www.cybok.org 3.11.4 Matters classiﬁed as secret by a state Practitioners who are employed or engaged by states are routinely subject to laws that mandate secrecy of certain information classiﬁed as secret by those states .
Most commonly , this arises in an environment where the disclosure of relevant secrets could harm the defence of the state , the integrity of a police investigation , the safety or efﬁcacy of persons conducting state sponsored espionage activity , etc .
These laws can sometimes be used to intervene and classify as secret the research and development work of third parties .
Practitioners may also come within the remit of these laws when state security ofﬁcials choose to disclose certain classiﬁed information relating to cyber threats .
These laws tend to authorise extremely severe criminal penalties for those who violate them .
3.12 PUBLIC INTERNATIONAL LAW [ 104 ] Public international law181 is the body of law that regulates relationships among and between states , which for this purpose includes international governmental organisations but excludes constituent states of a federal state .
Sources of public international law include treaties , widely accepted international norms and customs , and decisions of international tribunals .
Only states are said to have ’ standing ’ to enforce claims arising under public international law .
Non-state persons are normally unable to take legal action against states for violation of public international law .
A non-state person may hold the right to take legal action against their home state for failure to implement obligations imposed upon the state by public international law , although states normally must afﬁrmatively grant these rights to non-state persons [ 155 ] .182 Similarly , international law normally seeks to regulate the behaviour of states rather than the actions of their residents or nationals.183 Cyber operations undertaken by a non-state person in State A against persons or infrastructure in State B normally do not constitute a violation of international law , unless the action can be attributed to State A or to some other State C ( see Section 3.12.1 . ) .
Having said this , states can and do diverge in their opinions of how these principles should be interpreted in the context of speciﬁc types of cyber operation .
At the time of writing , the most comprehensive and most widely accepted published source of analysis on the application of international law to cyber operations is the restatement of international law found in the Tallinn Manual 2.0 [ 104 ] .184 KA Law & Regulation | October 2019 Page 118 The Cyber Security Body Of Knowledge www.cybok.org 3.12.1 Attributing action to a state under international law Attribution is the process of determining if a state is legally responsible under international law for a given action .
In extreme circumstances , if illicit activity is regularly initiated by non-state actors from cyber infrastructure inside the territory of a state , and that state remains willfully blind to that activity or otherwise fails to exercise appropriate due diligence in attempting to identify and restrain the illicit activity , then it may be possible to attribute the illicit activity to that state .
3.12.2 State cyber operations in general Public international law is founded on the principle of territorial sovereignty.186 A state is said to be sovereign within its own territory , and also has the right to conduct activities outside of its territory consistent with international law .
Countermeasures are actions that would normally violate international law that are directed against the second state in an effort to encourage it to comply with its obligations under international law .
Countermeasures must be proportional to the complained-of violation of international law by the second state .
Countermeasures in response to an illegal cyber operation might consist of cyber or non-cyber responses .
A cyber operation of one state directed against another state is normally contrary to the principles of international law if it interferes in the affairs of the second state ( [ 104 ] at R.66 ) .
Finding the dividing line between them is challenging and is generally measured by reference to the scale and effects of the complained-of act .
Because of the uncertainty over when the scale and effects of a cyber operation are sufﬁciently severe to constitute an armed attack , it has been suggested that some states have adopted a strategy using this uncertainty to conduct cyber operations in a ’ grey zone ’ somewhere between peace and armed conﬂict [ 278 ] .
Furthermore , methods that support espionage by harming equipment within the territory of the second state would constitute a violation of that state ’ s sovereignty and ( if sufﬁciently damaging ) could amount to a use of force.188 A speciﬁc example of this principle applies to state efforts to tap submarine communication cables for the purpose of intercepting communications .
If a state covertly taps cables in international waters without signiﬁcantly interrupting their functionality , this very likely does not constitute a violation of international law .
3.12.4 Cross-border criminal investigation Actions by one state that constitute the exercise of police power within the territory of another ( unrelated ) 189 state normally constitute a violation of that state ’ s sovereignty under international law .
This is easy to see in cases where police powers involve the use of force in person , such as searching physical premises , or arresting or interrogating a suspect located in the second state .
Acts of surveillance conducted from within the territory of one state that do not involve physical contact by that state ’ s agents with the territory of another state are more complex to analyse .
Nonetheless , it is well documented that remote cyber surveillance and evidence gathering activities are conducted by the law enforcement agencies of various states from time to KA Law & Regulation | October 2019 Page 120 The Cyber Security Body Of Knowledge www.cybok.org time with the express or implied authorisation of the investigating state , and directed against cyber infrastructure located in another , non-consenting , state [ 109 ] .
3.12.5 The law of armed conﬂict Upon commencement of armed conﬂict , the conduct of activity within the context of that conﬂict is said to be governed by the ’ law of armed conﬂict ’ ( also known variously as the ’ law of war ’ and ’ international humanitarian law ’ . ) .
190 State cyber operations conducted as part of an armed conﬂict are assessed by reference to the law of armed conﬂict .
This ﬁeld is the subject of extensive study and debate by the military leadership of many states , which invest signiﬁcant time and effort producing legal guidance for their military commanders concerning that state ’ s interpretation and implementation of the law .
, the 1944 Chicago Convention on civil aviation ) are suspended or otherwise altered as between belligerent states engaged in hostilities .
Key principles that underpin the law of armed conﬂict include : • Military necessity : a state may use such force as is necessary to defeat an enemy quickly and efﬁciently , provided that such force does not violate other principles of the law of armed conﬂict .
This imposes an obligation upon a belligerent state to distinguish its own military person and objects from civilian persons and objects , as well as working to distinguish enemy state military and civilian persons and objects .
A recurring issue of discussion among experts concerns what is required to treat a cyber operation , on its own , as an ’ attack ’ under the law of armed conﬂict .
The Tallinn Manual 2.0 refers to such an operation as a ’ cyber attack ’ , which the expert group deﬁnes as a cyber operation ’ that is reasonably expected to cause injury or death to persons or damage or destruction to objects ’ ( [ 104 ] at R.92 ) .191 The characterisation of a cyber operation as a cyber attack under international law is critical , as the law of armed conﬂict limits how states carry out such attacks .
Although the principles of the law of armed conﬂict are not signiﬁcantly in dispute , how to interpret and apply these in the context of speciﬁc cyber operations raises a series of re- KA Law & Regulation | October 2019 Page 121 The Cyber Security Body Of Knowledge www.cybok.org curring questions .
For example , many legal experts take the view that the principle of not targeting cyber attacks against civilian objects applies only to tangible objects and that intangible data , as such , does not fall within the legal deﬁnition of ’ object ’ [ 283 ] .
Another difﬁculty in application concerns the intermingling of military and civilian cyber infrastructure .
This leads to the possibility that signiﬁcant components of public cyber infrastructure , including dual-use data networking and cloud services infrastructure , could be characterised as a legitimate target of cyber attack in time of armed conﬂict ( subject to other legal limitations such as the need to respect the principles of humanity and proportionality ) ( [ 104 ] at R.101 , cmt.4-5 ) .
Some have argued that such outcomes point to the need to reconsider how public international law should operate in this context [ 283 ] .
3.13 ETHICS Cyber security practitioners often ﬁnd themselves operating in positions of trust , where special knowledge and skills potentially give them asymmetric power to inﬂuence or disrupt the affairs of their clients or other members of the public .
Those who act outside of a speciﬁc client relationship , such as product developers and academic researchers , exercise special skills in a manner that could cause harm to a wide variety of third parties .
Practitioner activities often take place behind closed doors away from the glare of public scrutiny .
Ethical norms might assist in curbing behaviours that abuse positions of trust or otherwise present signiﬁcant risk to the public .
Early cyber security ethics guidance focused signiﬁcantly on legal risk management such as liability arising under intellectual property , data protection and privacy laws [ 284 ] .
Although practitioners should remain aware of laws that apply to their actions , compliance with the law , on its own , may be insufﬁcient to guide a practitioner to ethical action.192 As a practice that is generally conducted in the absence of formal state professional regulation , it is difﬁcult to identify generalisable norms that are expected to apply to activities undertaken by security practitioners.193 This section will survey some of the recurring issues and potential sources of guidance .
3.13.1 Obligations owed to a client A review of some obligations normally owed by regulated professionals to clients may be helpful as societies ( and various nascent professional bodies ) continue to develop approaches to obligations that should be owed by cyber security practitioners to their clients .
At the very least , one can identify various duties of care that arise under contract or tort law to conduct services and other activities that involve risk in a reasonable fashion and with appropriate expertise .
Product designers similarly owe various legal obligations under the normal rules of tort law .
KA Law & Regulation | October 2019 Page 122 The Cyber Security Body Of Knowledge www.cybok.org Regulated professionals are normally expected to act in the best interests of their clients , to avoid conﬂicts of interest and to maintain the conﬁdentiality of client affairs .
While afﬁrmatively adopting these types of obligation by contract is often non-controversial , difﬁculties can arise when a security practitioner and client disagree about the most appropriate course of action in speciﬁc circumstances .
Challenges can arise with respect to non-mandatory disclosure of evidence to interested third parties.194 If a practitioner discovers evidence of wrong-doing and there is no supervening legal obligation to report that evidence , the practitioner and client might disagree concerning the disclosure of such evidence to interested third parties such as relevant police authorities , CERTs or tort victims .
These cases can be difﬁcult to navigate .
, petty theft ) , the client may view public disclosure as more damaging than handling the matter solely on an internal disciplinary basis .
In cases where an employee is found to have harmed a third party through tortious action such as negligence , disclosing this evidence to the victim may work to the ﬁnancial detriment of the client ’ s company through vicarious liability .
Other difﬁcult cases arise when the interests of the practitioner and their client are not aligned .
Such disclosures must normally be limited to information that is necessary to pursue collection and may come with obligations to seek appropriate protective orders from the courts .
Actions by a practitioner that interfere with the proper functioning of their client ’ s infrastructure in an effort to exercise undue inﬂuence over the client are unsavoury at best , and might cross a line into criminal conduct at worst .
An express or implied threat of such action seems no better .
It remains to be seen whether cyber security practitioner-client relationships will become the subject of formal state regulation or licensure in due course .
3.13.2 Codes of conduct Various professional bodies have published codes of conduct and ethical guidelines for cyber security practitioners .
Many of these refer to high-level ethical principles without the more detailed guidance that is necessary to assist practitioners with interpretation of the principles.195 Examples of two more recent and carefully considered codes of conduct are presented below for consideration .
One is framed as a code of general applicability and one is built around a deﬁned business process .
The ACM Code of Ethics and Professional Conduct was extensively revised in 2018 to take account of the impact of data connectivity [ 286 ] .
The revised ACM Code provides multiple points of guidance relevant to the ﬁeld of cyber security .
KA Law & Regulation | October 2019 Page 123 The Cyber Security Body Of Knowledge www.cybok.org The ACM Code clearly demonstrates the difﬁculties of balancing ethical imperatives .
In its admonition to avoid harm ( Section 1.2 ) , it states there is an ’ additional obligation to report any signs of system risks that might result in harm ’ .
While the Code addresses the possibility of ’ whistle-blowing ’ as a reporting technique in appropriate circumstances , it also cautions that ’ capricious or misguided reporting of risks can itself be harmful .
By contrast , CREST was established in the UK in the early twenty-ﬁrst century originally as a membership body for ﬁrms that supply penetration testing services.196 At the time of writing , it has more than 180 accredited member ﬁrms [ 288 ] .
Penetration testing typiﬁes a service that should be of signiﬁcant concern to the public : information asymmetry means clients are generally unable to distinguish good practice from bad , services are supplied conﬁdentially away from public scrutiny , and practitioner errors can cause disproportionate harm to clients or third parties .
The CREST Code of Conduct for CREST Qualiﬁed Individuals provides guidance on numerous topics relevant to delivering these services including service methodology , ethical business practices , and obligations owed to clients [ 289 ] .
The CREST Code also provides a client complaint mechanism and the organisation reserves the right to expel from membership those who fail to adhere to the CREST Code .
To the extent that clients mandate that suppliers of relevant services maintain CREST membership , these mandates may slowly migrate CREST from a purely voluntary membership association into a de facto regulator of those who supply these services .
By historical standards , cyber security presents a relatively new set of methods and processes which are at best poorly understood by the public .
Generalised codes like the ACM Code are helpful , as they guide a community of persons with relevant technical expertise who may work in ﬁelds as diverse as research and development or security management .
Service-speciﬁc codes like the CREST Code are helpful , as they focus clearly on speciﬁc highrisk services .
Codes of conduct will undoubtedly continue to develop as the impact of cyber security practitioner activity on the public becomes better understood .
3.13.3.1 Testing for vulnerabilities Practitioners who test for security vulnerabilities should consider carefully the nature of their activities .
The mere act of studying and analysing objects such as tangible hardware products , locally resident licensed software , or published cryptographic primitives and communication protocols , is normally uncontroversial .
It is difﬁcult to draw a line of causation from the mere act of analysis to public harm .
Practitioners should be careful , however , to consider the source of the security object under study .
There may be a distinction , for example , between reverse engineering a silicon chip to discover the functionality of a trade secret cryptographic scheme and reverse engineering third-party software of suspicious provenance that embodies the same secret methodology .
When vulnerability testing is conducted remotely , the testing methods can raise additional KA Law & Regulation | October 2019 Page 124 The Cyber Security Body Of Knowledge www.cybok.org issues .
Practitioners must ﬁrst remain cognisant that unauthorised efforts to gain access to a computer system are often deﬁned as a crime ( see Section 3.5 ) .
As stated in the ACM Code Section 2.8 , ’ A system being publicly accessible is not sufﬁcient grounds on its own to imply authorization ’ [ 286 ] .197 If practitioners are testing in response to a ’ bug bounty ’ program , they should review carefully the terms of the program to assure that they are not exceeding the scope of authorised testing activity .
Practitioners should also consider the potential impact of their testing methods on the stability of public or private infrastructures , including those that are the target of testing as well as intermediary and third-party systems .
3.13.3.2 Disclosure of vulnerabilities Those who ﬁnd security vulnerabilities face a choice of what to do with their new-found knowledge .
Choices exist on a spectrum from making no disclosure , to publishing every detail immediately to the world at large .
In between these two extremes lie an array of possibilities .
Those who make no disclosure choose to do so for different reasons .
Some wish to make no disclosure in an effort to avoid complicated problems of ethics and potential liability .
It is difﬁcult to reconcile this position with the ethical principle expressed in the ACM Code Section 2.8 ’ to report any signs of system risks that might result in harm ’ [ 286 ] .
Finders who choose to make an immediate full public disclosure of vulnerabilities without any prior warning to any effected person may do so for a variety of reasons .
Some suggest that this is the only certain method of encouraging remediation efforts by developers .
Some do not wish to invest in the time-consuming process of staging the private and public disclosures described below .
Some fear that engaging with developers will prompt a legal intervention prohibiting disclosure.199 It is difﬁcult to reconcile these arguments with the guidance from the ACM Code to minimise harm .
The idea is to disclose ﬁrst on a conﬁdential basis to a person or group of persons who may be able to remediate or mitigate the impact of the vulnerability .
After a period of time has elapsed , the ﬁnder might then proceed to a second stage of public disclosure .
Second-stage public disclosure is often justiﬁed by the practitioner on the theory that publication will enable other practitioners to study and avoid similar vulnerabilities , and/or incentivise product and service providers to remediate the vulnerability .
At the time of writing , there appear to be no generally agreed principles on the proper conduct of responsible disclosure .
Points of divergence include : • how to manage private disclosure when the vulnerability forms part of a widely adopted industry standard ; • how to manage private disclosure when the vulnerability is found in a product which forms a component or sub-component in downstream products ; 200 • deﬁning the appropriate length of time between private and public disclosures ; KA Law & Regulation | October 2019 Page 125 The Cyber Security Body Of Knowledge www.cybok.org • deﬁning what circumstances , if any , mandate an indeterminate delay to public disclosure ; and • deﬁning how to respond if the relevant vendors or purchasers of compromised products disagree with the ﬁnder about the wisdom or timing of public disclosure .
Public disclosure of vulnerabilities could also create tortious liability for a disclosing ﬁnder , especially if the process or sequence of disclosures is poorly managed or the vulnerability is misdescribed .
Practitioners who seek to justify publication on the basis that it ﬁts generally within the rubric of ’ responsible disclosure ’ may receive a poor reception from state authorities [ 249 , 250 ] .201 Various efforts to obtain ﬁnancial beneﬁts from disclosing a vulnerability also lead to debate .
Practitioners who ﬁnd vulnerabilities during the course of their work as security researchers must further consider the extent to which they may be accountable to their employer or funder for any ﬁnancial beneﬁts obtained .
3.13.3.3 Facilitating and acting on vulnerability disclosures Product and service vendors should consider how they can facilitate and then act upon vulnerability disclosures in a manner that minimises harm to customers and third persons.202 Key principles to facilitate proper vendor handling of vulnerability disclosures include : publishing acceptable methods for ﬁnders to disclose vulnerabilities to the vendor , working diligently to verify the vulnerability once it is disclosed , developing remediation or mitigation strategies , disseminating ﬁxes , working with supply chain partners , and providing feedback to ﬁnders .
There were many points implicit in that introduction , however , including Bob ’ s awareness of : Alice , her right of action , as well as details of applicable substantive and procedural law .
On its own , the function presented is most helpful after-the-fact - after Bob receives a threat of legal action from Alice .
The purpose of this Section is to consider legal risk management before-the-fact .
Anyone seeking to understand legal risk often begins with an information deﬁcit .
Simply learning about the many laws and regulations that can or should inﬂuence the operation of a single enterprise can be prohibitively time-consuming and expensive .
This problem multiplies according to the number of jurisdictions with which a person may be dealing – a signiﬁcant challenge if cyberspace truly enables contact with every jurisdiction in the world .
In the modern era of more than two hundred sovereign states recognised under public international law , plus hundreds of states that are members of a federal or similar structure , plus untold tens ( or hundreds ) of thousands of additional municipal jurisdictions with varying degrees of law making and enforcement authority , merely discovering the content of applicable laws and regulations and assessing enforcement risks can be a monumental task .
In a ﬁeld where multinational contacts and relationships are commonplace , considerations of the effective limits of state power are also appropriate .
What follow are a few subjects for consideration when constructing a legal risk management framework .
Identify subject matter areas of greatest risk .
The nature of the activities undertaken by a person helps to identify which laws and regulations will be of most signiﬁcance to that person .
For example , banks , telecommunications infrastructure providers , and providers of medical and legal services are always cognisant of their need to seek and maintain appropriate licenses for their activities .
Providers of gaming ( gambling ) services are also very attuned to the wide variation of laws that apply speciﬁcally to their operations .
And all businesses are extremely aware of the need to understand tax reporting , collection , and payment obligations .
Consider the impact on human life .
A strict cost-beneﬁt analysis may be useful when making operational decisions , but becomes problematic where matters of human life and safety are concerned .
Laws and regulations adopted to protect human life and compensate for personal injury should be accorded special respect .
A blatant disregard of such rules raise signiﬁcant moral and ethical concerns and can also result in exceptional or punitive measures when these rules are enforced .
Conduct due diligence that is aligned with identiﬁed risks .
Nobody instructs a lawyer to ’ Go and ﬁnd every law in the world that arguably might apply to anything I do .
’ A typical due diligence strategy involves ﬁrst identifying and investigating the laws that could destroy or bankrupt an enterprise .
Other laws and regulations may become increasingly signiﬁcant as an enterprise grows or changes character .
Foreign laws become increasingly signiﬁcant as the enterprise makes increasing contact with new jurisdictions .
Consider the practical limits of territorial enforcement jurisdiction .
In the era of online commerce , some enterprises become paralysed with fear about the potential legal obligations to hundreds of states whose residents might gain access to site content .
Most of the others try to adopt pragmatic approaches that include good faith efforts to ﬁlter content or otherwise block access to residents of states that characterise one ’ s products or services as illicit .
There are times when the cost of answering a civil legal action is less than the cost of compliance .
Most commonly , this occurs in the context of a commercial contract which has become uneconomic to perform , or a civil regulatory requirement with a ﬁxed ﬁnancial penalty .
In appropriate circumstances , a person might reasonably conclude that repudiating its civil obligation ( and accepting the risk of a legal action for money damages ) is less expensive than fulﬁlling the corresponding obligation .
Cyber security practitioners are sometimes confronted with situations where they are tempted , or instructed , to violate criminal law .
Those who face this circumstance should remember that they may personally suffer the consequences of their actions , irrespective of whatever incentive has been provided by an employer or client .
There are times when persons who have legal rights choose not to enforce them .
For example , the risk of legal action from an individual natural person who has suffered a de minimis loss as a result of a minor business tort may be diminishingly small .
If the rights of thousands or millions of these persons can be joined together in a class action lawsuit , however , the risk increases signiﬁcantly .
Efforts to enforce legal rights and efforts to defend against claims all hinge on one ’ s ability to prove , or to rebut an adversary ’ s efforts to prove , the underlying facts in dispute .
Consider what issues will require proof when an adverse party seeks to enforce a legal right , and how one can collect and preserve evidence to an appropriate forensic standard in anticipation of the need to defend against this effort .
Practitioners are also cautioned to explore the parameters of any applicable document or data retention policy , which involves the routine and regularly scheduled destruction or deletion of documents .
While the routine destruction of documents in accordance with a carefully deﬁned governance policy is usually permissible , these procedures normally must be suspended to the extent that documents may be relevant to any legal action that has commenced or been threatened .
Any attempt to destroy evidence that might be relevant to such a legal action often constitutes a violation of the law and can result in severe consequences.204 Consider vicarious liability .
The only certain way to reduce vicarious liability is to inﬂuence employee behaviour to reduce the number of acts that are tortious or otherwise violate applicable regulations .
Internal governance documents intended to reduce liability to third parties should therefore be written with the goal of inﬂuencing this behaviour .
Consider localising risky activities in separate limited liability legal persons .
Lawyers routinely counsel business clients concerning the creation and structuring of separate legal persons in an effort to contain liabilities within deﬁned pools of investment capital .
Consider risks that are external to the legal system , per se .
In some circumstances , the greatest risk arising from a legal action or a threat of legal action has almost nothing to do with laws or regulations , as such .
Consider , for example , the impact of a potential legal action on the reputation of an organisation or the impact of an adverse ﬁnding on the maintenance of relevant state licenses to conduct business .
KA Law & Regulation | October 2019 Page 128 The Cyber Security Body Of Knowledge www.cybok.org Consider changes to law or enforcement policy that are likely to arise .
Societies and policy makers are generally becoming more aware of the impact of cyber security .
As this awareness increases , states and their agents may increase enforcement activities , re-examine assumptions about existing policy , and intervene rapidly with amended or new laws .
Examples of these rules can be found in the [ England and Wales ] Civil Procedure Rules , Title 28 of the United States Code , and the [ US ] Federal Rules of Civil Procedure .
Because criminal proceedings place at risk the individual liberty of the accused , these rules are heavily inﬂuenced by human rights law , can be signiﬁcantly different from civil procedure , and thus are often maintained separately from civil procedure rules .
3 Rules of evidence govern the presentation and examination of evidence before a tribunal .
4 Cyber security practitioners are not alone in this respect .
Highly experienced lawyers routinely require guidance from ’ local counsel ’ who are retained speciﬁcally to assure compliance with these rules when attempting to manage multi-state disputes .
5 See Note 13 6 Anecdotal evidence gathered by the author over many years of ICT-focused international commercial legal practice , however , strongly suggests that many of the norms expressed in this knowledge area are also reﬂected in systems of civil law ( see Note 14 ) .
There is no claim that the norms presented here would necessarily be found in other systems of domestic law such as those founded on religious doctrine or sui generis customary law .
9 While jurists and legal scholars tend to agree on the process of legislative amendment to law , the idea that evolution in societal values can lead to changes in the interpretation of un-amended law is not universally accepted .
Depending upon the system of law in question , some jurists and legal scholars take the view that KA NOTES | October 2019 Page 130 The Cyber Security Body Of Knowledge www.cybok.org some laws represent unchanging ( perhaps even universal ) values and reject any other notion as inappropriate or heretical .
This disagreement also exposes a recurring tension in deﬁning and maintaining the division of legislative from judicial authority .
For the security practitioner this debate can be simpliﬁed as follows : by whatever mechanism , law changes over time .
11 The pace of change in various laws depends upon how deeply rooted they are in social values .
, the right to notice and the right to present one ’ s case to a tribunal ) , are so slow to change that they appear within the span of a single generation to be immutable .
12 Indeed , the relative utility of a system of law arguably depends upon this characteristic of predictability of outcome .
A contrary , even nihilistic , view of law and legal analysis is found in the academic school of critical legal studies .
13 Common law systems are those derived from the law of England .
These are the foundation of legal systems in states that had close historical connections with Great Britain , including England , Wales , Ireland , Australia , New Zealand , Singapore , most of the constituent provinces of Canada , most of the constituent states of the United States , etc .
As a result , this system of law is nearly ubiquitous in anglophone territories .
These are the foundation of legal systems throughout Europe ( with the exception of a few common law jurisdictions ) and in states that had close historical connections with continental Europe .
This is especially easy for the unwary who stumble across the annual mountain of bills introduced by members of the US Congress which never become law .
17 As a limited narrow exception , some states adopt the practice of examining legislative history ( such as the series of draft bills as they were amended in the process of debate to become law ) as a means of helping to interpret the law as ﬁnally adopted .
18 The status of European Union legislation in the United Kingdom after Brexit is complex .
The UK has adopted legislation that will generally continue within the body of UK domestic law those pre-Brexit EU laws that are most relevant to cyber security ( e.g .
, data protection regulation ) unless and until the UK Parliament decides to diverge from EU legal principles .
Thus , courts of the State of New York would regard interpretations of law issued by courts of the State of California as the decisions of a foreign state .
As such , they would not constitute binding authority in New York State courts , although they might have value as a source of persuasive authority .
This discussion should not be confused with the subject of enforcing foreign judgments ( see Section 3.2.4 ) .
( a collection of otherwise disparate Acts of the US Congress organised into code form by editors who then revise the code as further legislation is adopted or amended ) , and the Bürgerliches Gesetzbuch ( BGB ) ( the comprehensive code of German civil law adopted en masse at the start of the 20th century and amended from time to time ) .
( a set of model laws produced as a joint project of the Uniform Law Commission and the American Law Institute , which has in turn been adopted with some local variations by most constituent states of the United States and has thus become extremely inﬂuential ) .
23 This last category can sometimes suggest the future development of law , as states may decide to mandate compliance with codes that began life as suggested rules .
Similarly , courts may use advisory codes as a way of interpreting responsibilities such as the requirement to act ’ reasonably ’ in assessing negligence liability .
26 Some creative arguments against this result include attempting to recharacterise cyberspace as ’ territory ’ that exists separately from sovereign states , thus attempting to describe a universal and harmonised set of legal principles that should be applicable to all uses of cyberspace globally , and in some cases rejecting the authority of sovereign states to intervene in cyberspace-related activities .
Many of the computer crimes discussed in Section 3.5.1 may not require such proof .
31 ’ Civil law ’ in this context , meaning non-criminal law , should not be confused with the term ’ civil law ’ as a means of classifying systems of law such as are found in the states of continental Europe .
32 Principles of human rights law designed to guarantee a fair trial for Alice often force people like Bob to delay their civil action until the relevant criminal prosecution is concluded .
The difference in standards of proof , it is entirely possible for Alice to be found ’ not guilty ’ of the alleged crime and still be found liable for the alleged tort .
33 The law of the United Kingdom expressly prohibits introducing the content of such intercepted communications as evidence in court proceedings .
In the ﬁeld of mathematics , to ’ prove ’ something means to establish undeniability as a logical necessity – to establish the truth of a proposition beyond any dispute .
A technology journalist eloquently summarised this when he stated , ’ The purpose of law is not to achieve philosophical or mathematical truth , but to take a messy reality and achieve workable results that society can live with ’ [ 310 ] .
35 An ’ afﬁrmative defence ’ is contrasted with other types of defence where the party pursuing a right of action continues to carry the burden of proof .
For example , in a criminal prosecution for murder under English law if the accused claims ’ self-defence ’ it remains the responsibility of the state to prove beyond reasonable doubt that the accused is NOT entitled to the defence .
36 There are many possible criticisms of this approach to explaining legal risk analysis , including the focus on ’ cost ’ as a determinant of risk .
Factors beyond the mere ﬁnancial are considered in Section 3.14 .
37 Although courts use this same phrase to describe the two standards of proof , they remain free to deﬁne them differently in the context of interpreting two different laws adopted for two different purposes .
38 This term can also be used to describe subject matter and territorial authority of legal persons created by treaty between states , such as international governmental organisations ( e.g .
For example , a single state might choose to divide its court system into two parts : one that addresses only criminal complaints and one that addresses only civil matters .
While the territorial jurisdiction of both courts might be identical , the subject matter jurisdiction is clearly different .
40 A good introduction to the principles of juridical jurisdiction for civil cases is found in the recast Brussels I Regulation , which presents the rules normally applicable to civil matters in courts located within the European Union [ 312 ] .
To take an admittedly whimsical ﬁctional example from the Wild West , in the ﬁlm Silverado Sheriff Langston ( portrayed by John Cleese ) discontinues his hot pursuit of criminal suspects through the wilderness after a sniper opens ﬁre on his posse .
Sheriff Langston ’ s quandary illustrates the relationship between state power and enforcement jurisdiction .
Non-ﬁctional examples that explore the territorial limits of state enforcement power are readily available , albeit controversial , and in some cases are the subject of diplomatic and international legal dispute .
43 Reasons this activity might not be illegal under the law of the ﬁrst state include , most obviously , where the ﬁrst state has not adopted any law to criminalise the complained-of hacking activity .
Alternatively , the ﬁrst state may criminalise the activity in normal circumstances but ofﬁcially warrants the cyber operation pursuant to the lawful domestic authority of the ﬁrst state .
In this second scenario , the person undertaking the operation would normally be immune from criminal prosecution in the ﬁrst state but subject to criminal prosecution in the second .
This discussion focuses solely on liability of the relevant non-state person undertaking the cyber operation .
The liability of states to one another for such operations is addressed in public international law ( see Section 3.12 ) .
46 A bank in this situation faces the practical problem of two competing states making conﬂicting demands : one ordering payment , and a second prohibiting payment .
Taking the analysis one step further , imagine what could happen if ( in an effort to avoid adverse enforcement actions by the United States ) the London branch of a US bank refused to comply with the judgment of an English court .
This bank might jeopardise its ability to conduct regulated banking activities in London .
Presumably , the depositor could also ask English courts for enforcement assistance by demanding the seizure and forfeiture of funds held by such defaulting US banks on deposit with other banks in the UK .
The depositor could also take the judgment and request enforcement by third-party states where the US bank also held funds on deposit .
These are the types of analysis that arise when a non-state person considers the risk of potentially conﬂicting state mandates .
47 In the context of the US federal system , each member state of the US is normally required to enforce civil judgments issued by courts of other member states under the Constitutional mandate to give ’ full faith and credit ’ to acts of other US states .
This continues to hold true even if the suspect does not request entry to State B .
Criminal suspects can be , and have been , arrested in the international transit areas of airports .
Both are mechanisms that can serve to limit how systems are used .
However , the phrase has been interpreted by some to mean that ’ whoever writes the computer code is essentially making the law ’ .
The history of how laws are enforced with respect to Internet-related activity strongly suggests that this interpretation is ( at best ) terribly misleading and ( at worst ) misunderstands the direction of causality between computer and legal code .
While technologists certainly enjoyed ﬁrst-mover advantage in choosing the design of the underlying architecture of the Internet and related applications , law makers - and the societies for whom they serve as a proxy - have responded strongly with their own opinions about how systems should work .
In other words , one KA NOTES | October 2019 Page 133 The Cyber Security Body Of Knowledge www.cybok.org should not assume that the persons who write the ( computer ) code are the same persons who create the legal norms to be enforced .
50 The signiﬁcant role undertaken by various platform operators in ﬁltering content on a state-speciﬁc basis and supplying similar geo-ﬁltering tools to their content supplying customers is often overlooked in policy debate .
51 An example of collaborative ﬁltering is found in the work of the Internet Watch Foundation .
Among other things , the IWF maintains a URL database of sites known to host images of child sexual abuse .
52 The opinion of Judge Lynch , concurring , is especially interesting as he wrote to highlight many of the more unsettling and counter-intuitive policy aspects that would result from the judgment and ’ to emphasize the need for congressional action to revise a badly outdated statute ’ .
53 Although the Microsoft case was dismissed prior to judgment , the extensive collection of briefs ﬁled with the US Supreme Court by a variety of interested third parties constitutes a treasure trove of analysis and advocacy on this topic .
It remains possible that a future dispute might be brought in the US courts to challenge the authority of the US Congress under the terms of the US Constitution to extend jurisdiction in this fashion .
While the outcome of any such future challenge is debatable , it seems unlikely to succeed .
54 The precise meaning of ’ lawful and voluntary consent ’ in Article 32b of the Budapest Convention has prompted much discussion .
One area of repeated concern is the acceptance by some states of criminal plea bargaining techniques as a means of obtaining consent from criminal suspects [ 139 , 317 ] .
55 Although people most often discuss the issue of data sovereignty in the context of compelled disclosure of data , other state interventions may also be possible such as compelled data alteration or deletion , or compelled service interruption .
56 Methods used in an effort to mitigate this risk using cryptographic technology , database sharding or replication over servers in multiple states , etc .
are outside the scope of this knowledge area .
57 The Regulation , of course , does not interfere with any data localisation rules imposed for reasons of state security as this subject area falls outside the regulatory subject matter jurisdiction of the European Union .
58 The discussion in the Section focuses primarily on the privacy rights of natural persons .
States can and do apply these or similar rights to legal persons , although the privacy rights of legal persons may be less than those accorded to natural persons in some circumstances .
59 To understand the legal context of the international instruments cited , see the introductory discussion of public international law in Section 3.12 .
61 In the US legal system , for example , the Fourth Amendment to the US Constitution provides a set of rights that limit only state actions , while the California Constitution grants a general right of privacy effective against state and non-state actions .
Both the US and its constituent states have promulgated a large number of laws that regulate intrusions under various conditions .
62 Examples made possible by the emergent mobile app economy include processing data concerning personal contacts , calendar and scheduling information , banking data and authentication credentials , personal notes and communications , browsing and shopping history , intimate relationship data , and a variety of healthrelated data from heart rate and exercise patterns to menstruation data .
Each new data set presents a question about the ’ normal ’ expectation of privacy when using these services , and the permissible scope of intrusion by state and non-state persons .
63 In the referenced case of Smith v Maryland , the US Supreme Court decided in 1979 that compelled disclosure of customer dialling records did not constitute a ’ search ’ for purposes of the Fourth Amendment to the US Constitution as the customer had no expectation of privacy in the list of numbers dialled [ 158 ] .
In this example , the URL meta- KA NOTES | October 2019 Page 134 The Cyber Security Body Of Knowledge www.cybok.org data leads to a strong inference of communication content and the probable ability to reconstruct accessed content precisely .
In Europe , customer location data has been expressly protected under privacy and data protection laws for some time .
66 Consider , for example , the capability of various de-anonymisation techniques that can be applied to metadata as well as the reported growth of metadata analysis in the ﬁeld of signals intelligence .
67 There are , of course , risks associated with the implementation of these facilities and examples of how they have been abused in violation of applicable law .
Anti-abuse measures can and should be founded on both technological and organisational controls .
69 In an effort to navigate potential restrictions on reporting new types of interception , some service providers adopted the practice of publishing so-called ’ Warrant Canaries ’ – a statement published on a recurring basis that no interception warrants of a given type had been received .
The theory behind this practice was that a subsequent failure to re-publish the Canary statement would allow the public to infer ( without the communication provider expressly stating ) that state-warranted interception had commenced .
This practice seems to have fallen into disfavour , probably aided by the sometimes-debatable legal status of the practice plus additional state legal interventions that made this strategy more difﬁcult or impossible to carry out within the terms of applicable law .
70 In the US , some courts have held that efforts to compel disclosure of passwords triggers scrutiny under human rights law as it forces a suspect to give testimony against himself , while mandatory presentation of a ﬁngerprint to unlock a device does not trigger this same legal objection [ 165 ] .
This is an area where legal standards remain murky and the topic is ripe for further dispute and development [ 166 ] .
72 Practitioners should be careful to distinguish between activities such as developing a communications protocol , writing software that implements a protocol , supplying such software to the public , and supplying a service that implements a protocol .
A quick test that may assist in clarifying a person ’ s status is to ask this question : ’ Would the relevant communications service continue to operate if the processes administered by this person ceased to function ?
’ Thus , a person who supplies IMAP services , SMTP services , or a key distribution service to support end-to-end encryption for a communications app is more likely to be classiﬁed as a communications service provider under relevant legislation than a person who merely writes software that implements a protocol .
Details of applicable laws diverge signiﬁcantly and must be investigated on a state-by-state basis .
This is less likely to occur to the extent that the law of a state ( such as the UK ) prohibits use of intercepted communications as evidence in legal actions [ 167 ] at s.56 .
74 The US exclusionary rule has been hotly debated for more than half a century .
75 Activities undertaken by states in defence of state security generally fall outside the prescriptive jurisdiction of the EU .
76 Practitioners must not lose sight of this regulatory purpose .
When assessing risks of various processing activities and security arrangements in the context of data protection law compliance , the risk to be assessed is normally the risk of harm to data subjects - living human beings .
Risks faced by the processing enterprise ( including risks of non-compliance with data protection law ) should be evaluated separately .
A similar observation can be found in the context of the Carroll Towing case discussed in Section 3.7.1.2 and Note 123 .
This is a natural result of the US approach to this subject , which is to adopt narrowly drawn sui generis laws that speciﬁcally focus on individual use cases .
The cited decisions are drawn from examples of the US courts interpreting a 1988 law originally adopted to restrict the disclosure of video rental records as they were kept in the 1980s .
The courts were called upon to interpret this ageing statute in the context of online streaming service records in 2015 .
Practitioners may be interested to note that as US courts are charged with responsibility to interpret the will of the US Congress when resolving these cases , they seem unaware of ( or perhaps uninterested in ) the technical deﬁnitions of PII offered by the ISO and NIST publications [ 179 , 180 ] .
79 80 In practice , there may be a strong temptation , and corresponding pressure , to assume that the absence of obvious personal identiﬁers in a data set means that no personal data are present .
A better approach is to appreciate that data protection law tends to measure obligations in proportion to the risks presented by any given processing activity .
Data sets containing personal data without obvious personal identiﬁers might therefore present a lower risk when processed , thus making compliance less onerous in such cases .
81 Consent is perhaps one of the least well understood , and hotly debated , terms in data protection law .
In addition to many sources of guidance published by public authorities on this topic , practitioners who wish to explore this concept in depth might take inspiration from outside the body of data protection law [ 318 ] .
82 The notiﬁcations discussed in this section are distinguished from separate requirements , if any , to share security breach information with relevant industry-speciﬁc regulators or security coordination authorities ( see Section 3.11.1 ) .
84 Mandatory obligations to communicate personal data breaches to data subjects irrespective of the risk of harm has been criticised on a number of grounds , including : data subjects become overwhelmed by communications and are unable to distinguish the degree of risk presented by any individual breach , communicating to a large set of data subjects is extremely resource-intensive , and communicating to data subjects could interfere with the ability of police authorities to investigate the breach .
This incident in part involved user trafﬁc to the British Airways website being diverted to a fraudulent site .
Through this false site , customer details were harvested by the attackers .
Personal data of approximately 500,000 customers were compromised in this incident , which is believed to have begun in June 2018 .
The ICO ’ s investigation has found that a variety of information was compromised by poor security arrangements at the company , including log in , payment card , and travel booking details as well name and address information .
A variety of personal data contained in approximately 339 million guest records globally were exposed by the incident , of which around 30 million related to residents of 31 countries in the European Economic Area ( EEA ) .
Seven million related to UK residents .
It is believed the vulnerability began when the systems of the Starwood hotels group were compromised in 2014 .
Marriott subsequently acquired Starwood in 2016 , but the exposure of customer information was not discovered until 2018 .
The accused were arrested in the UK in 1985 after they had obtained a system password for an early email system and used it to access an email account assigned to a member of the British Royal Family .
Although the accused were originally convicted following trial in 1986 for violating the Forgery and Counterfeiting Act 1981 , the House of Lords ( at that time the court of last resort in the UK ) quashed the conviction in 1988 holding that the complained-of action was not a violation of the 1981 statute .
88 89 Bruce Sterling provides an interesting history of early computer crime investigation and prosecution efforts in the 1980s by the US authorities , and colourfully describes how they sometimes missed their intended target KA NOTES | October 2019 Page 136 The Cyber Security Body Of Knowledge www.cybok.org [ 329 ] .
Clifford Stoll also describes the contemporaneous challenges he encountered as a private citizen attempting to investigate computer intrusion , complaining that he often could not ﬁnd law enforcement ofﬁcials able to assist him [ 330 ] .
91 Both the Budapest Convention and Directive 2013/40 allow states a certain degree of ﬂexibility in the detail of their domestic laws , and many contracting states have declared reservations against certain provisions of the Budapest Convention .
This positive connotation of the term now extends beyond the realm of ICT development , as can be found in emerging phrases such as ’ life hack ’ and ’ hackathon ’ .
The role of prosecutorial discretion is one possible explanation for the lack of a de minimis exception in the deﬁnition of computer crimes .
95 In some rare instances , non-state persons are granted the right to bring a criminal prosecution when state ofﬁcials have chosen not to do so .
96 US Federal Courts undertake an algorithmic approach in calculating recommended criminal sentences pursuant the US Federal Sentencing Guidelines [ 337 ] .
Under these guidelines , crimes against information systems are classiﬁed as ’ economic ’ crimes and sentences may be signiﬁcantly enhanced based upon value of damage caused by the criminal activity [ 197 ] .
Although federal judges are required to take this calculation into account when passing sentence , they may deviate from the sentencing guidelines subject to whatever limits may be mandated by Congress in the substantive criminal statute .
97 This becomes more obvious when considering intrusion efforts against industrial control systems such as those that operate dam sluice gates , national electricity power grids , steel mills and foundries , automobiles , oil tankers , pipelines , and nuclear power generation facilities .
This express exception to criminal liability under the 1990 Act ﬁrst appeared in the Regulation of Investigatory Powers Act 2000 , the predecessor of the Investigatory Powers Act 2016 .
99 Such proof would most likely consist of asking the fact ﬁnder to draw reasonable inferences from the circumstances surrounding any given act of production or distribution .
Similar arguments have been advanced in the cause of security-related journalism .
These policy arguments have not yet found overwhelming support from various state law makers , although the debate is not well advanced .
101 It has been suggested that persons who engage in security research and development activity that might otherwise constitute a de minimis violation of computer crime laws might enter into formal or informal agreements with law enforcement or state security ofﬁcials to receive an assurance of non-prosecution .
Risks to the practitioner include potential misunderstanding with state ofﬁcials , potential inability to enforce the nonprosecution agreement , or collateral legal risk such as tort liability [ 206 ] .
Risks to a state pursuing this strategy include the possibility that such an agreement might be used to attribute responsibility to the state under public international law for the actions of such researchers or developers ( see Section 3.12.1 ) .
102 In some systems of contract law , however , a service provider may be required to give customers additional time to pay or special notices before services can be suspended .
, energy services supplied in a freezing cold climate ) are often separately regulated and can be suspended only in accordance with strict rules .
KA NOTES | October 2019 Page 137 The Cyber Security Body Of Knowledge www.cybok.org 104 Indicia of enforceability are generally beyond the scope of this work .
It is both difﬁcult to describe generalisable multinational legal norms about these , and this topic is of lesser concern to cyber security practitioners .
While some ecommerce systems make contractual offers to a wide range of potential customers , the most common design is for the vendor to publish invitations to treat – essentially asking customers to make an offer when placing an order .
This generally shifts who has control over the time of contract creation back into the hands of the online vendor – an often-useful risk management device .
106 Practitioners skilled in computer science might wish to draw inspiration from the Two Generals Problem .
In practice , an order usually constitutes either an offer or an acceptance depending on the terms and conditions applicable to the relevant online platform .
In the ﬁeld of B2C online commerce , it has become common practice for an order to be deﬁned as a contractual offer – capable of being accepted or rejected by the online supplier .
108 The rule embodied in Article 11 is a rather muted result of a European debate in the 1990s concerning whether to harmonise the time of the contractual trigger in online commerce .
Law makers , facing a wide variety of contract rules which are beyond scope of this knowledge area , ultimately chose not to harmonise this aspect of law .
The resulting version of Article 11 is limited to this question of deﬁning the time of receipt of electronic orders and acknowledgments .
Although these create different rights in the hands of a party suffering a breach , the topic is beyond scope of this knowledge area .
112 Under English law , this is normally styled as the condition of ’ satisfactory quality ’ and was formerly known as the condition of ’ merchantable quality .
113 In the law of England and most US states this is styled ’ ﬁtness for purpose ’ .
Once again , in England this is said to be a contractual condition and in US states it is generally a warranty .
114 Examples of typical language found in contracts for the supply of software include , ’ Vendor warrants that the software will comply with the Documentation for a period of 60 days following delivery .
’ 115 These are not legal terms of art , but merely used to illustrate the variable degree of breach severity .
116 The names of the remedies are drawn from common law practice .
Other legal systems may employ different terms and/or grant alternative remedies .
The deﬁnition of the trigger is limited only by the imagination of the drafter , although some legal systems impose limits on the effectiveness of these clauses .
118 The leading case on this issue in England in the early twentieth Century concerned the duty of a person who bottles beverages owed to those persons who eventually drink them .
The advent of the modern economy created supply chains in which the producer and consumer had no direct business relationship , where products change hands multiple times before being consumed .
Applying an earlier version of the rule described above , the English court ( acting in its capacity as a common law policy maker ) stated that the bottled beverage was itself the proximate link between producer and consumer , and that a producer of such a drink could readily foresee the harm caused by the adulteration of the bottle ’ s contents .
120 This last category is mentioned because of the occasionally encountered practice where a person attempts to avoid liability by purposefully avoiding knowledge of risk .
This strategy is unlikely to defeat a claim of neg- KA NOTES | October 2019 Page 138 The Cyber Security Body Of Knowledge www.cybok.org ligence and may even exacerbate liability in jurisdictions that award punitive damages .
In the cited 2018 Dittman case , the Pennsylvania Supreme Court announced that the common law of Pennsylvania imposes a duty of care on employers to safeguard the electronic storage of employee data .
In the US , negligence law may play an increasing role in deﬁning responsibilities to safeguard personal data .
123 Judge Hand surprised legal practitioners of the day by expressing this concept using a mathematical formula , stating that if B < P L then the failure to adopt a given precaution constitutes negligence , where B is the burden ( cost ) of the method , P is the probability of loss in the absence of the method , and L is the amount of loss to be avoided .
These two cases and one formula have been the subject of extensive comment , debate and analysis by generations of US lawyers and law students and it remains a useful framework to discuss risk and responsibility [ 218 , 220 ] .
The speed at which these variables change may help to plan the frequency for reassessing decisions to reject proposed precautions .
125 In the referenced case , the negligence per se claim was based on an allegation that Target had failed to comply with a Minnesota law concerning the proper storage of credit card details [ 215 ] .
127 This section is addressed primarily to ’ design defects ’ and does not discuss ’ manufacturing defects ’ , in which individual products from a production run deviate from their speciﬁcation due to sporadic intermittent errors in the manufacturing process .
A victim taking legal action against a software producer based on a theory of negligence would need to prove unreasonable conduct by the software producer .
130 Such attenuated chains of causation are a familiar meme in science ﬁction stories about time travel .
A non-ﬁction but entertaining exploration of highly attenuated chains of causation from scientiﬁc history is found in the work of journalist James Burke in various iterations of his BBC television programme , ’ Connections ’ .
132 Such ’ negligent mis-statement ’ cases are watched closely by professionals and other service providers in the business of supplying critical information-related services such as public accountants .
This type of negligence theory is also of special interest to providers of trust services , as it potentially deﬁnes their liability to third parties who rely upon the accuracy of issued certiﬁcates .
( See Section 3.10.3 ) In the cited Dittman case the Supreme Court of Pennsylvania , acting in its role as interpreter of the common law of Pennsylvania , held in November 2018 that employers owe a duty of care to their employees to maintain reasonable cyber security to safeguard employee data from loss [ 216 ] .
In any similar incident in the EU , a tort action could be fashioned easily under a theory of breach of data protection rights .
133 134 An obvious example is the various legal actions brought by ﬁnancial institutions against Target following its well-known 2013 loss of card data incident .
Plaintiff banks in at least one of the actions based their claim on various legal theories including negligence and negligence per se [ 215 ] .
KA NOTES | October 2019 Page 139 The Cyber Security Body Of Knowledge www.cybok.org Compare easily quantiﬁable losses resulting from breach of privacy such as loss of revenue from an exclusive agreement to publish the victim ’ s wedding photographs in a speciﬁc newspaper , loss of salary as a result of victim ’ s dismissal from employment etc .
137 The internal auditor was arrested and charged with criminal violation of data protection law , computer crime , and fraud .
He was convicted and sentenced to eight years imprisonment .
Compare potential application of the state-of-the-art defence in the context of materials science where ( for argument ’ s sake ) at the time of production there was no known scientiﬁc test for the later-discovered defect in the material , with the context of a software-induced product defect due to a previously unknown zero day exploit .
The former might be said to have been undiscoverable , while the latter was merely undiscovered .
139 140 It has been suggested anecdotally that some regulation of safety-critical systems can lead to weaknesses in that system ’ s cyber security by limiting or foreclosing the possibility of adopting state-of-the-art security measures .
A speciﬁc instance related to the author concerns a regulatory requirement that certain safety-critical control systems must be exhaustively tested by examining every possible state of the control device prior to use .
Some defensive cyber security methods , especially those that adopt artiﬁcial intelligence or machine learning , are by their nature impossible to test to exhaustion in this fashion .
141 A favourite example beloved of law professors involves the hypothetical case of the badly loaded rail car .
The car may have been improperly overloaded in State A , but only produces injury after the train begins to descend a steep grade many hours later in State B .
A darker shadow was cast over the practice of intellectual property law by Lord Esher , MR , when in 1892 he observed , ’ a man had better have his patent infringed , or have anything happen to him in this world , short of losing all his family by inﬂuenza , than have a dispute about a patent .
His patent is swallowed up , and he is ruined .
143 144 In United States law , copyright comes into existence automatically but must be registered prior to commencement of any US infringement proceedings .
147 The European Union is in the process of adopting the Unitary Patent , a single patent right that applies throughout much , but not yet all , of the territory of the EU .
The status and use of this new patent right continues to evolve .
148 Inventors should not confuse this concept from patent law with various scientiﬁc or academic deﬁnitions of signiﬁcant or trivial .
150 While copies of patents and published applications from many states are now easy to ﬁnd online , correspondence with the patent examiners and the prosecution history is often more difﬁcult to obtain and may require assistance from a legal practitioner .
Once obtained , however , this can be very enlightening to any person who wishes to challenge post-facto the validity of a granted patent .
KA NOTES | October 2019 Page 140 The Cyber Security Body Of Knowledge www.cybok.org 151 A very limited subset of patent applications for inventions are subject to a state secrecy classiﬁcation and are only published in a register of secret inventions .
The pace of ICT innovation is so fast , the intermingling of parallel innovative ideas so commonplace , the number of patent applications ﬁled so large , and the prior art cataloguing ICT innovation so untidy , that it is difﬁcult to produce any innovative ICT product that does not infringe some extant third-party patent , or published or unpublished application .
A typical strategy adopted by large ICT developers is to ﬁle large numbers of patent applications on their own inventions , move to market as quickly as possible with new products , and then wait to receive suggestions of patent infringement from third parties in the hope of eventually defending against some of these threats or negotiating an acceptable cross-license arrangement .
153 In the US patent system , awareness by the infringing party of patent rights triggers a special ’ treble damages ’ rule : monetary damages awarded to the rights holder are multiplied by three with effect from the date of the infringer ’ s awareness .
This is why rights holders typically begin a US patent enforcement process by sending copies of their patents together with a ’ we wish to make you aware ’ cover letter that does not expressly accuse the recipient of infringement .
This , combined with the factors set out in Note 152 , is why many ICT innovators assiduously avoid researching third-party patents and patent applications .
154 Some states deﬁne ’ unregistered ’ trademark rights which are similar in character to the English law tort of passing off .
156 In modern trademark practice , the relevant sign can consist of sounds or smells .
158 Courts are divided on the question of whether meta-tags , not normally visible to end users , can constitute an infringement of registered trademarks .
Even where meta-tags can not be used to prove infringement , they can serve as useful evidence for other purposes such as demonstrating the knowledge or awareness of the tag author in related tort actions such as passing off .
159 By contrast , in actions based on theories of passing off or unregistered trademark rights the complaining party is usually required to prove that the accused party has knowledge of the unregistered mark and is purposefully taking advantage of the reputation connected to that mark .
§230 ( shielding from liability those who block or screen offensive material , although not applicable as a shield against liability arising under obscenity , intellectual property or privacy laws . ) .
Section 230 in particular has come under increasing scrutiny by US courts as more legal actions have been taken against social media service providers .
167 Although these legal deﬁnitions are not speciﬁcally linked to technical deﬁnitions , this concept is approximately equivalent to providing services that consist of nothing more than carrying and routing trafﬁc at the physical , data link and/or network layers of the TCP/IP protocol suite .
A legal action challenging this law as a violation of US freedom of speech principles was launched shortly after its passage and remains pending at the time of writing [ 353 , 354 ] .
171 The ability to admit ( to present ) evidence to a court is a threshold question governed by the rules of evidence used by that court .
Admissibility asks simply whether such evidence will be considered at all .
The rule book was used to translate between structured messages and legally signiﬁcant communication , and served as the speciﬁcation for software used to access the system .
173 By underwriting the risk of many such transactions , the positive impact of the payment card industry to the growth and success of these platforms should not be underestimated .
174 The ’ three-corner ’ model for this purpose comprises only three persons : the certiﬁcate issuer who both identiﬁes the signatory and issues the certiﬁcate , the signatory whose identify is bound to the certiﬁcate and the third party who relies on the certiﬁcate to identify the signatory .
As each of these roles becomes divided among more persons , analysing the relationships and responsibilities becomes more complex .
For example , there may be failure to form a contract with a relying party because of failure to communicate the terms of contract .
Courts might refuse to enforce limitations of liability presented in certiﬁcates or elsewhere due to public policy concerns such as the reasonability of the limitation .
In the two-corner model there is no ’ third party ’ and the signatory may have a direct relationship with the relying party more easily enabling the imposition of liability limits .
178 A similar analysis could apply in circumstances where enterprises order their members of staff to adopt and install trust certiﬁcates issued by the enterprise speciﬁcally to support SSL/TLS inspection .
Such enterprises should consider the various types of liability that might arise as a result .
179 States may also apply embargoes on most or all trade with speciﬁc states as part of a more general programme of sanctions .
180 The precise status of software as speech for purposes of US free speech law remains somewhat murky .
While US Federal courts seem willing to classify source code as protectable expression , they also appear to take its inherent functionality into account when assessing free speech rights .
By contrast , the ﬁeld of ’ private international law ’ describes the process of determining which domestic state law ( s ) will be applied to various aspects of private law disputes such as tort and contract actions .
Aspects of private international law , or conﬂicts of law , are considered in this knowledge areas in the context of individual substantive legal subjects .
In the referenced Halford case the complaining party successfully argued that the United Kingdom had failed to provide her with privacy rights required by the European Convention on Human Rights as regards interception of communications by state authorities [ 155 ] .
This case precipitated the adoption by the UK of comprehensive legislation regulating the interception of communications .
182 183 A notable exception involves prosecution according to the principles of international criminal law such as crimes against humanity .
The Tallinn Manual itself helpfully provides extensive commentary that highlights circumstances where some states disagree with the unanimous views of the expert group , and other issues where the expert group itself did not achieve consensus .
It is therefore not surprising that the Tallinn Manual 2.0 does not represent the ofﬁcial policy of the project ’ s sponsors ( NATO and its member states ) or the various additional organisations whose experts participated in its creation and revision .
Nonetheless , anecdotal evidence suggests that experts who advise all of these persons keep a copy of the Tallinn Manual close at hand and consult the work routinely .
Practitioners should be careful to distinguish the legal doctrines used to analyse attribution from the process of collecting and presenting evidence intended to prove attribution .
This section discusses only the former .
The latter is more properly addressed in the ﬁeld of forensics .
186 The principle of territoriality and the exercise of state power is explored in the context of jurisdiction in Section 3.2 187 Espionage during armed conﬂict is treated separately under the law of armed conﬂict .
189 The qualiﬁer ’ unrelated ’ state is meant to distinguish circumstances where more than one sovereign state maintains concurrent jurisdiction over a single territory , as found in federal states .
190 The term ’ law of war ’ signiﬁcantly predates the term ’ law of armed conﬂict ’ , but is now used less frequently especially as armed conﬂict often takes place in the absence of any formal declaration of war .
191 Although this should be obvious , the concept of ’ cyber attack ’ used to discuss obligations under international law is signiﬁcantly more narrow than the term ’ attack ’ which is broadly deﬁned for most other purposes in cyber security .
192 In the case of offensive cyber operations undertaken at the direction of a state , compliance with ’ all applicable laws ’ may indeed be impossible as the actions taken at the direction of a sponsoring state may constitute crimes under the domestic law of the target state .
This section does not attempt to resolve these issues .
, a legal , medical , or public accountancy ﬁrm ) the practitioner may be obliged by applicable law to conform with the rules of the relevant regulated profession – especially on matters such client conﬁdentiality or client ’ s legal privilege to prohibit the disclosure of sensitive information .
These practitioners must become familiar with the obligations imposed by the regulations that apply to that ﬁrm .
194 This discussion does not address circumstances where applicable law mandates disclosure of this evidence to identiﬁed third parties , such as the data breach disclosure requirements imposed by GDPR .
In such cases , a practitioner should be careful to take appropriate advice concerning their individual legal reporting obligations as distinct from obligations imposed upon their client , and to urge their client to investigate the client ’ s own potential legal reporting obligations .
Some include the concept of avoiding harm to others without discussing the subtleties of this proscription .
Some speak of a general afﬁrmative obligation to protect ’ society ’ , without identifying the nature of the obligation in practice , identifying the relevant society in cases where two societies are in conﬂict , or discussing the possible conﬂict between protecting society generally and a client individually .
Many of these codes fail entirely to discuss speciﬁc obligations owed to a client and how to manage potential conﬂicts .
198 Some risks of disclosure might include the impracticability of patching or ﬁxing the vulnerability .
The beneﬁts of secrecy might include a state security agency ’ s ability to exploit the given vulnerability .
Disclosing ﬁrst to downstream producers of ﬁnished goods or services focuses the disclosure on those who appear to have the most at risk from security failure , but who may not have the tools necessary to mitigate the threat .
This downstream disclosure also creates a risk of alienating the upstream developer of the component – especially if the vulnerability is misdescribed .
In the ﬁeld of academic security research in particular , researchers often depend on good continuing relationships with the developer community .
Disclosing ﬁrst to the upstream developer creates a challenge if that developer is dilatory in remediating the vulnerability .
Finders in this situation might consider the potential for a multi-step private disclosure process starting ( perhaps ) with the upstream party most likely to be able to understand and remediate the threat .
Having disclosed and then provided an opportunity for that party to analyse or rebut the claim of vulnerability , the ﬁnder might begin additional private disclosures one step at a time down the supply chain to those who might take action to mitigate the threat .
201 Commenting on a decision by academics to publish vulnerability details more than nine months after private disclosure to an upstream security component vendor , but in the face of strong objections by a downstream purchaser who incorporated the compromised security product into their mass-produced automobiles , an English High Court Judge noted , ’ I think the defendants ’ mantra of `` responsible disclosure `` is no such thing .
Note that the academics in the Megamos Crypto case claimed that they were adhering to then-current responsible disclosure procedures published by the National Cyber Security Centre of the Netherlands , the state in which they conducted the bulk of their research .
202 While the mere presence of a vulnerability in a product or service does not necessarily constitute vendor negligence , vendors who receive a vulnerability report should consider that a failure to act in a reasonable fashion following receipt of such a report could constitute an independent act of negligence .
203 Some have attempted to address this issue by adopting legislation that would regulate the disclosure process .
204 An example likely to be familiar to practitioners was the fate of the Arthur Andersen accounting ﬁrm in the early 21st century .
The ﬁrm was an adviser to the Enron Corporation , and was accused by the US government of improperly destroying evidence related to the Enron investigation .
Upon conviction , the ﬁrm was debarred from conducting public company audit work effectively ending its ability to operate as a going concern .
This came too late for the ﬁrm , which had ceased ongoing operations .
KA NOTES | October 2019 Page 144 Chapter 4 Human Factors Ruhr Universität Bochum & University College London University of Bristol M. Angela Sasse Awais Rashid 145 The Cyber Security Body Of Knowledge www.cybok.org 4.1 INTRODUCTION : UNDERSTANDING HUMAN BEHAVIOUR IN SECURITY In their foundational 1975 paper , The Protection of Information in Computer Systems , Jerome Saltzer and Michael Schroeder established ten principles for designing security [ 8 ] .
Three of those principles are rooted in the knowledge of behavioural sciences : • Psychology : the security mechanism must be ‘ psychologically acceptable ’ to the humans who have to apply it ; • Human Factors and Economics : each individual user , and the organisation as a whole , should have to deal with as few distinct security mechanisms as possible ; • Crime Science and Economics : the effort required to beat a security measure should exceed the resources and potential rewards for the attacker .
Nearly 100 years before Schroeder & Saltzer , the founding father of cryptography , Auguste Kerckhoffs formulated six principles for operating a secure communication system , with a key focus on human factors : Three of those were “ it must be easy to use and must neither require stress of mind nor the knowledge of a long series of rules ” .
Both of these foundational texts recognised that security measures can not be effective if humans are neither willing nor able to use them .
We have had tools for encrypting email for over 20 years .
Over the past 20 years , there has been a growing body of research into the underlying causes of security failures and the role of human factors .
The insight that has emerged is that security measures are not adopted because humans are treated as components whose behaviour can be speciﬁed through security policies , and controlled through security mechanisms and sanctions .
But the fault does not lie primarily with the users , as suggested by the oft-used phrase that humans are the ‘ weakest link ’ , but in ignoring the requirements that Kerckhoffs and Schroeder & Saltzer so clearly identiﬁed : that security needs to be usable and acceptable to be effective .
An example of this is the case of password policies .
Adams & Sasse showed that password policies and mechanisms agreed upon by security experts did not work at all in practice and , consequently , were routinely bypassed by employees [ 368 ] .
showed that not only end-users have trouble with passwords but developers do as well .
The aim of this CyBOK Knowledge Area is to provide a foundational understanding of the role of human factors in cyber security .
One key aspect of this is how to design security that is usable and acceptable to a range of human actors , for instance , end-users , administrators and developers .
This knowledge area also introduces a broader organisational and societal perspective on security that has emerged over the past decade : the importance of trust and collaboration for effective cyber security , which can only be achieved by engaging stakeholders and negotiating security solutions that meet their needs [ 371 ] .
This requires a set of skills that have traditionally not been part of the training provided for security experts and practitioners .
This knowledge area aims to capture the knowledge to change that .
This knowledge area is organised ( Figure 4.1 ) in a starting on the inside , working outwards manner : starting with the individual and internal factors that drive human behaviour ( capabilities and limitations , mental models ) , moving onto aspects of the broader context in which interaction with security takes place .
We will then consider the other immediate factors that have an impact : the behaviour of others around us , and especially how they handle security risks , users ’ emotional stances towards the organisation and how security behaviour can be successfully managed through design and a range of group and organisational factors .
Note that human factors and usability in a security context can be distinguished from other contexts by the presence of adversaries or risk .
These mechanisms offer some protection , but require user time and effort .
Therefore , KA Human Factors | October 2019 Page 147 The Cyber Security Body Of Knowledge www.cybok.org as we discuss later , the total security workload needs to be monitored so that productivity is not reduced and workarounds induced .
Furthermore , they have implications in terms of users ’ trust in the organisation and completion of the primary ( non-security ) task at hand – the design of any such interventions or campaigns needs to consider and address these risks [ 375 ] .
Note that we do not discuss the speciﬁcs of adversarial behaviours , as these are the subject of the Malware & Attack Technology Knowledge Area ( Chapter 7 ) .
However , we will touch on any relevant elements where they relate to usability and human factors , for example , security awareness , training and anti-phishing .
Usability considerations are equally important with regards to privacy controls and technologies .
This discussion formulates part of the Privacy & Online Rights Knowledge Area ( Chapter 5 ) and hence is not considered here any further .
Most choose productivity over security , because that is what the organisation also does .
But Human Factors research established decades ago that , when we take all of the costs and the resulting performance into account , ‘ ﬁtting the task to the human ’ is more efﬁcient .
There is a role for security awareness and training ( Section 4.4 ) but it should be thought of as one of the options but not the ﬁrst resort .
As the UK ’ s National Cyber Security Centre ( NCSC ) policy puts it : ‘ The way to make security that works is to make security that works for people ’ 1 In other words , security has to be usable .
The ISO deﬁnes usability ( ISO 9241–11:2018 ) as ‘ The effectiveness , efﬁciency and satisfaction with which speciﬁed users achieve speciﬁed goals in particular environments .
’ And the criteria by which usability is assessed are : 1. effectiveness : the accuracy and completeness with which speciﬁed users can achieve speciﬁed goals in particular environments ; 2. efﬁciency : the resources expended in relation to the accuracy and completeness of the goals achieved ; 3. satisfaction : the comfort and acceptability of the work system to its users and other people affected by its use .
But how to deliver this in practice ?
4.2.1 Fitting the task to the human From a practical point of view , making security tasks ﬁt or usable means establishing a ﬁt with four key elements [ 377 ] : 1. the capabilities and limitations of the target users ; 2. the goals those users have , and the tasks they carry out to achieve them ; 3. the physical and social context of use ; and 4. the capabilities and limitations of the device on which the security mechanism is used .
We now examine each of these in turn , and how they apply to designing a usable security mechanism .
4.2.1.1 General human capabilities and limitations There are general capabilities and limitations – physical and mental – that apply to most humans .
Giving humans a task that exceeds their capabilities means we set them up to fail .
When the demand they face is borderline , most humans make an effort to meet it .
But this will come at a signiﬁcant cost , which may ultimately prove to be unsustainable .
With general computing devices today , the physical capability that can be exceeded by security tasks is most likely the ability to detect signals : many security systems provide status messages , reminders or warnings .
Humans can only focus their attention primarily on one task at any one time .
That focus will be on their main activities , and many security mechanisms demand more time and attention than users can afford [ 376 ] .
This means that changes in passive security indicators are often not noticed , in particular if they are on the edges of the screen .
Asking users to check these indicators is setting them up to fail—even if they consciously try to do it , their focus will be drawn back to the main task .
If security indicators need to be attended to , they should to be put in front of the person , and require a response .
KA Human Factors | October 2019 Page 149 The Cyber Security Body Of Knowledge www.cybok.org Alarm fatigue The brain stops paying attention to signals it has classiﬁed as irrelevant .
It means humans do not perform well on tasks where they have to screen for rare anomalies ( e.g .
We need technology support and processes such as job rotation to get good performance .
Once alarms have been classiﬁed as unreliable , people stop paying attention to them .
How high a false alarm rate ( with which people can work ) depends on the risk , the frequency at which false alarms occur , and the demands of the other tasks they have to complete .
Once people start to dismiss alarms , it is hard to get them to take them seriously again .
Moreover , once they dismiss one type of security warning as false , similar-looking or sounding ones will also be dismissed .
Many security warnings today have far too high a false alarm rate and are thus dismissed .
So , it is not surprising that people ignore them , particularly if no secure alternative for completing the task is offered at the same time .
There are several types of memory .
When one tries to memorise an item , it needs to go round the STM loop a few times before it is transferred into the LTM .
STM is what is , for instance , used for one-time passwords , such as numeric codes displayed by tokens or displayed on another device .
We focus our attention on the number displayed and repeat it to ourselves ( mentally or aloud ) .
Then we turn our attention to the entry ﬁeld , retrieve the item from the STM loop , and repeat it to ourselves while entering it .
What is important to note is that this works for most people for strings of up to 6 characters , that is , a 6-digit number , because we can break them into 2 bits of 3 characters each .
Codes that are longer overload the STM loop .
People have to start looking forwards and backwards between the display to read the characters and enter them .
This increases both the entry time and the likelihood of error .
Whether a user will be able to recall what is stored in LTM depends on how embedded it is : items retrieved frequently are well embedded , those that are not will fade over time .
Items stored in LTM-SM fade faster than those in LTM-EM because , in the latter case , one stores not just the item , but the images and emotions connected to them .
KA Human Factors | October 2019 Page 150 The Cyber Security Body Of Knowledge www.cybok.org LTM and passwords LTM-SM is divided into areas in which similar items are stored .
When one tries to retrieve an item , the section in which it is stored is activated , and the items in the section compete to be retrieved – with those that have been retrieved most frequently ‘ coming to mind ’ ﬁrst .
This interference effect is quite powerful and disruptive , particularly because items one does not need any more ( such as old passwords ) keep lingering and compete with those that need to be recalled .
Thus , managing a multitude of the same type of credentials is impossible , especially if several of them are used infrequently .
But , since most users now have dozens of passwords , the insistence on strong passwords has created a humanly impossible task .
Most people struggle if they have more than 2–3 passwords or PINs – and the longer and stronger they are , the more they will struggle .
The NCSC Password Guidance a , therefore , recommends several ways of supporting people in managing large numbers of unique passwords : switching to 2FA solutions and/or password managers , and if it is not possible to do either , not expiring strong passwords on a regular basis .
People can brute-force the old password out by repeating the new password around ten times immediately , and repeating that process three or four times at hourly intervals .
Due to human physical and mental characteristics , the selection of credentials is , however , often biased towards the familiar , or those that can be more easily distinguished from others .
, those that have meaning for them such as memorable names or dates .
When users have to choose images as credentials , they prefer strong colours and shapes over more diffuse ones [ 380 ] .
These human biases reduce the diversity ( number of different passwords ) in a password database , and increase the likelihood of an attacker guessing a password .
To counteract this , security policies have barred too obvious choices .
Similarly , password strength meters are often used to guide and inﬂuence the user ’ s password choices .
[ 385 ] discussed the impact of various password meter designs on users ’ choice of passwords , as well as highlighting the increased workload for users and the frustration faced by them when faced with more stringent password meters .
Their work shows a degree of variation in terms of accuracy and , more critically , that this has not signiﬁcantly improved over ﬁve years .
So , even if we are to disregard the additional workload on users ( not that we should ) , these approaches do not always have the level of accuracy required to effectively implement password policies .
These considerations must be borne in mind when deploying solutions to enforce security policies .
Sometimes , the question is raised as to whether there is training to help users cope with recalling security credentials .
Memory athletes use speciﬁc exercises to enhance memory performance .
We have , so far , discussed the capabilities and limitations that apply to most people .
But , speciﬁc user groups will have additional needs that should inform the selection or conﬁguration of security mechanism or processes .
People with larger ﬁngers struggle to hit small targets accurately , such as the small keys on a soft keyboard .
Cultural values and norms need to be considered .
The physical and mental conditions of users also need to be taken into account .
Not all users are able to operate equipment with their hands , read from screens , or hear audio .
Conditions such as colour blindness affect sizeable numbers of people , so images used for graphical authentication need to be checked .
Certain audio or video effects can harm users with conditions such as autism or epilepsy .
However , one needs to bear in mind that CAPTCHAs add more effort for the legitimate user , impeding the achievement of the intended goal , i.e .
To prepare a quotation , these would include working out the materials required and their cost , the personhours required and their cost , the relevant fees , taxes etc .
For instance , working out the person-hours required on a job can be broken down into the following tasks : 1. identify all the worksteps that need to be completed , 2. work out what type of employee is required to complete each task , 3. how long each speciﬁc type of employee needs to spend on which task , 4. what preparations each type of employee may need to make .
These tasks are called primary or production tasks in human factors terminology , and designing the technology tools so people can complete these tasks effectively and efﬁciently is the most fundamental aspect of usability .
To ensure people can complete tasks effectively , technology ( and security ) designers need to know the requirements for the tasks they perform : Production and enabling tasks Production tasks are what people consider ‘ their job ’ , and in many jobs , they may have spent years studying or training for them .
At an organisational level , the production tasks performed by many individuals in an organisation add up to business processes that produce the goods or services .
Anything that stops these processes or slows them down will cause the organisation signiﬁcant problems .
When we talk about ‘ resilience ’ of an organisation , it is about the ability to keep those business processes going to produce the output .
As well as production tasks , an organisation has tasks that do not directly contribute to business processes , but have been added to protect its ability to keep going in the long term : safety and , indeed , security are key enabling tasks .
Some organisations get away with not supporting these enabling activities for a period of time and this explains the grudge with which some individuals and organisations view security .
The fact that safety or security measures do not immediately contribute to the output and the bottom line explains why it is a grudge sale , particularly when individuals or organisations feel under pressure .
What output has to be produced so the goal is achieved ?
, if the quotation is not correct or not sent to the customer in time , the task is not completed effectively .
Are there constraints on time and resources ?
Business processes may set an upper limit on the time tasks can take , or the resources they can draw upon , such as , access to information or services for which the organisation has to pay .
For frequently performed tasks , the design should optimise for speed and reduce physical effort ( which could lead to fatigue ) .
For infrequent tasks , the design should try to reduce mental effort by guiding the users and minimising how much they have to remember .
People focus on the production task , and enabling tasks are often experienced as an unwel- KA Human Factors | October 2019 Page 153 The Cyber Security Body Of Knowledge www.cybok.org come interruption or distraction .
To stay with our authentication example2 : an employee has to authenticate with a password to a database to ﬁnd out the hourly rate of a particular specialist that the business charges .
If she does this frequently , and can remember the password , it may only take a few seconds for her to recall and enter it .
But if she has just returned from a vacation , can not remember it and it takes 20 minutes to get through to a help desk to have it reset , and then she has to think up and memorise a new password – all before she can get to the database – the security task has suddenly become a massive disruption , and perhaps the effective completion of the production task is now under threat .
Most workarounds to security mechanisms , such as , writing passwords down or sharing them , happen because people try to ensure effective production task completion ( to protect business productivity ) .
For instance , people often keep their own copies of documents that should be in an access-controlled repository , or clear-text copies of documents that should be encrypted , because they fear not being able to access them when they need them .
Or when the repeated effort and disruption resulting from having to enter a password to unlock a screen gets too much , they install mouse-jiggling software to stop the screen locking and having to enter their password [ 388 ] .
Even if a user knows the password well , the seconds it takes add up if it needs to be done dozens of times a day .
Therefore , to avoid security tasks being bypassed , we must design them to ﬁt into primary tasks .
We can achieve a good ﬁt in a number of ways : • Automating security , for instance , using implicit authentication to recognise authorised users , instead of requiring them to enter passwords many times over .
• If explicit human action is necessary in a security task , we should minimise the workload and the disruption to the primary task .
• Design systems that are secure by default3 so that they do not push the load of security conﬁgurations and management on to the users .
Humans generally try to be efﬁcient and keep both their physical and mental workload as low as possible .
Mental workload quickly becomes too much , especially if adjacent tasks require the same mental capability , such as memory .
Therefore , in order to design a security task that ﬁts well , we need to know the production tasks , and consider the mental and physical workload .
What is the workload associated with the primary and secondary ( security ) task ?
Are there resource constraints ( mental or physical capability , or external ones such as limited access to paid services ) ?
What is the impact of failing to complete the security task ?
Workload measurement How can we measure the workload associated with a security task ?
A simple proxy is the time : how long does it take to complete the security task ?
Considering this before implementing a new policy or security measure would be an improvement on the status quo , whereby the impact of a policy or measure is only considered once it is causing problems .
Once we know how long it takes , we need to determine if and where it disrupts primary activity .
The assessment of whether the impact on the primary task is acceptable can be carried out informally , for instance , with experienced staff and line managers who know the production task well .
As we have already discussed , people are hardwired to protect their productivity .
They have a built-in awareness of how much time and effort they are spending on non-productive tasks , and an idea of how much non-productive activity is reasonable .
They have what Beautement et al .
As the day progresses and enabling tasks add up , the likelihood that they will seem too much and be bypassed increases .
Security is not the only enabling task employees face .
[ 393 ] , recommend that security specialists have an open and honest discussion with line managers and business leaders about the time and budget available for enabling activities , and how much of it is available for security versus other enabling functions .
Once that is known , the workload of the security tasks can be calculated and priorities identiﬁed – which security behaviours really matter for the key risks a particular group of employees face – and security tasks streamlined .
Making security mechanisms smarter and less ‘ all or nothing ’ can also help reduce compliance fatigue .
For instance , allowing authentication with an old password , or having ‘ break the glass ’ policies that allow but ﬂag access by users who do not have permission reduces the likelihood of task disruption .
And if users know they have access to efﬁcient security recovery and support services , it will reduce the need for workarounds .
KA Human Factors | October 2019 Page 155 The Cyber Security Body Of Knowledge www.cybok.org 4.2.1.3 Interaction Context Contextual Inquiry In modern work organisations , staff can work in many parts of the world , and in many different physical and social environments .
It can be quite a challenge for a security expert to identify all the factors that could impact security and usability .
Many usability professionals follow an approach called Contextual Inquiry [ 395 ] : ‘ The core premise of Contextual Inquiry is very simple : go to the user , watch them do the activities you care about , and talk with them about what they ’ re doing right then .
’ Contextual Inquiry uses a mixture of observation and interview to identify the primary tasks people are carrying out , and what makes them do this well .
Both the physical surroundings and the social environment in which people have to perform security tasks affect performance and security .
Most working age people now interact with technology on the move more frequently than at the desk traditional working environments .
This change in the context of use affects a number of security mechanisms , not least of being overheard when on the phone – the case of former CIA Director Michael Hayden being overheard giving an off-the-record interview on board a train being a particularly spectacular one4 .
The risk of being overheard is now addressed in many corporate training packages , but several security mechanisms are still in use that are vulnerable to being overheard , e.g .
Using partial credentials only and entry via keypad increases security but also accentuates the mental and physical workload at the same time .
Some attackers can also try to glean credentials via shouldersurﬁng or hidden cameras .
The usability of security mechanisms can be affected by the following physical characteristics : 1 .
Light : In bright light , displays can be hard to see , which can affect graphical authentication in particular .
Biometric systems such as iris and face recognition rely on input from cameras .
Bright light can lead to glare , which means the images captured are not good enough to process .
Noise will most obviously interfere with the performance of voice recognition systems .
But high levels of noise also impact human performance in general due to increased stress and , in turn , increased likelihood of error .
Unexpected loud noises trigger a human startle response , which diverts attention away from the task .
Ambient temperature can affect the performance of both technology and humans .
Fingerprint sensors can stop working when it is cold , and humans are slower at pointing and selecting .
They may also need to wear protective clothing such as gloves that make physical operations of touchscreens impossible or difﬁcult .
Similarly , too hot an environment can lead to discomfort and sweat can interfere with sensors .
Pollution can impact equipment operated outdoors .
This is a particularly concern for ﬁngerprint sensors and touchscreens .
The lipids left behind combine with the particles and the resulting dark grease can clog sensors or leave a clearly visible pattern on the touchscreen .
4 https : //www.theguardian.com/world/2013/oct/24/former-spy-chief-overheard-acela-twitter KA Human Factors | October 2019 Page 156 The Cyber Security Body Of Knowledge www.cybok.org The social context in which people ﬁnd themselves strongly inﬂuences behaviour though values : shared beliefs about what is important and worthwhile , and norms : rules and expectations about actual behaviour .
If the expected security behaviour is in conﬂict with day-to-day behavioural norms , we can expect problems .
For instance , if an organisation values customer satisfaction , and employees are told to be friendly towards customers at all times , a security policy that requires staff to treat any customer enquiry as a potential attempt to extract information will not ﬁt .
Understanding the reasons underpinning non-compliance with security policies can shed light on these conﬂicts between security requirements and the primary task [ 396 ] .
Humans do not like to feel distrusted – and it has been shown that communicating distrust to employees encourages bad behaviour , rather than prevent it [ 397 ] .
Other aspects need to be considered in order to understand how security beliefs , norms and coping strategies are shaped .
4.2.1.4 Capabilities and limitations of the device We have already discussed that the physical characteristics of a device may make interaction with security mechanisms difﬁcult in certain circumstances .
Some characteristics of the device can result in security mechanisms becoming difﬁcult to use in any circumstance .
And while with frequent use on a keyboard , most people can become quite proﬁcient at entering a complex password , performance does not improve when humans hit a basic limitation .
What is particularly worrying from a security point of view is that ( without colluding ) a user population starts to converge on a small number of passwords that are easiest to enter with the minimum amount of toggles , which makes guessing a valid password easier for attackers [ 401 ] .
Whilst 2FA has security beneﬁts and reduces the need for strong passwords , not all 2FA solutions are usable by default .
Many users ﬁnd widely used 2FA tokens such as Digipass difﬁcult .
Also , over half of online banking users have accounts with more than one ﬁnancial services provider .
The fact that even those that use 2FA implement it differently ( which token is used when it has to be used , and how the different elements of authentication are referred to ( passphrase , passcode , key phrase ) causes confusion for the users .
Similarly , different implementations of Chip and PIN create slightly different variations in the task that catches users out , leading to human error ( Section 4.3 ) .
With increasing numbers of new devices appearing , from smart watches to home devices , and even smaller screen sizes and implicit interactions between users and devices through a variety of sensors and actuators , considering the ergonomics of security interactions [ 403 ] is ever more important .
They occur as a result of latent failures ( organisation and local workplace conditions ) and active failures ( errors and violations by humans ) in combination to allow the accident to occur .
A person may be the one who pushed the wrong button or clicked on the link and caused the incident .
However , several other failures preceded this , leading to that person being put in a position where making what appeared the right choice turned out to be the wrong one .
Latent usability failures in systems-of-systems One can also not assume that all systems are designed from scratch with usable security considerations in mind .
Poor usability and task fatigue represents a sufﬁcient risk to the security of the SoS to warrant upfront investment in order to avoid latent failures .
The work of Reason and his fellow safety researchers [ 406 , 407 ] led to organisations being held responsible for ﬁxing upstream safety issues as they are discovered , rather than waiting for an accident to happen .
The concept of a near miss describes a situation where safety issues become apparent , but an accident is avoided at the last minute .
In most industries that are subject to safety regulations , there is an obligation to report near-misses and investigate any failure as soon as it is discovered – with a requirement to address the root causes identiﬁed through the investigation so that future failures are mitigated .
Applied to security , an employee not following a security procedure constitutes an active failure and should be investigated and ﬁxed .
If the investigation shows that the conﬂicting demands of production task and security lead the employee to disregard security , the conﬂict is an underlying latent failure that the organisation needs to address .
Often security noncompliance is ignored until an incident occurs .
Unlike security , safety does not have active adversaries with whom to contend .
But many improvements could be made to current security practices by applying safety concepts ( as discussed in Section 4.2.1.2 ) .
As already mentioned in Section 4.2.1.2 , tasks that people carry out frequently become automatic , whereas tasks they are doing for the ﬁrst time or very infrequently are carried out in a conscious , step-by-step manner .
One very important insight is that the majority of activities people undertake are carried out in System 1 mode , and this is what makes us efﬁcient .
If people carried out most of their activities in System 2 mode , they would not get much done .
Exhortations to ‘ Take Five ’ 5 every time before clicking on a link are unrealistic when people get dozens of work emails with embedded links .
Furthermore , if without clicking on that link or giving personal information , there is no way of completing the primary task , productivity comes under serious threat .
When a threat ﬁnds one in successive layers then the threat succeeds .
vice such as ‘ just stop and think ’ rarely works because just stopping people in their tracks and without supporting them achieving their goals securely is not helpful .
In addition , considering the workload of security measures , security experts need to consider the further impact that following their advice has on people ’ s ability to complete their primary tasks , as well as the impact on the effectiveness of general communication between organisation and employees .
The use of Domain-based Message Authentication Reporting and Conformance ( DMARC ) , for instance , should enable employees to distinguish genuine internal communications from potential phishing attempts .
The use of DMARC to provide a reliable indication of ‘ safe ’ senders can reduce the number of emails about which users have to be cautious .
Even better , the provision of ultra-secure browsing technology , which is now available , means that clicking on links has no adverse technical consequences , so user education and training can focus on explaining social engineering and manipulation techniques .
When tackling complex problems , humans often have to combine both fast and slow processes , and there is an in-between mixed-mode , where task execution is not fully automatic : some of the behaviours are automatic , but one needs to stop and consciously work out which behaviour to select .
For instance , using slow mode can also lead to overthinking , to rationalising or explaining away evidence , to bringing irrelevant concerns to bear , focusing on the wrong goals ( e.g .
KA Human Factors | October 2019 Page 159 The Cyber Security Body Of Knowledge www.cybok.org Mode Automatic ( fast ) mode Type of error Cause Security Example Slips lapses Recognition failure Memory failure Attention failure Human chooses incorrect response “ I forgot to check for the padlock before I entered my credit card details .
” Mixed mode Mistake I Conscious mode ( slow ) Mistake II and Human does not know correct response Table 4.1 : Automatic , mixed mode and conscious workspace ( based on [ 11 ] ) Even in conscious mode , people try to be efﬁcient , resorting to ‘ the closest thing they know ’ , that is , they are most likely to choose behaviours they use frequently , or those that seem most similar to the situation they encounter .
Attackers exploit this by creating very similar-looking websites , or incorporating security messages into their phishing emails .
Reason identiﬁes four types of latent failures that are more likely to cause people to make errors .
Human Factors include the limitations of memory ( as discussed in Section 4.2.1.1 ) but also common habits and widely shared assumptions .
Task factors include time pressure , high workload and multiple tasks , but monotony and boredom are equally error-inducing because people shift their attention to diversions .
Uncertainty about roles , responsibilities and rules also lead to incorrect choices .
Work environment factors include interruptions to tasks ( as discussed in Section 4.2.1.2 ) and poor equipment and information .
People are also particularly prone to error when rules and procedures change .
Task and work environment factors are clearly the responsibility of the organisation .
There should be regular reviews of how well policies are followed .
If they are not , the underpinning causes must be identiﬁed and addressed .
The causes of near misses , mistakes that happened but did not lead to an incident , should be similarly used to identify and change the underlying causes .
We also need to develop a better understanding of how humans respond when under stress conditions , e.g .
’ He recognised the corrosive impact of a single order that can not be followed in reality—it undermines the credibility of all orders and the superiors who issue them and seeds uncertainty and doubt .
It is the same with security policies : when employees encounter security policies that are impossible to follow or are clearly not effective , it provides a justiﬁcation for doubting all security policies .
That is why security hygiene is essential .
When policies are not being followed , security professionals must investigate , in a nonconfrontational manner , why and if it is because they are impossible or too onerous to follow and re-design the solution .
pointed out that in most cases , employees do not show blatant disregard for security , but try to manage the risk they understand in the best way know how , what they call shadow security [ 396 ] .
Their ‘ amateur ’ security solutions may not be entirely effective from a security perspective , but since they are ‘ workable ’ , asking ‘ how could we make that secure ’ is a good starting point for ﬁnding an effective solution that ﬁts in with how people work .
But , in Section 4.3 we established that security hygiene must come ﬁrst : if people keep being told that the risk is really serious and they must follow policy , but can not do so in practice , they develop resentment and a negative attitude towards security and the organisation ( which is counter-productive ) .
In practice , the three terms : awareness , education and training , are often used interchangeably but are different elements that build on each other : Security Awareness .
The purpose of security awareness is to catch people ’ s attention and convince them security is worth the engagement .
We need to capture people ’ s attention , and get them to realise that ( a ) cyber security is relevant to them , that is , the risks are real and could affect them , and ( b ) there are steps they can take to reduce the risk and that they are capable of taking those steps .
Crafting effective awareness messages is not an easy task for security professionals .
They not only know how to craft messages that catch people ’ s attention , but know how to reach different audiences via the different channels available to them , and integrate them into the overall set of communications to avoid message fatigue .
Once people are willing to learn more about cyber security , we can pro- KA Human Factors | October 2019 Page 161 The Cyber Security Body Of Knowledge www.cybok.org vide information about risks and what they can do to protect themselves against them .
Most people currently have very incomplete and often incorrect mental models ( see Section 4.4.2 ) on cyber risks .
Transforming them into more accurate ones provides a basis on which to build cyber security skills .
However , it is hard to ascertain whether the education leads to more accurate mental models or at least the ones that security professionals expect people to possess .
This divergence must be borne in mind .
[ 411 ] introduce the Cybersurvival task as a means to understand such divergence between security experts and employees in order to inform the design of security education programmes .
In addition to showing people how to do something , we need to support the acquisition of skills by letting them practise the skills in a setting where they can ‘ experiment ’ with security decision-making and reﬂect on their perceptions and biases [ 412 ] .
Parts of skill acquisition can be supported online , but , like all learning , it is much more likely to be successful when taking place in the context of a social community [ 413 ] .
A common misunderstanding is that if people complete the three steps above and know what to do , they will change their behaviour .
But knowing what to do and how to do it is not enough .
The new security behaviour needs to be embedded there but its place is occupied by an existing behaviour ( similar to an old password ) .
The adage that ‘ old habits die hard ’ accurately describes the fact that until we manage to push the old behaviour out and the new behaviour becomes automatic , all our awareness , education and training efforts may not yield the changes in behaviour we are seeking .
Since productive activity needs to carry on while we change security behaviour ( Section 4.2 ) , we can only target 1–2 behaviours at a time , and embark on changing the next 1–2 only once these have become genuinely embedded .
Nor should one conﬂate security awareness and education with security culture ( cf .
These can be one element in developing a security culture but are not in themselves representatives of an effective security culture .
It shows that the three steps we have discussed so far are only the ﬁrst steps , and that a further four steps are required to achieve behavioural change .
To support these additional steps , we can draw on a new generation of learning resources that have evolved .
And such steps require investment from organisations - in terms of strategy , time , planning and resources .
4.4.1 New approaches to support security awareness and behaviour change Simulations and games are increasingly being used , both to make security awareness more attractive , and to help with more complex educational measures and behavioural change .
Anti-phishing simulations designed to teach employees not to click on suspicious links are probably the most widely used in organisations today .
Their popularity stems from the fact that they provide the ability to measure the impact of interventions , and they tend to show a decrease in click rates in the short term .
The argument is that the experience of having been phished is a ‘ teachable moment ’ that captures the employees ’ attention and persuades them KA Human Factors | October 2019 Page 162 The Cyber Security Body Of Knowledge www.cybok.org Figure 4.3 : Behaviour change model from RISCS White Paper [ 409 ] to work their way through the education being offered .
Figure 4.4 ) is very clear that they will only lead to behaviour change if the person has a sufﬁcient level of motivation to engage with the training provided , and the ability to apply the skills being taught .
Joinson argues that certain emotional and contextual triggers employed by social engineering attackers are so targeted and powerful ( for instance , a notiﬁcation purporting to have information about trafﬁc or public transport disruptions shortly before the end of the working day ) that they can not be prevented by training [ 414 ] .
From a human factor perspective , anti-phishing simulations can be problematic : 1 ) because employees may perceive this as being attacked by their own organisation , which reduces trust [ 404 ] and 2 ) they may lead employees to become so reluctant to click on links that they do not act on genuine emails that may be important .
Furthermore , as we discussed above , the use of mechanisms such as DMARC can reduce the number of suspicious emails on which users need to focus , enabling education and training to be geared towards explaining social engineering and manipulation techniques .
The idea is that by seeing how they can use the vulnerabilities to attack a system , defenders learn to not incorporate them in their own systems .
However , the focus is on training those charged with securing the organisation and not the wider set of users and employees .
There are also board games designed to be played by work groups to raise awareness of cyber security threats and the complexity of cyber risk decision-making , e.g .
All of these games have the potential advantage of offering a social learning experience if played in a group context .
Overall , games and simulations have the potential to offer engaging new elements that can be deployed at different stages of the behaviour change model ( see Figure 4.3 ) but they need to be part of a planned behaviour transformation programme , not one-shot interventions .
They can range in detail from structural models ( like blueprints ) that experts have , to task-action models that enable nonexperts to operate a device competently .
Clearly , we can not expect non-security experts to understand all cyber risks in detail .
Perceptions of risk are also relevant in this regard .
When asked , most people ’ s ﬁrst response is along the lines of preventing cyber attacks or at least reducing the risk of attacks succeeding , or losses being too high .
pointed out , vendors and those who want organisations to take security more seriously resort to a ‘ Fear Uncertainty and Doubt ( FUD ) sale ’ – creating fears of attacks and their consequences , Uncertainty about consequences and Doubt about organisations ’ ability to defend themselves – thus boosting the cyber security market and the sale of products [ 418 ] .
, raw number of malware samples , activity on underground markets , or the number of users who will hand over their password for a bar of chocolate ) the effect of which is to persuade us that things are bad and constantly getting worse .
’ Security practitioners today complain that most individuals and businesses do not take cyber risks seriously .
The problem is that fear sales are not a good basis for security decisionmaking : when the resulting investment in security turns out not to be effective , decisionmakers become skeptical about the beneﬁts of cyber security .
This , in turn , encourages the other side to ramp up the FUD , leading to a spiral of fear and grudging investment in security .
In order to defend from novel threats , companies need more than passive adherence – employees wanting to defend the organisation , and understanding and agreeing with the responsibilities they have been assigned in the defence .
To achieve that , we must make security a proposition that is credible , so that people want to buy into it .
Roe argues that a positive conception of security will open ideas for new policy options and interventions , and encourage individuals or groups to become more involved in decision-making about security , and being part of delivering it [ 420 ] .
Another key aspect of positive security is the language we use in connection with it .
As a ﬁrst step , we must stop the practice of demonising people who are unwilling or unable to follow security advice : calling these people ‘ The Weakest Link ’ implicitly blames them for not being able to make sense of , or comply with , security .
Communication and leadership are important in this regard .
Here , we focus on employees rather than organisational leadership and aspects , such as strategic board-level leadership of cyber security .
Lizzie Coles-Kemp and colleagues have developed an approach that takes employee involvement in improving security a step further .
, drawings and collages ) to build representations of daily activity , and ground the discussion of security in these .
Case studies [ 371 , 396 ] show how this helps to identify the root causes of insecure behaviour that the organisation sees as undesirable , in many cases badly designed security ( echoing the results of Beautement et al .
Creative security engagements ( ﬁrst mentioned by Dunphy et al .
One particular technique for creative engagements using Lego for the physical modelling of information security threats was developed by the EU Trespass Project6 .
This type of physical modelling bridges the gap between the typical diagrams ( ﬂow-charts and Uniﬁed Modelling Language ( UML ) diagrams , for example ) with which security practitioners commonly work , and the everyday practices of the consumers who are affected by security design .
Heath , Hall & Coles-Kemp [ 424 ] reported a successful case study of this method to model security for a home banking application , which identiﬁed areas where human intervention and support needed to be provided to make security work overall .
These studies provide examples of different ways of engaging with employees , consumers and citizens on security .
work on Productive Security [ 425 ] ) , moving away from the mechanistic approach of looking for traits within individuals that are conducive to the desired security behaviour , or trying to change behaviour by addressing or tweaking those traits .
The fundamental focus of these approaches is about changing the design of security to align with user and organisational tasks to reduce work6 https : //www.trespass-project.eu/ KA Human Factors | October 2019 Page 166 The Cyber Security Body Of Knowledge www.cybok.org load and increase productivity for an organisation .
4.6.2 Software developers and usable security Zurko & Simon pointed out that unusable security affects not only general employees who may not have speciﬁc computing or security education but also those who have signiﬁcant technical skills , such as developers and system administrators [ 426 ] .
They also face increasing workloads and complexity , and make mistakes because the libraries and application programming interfaces ( APIs ) they draw on are not usable .
Arguably , errors that these technical users make generally have a more signiﬁcant impact than mistakes made by general employees , e.g .
Developers and password security We noted above the usability issues of password and other authentication systems that have been studied extensively for end-users , highlighting problems and informing design decisions for better policies and motivating research into alternatives .
However , end-users are not the only ones who have usability problems with passwords .
The developers who are tasked with writing the code through which the passwords are stored must do so securely .
Yet , history has shown that this complex task often fails due to human error with catastrophic results .
None of the student participants , and only a small number of freelance developers , implemented any kind of security unless explicitly prompted to do so .
Interestingly , of those participants who did implement some security measures , the students did better than the freelance developers , who on the whole used more outdated and incorrect cryptographic mechanisms to store their passwords .
It was notable that , of the 96 developers who were contacted by Fahl et al .
, a large number were willing to provide information , but only 13 were interviewed because their companies refused permission for them to do so .
found that developers had little to no security training and were under extreme pressure to complete the app quickly—and that was the reason for the mistakes that led to vulnerabilities .
Two thirds of the developers who used StackOverﬂow or a textbook managed to produce a functionally correct solution within the allocated time , whereas only 40 % of those using ofﬁcial documentation did .
In terms of the security tasks , the results were reversed .
Those using ofﬁcial documentation produced the most secure code and those using the StackOverﬂow the least .
A traditional security response to this result would be ‘ use of StackOverﬂow should be forbidden .
’ But clearly , the productivity price developers and their organisations would pay would be a hefty one .
That is not to say that such advice is always effective ( as noted above ) but the forums do provide a community of practice in which developers can share their problems and seek help .
Banning such forums outright without replacing them with relevant support would , therefore , not address the crux of why developers seek such support .
KA Human Factors | October 2019 Page 167 The Cyber Security Body Of Knowledge www.cybok.org The usability challenges of cryptographic APIs and their documentation have been highlighted by Arzt et al .
Green and Smith have synthesised insights from the existing body of research into a set of ten principles to make application programming interfaces for security and cryptography libraries more usable for developers [ 422 ] .
[ 434 ] identify four usability smells that indicate that cryptographic APIs may not be fully addressing such principles , offering insights to library developers on the key areas on which to focus in order to improve the usability of their libraries .
The disconnect between developers and users also needs to be considered .
[ 435 ] highlighted that developers did not understand the impact of the lack of usability on individual performance and wellbeing , organisational productivity , or the effectiveness of security .
They recommend that management must ensure that developers experience the results of the lack of security and usability directly – by having to deal with help desk calls , the impact of losses – and engage more .
Recent work has provided insights into the role of strong organisational security cultures on developers ’ mindsets with regards to security [ 436 ] and how experts improve their security practices [ 437 ] .
4.7 CONCLUSION Humans and technologies do not exist in isolation .
Humans conceive new technologies , design and implement them , and are also their users and maintainers .
Human factors must play a central role as , after all , the purpose of cyber security is to protect people , their data , information and safety .
We must – as far as possible – ﬁt the task to the human and not the human to the task .
, when published information can be used by thieves to infer when users are not home , by enemies to ﬁnd out weak points to launch attacks on users or by advertising companies to build proﬁles and inﬂuence users .
On a large scale , the use of this information can be used to inﬂuence society as a whole , causing irreversible harm to democracy .
The extent of the harms that privacy loss causes highlights that privacy can not simply be tackled as a conﬁdentiality issue .
Beyond keeping information private , it is important to ensure that the systems we build support freedom of speech and individuals ’ autonomy of decision and self-determination .
The goal of this knowledge area is to introduce system designers to the concepts and technologies that are used to engineer systems that inherently protect users ’ privacy .
We aim to provide designers with the ability to identify privacy problems , to describe them from a technical perspective , and to select adequate technologies to eliminate , or at least , mitigate these problems .
First , to better understand what privacy means for society and individuals .
Second , to ensure that the legal frameworks that underpin our democracies support privacy as a right .
Probably one of the best examples of the latter are the principles and rules associated with the European Data Protection Legislation [ 443 ] covered in the Law & Regulation Knowledge Area ( Chapter 3 ) .
All of these conceptualisations are of great importance to deﬁne and understand the boundaries of privacy and its role for society .
However , their abstract and context-free nature often makes them not actionable for system designers who need to select technologies to ensure that privacy is supported in their systems .
We consider that privacy concerns , and the solutions that can address them , are deﬁned by the adversarial model considered by the designer , the nature of the information to be protected , and the nature of the protection mechanism itself .
Typical examples of adversarial models can be : third-party services with whom data are shared are not trusted , the service provider itself is not trusted with private data of the users , or users of a service should not learn private data from other users .
Typical examples of private data to be protected from these adversaries can be : the content of users ’ communications , their service usage patterns , or the mere existence of users and/or their actions .
Finally , typical examples of protection means can be techniques that enable information availability to be controlled , such as access control settings , or techniques to hide information , such as Encryption .
This knowledge area is structured as follows .
The ﬁrst part , comprising three sections , considers three different privacy paradigms that have given rise to different classes of privacy technologies .
The ﬁrst is privacy as conﬁdentiality ( Section 5.1 ) , in which the privacy goal is to hide information from the adversary .
We revise technological approaches to hide both KA Privacy & Online Rights | October 2019 Page 172 The Cyber Security Body Of Knowledge www.cybok.org data and Metadata , and approaches to hinder the adversary ’ s ability to perform inferences using the data that can not be hidden .
The second is privacy as informational control ( Section 5.2 ) , in which the goal is to provide users with the means to decide what information they will expose to the adversary .
We revise technologies that support users in their privacyoriented decisions and techniques that help them express their preferences when interacting with digital services .
Finally , we introduce privacy as transparency ( Section 5.3 ) , in which the goal is to inform the user about what data she has exposed and who has accessed or processed these data .
We revise solutions that show users their digital footprint , and solutions that support accountability through secure logging .
The privacy requirements that deﬁne the privacy goals in the paradigms mentioned above are often context dependent .
That is , revealing a particular piece of information may be acceptable in some environments but not in others .
For instance , disclosing a rare disease is not considered a privacy concern in an interaction with a doctor but would be considered a privacy violation in a commercial interaction .
Nissembaum formalizes this concept as contextual integrity [ 446 ] , which explicitly addresses an information ﬂow may present different privacy needs depending on the entities exchanging this information or the environment in which it is exchanged .
We note that once the requirement for a ﬂow are clear ( including the adversarial model ) , a designer can directly apply the technologies described in this chapter .
The second part of the knowledge area is devoted to illustrating how privacy technologies can be used to support democracy and civil liberties ( Section 5.4 ) .
We consider two core examples : systems for secure voting and to circumvent censorship .
For the former , privacy of the votes is imperative for the functionality itself .
For the latter , privacy of communication partners is necessary to ensure that content can not be blocked by a censor .
While there exist solutions to selectively revoke the protection provided by privacy technologies , these are strongly discouraged by privacy researchers and privacy advocates .
The reason is that adding backdoors or escrow possibilities to ease law enforcement , inherently weakens the security of the privacy-preserving systems as they can also be exploited by malicious actors to undermine user ’ s rights .
Therefore , we do not consider these techniques within this document .
We conclude the knowledge area by outlining the steps involved in the engineering of privacypreserving systems ( 5.5 ) .
We provide guidelines for engineers to make informed choices about architectural and privacy technologies .
These guidelines can help system designers to build systems in which the users ’ privacy does not depend on a centralised entity that may become a single point of failure .
We note that many of the privacy technologies we revise in this knowledge area rely on the cryptographic concepts introduced in the Cryptography Knowledge Area ( Chapter 10 ) .
Throughout this knowledge area , we assume that the reader is familiar with these basic concepts and avoid repeating cryptographic deﬁnitions and reiterating on the explanation of common primitives .
Under this deﬁnition , the objective of privacy technologies is to enable the use of services while minimising the amount of exposed information .
Here , information refers to both data exchanged explicitly with the service , as well as information made implicitly available in the Metadata associated with these exchanges ( e.g .
5.1.1 Data Conﬁdentiality We now describe two approaches to minimise the amount of exposed information .
We ﬁrst present methods that provably prevent unauthorised access to information , typically based on the use of advanced cryptographic primitives to ensure that no data can be inferred .
Second , we present disclosure control methods , which relax the Conﬁdentiality deﬁnition to ensure that the information leaked to the adversary is limited to a certain amount , or is not linkable to an individual person .
These technologies mainly consider two adversary models : one where the recipient is considered trusted and the data have to be protected while in transit , and one in which the recipient is not trusted and the data must be kept private even when it is processed .
Here , an end refers to the origin and destination of the communication .
For instance , the sender and receiver of an email , or the client and server of a service .
E2EE ensures that the Conﬁdentiality of data is ensured between both ends .
Additionally , E2EE typically provides Integrity , impeding any intermediary from modifying the data exchanged , and Authentication , ensuring that the communication parties can be sure of each others ’ identity .
From a technical perspective , in E2EE the devices at the end of the communication hold the Encryption key used to protect the data .
Usually , these are symmetric encryption keys and can be agreed using key transport , or can be established using any modality of the DifﬁeHellman exchange .
The use of Difﬁe-Hellman to agree one key per session additionally provides forward secrecy , but one must be careful when implementing the exchange [ 455 ] .
Typically , Digital Signatures and Message Authentication Codes are used to provide Integrity and authentication .
It considers an adversary that can not only observe the communication , but also eventually compromise one of the devices participating in the communication .
This compromise gives the adversary the chance to get the long-term keys of the participants .
In such a demanding scenario the two main goals of OTR are to provide i ) perfect forward secrecy and ii ) repudiable Authentication , which permits a user to deny having sent a message in the past .
The protocol derives the cryptographic keys used for the conversation using an unauthenticated Difﬁe-Hellman key exchange .
Then , the participants carry out a mutual authentication inside the protected channel , which guarantees the future repudiability .
Encryption keys are rotated , and old keys are deleted , so as to maintain forward secrecy .
Similar to OTR , this protocol provides authenticated messaging between users with end-to-end Conﬁdentiality , and messages are kept secret even if the messaging server is compromised , and even if the user ’ s long-term keys are compromised .
These properties rely on an authenticated key exchange protocol that mixes multiple Difﬁe-Hellman shared secrets , and on a protocol to refresh the keys called double ratcheting [ 452 ] .
Note that all of the above protocols only offer strong guarantees as long as the mechanisms to authenticate the communication parties work as expected .
For instance , the Conﬁdentiality provided by TLS relies on services keeping their keys secret and the Public Key Infrastructure operating reliably , so that the communication parties can be authenticated .
Similarly , WhatsApp ’ s Conﬁdentiality relies on the fact that phone numbers are hard to spoof and , thus , users are sure that the recipient of their message is their intended interlocutor .
The previous protocols focus on protecting data in transit from third parties other than the communication participants .
We now consider situations in which the recipient needs to perform some computation on the data , even though she is considered adversarial .
We distinguish two scenarios : one in which computation is completely outsourced and one in which the sender participates in the computation .
In the ﬁrst scenario , commonly known as outsourcing , the data belong to the sender and the recipient acts as the data processor .
The solutions to this problem are based on advanced cryptographic protocols .
We now illustrate the use of these protocols in a couple of examples , and we refer the reader to the Cryptography Knowledge Area ( Chapter 10 ) for more details on the technical details of the underlying primitives .
A common problem when outsourcing services is that accessing particular pieces of outsourced data may reveal information about the user to the entity holding the data .
Another example where remote processing is needed comprises digital shops or digital banking , where a server returns information to a user depending on the inputs .
The shop needs to process payments and then ship the digital item ; and the bank provides money , or makes a payment , upon authentication .
The previous techniques are useful for particular operations : search an item on a database , transfer that item .
Ideally , we would like to be able to perform any operation on outsourced data .
This type of encryption allows any operation on encrypted data to be performed .
Such ﬂexibility , however , comes at a high cost in terms of computation time , and for some implementations also in terms of bandwidth , thus making it far from practical at this point .
Less general versions such as somewhat homomorphic encryption or partially homomorphic encryption , which only permit limited operations ( sums , multiplications or evaluating a given function ) provide better trade-offs and can already be used for simple concrete tasks .
While this combination indeed brings the performance of privacy-preserving cryptography closer to the benchmarks needed for deployment , it is important to highlight that such an improvement comes at the expense of trusting the manufacturer of the secure hardware not to leak the information ( or the key ) to unintended parties .
In the case of database outsourcing , it is worth mentioning tailored solutions that combine different types of privacy-preserving cryptography in order to increase efﬁciency [ 471 ] .
These schemes indeed provide great performance .
Therefore , they are only recommended to support compliance , and should only be deployed in a trusted environment where attacks are unlikely .
It is not recommended to use them in scenarios where data privacy is of critical importance and the entity that holds the database is not trusted .
, the entities involved in the communication collaborate to perform the computation .
The result of this computation may be of interest for the sender , for the receiver , for both , or for third parties .
These protocols allow two parties to compute the intersection of datasets without revealing anything except the inter- KA Privacy & Online Rights | October 2019 Page 176 The Cyber Security Body Of Knowledge www.cybok.org section , or the cardinality of the intersection .
When data are processed in the encrypted domain , it is hard for the entities performing the computation to run any check on the adequacy of the inputs .
To solve this problem , many primitives build on Zero-Knowledge Proofs ( see the Cryptography Knowledge Area ( Section 10.9.1 ) ) to prove to the entity performing the computation that the inputs comply with a certain format or with certain constraints .
We now describe three cases in which veriﬁcation in the encrypted domain is key to enabling the use of privacy-preserving cryptographic protocols .
Zero knowledge proofs are very well suited to ensuring that the input to a privacy-preserving protocol is of a particular form or is not malicious .
To maintain Conﬁdentiality , entities participating in protocols may want to authenticate their communication partners .
However , typical Authentication systems are based on revealing the identity of the authenticating party .
Instead of authenticating an entity with respect to an identity in order to grant authorisation , ABCs enable the entity to prove possession of a combination of different attributes to obtain the same authorisation .
This proof does not reveal any additional information about the entity authenticating , nor does it reveal the concrete values of the attributes .
In other words , credentials look different every time they are shown , such that different showings can not be linked to each other .
While from the point of view of privacy , ABCs bring many advantages , they also introduce new challenges .
Anonymity may open the door to misbehaviour .
Unfortunately , the strong Anonymity and Unlinkability properties provided by original ABCs do not allow an authority to limit or revoke authorisation for misbehaving users .
These implementations offer different subsets of the functionalities mentioned above .
Veriﬁcation of encrypted data is also key to enabling privacy-preserving payments , in which the payer may have to prove to the buyer , for instance , that he has enough funds without revealing the exact amount .
To spend the e-coin , the client would give this number to the seller , who could redeem it at the bank .
By storing the random number , banks can detect double spending , but not identify the double spender .
In each transaction , the user proves , in zero knowledge , that she owns the e-coins input to the transaction ; that each one of the input e-coins was either recently mined ( minted in Zerocash terms ) or was the output of a previous transaction ; and that the input and output values of the transaction are the same , i.e .
These proofs are shorter ( in the order of hundreds of bytes ) and relatively fast to verify .
5.1.1.2 Obfuscation-based inference control The protocols discussed in the previous section provide strong ( cryptographic ) guarantees regarding the Conﬁdentiality of data .
Such strong protection , however , comes at the cost of efﬁciency and ﬂexibility .
On the other hand , they narrow down the type of processing that can be done on data .
This is inherent to cryptographic constructions that ﬁx inputs and outputs , and strictly deﬁne what information will be available after the protocol is executed .
In this section , we describe approaches to protect data Conﬁdentiality based on obfuscating the data exposed to an adversary .
These techniques provide a more relaxed deﬁnition of Conﬁdentiality than cryptography , in the sense that they can not completely conceal information .
Instead , their goal is to provide a way to control the extent to which an adversary can make inferences about users ’ sensitive information .
In fact , for most of these techniques , the level of protection depends on the concrete data and adversarial knowledge .
Also , we note that the privacy gained from these techniques is based on limiting the information available to one ’ s adversary .
Consequently , these techniques reduce the amount of information available for anyone and , hence , may have an impact on utility if the purpose of the application is based on sensitive information , e.g .
However , we note that when the sensitive information is not crucial for the purpose of the application these techniques may be deployed without affecting utility , e.g .
There are four main techniques to obfuscate data , as described below .
We note that these techniques are mostly oriented to obfuscate numerical or categorical ﬁelds .
Obfuscating more complex content , such as free text , is a much more difﬁcult task due to correlations that are hard to remove in a systematic manner .
To date , there are no known techniques that can reliably anonymise free text .
However , these techniques are quite effective at reducing the information leaked by Metadata , as we discuss in Section 5.1.2 .
For the sake of illustration , let us take the following microdata ﬁle as a current example .
This is a very simple example , and we stress that the techniques introduced below can be applied to many types of data formats and domains .
A common technique used to permit data processing without risk for individuals is data anonymisation .
The idea is that removing identifying information from data points makes them unlinkable ( i.e .
, they can not be grouped as belonging to the same entity ) , thus hindering the ability of the adversary to perform inferences from the data .
Data in and on themselves contains enough information to correlate different attributes and/or records on a database .
Given these groups , there are many techniques to re-identify individuals behind the data release .
There may be many combinations of the information released in a dataset that are unique to an individual .
Thus , anonymisation is commonly combined with the obfuscation techniques described below to limit the risk of re-identiﬁcation .
At this point in the knowledge area , it is worth referring to the notion of k-anonymity , which advocates combining generalisation and suppression in order to ensure that records on a database are anonymous among ( i.e .
First , due to the uniqueness of the problem mentioned above , obtaining kanonymity may require an unacceptable amount of generalisation in the database .
This is illustrated in our running example in the Gender column .
This technique consists in reducing the precision with which data are shared , with the goal of reducing the accuracy of the adversary ’ s inferences .
This technique consists in suppressing part of the information before it is made available to the adversary .
The rationale behind suppression is that the fewer the data are provided to the adversary , the more difﬁcult is for her to make inferences .
The suppression strategy , which decides which information to hide , is key for the level of privacy protection that such a scheme may provide .
For instance , suppressing information at random is unlikely to destroy the patterns in the data that allow for inferences .
Thus , unless most of the data are deleted , this strategy seldom provides good protection .
The level of protection of this strategy depends on the type of access to the data and the knowledge of the adversary [ 513 ] .
This technique consists in adding fake data points , so-called dummies , to the data made available to the adversary in order to hide which are the real samples .
The idea is that , as the adversary considers fake points when running the attack , her inference will have errors .
For this defense to be effective , fake points have to be indistinguishable from real points .
Ideally , from the point of the view of the adversary , any sample should look like a real or dummy one with equal probability .
Thus , this technique is useful in very few domains .
Perturbation techniques inject noise into the data made available to the adversary .
Similar to suppression techniques , the strategy used to introduce noise plays a crucial role in the level of privacy provided .
This approach was not really effective , as an adversary with knowledge of the noise distribution could infer the original data values with reasonable accuracy and thus risked leaking more information than intended .
Currently , the gold standard in perturbation-based techniques is to add noise to achieve socalled differential privacy .
The main goal of this technique is to address the limitations of data anonymisation techniques for publishing such as the aforementioned k-anonymity .
about users on a database while minimising the risk of unintended inferences .
An algorithm is differentially private if , by looking at the result of the query , the adversary can not distinguish whether an individual ’ s data were included in the analysis or not .
Differential privacy ensures that , given a perturbed data sample , the adversary gains a negligible amount of new information about the original data sample with respect to the her prior knowledge , regardless of what this prior knowledge was .
Differential privacy is an extremely useful deﬁnition because it gives a formal framework to reason about the amount of information a powerful adversary might be able to infer about individuals in the data , regardless of the adversary ’ s prior knowledge .
This means that the protection provided is regarding the prior knowledge of the adversary .
If the adversary already has full knowledge , differential privacy will not improve privacy .
In other words , differential privacy ensures that the release of data does not worsen the privacy loss of a user or population by more than a set threshold .
Therefore , to claim privacy , it is important to not only ensure that a scheme provides a given guarantee , but also computes the adversarial error on the inferences so as to ensure that users ’ sensitive information is actually protected ( see Section 5.5 ) .
• One of the current practical challenges of differential privacy is to determine what values of  provide an acceptable level of privacy .
The level of protection of crucially de- KA Privacy & Online Rights | October 2019 Page 182 The Cyber Security Body Of Knowledge www.cybok.org pends on the value of this parameter .
This means that merely fulﬁlling the differential privacy deﬁnition with arbitrary parameter values does not directly guarantee that the adversary does not learn too much new information from the data .
It is important to ensure that the value of  is such that the probabilities for different inferences are actually indistinguishable .
This probabilistic difference can typically be detected by classical statistical detectors , or any modern machine-learning classiﬁer .
In general ,  values greater than one deserve a closer look to verify that the algorithms provide the sought level of protection .
• The amount of noise required to hinder inferences on the data depends on the so-called sensitivity of the algorithm .
Sensitivity measures how much a change in the input will change the output of the algorithm A .
When the input is a database and the output a statistical function , small input changes have little inﬂuence on the output and , thus , a small amount of noise is enough to make the algorithm differentially private .
We note , however , that when differentially private algorithms are applied to protect the privacy of a single sample instead of to the result of a statistical query on a database , the sensitivity may be much higher .
• Differential privacy provides a worst-case guarantee , which means that the amount of noise introduced is tailored to bound the leakage given by the data point in the dataset that provides the most information to the adversary with the best knowledge .
This means that in an average case the amount of noise is larger than needed .
Recent studies have been working towards tighter bounds that permit reduction in the noise required to provide a desired protection level [ 523 ] .
Finally , it is important to remark that for many real cases , one of these inference controls can not provide enough privacy on its own .
Therefore , typically one needs to combine several of these techniques to limit the numbers of inferences that can be made .
5.1.2 Metadata Conﬁdentiality In the previous section , we discussed means to protect the Conﬁdentiality of the contents of messages , databases , queries , etc .
These techniques are essential to ensure privacy .
Yet , they do not protect against an adversary that uses the Metadata to infer sensitive information about individuals .
Concretely , there are three types of metadata that have been demonstrated to be extremely vulnerable to privacy attacks : trafﬁc metadata , associated to the communication infrastructure ; device metadata , associated with the platform generating the data , and location metadata , associated with the physical location from which data is generated .
In this section , we discuss the privacy risks associated with these types of metadata and the relevant controls to address these risks .
Network-layer information , such as the identities of the participants in the communication ( IP addresses ) , the amount and timing of the data transferred , or the duration of the connection , is accessible to observers even if communications are encrypted or obfuscated .
This information , commonly known as trafﬁc data , can be exploited to deduce potentially sensitive private information about the communication .
However , the mere fact that a patient is seen communicating with a specialised doctor can reveal highly sensitive information even when the messages themselves can not be decrypted .
Conﬁdential communications are not only desirable for personal reasons , but they also play an important role in corporate environments .
A technique to protect trafﬁc data is the use of anonymous communications networks .
These networks are typically formed by a series of relays such that communications do not travel directly from origin to destination , but are sent from relay to relay .
These relays also change the appearance of a message through means of Encryption to provide bitwise Unlinkability , i.e .
, to ensure that packets can not be linked just by looking at their bit content ; they can also change trafﬁc patterns by introducing delays , re-packaging messages , or introducing dummy trafﬁc .
In the following , we focus on the two most known anonymous communications network types which have real-world deployment .
We refer readers to the surveys by Danezis et al .
The core element of the Tor Network are Onion Routers ( ORs ) , which are essentially routers that forward encrypted data .
ORs encrypt , respectively , decrypt packets along the way to achieve bitwise unlinkability , as detailed below .
When a user who wants to anonymously access an Internet service through the Tor network , she installs a Tor client in her device .
This software builds a circuit of connections over three ORs , called entry , middle and exit nodes , and the client routes encrypted trafﬁc to the destination server through this circuit .
Every packet routed through the circuit gets encrypted with these three keys , ﬁrst with the exit OR ’ s key , then the middle OR ’ s key , and ﬁnally that of the entry OR .
When the message travels through the circuit , the nodes ‘ peel ’ each layer of encryption until the original packet is sent to the destination .
The server sends data to the client using the same circuit , but in the inverse order ; i.e .
, the server encrypts the message in layers that are decrypted by exit , middle , and entry ORs .
In order to support lowlatency applications , Onion Routers do not impose delays on the messages they receive and resend .
Thus , trafﬁc patterns are conserved while packets travel through the network .
At this point it is important to highlight the difference between using Tor and using a Virtual Private Network ( VPN ) .
Both technologies give the protection against an adversary that observes only one side of the communication , and both fail to protect against an adversary that can see both extremes .
However , while in Tor no single relay can on itself learn the link between sender and receiver ( i.e .
In order to destroy trafﬁc patterns and protect correlation attack relays in an anonymous communication , networks need to delay packets or add new ones .
As opposed to onion routing , where all the packets from a communication are routed through a circuit , in mix-based communications routes are selected for every message .
Then , when a mix relay receives a packet , instead of immediately decrypting and send it to the next hop on the path , the message is delayed .
How many messages are delayed is determined by a ﬁring condition , which is an event such as the arrival of a message or the expiration of a timeout that causes the mix to forward some of the messages it has stored .
Which messages are ﬁred depends on the batching strategy , which can select all of the messages or a fraction according to a probabilistic function .
Both mixes and users can send dummy trafﬁc , which may be absorbed by other mixes or by the recipient .
As opposed to Tor , where users ’ clients communicate directly with the Tor nodes , Loopix assumes that users communicate with providers that in turn send messages to each other through the Loopix anonymous communication network .
Providers choose a random route composed of Loopix routers and send the message to the ﬁrst node .
Similar to Tor , messages get encrypted with the keys of each of these routers using the Sphinx packet format [ 535 ] .
In addition to the Encryption , messages are assigned a delay for every relay they visit according to an exponential distribution .
Finally , providers inject dummy trafﬁc into the network by sending packets to themselves via a Loopix path , so as to provide cover for real messages .
The combination of providers that hide mix messages from users sending ( respectively receiving ) messages at the same time , delays and cover trafﬁc enable Loopix to provide provable guarantees regarding the Unlinkability of the senders and receivers of messages .
In today ’ s optimised Internet services , the concrete characteristics of users ’ devices are frequently sent along with their data requests in order to optimise the service providers ’ responses .
This is because combinations of features such as the User Agent ( the browser software vendor , software revision , etc .
Device or browser ﬁngerprinting is the systematic collection of this information for identiﬁcation and tracking purposes .
A large number of attributes , such as browser and operating system type and version , screen resolution , architecture type , and installed fonts , can be collected directly , using client-side scripting and result in unique ﬁngerprints .
As an illustrative example , let us consider the list of fonts installed on a particular user ’ s web browser as an identiﬁer that enables tracking .
There are two techniques to obtain the list of installed fonts , which is known to provide a good level of uniqueness .
This is because browsers install fonts on demand depending on the sites visited .
Since users have different browsing patters , their lists of installed fonts become different as well .
Font ﬁngerprinting techniques exploit the fact that if a font is installed , browsers will render it , but if not .
browsers will revert to monospace font .
In the ﬁrst technique , the tracking web sends a sentence to the browser to be printed with a series of fonts .
When the size is equal to the sentence printed in monospace , the tracker learns that the font is not installed .
In this case , the tracker exploits the HTML5 Canvas feature , which renders pixels on the ﬂy .
As before , different font size result in different pixel footprints .
Measuring the result of the canvas rendering the tracker can ascertain which fonts are installed in a browser .
Defending against device Metadata attacks while retaining utility is extremely difﬁcult .
On the hand , hiding these metadata from service providers has an impact on the performance of the services , since it limits personalisation and deteriorates the rendering of information .
On the other hand , it is hard to establish which combination of features would actually make users indistinguishable from other users .
This is because we have no knowledge of the distribution of ﬁngerprints in order to imitate one of them , and trying combinations at random runs the risk of being as unique as the original ﬁngerprint [ 538 ] .
We note that besides tracking based on metadata , trackers also use a series of techniques based on the use of cookies .
Third parties can also use cookie syncing , whereby , besides adding their own tracking , webs redirect cookies to other trackers to inform them of where the users are going [ 541 ] .
This information can be revealed explicitly , for example , when the user makes queries to location-based services to ﬁnd nearby points of interest or friends ; or implicitly , for example , when GPS coordinates are associated with photos or content published on social networks , or inferred from the access point used to access the Internet .
Clustering techniques to ﬁnd groups of nearby points where the user spends not signiﬁcant amounts of time can be used to infer users ’ points of interest such as where they live , where they work or their favourite leisure places .
In many cases , points of interest can be used as quasi-identiﬁers for users .
Similarly , the types and patterns of locations visited can be used to infer demographic data about users such as age or gender [ 543 ] .
There are two kinds of defence for protecting location Metadata in the literature .
The second kind of defence is based on the obfuscation techniques described in Section 5.1.1.2 in order to control the inferences that an adversary draws from the location data .
A wider notion of privacy , which is usually referenced in regulations , broadens privacy from the notion of concealment of personal information , to the ability to control what happens with the information that is revealed [ 441 , 443 ] .
The idea behind the shift from technologies that minimise disclosure to technologies that provide the means to control information use , is that in many cases , revealing data may be unavoidable or perceived as beneﬁcial to the data subject .
Thus , it is advisable to consider the use of technologies that address two major concerns : i ) enable users to express how they expect that data disclosed to the service provider are used , so as to prevent undesirable processing of these data ; and ii ) enable organisations to deﬁne and enforce policies that prevent the misuse of information , as deﬁned by the users .
In this section , we revise techniques that have been designed under the privacy as control paradigm .
We focus on techniques for the creation and conﬁguration of good privacy settings that help users express their preferences with respect to data disclosure and processing ; and techniques that support the automated negotiation of privacy policies across services .
Because much of the protection relies on trust , privacy technologies that enhance privacy in a system through improved control are less numerous and varied than those designed to achieve Conﬁdentiality .
It is important to highlight that these techniques inherently trust the service provider that collects the data to correctly enforce the policies established by the user with respect to third parties , as well as not to abuse the collected data itself .
KA Privacy & Online Rights | October 2019 Page 187 The Cyber Security Body Of Knowledge www.cybok.org 5.2.1 Support for privacy settings conﬁguration Privacy settings are those controls in a web service that allow users to express their preferences regarding how data should be revealed to other users , shared with third parties , and processed by the service providers .
have shown that the complexity of these privacy settings makes them barely usable by individuals [ 553 ] .
This in turn results in unintended disclosure of data .
We refer readers to the Human Factors Knowledge Area ( Chapter 4 ) for further information about the impact of usability of systems on security and privacy .
To counter this problem , researchers have proposed a number of techniques whose goal is to identify groups of individuals that share certain characteristics , and then establish the most adequate settings for each user group .
One area of research suggests letting security and privacy experts deﬁne what are the best policies are .
This approach , however , is difﬁcult to generalise from targeted groups to the general population , and in many cases may result in strategies that overestimate the need for protection .
This in turn limits too much the sharing and processing of data , thus rendering systems unusable .
A third approach does not require knowledge of a user ’ s social graph , but tries to ﬁnd adequate privacy settings by looking at a larger set of users .
These techniques have been shown to be prone to produce policies that are valid for the majority of users , but often discriminate against user groups with speciﬁc privacy requirements such as activists or persons of public interest .
Furthermore , ML-based techniques often augment and perpetuate biases present in the data from which the initial policies are inferred .
These techniques are more ﬂexible in the sense that users have more leeway to inﬂuence the policies .
However , they are still inﬂuenced by majority votes and may not be ideal for users who do not follow mainstream practices .
5.2.2 Support for privacy policy negotiation The previous technologies support users at the time of conﬁguring their privacy settings in an online service .
An orthogonal line of work is dedicated to automating the communication of user preferences to the service , or between services .
P3P is an industry standard that allows websites to encode their privacy policies ( what information is collected , how it is used etc . ) .
These policies can be read and interpreted by browsers equipped to do so .
P3P , however , does not have any means to enforce that the service provider actually follows the practices described in the policy .
Other technologies such as purpose-based access control [ 560 ] or sticky policies [ 561 ] provide the means to specify allowed uses of collected information , and to verify that the purpose of a data access is compliant with the policy .
These technologies can be supported by KA Privacy & Online Rights | October 2019 Page 188 The Cyber Security Body Of Knowledge www.cybok.org cryptographic mechanisms that guarantee that the service providers must comply with the preferences established by users .
5.2.3 Support for privacy policy interpretability In order to conﬁgure the privacy settings according to their expectations of how data should be handled , users need to understand the privacy policies that describe the meanings of these settings .
These policies are often long , verbose , and contain a lot of legal terms ; and they often evolve over time .
Researchers have developed technologies that enhance users ’ ability to interpret privacy policies .
Currently , there exist two approaches to improve users ’ understanding of privacy policies .
Another avenue is to completely automate the interpretation process .
This tool offers a visual representation of the policy specifying the types of data collected , the purpose of this collection , and the sharing practices , among others .
As opposed to technologies that limit data disclosure or the use of disclosed data , transparency mechanisms analyse users ’ online activities in order to either provide them with feedback about the implications of their actions , or run audits to check that there has been no violation of privacy .
In fact , feedback or audits happen after the users have already disclosed data to the provider .
Thus , providers are again trusted with making sure that the collected data are not processed or shared in ways not authorised by the users .
5.3.1 Feedback-based transparency We ﬁrst describe mechanisms that make transparent the way in which information is collected , aggregated , analysed and used for decision making .
The common factor between these technologies is that they provide users with feedback about how their information is processed or perceived by others .
This concept was adopted by popular online social networks such as Facebook , which allows users to check how different audiences ( e.g .
A similar line of work provides other means of visualising how privacy settings affect data sharing in order to improve users ’ understanding of the set of permissions they have selected .
This solution provides visual cues to users that indicate the access permissions associated with the data they shared [ 566 ] .
Both solutions help users understand their practices and modify their actions .
However , they can only do so after the information has been revealed to the provider ( and possibly to other users ) .
Nudges assist users in making choices about their privacy and security settings .
They give users immediate feedback whenever the user performs an online action in a way that the action could be cancelled or modiﬁed .
For instance , the nudge can inform the user that the post she is currently writing is public so that the user is careful about the words she chooses to use .
Nudging tools can be even more sophisticated and use modern machine learning algorithms to analyse photos or text as they are being uploaded , and provide users with more concrete feedback such as ‘ the post can be perceived as negative ’ or ‘ the photo is very explicit ’ .
While immediate feedback presents evident beneﬁts compared to mirrors , since actions can be modiﬁed before information is sent to the provider , it also has drawbacks .
Experiments with users have shown that immediate feedback results in an uncomfortable feeling for users as they feel monitored , and users sometimes perceive the advice as paternalistic and out of place [ 565 ] .
5.3.2 Audit-based transparency As mentioned before , even with privacy policies and access control in place , there is no guarantee that user preferences will be respected .
Additional measures can be put in place to enable users to verify that no abuse has taken place .
To realise these audits , the system is required to log all data access and processing operations .
This logging may reveal when users log into the system , and when and how their data are transmitted to others .
Thus , depending on the amount and granularity of the information , logging may introduce additional privacy risks .
One approach to do this is to derive the auditing speciﬁcations from the policies using formal methods [ 567 ] .
This guarantees that the generated logs , while being minimal , still contain enough information to audit whether the policies are being respected .
The solutions , however , are limited in their expressiveness and can not handle privacy policies in modern systems where the amount of data collected and the number of entities involved make a formal analysis extremely cumbersome .
The use of formal methods assumes that data sharing is managed by a centralised authority that must be trusted .
This is problematic because the centralised authority becomes a single point of failure .
Recent advances in cryptography and distributed ledgers permit the design of solutions that provide the means to create highly secure logs , while ensuring that no private information is shared with unauthorised parties .
When logging is made in such a distributed manner , no individual party can modify the log on its own , reducing the need for trust and eliminating any single point of failure .
For instance , systems like UnLynx [ 568 ] permit entities to share sensitive data , and perform computations on them , without entrusting any entity with protecting the data .
All actions are logged in a distributed ledger for auditing , and the correctness of the operations is ensured by using veriﬁable cryptographic primitives and zeroknowledge proofs .
Therefore , it is not necessary to publish or log the sensitive data or the operations done on them .
Privacy protection is crucial for underpinning the values that support our democratic societies .
Citing Daniel Solove : ‘ Part of what makes a society a good place in which to live is the extent to which it allows people freedom from the intrusiveness of others .
While such a society seemed science ﬁction not so long ago , episodes such as the Facebook Cambridge Analytica case highlight the importance of securing data from being accessed by unintended parties ( e.g .
, using Conﬁdentiality or control techniques ) to protect citizens from interference and manipulation .
In this section , we provide two examples that highlight the importance of privacy technologies in supporting democracy .
On one hand , we consider electronic voting systems that enable fair elections to take place using electronic infrastructure in adversarial conditions .
On the other hand , we give an overview of censorship resistance technologies .
These systems ensure that in a digital world , where communication infrastructure is dominated by a small number of companies and state actors can observe all communications , individuals have the means to communicate freely .
5.4.1 Privacy technologies as support for democratic political systems The growing use of electronic applications to interact with governmental bodies brings great advantages to society .
Providing citizens with easy means to express their opinions , comment on government initiatives , or vote in elections , increases their involvement in public decision processes .
This in turn improves the power balance between those who can execute decisions and those who are affected by the outcome of the decision process .
For these improvements to be effective , citizens must be able to freely express their opinions and must be sure that their inputs can not be modiﬁed or lost during the process .
Therefore , it is important that these applications are supported by strong privacy technologies that can protect users ’ identities , as well as their sensitive data and inputs to the system .
We describe two example applications , electronic voting and electronic petitions , whereby the technologies introduced in the previous sections are combined to enable citizens and governments to enjoy technological progress without compromising our democratic values .
Electronic voting systems have the goal of enabling fair elections to be conducted via electronic infrastructure in adversarial conditions .
• Universal veriﬁability : an external observer can verify that all the votes cast are counted and that the tally is correct .
Some protocols provide a weaker property , individual veriﬁability , where each voter can verify that his/her vote has been correctly tallied .
KA Privacy & Online Rights | October 2019 Page 191 The Cyber Security Body Of Knowledge www.cybok.org • Eligibility veriﬁability : an external observer can verify that all the votes cast were made by a unique eligible voter .
In order to guarantee the ﬁrst aspect , it is key to break the links between the votes putting their ballots into the system , and the ballots that come out .
In traditional pen-and-paper physical elections , this is done by mixing the ballots all of which have exactly the same appearance in an urn .
the votes are passed through a series of mixes , which must not belong to the same authority .
Otherwise , this authority could trace the votes and link the voters to their voting choices .
The results are published on a public bulletin board which anybody can read and verify that the election was carried out in a honest manner .
Voting mix networks are designed in a slightly different way than those mentioned in Section .
In the case of eVoting , the mixes ﬁre when all votes are in , and the batching strategy is to take all the votes .
In simple terms , it ensures that all votes are mixed together , obtaining the maximum Anonymity set .
This fulﬁlls the ballot secrecy criterion as any vote could have been cast by any voter .
This means that the mixes prove , in zero knowledge , that they mix all the votes ( all the votes at the input appear at the output ) and the mixing is random .
Eligibility veriﬁability can be obtained by requiring voters to prove in zero-knowledge that they are eligible to vote .
The user provides a zero-knowledge proof along with the vote that the vote has been correctly constructed .
Then , users submit the signed votes to the tally server using an anonymous communication channel .
This way no entity in the system can link voter to votes .
Then , every user adds his vote to the desired candidate , and randomises the rest of the encryptions ( so that encryptions of the same number never look the same ) .
As before , zeroknowledge proofs can be used to ensure that sums and randomisation have been performed in the correct way .
Besides the above three properties , some voting protocols additionally aim to provide coercion resistance , whereby a user can not be forced to vote for a particular candidate against her will .
Then , when users are under coercion they follow the instructions of the coercer , but provide their fake credentials to the system .
This enables the tally server to ignore any votes produced under coercion .
These schemes deﬁne policies to establish how to count votes whenever a given credential has cast more than one vote .
KA Privacy & Online Rights | October 2019 Page 192 The Cyber Security Body Of Knowledge www.cybok.org In petition systems based on anonymous credentials , citizens can register with the authority managing the petition system to obtain an anonymous signing key associated with some attributes relevant for the petitions .
, they are inhabitants of the municipality referred to ) but do not need to reveal their identity .
Advanced credential properties such as double signing detection enable the creation of this system while avoiding abuse from misbehaving citizens [ 581 ] .
More modern approaches rely on advanced cryptographic primitives to remove the need for a central trusted party that registers users .
This scheme improves Conﬁdentiality , authenticity , and availability through the use of distributed ledgers .
This approach increases the level of privacy in the system , while at the same time reducing the need to trust one single party .
5.4.2 Censorship resistance and freedom of speech Censorship systems attempt to impose a particular distribution of content across a system .
They may prevent users from publishing particular content that is considered controversial or dangerous for the censorship regime ; or they may prevent users from accessing content that may undermine the societal equilibrium that the censor wishes to impose on their society .
In this section , we show how privacy-preserving technologies can act as a cornerstone to support freedom of speech and freedom of access to information .
We will elaborate on some examples for each of these goals in order to illustrate the fundamental principles that make censorship resistance possible .
We refer the interested reader to the surveys by Khattak et al .
This was the ﬁrst system to use privacy technologies to protect the publishing of content on the Internet [ 585 ] .
Anderson ’ s scheme proposed to distribute copies of ﬁles across servers in different jurisdictions , so that those servers can not be subpoenaed at the same time .
In this scheme , privacy technologies have fundamental roles for resistance : Encryption not only provides privacy for users , but also prevents selective denial of service at retrieval time ; and anonymous Authentication not only protects users from the service , it also protects the service from being coerced into revealing the identities of users , e.g .
, the servers can not know the content of the ﬁles they store and thus , can always claim to be unaware of what they are serving .
In Freenet , ﬁles are located according to a key that is typically the hash of the ﬁle , but can also include a ﬁle description , or be a simple string .
To retrieve a ﬁle , a user obtains or computes the keys and asks Freenet nodes to ﬁnd it .
When the ﬁle is found , it is sent back along the same path that the request followed in the network .
This ensures that the node holding the data does not know the recipient .
To store a ﬁle , if the key does not already exist , the publisher sends the ﬁle along a path and every node on the path stores the ﬁle .
To protect the anonymity of the publisher , nodes that store the ﬁle also decide at random whether to KA Privacy & Online Rights | October 2019 Page 193 The Cyber Security Body Of Knowledge www.cybok.org also claim ownership .
Such random claims also provide nodes with deniability as to which of the ﬁles they are storing are actually theirs .
The design of Freenet is based on strong cryptography , which protects the content of messages .
However , in the early days , the routes and timing of messages allowed attacks to break the system ’ s anonymity .
[ 587 ] show that a passive attacker deploying a number of nodes in the network that can monitor requests can re-identify the requester by recursively asking other nodes if they have seen the request .
These issues are now addressed by Freenet , but others remain such as the attack by Levine et al .
The attack only requires passive observation of trafﬁc , and exploits the fact that the Freenet protocol determines the average number of requests for a ﬁle observable by a node depending on how far this node is from the requester .
The system also provides publisher and reader anonymity , but achieves censorship resistance in a different way .
Instead of simply storing the ﬁle replicated in many nodes in an anonymous way , Tangler ﬁles are split into small blocks that are stored on different servers .
In order to recover a ﬁle , one must thus contact a number of servers to retrieve enough of these blocks .
In order to avoid a server being compelled to delete a block belonging to a ﬁle , Tangler builds blocks in such a way that blocks contain parts of many documents .
Tangling improves availability in two ways .
First , a censor can only delete a target ﬁle by causing collateral damage to other ﬁles that may be allowed .
Second , whenever one wants to replicate a ﬁle , the ﬁles entangled in the replicated ﬁle blocks are also replicated .
To enable censorship-free access to data , systems must be able to conceal that users are accessing these data .
These approaches are effective , but have been shown to be vulnerable to active attacks in which the adversary probes the suspicious connection to ﬁnd out if any of the expected functions of the application being mimicked are missing [ 593 ] .
In this case , the censored communication is directly tunnelled through an uncensored service , instead of pretending to be that service .
This approach not only makes communications unobservable , but also deniable for all senders , recipients and applications hosting the content .
Finally , some censorship resistance systems rely on hiding the destination of the communication to prevent censors from blocking connections .
This is achieved by relaying censored trafﬁc through one or more intermediate nodes .
These bridges are Tor relays whose IPs are not public so that they can not be identiﬁed as members of a censorship resistance system .
To avoid the censor identifying connections to bridges due to their appearance , these are disguised using so-called pluggable transports [ 597 ] , which transform the trafﬁc ﬂow following one of the approaches referenced in this section .
This trafﬁc includes an undetectable signal that can only be interpreted by a cooperating Internet router .
This router deﬂects the client ’ s trafﬁc to the censored site and returns the responses to the client .
This concept advocates for the design and development of systems that integrate privacy values to address users ’ concerns .
However , the literature around this concept rarely addresses the actual processes behind the design , implementation , and integration of privacy protections into products and services .
In this knowledge area , we ﬁrst gave an overview of the landscape of privacy technologies , and subsequently provided a series of examples in which these technologies are combined to support the use of electronic systems while maintaining core democratic values .
We brieﬂy discussed how these principles can be used to generally approach the engineering of systems that embed strong privacy protections .
We refered the reader to the work by Gürses et al .
A relevant paper to help the reader understanding these principles is the work Hoepman on privacy strategies [ 604 ] The two primary goals when designing privacy-preserving systems are to : • Minimise trust : limit the need to rely on other entities to behave as expected with respect to sensitive data .
For instance , in mix-based eVoting , trust is not only distributed across the entities managing the mixes , but veriﬁable shufﬂes are put in place to limit to a maximum the amount of reliance on the good behaviour of each mix .
Similarly , the cryptographic primitives used to implement privacy-preserving electronic petitions do not require trust on the registration authority to protect the identities of the signers .
For instance , in Tor , compromising one relay does not provide any sensitive information about users ’ browsing habits .
If one compromises the entry node , one can not learn the destinations of the communications , only the middle nodes of the circuits ; and if one compromises the exit node , one can not learn the origin of the communication .
To minimise both trust and risk , privacy experts typically design systems in accordance with the following strategies : KA Privacy & Online Rights | October 2019 Page 195 The Cyber Security Body Of Knowledge www.cybok.org • Minimise Collection : whenever possible , limit the capture and storage of data in the system .
• Minimise Disclosure : whenever possible , constrain the ﬂow of information to parties other than the entity to whom the data relates .
, use of control techniques to limit the information available when publishing or querying a dataset .
• Minimise Replication : whenever possible , limit the number of entities where data are stored or processed in the clear .
Implementing these strategies at ﬁrst may seem incompatible with maintaining the Integrity of the system .
For instance , if no information is disclosed or collected , how can one make sure that no entity is abusing the system ?
If there is no central authority , how can one make sure that Authentication and authorisation work as expected ?
This is where privacy technologies come into play .
They enable the design of systems where as little information as possible is revealed to parties other than the ones to which the information relates , and in which there is a minimum need to trust providers or other users in order to preserve the privacy of sensitive information while still pertaining Integrity and allowing information exchange .
In order to decide which privacy technology is most adequate to build a system , a ﬁrst step is to identify the data ﬂows that should be minimised ; i.e .
, those that move data to entities to whom the data do not relate .
The second step is to identify the minimal set of data that needs to be transferred to those entities .
To identify the minimum required information that needs to be transferred , the designer should attempt to keep as much data as possible out of reach of those entities without harming the functionality of the system .
Strategies to minimise unnecessary information ﬂow ( based mainly on the technologies introduced throughout Section .
Additional information , such as zero-knowledge proofs or commitments , may be needed to guarantee the correctness of the operations .
• Encrypt the data : encrypt the data locally and send only the encrypted version to other entities .
If any operations on the data are needed , see the next point .
• Use privacy-preserving cryptographic protocols : process data locally to obtain inputs to a protocol in which , by interacting with the untrusted entities using one of the protocols introduced in the previous sections , the user can obtain or prove information while limiting the information made available to those entities .
For instance , using anonymous credentials for Authentication without revealing the identity or even the value of an attribute , or using private information retrieval to perform a search on a database without revealing the query to the database holder .
• Obfuscate the data : use techniques to control inference to process the data locally and only send the perturbed version to the untrusted entity .
KA Privacy & Online Rights | October 2019 Page 196 The Cyber Security Body Of Knowledge www.cybok.org • Anonymise the data : process the data locally to remove identiﬁable information and send it to the untrusted party via an anonymous channel .
By seeking minimisation of trust and using the above techniques , system designers are bound to collect , process and retain fewer data than with other strategies based on compliance with regulation .
We recognise that many systems and applications can not be built without collecting some user-related data .
For these cases , designers must take into account the privacy technologies outlined in Section .
These techniques , while requiring trust , help minimise the risk of a breach and , if the breach happens , minimise the impact that the disclosure of data may have for the users .
Once privacy technologies or end-to-end systems have been designed , it is important to conduct a privacy evaluation .
This evaluation has the goal of quantifying the level of privacy that the technology , and respectively the system , can provide .
For privacy technologies based on cryptographic primitives , the privacy evaluation is typically covers the cryptographic proofs that ensure that only the intended information is leaked by the operations .
On the contrary , for privacy techniques based on obfuscation , it is necessary to carry out an analysis to validate that the combination of techniques provides the desired level of privacy .
A systematic privacy evaluation typically consists of the following steps .
, what the adversary can see and what is her prior knowledge .
Third , assuming that the adversary knows the mechanism , consider how he would annul the effect of the privacy mechanism .
This usually entails either doing an analysis of the probability distributions , or using inference techniques such as machine learning to compute what the adversary can learn .
At the end of the process , one usually has a distribution describing the probability that the adversary infers each of the possible inputs .
This probability distribution is then used as input to a privacy metric that captures the inference capability of the adversary .
We refer the reader to the survey by Wagner and Eckhoff for a comprehensive description of privacy metrics in the literature [ 603 ] .
5.6 CONCLUSIONS Protecting privacy , as we have described in this knowledge area , is not limited to guaranteeing the Conﬁdentiality of information .
It also requires means to help users understand the extent to which their information is available online , and mechanisms to enable users to exercise control over this information .
We have described techniques to realise these three privacy conceptions , emphasising the adversarial model in which they operate , as well as providing guidelines to combine these techniques in order to build end-to-end privacy-preserving systems .
Preserving privacy and online rights is not only important for individuals , it is essential to support democratic societies .
The deployment of privacy technologies is key to allow users free access to content , and freedom of speech .
Of equal importance is to avoid that any entity gaining a disproportionate amount of information about individuals or groups , in order to prevent manipulation and abuse that could damage democratic values .
We use the terms malware and malicious code interchangeably .
Ransomware can encrypt data on a user ’ s computer and thus making it unaccessible to the user , and only decrypt the data after the user pays a sum of money .
Botnet malware is responsible for many of the Distributed Denial-of-Service ( DDoS ) attacks as well as spam and phishing activities .
We need to study the techniques behind malware development and deployment in order to better understand cyberattacks and develop the appropriate countermeasures .
As the political and ﬁnancial stakes become higher , the sophistication and robustness of both the cyber defence mechanisms and the malware technologies and operation models have also increased .
For example , attackers now use various obfuscation techniques such as packing and polymorphism as well as metamorphism to evade malware detection systems [ 605 ] , and they set up adaptive network infrastructures on the Internet to support malware updates , command-and-control , and other logistics such as transits of stolen data .
In short , it is becoming more important but also more challenging to study malware .
The rest of this chapter is organised as follows .
We will provide a taxonomy of malware and discuss their typical malicious activities as well as their eco-system and support infrastructures .
We will then describe the tools and techniques to analyse malware behaviours , and network- and host- based detection methods to identify malware activities , as well as processes and techniques including forensic analysis and attribution to respond to malware attacks .
It is instructive to create a taxonomy to systematically categorise the wide spectrum of malware types .
This taxonomy describes the common characteristics of each type of malware and thus can guide the development of countermeasures applicable to an entire category of malware ( rather than a speciﬁc malware ) .
Since there many facets of malware technologies and attack operations , based on which malware can be categorised and named , our taxonomy can include many dimensions .
It should be borne in mind that other , more specialised , attributes could also be used such as target processor architecture or operating system .
The ﬁrst dimension of our taxonomy is whether malware is a standalone ( or , independent ) program or just a sequence of instructions to be embedded in another program .
Standalone malware is a complete program that can run on its own once it is installed on a compromised machine and executed .
For example , worms and botnet malware belong to this type .
The KA Malware & Attack Technologies | October 2019 Page 202 The Cyber Security Body Of Knowledge www.cybok.org second type requires a host program to run , that is , it must infect a program on a computer by inserting its instructions into the program so that when the program is run , the malware instructions are also executed .
For example , document macro viruses and malicious browser plug-ins belong to this type .
In general , it is easier to detect standalone malware because it is a program or a running process in its own right and its presence can be detected by operating system or security tools .
The second dimension is whether malware is persistent or transient .
Most malware is installed in persistent storage ( typically , a ﬁle system ) as either standalone malware or an infection of another program that already resides in persistent storage .
Other malware is memory-resident such that if the computer is rebooted or the infected running program terminates , it no longer exists anywhere on the system .
Memory-resident malware can evade detection by many anti-virus systems that rely on ﬁle scanning .
The traditional way for malware to become memory-resident is to remove the malware program ( that was downloaded and installed previously ) from the ﬁle system as soon as it gets executed .
Newer approaches exploit system administrative and security tools such as PowerShell to inject malware directly into memory [ 607 ] .
For example , according to one report [ 608 ] , after an initial exploit that led to the unauthorised execution of PowerShell , meterpreter code was downloaded and injected into memory using PowerShell commands and it harvested passwords on the infected computer .
The third dimension generally applies to only persistent malware and categorises malware based on the layer of the system stack the malware is installed and run on .
Typically , malware in the lower layers is harder to detect and remove , and wreaks greater havoc because it has more control of the compromised computer .
On the other hand , it is also harder to write malware that can be installed at a lower layer because there are greater constraints , e.g .
, a more limited programming environment in terms of both the types and amount of code allowed .
The fourth dimension is whether malware is run and spread automatically vs. activated by a user action .
When an auto-spreading malware runs , it looks for other vulnerable machines on the Internet , compromises these machines and installs itself on them ; the copies of malware on these newly infected machines immediately do the same – run and spread .
Obviously , auto-spreading malware can spread on the Internet very quickly , often being able to exponentially increase the number of compromised computers .
, by sending email with itself as the attachment to contacts in the user ’ s address book , this spreading is not successful unless a user who receives this email activates the malware .
Most modern malware is supported by an infrastructure such that a compromised computer can receive a software update from a malware server , that is , a new version of the malware is installed on the compromised computer .
For example , updated malware can evade detection techniques that are based on the characteristics of older malware instances .
, isolated malware has become increasingly common in the forms of targeted attack .
That is , malware can be speciﬁcally designed to infect a target organisation and perform malicious activities according to those assets of the organisation valuable to the attacker .
memory-resident malware layers of system stack botnet malware persistent or transient viruses malicious browser extensions standalone or host-program Most modern malware uses some form of obfuscation in order to avoid detection ( and hence we do not explicitly include obfuscation in this taxonomy ) .
There is a range of obfuscation techniques and there are tools freely available on the Internet for a malware author to use .
For example , polymorphism can be used to defeat detection methods that are based on ‘ signatures ’ or patterns of malware code .
That is , the identiﬁable malware features are changed to be unique to each instance of the malware .
Therefore , malware instances look different from each other , but they all maintain the same malware functionality .
Some common polymorphic malware techniques include packing , which involves compressing and encrypting part of the malware , and rewriting identiﬁable malicious instructions into other equivalent instructions .
When the host-program runs , the malicious code executes and , in addition to performing the intended malicious activities , it can look for other programs to infect .
A virus is typically persistent and can reside in all layers of the system stack except hardware .
It can spread on its own because it can inject itself into programs automatically .
A virus can also be dynamically updated provided that it can connect to a malware update server .
A polymorphic malware virus can mutate itself so that new copies look different , although the algorithm of this mutation is embedded into its own code .
A virus is typically not part of a coordinated network because while the infection can affect many computers , the virus code typically does not perform coordinated activities .
These types of malware can be updated dynamically , form a coordinated network , and can be obfuscated .
Botnet malware refers to any malware that is part of a coordinated network with a botnet infrastructure that provides command-and-control .
Botnet malware is persistent and typically obfuscated , and usually resides in the kernel , driver , or application layers .
Other botnet malware is standalone , and can spread automatically by exploiting vulnerable computers or users on the Internet .
For example , when a user downloads the free version of a mobile game app , it may include adware , a form of PUP that displays ad banners on the game window .
without the user ’ s knowledge and consent , in order to serve more targeted ads to the user to improve the effectiveness of the advertising .
In this case , the adware is also considered spyware , which is deﬁned as unwanted program that steals information about a computer and its users .
PUPs are in a grey area because , while the download agreement often contains information on these questionable behaviours , most users tend not to read the ﬁner details and thus fail to understand exactly what they are downloading .
From the point of view of cybersecurity , it is prudent to classify PUPs towards malware , and this is the approach taken by many security products .
The simple reason is that a PUP has all the potential to become full-ﬂedged malware ; once it is installed , the user is at the mercy of the PUP operator .
For example , a spyware that is part of a spellchecker browser extension can gather information on which websites the user tends to visit .
But it can also harvest user account information including logins and passwords .
The ﬁrst step is Reconnaissance where an attacker identiﬁes or attracts the potential targets .
The next phase is to gain access to the targets , for example , by sending crafted input to trigger a vulnerability such as a buffer overﬂow in the vulnerable network service program or embedding malware in a web page that will compromise a user ’ s browser and gain control of his computer .
This corresponds to the Weaponization and Delivery ( of exploits ) steps in the Cyber Kill Chain Model .
Once the target is compromised , typically another piece of malware is downloaded and installed ; this corresponds to the Installation ( of malware ) step in the Cyber Kill Chain Model .
These are the Actions on Objectives in the Cyber Kill Chain Model .
Botnet malware runs on each bot and communicates with the botnet command-and-control ( C & C ) server regularly to receive instructions on speciﬁc malicious activities or updates to the malware .
For example , every day the C & C server of a spamming botnet sends each bot a spam template and a list of email addresses so that collectively the botnet sends a very large number of spam messages .
For example , it may look for a particular type of controller in the organisation to infect and cause it to send the wrong control signals that lead to eventual failures in machineries .
This means it not only receives regular updates .
For example , rather than sending the stolen data out to a ‘ drop site ’ all at once , it can send a small piece at a time and only when the server is already sending legitimate trafﬁc ; after it has ﬁnished stealing from a server it moves to another ( e.g .
, by exploiting the trust relations between the two ) and removes logs and even patches the vulnerabilities in the ﬁrst server .
When we use the Cyber Kill Chain Model to analyze a cyberattack , we need to examine its activities in each step .
This requires knowledge of the attack techniques involved .
An underground eco-system has also emerged to support the full malware lifecycle that includes development , deployment , operations and monetisation .
In this eco-system , there are actors specialising in key parts of the malware lifecycle , and by providing their services to others they also get a share of the ( ﬁnancial ) gains and rewards .
Such specialisation improves the quality of malware .
For example , an attacker can hire the best exploit researcher to write the part of the malware responsible for remotely compromising a vulnerable computer .
Specialisation can also provide plausible deniability or at the least limit liability .
For example , a spammer only ‘ rents ’ a botnet to send spam and is not guilty of compromising computers and turning them into bots ; likewise , the exploit ‘ researcher ’ is just experimenting and not responsible for creating the botnet as long as he did not release the malware himself .
That is , while they are all liable for the damage by malware , they each bear only a portion of the full responsibility .
First , we can understand the intended malicious activities to be carried out by the malware .
This will allow us to update our network and endpoint sensors to detect and block such activities , and identify which machines have the malware and take corrective actions such as removing it or even completely wiping the computer clean and reinstalling everything .
, the libraries and toolkits that it includes ) and coding styles , we may be able to gain information that is potentially useful to attribution , which means being able to identify the likely author and operator .
Third , by comparing it with historical as well as geo-location data , we can better understand and predict the scope and trend of malware attacks , e.g .
, mining cryptocurrencies ) are on the rise and if a cybercrime is moving from one region to another .
In short , malware analysis is the basis for detecting and responding to cyberattacks .
Malware analysis typically involves running a malware instance in an analysis environment .
There are also malware collection and sharing efforts where trusted organisations can upload malware samples found in their networks and also receive samples contributed by other organisations .
Academic researchers can typically just obtain malware samples without needing to contribute .
For example , we must protect the identities of the infection sites from which the malware samples were captured , and we must not share the malware samples with any organisation that is an unknown entity or that does not have the commitment or technical capabilities to analyse malware safely .
6.3.1 Analysis Techniques Malware analysis is the process of learning malware behaviours .
Due to the large volume and increasing complexity of malware , we need to be able to rapidly analyse samples in a complete , reliable and scalable way .
These program analysis techniques have been developed to support the software development cycle , and they often need to be customized or extended for malware analysis because malicious programs typically include code constructed speciﬁcally to resist analysis .
That is , the main challenge in malware analysis is to detect and bypass anti-analysis mechanisms .
A wide range of malware analysis techniques fall into the category of static analysis .
One limitation is that the analysis output may not be consistent with the actual malware behaviours ( at runtime ) .
A more serious problem is that malware authors are well aware of the limitations of static analysis and they leverage code obfuscation and packing to thwart static-analysis altogether .
For example , the packed code can not be statically analysed because it is encrypted and compressed data until unpacked into executable code at run-time .
Static analysis can provide more comprehensive coverage of program behaviours but may include unfeasible ones .
Dynamic analysis identiﬁes the precise program behaviours per the test input cases but misses behaviours that are not triggered by the input .
Additionally , dynamical analysis can defeat code obfuscation techniques designed to evade static analysis .
For example , when malware at run-time unpacks and executes its packed code , dynamic analysis is able to identify the ( run-time ) malicious behaviours in the originally packed code .
When performing dynamic analysis , the main questions to consider are : what types of malicious behaviours need to be identiﬁed and correspondingly , what runtime features need to be collected and when to collect ( or sample ) , and how to isolate the effects on the malware from those of benign system components .
Typically , the run-time features to be collected need to be from a layer lower than the malware itself in the system stack so that the malware can not change the collected information .
For example , instruction traces certainly cover all the details of malicious behaviours but the data volume is too large for efﬁcient analysis [ 624 ] .
6.3.1.3 Fuzzing Fuzzing is a method for discovering vulnerabilities , bugs and crashes in software by feeding randomised inputs to programs .
Fuzzing can explore the input space , but it is limited due to code-coverage issues [ 611 ] , especially for inputs that drive the program down complex branch conditions .
In contrast , concolic execution ( see 6.3.1.5 Concolic Execution ) is good at ﬁnding complex inputs by formulating constraints , but is also expensive and slow .
It treats variables and equations as symbols and formulas that can potentially express all possible program paths .
Unlike concrete execution , symbolic execution can explore multiple branches simultaneously .
To explore unseen code sections and unfold behaviours , symbolic execution generalises the input space to represent all possible inputs that could lead to points of interest .
Concolic execution , which combines CONCrete and symbOLIC execution , can reduce the symbolic space but keep the general input space .
The execution trace obtained by concrete execution is used to generate the path formulas and constraints .
The path formulas for the corresponding branch is negated and Satisﬁability Modulo Theories ( SMT ) solvers are used to ﬁnd a valid input that can satisfy the not-taken branches .
Generated inputs are fed into the program and re-run from the beginning .
This technique iteratively explores the feasible not-taken branches encountered during executions .
It requires the repetitive execution of all the instructions from the beginning and knowledge of the input format .
Whenever the concrete execution hits a branch , if both directions are feasible , execution is forked to work on both branches .
Unlike the ofﬂine executor , this approach can explore multiple paths .
This technique allows context-free concolic execution , which analyses any part of the binary at function and basic block levels .
Path explosion is also inevitable in concolic execution due to the nature of symbolic space .
Another approach is to prioritise the directions favouring newly explored code blocks or symbolic memory dependence [ 615 ] .
The design choice of the environment determines the analysis methods that can be utilised and , therefore , the results and limitations of analysis .
Creating an environment requires balancing the cost it takes to analyse a malware sample against the richness of the resulting report .
In this context , cost is commonly measured in terms of time and manual human effort .
Safety is a critical design consideration because of the concern that malware being executed and analysed in the environment can break out of its containment and cause damage to the analysis system and its connected network including the Internet ( see 6.3.2.1 Safety and Live-Environment Requirements ) .
An example is running a sample of a botnet malware that performs a DDoS attack , and thus if the analysis environment is not safe , it will contribute to that attack .
We can see that some architectures are easier to set up and give ﬁner control over the malware ’ s execution , but come at the cost of transparency ( that is , they are easier for the malware to detect ) compared to the others .
For example , bare-metal systems are very hard for malware to detect , but because they have no instrumentation , the data that can be extracted are typically limited to network and disk I/O .
KA Malware & Attack Technologies | October 2019 Page 210 The Cyber Security Body Of Knowledge www.cybok.org By contrast , emulators like QEMU can record every executed instruction and freely inspect memory .
A very large percentage of modern malware detect emulated and virtualised environments and if they do , then they do not perform their malicious actions in order to avoid analysis .
6.3.2.1 Safety and Live-Environment Requirements Clearly , safety is very important when designing a malware analysis environment because we can not allow malware to cause unintended damage to the Internet ( e.g .
In particular , malware authors know their code may be captured and analysed , and they employ code obfuscation techniques so that code analysis alone ( i.e .
, without actually running the malware ) will yield as little information as possible .
This is just one example that highlights how the design of a live-environment is important for the malware to be alive and thus exhibit its intended functionality .
6.3.2.2 Virtualised Network Environments Given the safety and live-environment requirements , most malware analysis environments are constructed using virtualisation technologies .
In addition , containment policies can be applied on top of the virtual environments to balance the live-environment and safety requirements to 1 ) allow malware to interact with the Internet to provide the necessary realism , and 2 ) contain any malicious activities that would cause undesired harm or side-effects .
Example architectures [ 617 ] include : 1 ) the GQ system , which is designed based on multiple containment servers and a central gateway that connects them with the Internet allowing for ﬁltering or redirection of the network trafﬁc on a per-ﬂow basis , and 2 ) the Potemkin system , which is a prototype honeyfarm that uses aggressive memory sharing and dynamically binds physical resources to external requests .
Such architectures are used to not only monitor , but also replay network-level behaviours .
KA Malware & Attack Technologies | October 2019 Page 211 The Cyber Security Body Of Knowledge www.cybok.org 6.3.3 Anti-Analysis and Evasion Techniques Malware authors are well aware that security analysts use program analysis to identify malware behaviours .
6.3.3.1 Evading the Analysis Methods The source code of malware is often not available and , therefore , the ﬁrst step of static analysis is to disassemble malware binary into assembly code .
The most general and commonly used code obfuscation technique is packing , that is , compressing and encrypting part of the malware .
Some trivially packed binaries can be unpacked with simple tools and analysed statically [ 651 ] , but for most modern malware the packed code is unpacked only when it is needed during malware execution .
By contrast , unpackers built on dynamic binary instrumentation ( DBI ) [ 622 ] are faster , but also easier to detect because the DBI code runs at the same privilege level as the malware .
The reason is that static analysis can be made impossible via advanced obfuscation using opaque constants [ 654 ] , which allows the attacker to hide what values will be loaded into registers during runtime .
This in turn makes it very hard for static malware analysis to extract the control-ﬂow graph and variables from the binary .
A more effective approach is to combine static and dynamic analysis .
For example , such an approach has been shown to be able to disassemble the highly obfuscated binary code [ 655 ] .
A less common but much more potent obfuscation technique is code emulation .
Borrowing techniques originally designed to provide software copyright protection [ 656 ] , malware authors convert native malware binaries into bytecode programs using a randomly generated instruction set , paired with a native binary emulator that interprets the instruction set .
Note that , for the same original malware , the malware author can turn it into many instances of emulated malware instances , each with its own random bytecode instruction set and a corresponding emulator binary .
It is extremely hard to analyse emulated malware .
Firstly , static analysis of the emulator code yields no information about the speciﬁc malware behaviours because the emulator processes all possible programs in the bytecode instruction set .
Static analysis of the malware bytecode entails ﬁrst understanding the instruction set format ( e.g .
, by static analysing the emulator ﬁrst ) , and developing tools for the instruction set ; but this process needs to be repeated for every instance of emulated malware .
Secondly , standard dynamic analysis is not directly useful because it observes the run-time instructions and behaviours of an emulator and not of the malware .
The main idea is to execute the malware emulator and record the entire instruction traces .
Applying dynamic dataﬂow and taint analysis techniques to these traces , we then identify data KA Malware & Attack Technologies | October 2019 Page 212 The Cyber Security Body Of Knowledge www.cybok.org regions containing the bytecode , syntactic information showing how bytecodes are parsed into opcodes and operands , and semantic information about control transfer instructions .
Malware often uses ﬁngerprinting techniques to detect the presence of an analysis environment and evade dynamic analysis ( e.g .
Examples of conditions include the correct date and time , the presence of certain ﬁles or directories , an established connection to the Internet , the absence of a speciﬁc mutex object etc .
If a condition is not true , the malware does not execute the intended malicious logic .
When using standard dynamic analysis , the test inputs are not guaranteed to trigger some of these conditions and , as a result , the corresponding malware behaviours may be missed .
The analyser monitors how the malware code uses condition-like inputs to make control-ﬂow decisions .
For each decision point , the analyser makes a snapshot of the current malware execution state and allows the malware to execute the correct malware path for the given input value ; for example , the input value suggests that the triggering condition is not met and the malware path does not include the intended malicious logic .
The analyser then comes back to the snapshot and rewrites the input value so that the other branch is taken ; for example , now the triggering condition is rewritten to be true , and the malware branch is the intended malicious logic .
6.3.3.2 Identifying the Analysis Environments Malware often uses system and network artifacts that suggest that it is running in an analysis environment rather than a real , infected system [ 605 ] .
In virtualisation ﬁngerprinting , evasive malware tries to detect that it is running in a virtualised environment .
Regarding environment artifacts , virtual machines and emulators have unique hardware and software parameters including device models , registry values , and processes .
In process introspection , malware can check for the presence of speciﬁc programs on operating systems , including monitoring tools provided by anti-virus companies and virtual machine vendors .
These are signals for whether a real human uses the environment for meaningful tasks .
An analysis environment is not transparent if it can be detected by malware .
There are mitigation techniques , some address speciﬁc types of evasion while others more broadly increase transparency .
Binary modiﬁcations can be performed by dynamically removing or rewriting instructions to prevent detection [ 658 ] , and environmental artifacts can be hidden from malware by hooking operating system functions [ 659 ] .
Hypervisorbased approaches [ 618 , 661 ] use introspection tools with greater privilege than malware so that they can be hidden from malware and provide the expected answers to the malware when it checks the system and network artifacts .
6.4.1.1 Finding Malware in a Haystack In order to identify malware , we must ﬁrst have an understanding of how malware is distributed to their victims ’ hosts .
A user on the computer can be socially engineered to open an email attachment or visit a web page , both may lead to an exploit and malware download .
On the other hand , trafﬁc content encrypted as HTTPS is widely and increasingly adopted by websites .
Using domain reputation systems [ 674 ] , network trafﬁc coming from domains and IP addresses known to be associated with malicious activities can be automatically blocked without analysing the trafﬁc ’ s payload .
As a ﬁrst layer of defence , malware detectors can analyse static features that suggest malicious executable contents .
, a detection system misses its presence in the payloads of network trafﬁc or the ﬁlesystem and memory of the end-host , it can still be detected when it executes and , for example , begins contacting its commandand-control ( C & C ) server and performing malicious actions over the Internet or on the victim computer system .
An AV or IDS on the network perimeter continuously monitors network packets travelling out of an end-host .
If the AV or IDS sees that the host is contacting known malicious domain names or IP addresses it can surmise that the host has been infected by malware .
In addition , an AV or IDS on the end-host can look for behaviour patterns that are associated with known malware activities , such as system or API calls that reveal the speciﬁc ﬁles read or written .
KA Malware & Attack Technologies | October 2019 Page 214 The Cyber Security Body Of Knowledge www.cybok.org Evasion and Countermeasures Since Antivirus and IDS solutions can generate signatures for malware executables , malware authors often morph the contents of their malware .
They can change the contents of the executables while generating identically functional copies of their malware ( i.e .
Since its static contents have been changed , the malware can evade an AV or IDS that uses these static features .
On the other hand , the malware can still be detected by an AV or IDS that uses the dynamic features ( i.e .
, signatures of a packing tool , or high entropy due to encryption , can be used to detect and block contents that suggest the presence of packed malware , but this may lead to false alarms because packing can also be used by benign software and services , such as video games , to protect proprietary information .
The most reliable way to detect packed malware is to simply monitor its run-time behaviours because the packed code will be unpacked and executed , and the corresponding malicious behaviours can then be identiﬁed [ 662 ] .
In addition to changing the malware executable , an attacker can also change the contents of its malicious network trafﬁc by using polymorphism to modify payloads so that the same attacks look different across multiple trafﬁc captures .
However , classic polymorphic malware techniques [ 677 ] make the payloads look so different that even a naive IDS can easily differentiate them from benign payloads .
On the other hand , with polymorphic malware blending attacks [ 663 ] malicious payloads can be made to look statistically similar to benign payloads .
Malware authors often implement updating routines , similar to updates for operating systems and applications such as web browsers and ofﬁce tools .
This allows malware authors the ﬂexibility to make changes to the malware to not only include new malicious activities but also evade detection by AVs and IDS that have started using patterns of the old malware and its old behaviours .
6.4.2 Detection of Malware Attacks We have discussed ways to identify static and behaviour patterns of malware , which can then be used to detect instances of the same , or similar malware .
Therefore , we need to go beyond identifying speciﬁc malware instances : we need to detect malicious activities in general .
An anomaly in system or network behaviour is an activity that deviates from normal ( or seen ) behaviour .
Anomaly detection can identify both old and new attacks .
It is important to note that an anomalous behaviour is not the same as a malicious behaviour .
Anomalous behaviours describe behaviours that deviate from the norm , and of course it is possible to have abnormal benign activities occurring on a system or network .
On the other hand , a more efﬁcient and arguably more accurate approach to detect an old attack is to ﬁnd the patterns or signatures of the known attack activities [ 605 ] .
This is often called the misuse detection approach .
Hostbased monitoring systems monitor activities that take place in a host , to determine if the host is compromised .
, temporal characteristics of access patterns of network trafﬁc ﬂows , the domain names the network hosts reach out to , the characteristics of the network packet payloads that cross the network perimeter , etc .
Let us look at several examples of malicious activities and the corresponding detection approaches .
The ﬁrst-generation spam detection systems focused on analysing the email contents to distinguish legitimate messages from spam .
Once a host is identiﬁed to be sending such trafﬁc , it is considered to be participating in a DDoS attack and its trafﬁc is blocked .
That is , each bot no longer needs to send a large amount of trafﬁc .
Correspondingly , DDoS detection involves correlating hosts that send very similar trafﬁc to the victim at the same time .
For ransomware detection , the main approaches include monitoring host activities involved in encryption .
The ‘ signiﬁcant ’ modiﬁcations reﬂect the fact that encrypting a ﬁle will result in its contents changing drastically from its original contents .
being transmitted in network trafﬁc , it is indicative that data are being exﬁltrated ( without the knowledge and consent of the user ) to an attacker ’ s server .
Since many malicious activities are carried out by botnets , it is important to include botnet detection methods .
The beneﬁt of machine learning is its ability to generalise over a population of samples , given various features ( descriptions ) of those samples .
For example , after providing an ML algorithm samples of different malware families for ‘ training ’ , the resultant model is able to classify new , unseen malware as belonging to one of those families [ 669 ] .
Both static and dynamic features of malware and attacks can be employed by ML-based detection models .
An example of success stories in applying machine learning to detect malware and attacks is botnet detection [ 690 ] .
ML techniques were developed to efﬁciently classify domain names as ones produced by Domain Generation Algorithm ( DGA ) , C & C domains , or legitimate domains using features extracted from DNS trafﬁc .
ML techniques have also been developed to identify C & C servers as well as bots in an enterprise network based on features derived from network trafﬁc data [ 668 ] .
A major obstacle in applying ( classical ) machine learning to security is that we must select or even engineer features that are useful in classifying benign and malicious activities .
Feature engineering is very knowledge- and labour- intensive and is the bottleneck in applying ML to any problem domain .
Deep learning has shown some promise in learning from a large amount of data without much feature engineering , and already has great success in applications such as image classiﬁcation [ 691 ] .
However , unlike many classical ML models ( such as decision trees and inductive rules ) that are human-readable , and hence reviewable by security analysts before making deployment decisions , deep learning outputs blackbox models that are not readable and not easily explainable .
It is often not possible to understand what features are being used ( and how ) to arrive at a classiﬁcation decision .
That is , with deep learning , security analysts can no longer check if the output even makes sense from the point-of-view of domain or expert knowledge .
6.4.2.3 Evasion , Countermeasures , and Limitations Attackers are well aware of the detection methods that have been developed , and they are employing evasion techniques to make their attacks hard to detect .
For example , they can limit the volume and intensity of attack activities to stay below the detection threshold , and they can mimic legitimate user behaviours such as sending stolen data ( a small amount at a time ) to a ‘ drop site ’ only when a user is also browsing the Internet .
Every misuse or anomaly detection model is potentially evadable .
It should also come as no surprise that no sooner had researchers begun using ML than attackers started to ﬁnd ways to defeat the ML-based detection models .
One of the most famous attacks is the Mimicry attack on detection models based on system call data [ 670 ] .
The idea is simple : the goal is to morph malicious features to look exactly the same as the benign features , so that the detection models will mistakenly classify the attack as benign .
The Mimicry attack inserts system calls that are inconsequential to the intended malicious actions so that the resultant sequences , while containing system calls for malicious activities , are still legitimate because such sequences exist in benign programs .
An attack payload can be encoded and padded with additional n-grams so that it matches the statistics of benign payloads .
For example , an attacker can insert various no-op features into the attack payload data , which will statistically produce a strong signal for the ML algorithm to select them as ‘ the important , distinguishing features ’ .
As long as such features exist , and as they are under the attacker ’ s control , any ML algorithm can be misled to learn an incorrect detection model .
Noise injection is also known as ‘ data poisoning ’ in the machine learning community .
We can make attacks on ML harder to succeed .
For example , one approach is to squeeze features [ 692 ] so that the feature set is not as obvious to an attacker , and the attacker has a smaller target to hit when creating adversarial samples .
This makes it more difﬁcult for an attacker to simply make small changes to features to ‘ jump ’ across decision boundaries and cause the model to misclassify the sample .
Another interesting approach is to have an ML model forget samples it has learned over time , so that an attacker has to continuously poison every dataset [ 694 ] .
A more general approach is to employ a combination of different ML-based detection models so that defeating all of them simultaneously is very challenging .
, using multiple classiﬁers trained on different feature sets to classify a sample rather than relying on singular classiﬁer and feature set .
This would force an attacker to have to create attacks that can evade each and every classiﬁer and feature set [ 672 ] .
As discussed earlier , deep learning algorithms produce models that can not be easily examined .
But if we do not understand how a detection model really works , we can not foresee how attackers can attempt to defeat it and how we can improve its robustness .
That is , a model that seemingly performs very well on data seen thus far can , in fact , be very easily defeated in the future - we just have no way of knowing .
For example , in image recognition it turned out that some deep learning models focused on high-frequency image signals ( that are not visible to the human eye ) rather than the structural and contextual information of an image ( which is more relevant for identifying an object ) and , as a result , a small change in the high-frequency data is sufﬁcient to cause a mis-classiﬁcation by these models , while to the human eye the image has not changed at all [ 695 ] .
There are promising approaches to improve the ‘ explainability ’ of deep learning models .
For example , an attention model [ 696 ] can highlight locations within an image to show which portions it is focusing on when classifying the image .
Another example is LEMNA [ 697 ] , which generates a small set of interpretable features from an input sample to explain how the sample is classiﬁed , essentially approximating a local area of the complex deep learning decision boundary using a simpler interpretable model .
In both the machine learning and security communities , adversarial machine learning [ 698 ] is and will continue to be a very important and active research area .
What we KA Malware & Attack Technologies | October 2019 Page 218 The Cyber Security Body Of Knowledge www.cybok.org have discussed above are just examples of evasion and poisoning attacks on ML models for security analytics .
These attacks have motivated the development of new machine-learning paradigms that are more robust against adversarial manipulations , and we have discussed here examples of promising approaches .
A misuse detection method which is based on patterns of known attacks is usually not effective against new attacks or even new variants of old attacks .
An anomaly detection method which is based on a normal proﬁle can produce many false alarms because it is often impossible to include all legitimate behaviours in a normal proﬁle .
That is , most machine-learning algorithms assume that the training data and the testing data have the same statistical properties , whereas in reality , user behaviours and network and system conﬁgurations can change after a detection model is deployed .
At the local network access point , we can update corresponding Firewall and Network Intrusion Detection System rules , to prevent and detect future attacks .
It is unfeasible to execute these remediation strategies if the infected machines can not be accessed directly ( e.g .
Takedowns aim to disrupt the malware communication channel , even if the hosts remain infected .
Last but not least , we can perform attack attribution using multiple sources of data to identify the actors behind the attack .
6.5.1 Disruption of Malware Operations There are several types of takedowns to disrupt malware operations .
However , it should be borne in mind that , in most territories active defence or intelligence gathering , such as hack-backs , access to or modiﬁcation of servers , DNS , or networks , is unlawful without appropriate legal authority .
We can also identify DGA domains by mining NXDomains trafﬁc using infected hosts features and domain name characteristic features [ 690 ] , or reverse-engineering the malware to recover the algorithm .
To counter bullet-proof hosting , we need to put legal , political and economic pressures on hosting providers .
Malware has also become increasingly resilient by including contingency plans .
If we hastily conduct botnet takedowns without thoroughly enumerating and verifying all the possible C & C channels , we can fail to actually disrupt the malware operations and risk collateral damage to benign machines .
Then , we use passive DNS data to retrieve related historical IP addresses associated with the seed set .
We remove sinkholing , parking , and cloud hosting provider IP addresses from them to mitigate the collateral damage from the takedowns .
The resulting IPs can also give us related historical domains that have resolved to them .
After following these steps , we have an extended set of domains that are likely to be used by the botnet .
Identifying the virtual attacker is an important ﬁrst step toward this goal .
At the source code level , we can use features that reﬂect programming styles and code quality .
From the enumerated attack infrastructure , we can associate the expanded domain name set with previously known adversaries .
For instance , unknown TDSS/TDL4 botnet ad-fraud C & C domains share the same IP infrastructure with known domains , and they are registered by the same set of email addresses and name servers .
6.5.2.1 Evasion and Countermeasures Many malware authors reuse different kits for the convenience offered by the business model of the underground economy .
Common for-sale kits allow malware authors to easily customise their own malware .
They can also evade attribution by intentionally planting ‘ false ﬂags ’ in malware .
However , WHOIS privacy protection has become ubiquitous and is even offered for free for the ﬁrst year when a user purchases a domain name .
This removes the registration information that could be used for attack attribution .
We need to combine multiple , different streams of data for the analysis .
CONCLUSION Attackers use malware to carry out malicious activities on their behalf .
Malware can reside in any layer of the system stack , and can be a program by itself or embedded in another application or document .
Modern malware comes with a support infrastructure for coordinated attacks and automated updates , and can operate low-and-slow and cover its tracks to avoid detection and attribution .
While malware can cause wide-spread infection and harm on the Internet , it can also be customised for attacks targeting a speciﬁc organisation .
Malware analysis is an important step in understanding malicious behaviours and properly updating our attack prevention and detection systems .
Accordingly , we need to make analysis environments transparent to malware , continue to develop specialised program analysis algorithms and machine-learning based detection techniques , KA Malware & Attack Technologies | October 2019 Page 221 The Cyber Security Body Of Knowledge www.cybok.org and apply a combination of these approaches .
Response to malware attacks goes beyond detection and mitigation , and can include take-down and attribution , but the challenge is enumerating the entire malware infrastructure , and correlating multiple pieces of evidence to avoid false ﬂags planted by the attackers .
Before the Internet revolution , most crime and malicious activity generally required a victim and a perpetrator to come into physical contact , and this limited the reach that malicious parties had .
Technology has removed the need for physical contact to perform many types of crime , and now attackers can reach victims anywhere in the world , as long as they are connected to the Internet .
This has revolutionised the characteristics of crime and warfare , allowing operations that would not have been possible before .
In this document , we provide an overview of the malicious operations that are happening on the Internet today .
We ﬁrst provide a taxonomy of malicious activities based on the attacker ’ s motivations and capabilities , and then move on to the technological and human elements that adversaries require to run a successful operation .
We then discuss a number of frameworks that have been proposed to model malicious operations .
While doing this , we discuss how these frameworks can be used by researchers and practitioners to develop effective mitigations against malicious online operations .
, from the ﬁeld of psychology [ 720 ] ) , we feel that the one presented here works best to illustrate known attackers ’ capabilities and the tools that are needed to set up a successful malicious operation , such as a ﬁnancial malware enterprise .
This characterisation also follows the evolution that cybercrime has followed in recent decades , from an ad-hoc operation carried out by a single offender to a commoditised ecosystem where various specialised actors operate together in an organised fashion [ 721 , 722 ] .
The characterisation presented in this section is driven by case studies and prominent examples covered in the research literature , and as such is not meant to be complete .
However , we believe that the set of crimes and malicious activities presented is comprehensive enough to draw a representative picture of the adversarial behaviours that are occurring in the wild at the time of writing .
We begin by deﬁning two types of cyber offences as they have been deﬁned in the literature , cyber-enabled and cyber-dependent crimes , and we continue by presenting different types of malicious activities that have been covered by researchers .
KA Adversarial Behaviour | October 2019 Page 224 The Cyber Security Body Of Knowledge www.cybok.org Cyber-enabled and cyber-dependent crimes One of the main effects that the Internet has had on malicious activity has been to increase the reach of existing crimes , in terms of the ease of reaching victims , effectively removing the need for physical proximity between the victim and the offender .
Using the Internet , it is easier to ﬁnd and contact victims .
By using the Internet , criminal operations can be run more cheaply .
Sending emails is free , while scammers previously had to pay postage to reach their victims .
This also allows criminals to increase the scale of their operations to sizes that were previously unthinkable .
Compared to their physical counterparts , the Internet allows crimes to be performed faster .
For example , emails can reach victims in a matter of seconds , without having to wait for physical letters to be delivered .
Using the Internet , it is easier to operate across international boundaries , reaching victims located in other countries .
By operating over the Internet , it is more difﬁcult for criminals to get caught .
This is mainly due to the transnational nature of cybercrime , and the fact that the problem of harmonising the appropriate laws of different countries is far from being solved [ 727 ] .
In addition , research shows that online crime is often under reported , both because victims do not know whom to report it to ( given that the offender might be located in another country ) , as well as the fact that they believe that they are unlikely to get their money back [ 728 ] .
Although the ﬁnal goal of this type of crime often has parallels in the physical world ( e.g .
In the rest of this section we analyse a number of cyber-enabled and cyber-dependent criminal schemes in detail .
KA Adversarial Behaviour | October 2019 Page 225 The Cyber Security Body Of Knowledge www.cybok.org Interpersonal offenders The ﬁrst category that we are going to analyse is that of interpersonal crimes .
While these crimes have always existed , the Internet has made the reach of harassers and criminals much longer , effectively removing the need for physical contact for the offence to be committed .
In the rest of this section , we provide an overview of these adversarial behaviours .
Willard [ 712 ] deﬁnes cyberbullying as ‘ sending or posting harmful material or engaging in other forms of social aggression using the Internet or other digital technologies ’ .
This practice has become a serious problem for young people , who are often targeted by their peers not only in real life , but also on online platforms [ 730 ] .
While the practice of bullying is nothing new , the Internet has changed the dynamics of these harassment practices signiﬁcantly .
One aspect that makes cyberbullying different from traditional , physical harassment is that people online can be anonymous , and do not have their name or face attached to the abusive activity that they are carrying out [ 732 , 733 ] .
This disinhibition effect can have the effect of making some people more likely to engage in abusive activity than they would do in the ofﬂine world [ 733 ] .
As such , harassers feel that their actions have no adverse consequences since there will be no hard evidence of it in the future .
This operation is usually part of a larger harassment campaign , where the release of sensitive information is used as a way of embarrassing the victim or facilitating further harassment , even in the physical world ( for example , by releasing information at the workplace or the home address of the victim ) .
The practice of doxing has become increasingly popular in recent years as a way of polarising online discussion and silencing people .
These attacks usually consist of hate speech and other abusive language .
While prominent in the online harassment space , the practice of doxing is also used by other offenders .
For example , it is one of the techniques used by hacktivist groups such as Anonymous to put their targets on notice .
We will discuss the other techniques used by hacktivists , 1 While there is no deﬁnition of cyberbullying in UK law , some forms of it can be prosecuted under the Protection from Harassment Act 1997 .
Another harmful activity that has been facilitated by the Internet is stalking .
Broadly speaking , we can identify two types of cyberstalkers : those who use the information that they ﬁnd online to help them stalk their victim in real life ( e.g .
, monitoring social media to know their whereabouts ) , and those who use the means offered by online services to stalk their victim purely online .
Further , the stalkers who operate online are divided into those who act purely passively , without any interaction with the victim , and those who perform interactions , for example , by sending their messages on a social network platform [ 740 ] .
To counter cyberstalking , legislation has recently been introduced in many countries , including the 2012 Protections of Freedoms act in the UK and the 2000 Violence Against Women Act in the US .
Sextortion is becoming such a relevant threat that crime prevention agencies such as the National Crime Agency ( NCA ) in the UK are launching dedicated awareness campaigns against it.2 Child predation .
Online services are a fertile ground for criminals to ﬁnd victims , whether on chats , online social networks , or online gaming platforms .
Compared to the corresponding ofﬂine offence , online sexual predation has two main differences : ﬁrst , the victim and the perpetrator almost never know each other in real life .
Second , the victim demographics are more skewed towards adolescents than young children , because the age at which kids start going online is slightly higher [ 743 ] .
Offenders use a range of tactics , including pretending to be young people and children in order to groom their victims [ 744 ] and research has shown the potential vulnerability of children of all ages to such online identity deception [ 745 ] .
Other offenders do not interact with children directly , but download and share child pornography on the Internet .
In such cases hands-on abusers often know their victims and disseminate child abuse material to these “ users ” of such material .
Cyber-enabled organized criminals In this section , we focus on cyber-enabled crimes that are carried out by career criminals .
In particular , we provide two prominent examples of cyber-enabled crimes that have received signiﬁcant attention by the research community : advance fee fraud and drug dealing .
These crimes are not usually carried out by single offenders , but rather by multiple criminals who act together in small organisations [ 749 ] or in actual structured criminal organisations [ 750 ] .
We acknowledge that other crimes exist that have seen increased reach because of technology .
However , these crimes have yet to be studied in depth by the research community and , therefore , we decided to focus on the one which the research community has a better understanding of .
In this type of scam , the victim is promised a reward ( ﬁnancial or otherwise ) , but in order to obtain it has to ﬁrst pay a small fee to the fraudster .
After the payment takes place , the victim often does not hear from the scammer again , while sometimes the relationship lasts for long periods of time and the victim is repeatedly defrauded of large sums of money [ 751 ] .
Named after the section of the Nigerian Criminal Code dealing with fraud , these scams became popular in the 1980s , when victims would receive physical letters from an alleged Nigerian prince , looking to transfer large amounts of money outside of the country .
As it can be imagined , the Internet allowed this type of fraud to ﬂourish , by enabling criminals to instantly reach a large number of potential victims .
Another example of advanced fee fraud is consumer fraud perpetrated on classiﬁeds websites such as Craigslist [ 752 ] .
The fraudster responds that they will need a small upfront payment to deliver the goods .
After receiving it , the victim will not hear from the fraudster again .
A ﬁnal example of advanced fee fraud is the online romance fraud .
Taking place on online dating sites , this type of fraud usually consists in criminals posing as attractive individuals looking to start a relationship with the victim .
By that time , the victim , who is likely emotionally involved with the persona impersonated by the criminal , is likely to comply .
Unlike other types of advanced fee fraud , however , the psychological damage of losing the ﬁctional relation can be much greater than the ﬁnancial one .
A common element of every type of advanced fee fraud is the need for criminals to build an enticing narrative that will lure victims into paying the fraudulent fee .
To this end , criminals often target speciﬁc demographics and impersonate speciﬁc personas .
For example , previous research showed that romance fraudsters often pretend to be members of the military stationed abroad [ 753 ] .
By doing so , the fraudsters can build a credible narrative as to why they can not meet the victim in person , and they can build an emotional connection with the victim , which will increase the chances of their falling for the scam .
Often , fraudsters pretend to be widowed middle-aged men who target widowed women in the same demographic , in an attempt to establish an emotional connection with their victim [ 749 ] .
In other cases , fraudsters employ psychological tricks to win their victims over , such as applying time pressure or remarking that they speciﬁcally selected the victim because of their high moral characters [ 713 ] .
More cynically , Herley argues that fraudsters are incentivised to build the most absurd narratives possible , to make sure that only those who are gullible enough to believe them will reply , and that these people will be the most likely to fall for the scam [ 754 ] .
His argument is that responding to the ﬁrst boilerplate message is expensive for the fraudster , while sending the ﬁrst copy to as many victims as they wish is free .
For this reason , it is in their interest to rule out those who are not likely to fall for the scam as soon as possible .
Another category of crimes for which the Internet has offered opportunities KA Adversarial Behaviour | October 2019 Page 228 The Cyber Security Body Of Knowledge www.cybok.org is the drug trade .
Thanks to anonymising technologies such as Tor [ 755 ] and cryptocurrencies [ 756 ] , online marketplaces have emerged where drug users can purchase illicit substances and have them delivered directly to their home .
Online drug markets provide an interesting paradigm switch for drug users , because they remove the need for the buyer to interact with criminals in a physical and potentially unsafe setting .
Recent work has shown , however , that the inception of the online drug market has not changed the worldwide drug trade ecosystem : the big players who produce and dispatch drugs remain broadly unchanged , while what has changed is the ‘ last mile ’ in the delivery ( i.e .
Unlike the cyber-enabled crimes described in the previous section , where the criminal is essentially replicating a physical criminal operation and using the Internet to enhance his/her reach , in the case of cyber-dependent crimes criminals have to set up complex technological infrastructures to achieve their goals .
, infecting computers with malware or performing money laundering ) and works together towards achieving a common goal .
In this section , we provide some examples of cyberdependent crimes that have been studied by the research literature in recent years .
Then , in Section 7.2 , we cover in detail the various elements that criminals need to put in place to make their operations successful .
Email spam has been a major nuisance for Internet users for the past two decades , but it has also been at the forefront of very successful criminal operations , who have managed to monetise the sale of counterfeit goods and pharmaceuticals by reaching billions of potential customers through malicious messages [ 759 ] .
Email spam is deﬁned as unsolicited bulk email ; this deﬁnition highlights the two main elements of the problem : the fact that the messages received by victims are unsolicited ( i.e .
, they were not requested in the ﬁrst place ) , and that they are sent in bulk to reach as many victims as possible .
The goal of these operations was to sell goods online , which could span from diet supplements to Nazi memorabilia [ 761 ] .
Although they were still rudimentary compared to the spam operations that came during the next decade , these criminal endeavours prompted the development of legislation to regulate unsolicited bulk emails , such as the Directive on Privacy and Electronic Communications in the EU,3 the Privacy and Electronic Communications Regulations in the 3 https : //eur-lex.europa.eu/legal-content/EN/ALL/ ?
The technical advancements of the early 2000s , and in particular the development of botnets , networks of compromised computers controlled by the same cybercriminal [ 758 ] , gave unprecedented opportunities to criminals who want to engage in email spam today .
Currently , anti-spam techniques ensure that the vast majority of malicious emails will never reach their victims ’ mailboxes .
To solve this issue , criminals have to send tens of billions of emails [ 723 ] to keep their operations proﬁtable .
Another issue is that , out of the victims reached by those spam emails that make it through , only a small fraction will purchase the advertised goods and turn a proﬁt for the criminals .
Of these , only 0.005 % of the users click on the links contained in the emails , while an even lower number ends up purchasing items - only 28 users in total out of the 469 million reached , or 0.0004 % of the total .
They also showed that key to this success are returning customers .
In fact , spam emails need to reach an interested customer only once , and this person can later keep purchasing on the site without having to worry about spam ﬁlters .
These emails typically lure users into handing out their usernames and passwords to these services by presenting them with a believable email asking them to visit the website ( e.g .
By clicking on the link in the email , users are directed to a website displaying fake but realistic login pages .
Once they have input their credentials , the criminals gain access to them and they will be able to later log in to those services on behalf of the users , potentially making money directly or selling the credentials on the black market .
For the criminal , a key component to the success of phishing pages is setting up web pages that resemble the original ones as much as possible .
These kits typically also provide functionalities to make it easier for the criminal to collect and keep track of the stolen credentials [ 766 ] .
Another element needed by criminals to host these pages is servers under their control .
Similar to spam , criminals , researchers , and practitioners are involved in an arms race to identify and blacklist phishing Web pages [ 767 ] , therefore it does not make economic sense for criminals to set up their own servers .
Previous research has shown that often these criminals log into the accounts themselves and spend time evaluating their value , for example , by looking for ﬁnancial information in webmail accounts .
Another popular criminal operation is ﬁnancial malware .
In this setting , criminals aim to install malware on their victims ’ computers and steal ﬁnancial credentials such as credit card numbers and online banking usernames and passwords .
This trend started with the Zeus malware , which criminals could purchase on the black market and use to set up their operations [ 770 ] .
Once installed on a victim computer , Zeus would wait for the user to visit a website on a pre-conﬁgured list of interesting ones that the criminal could specify .
It would then record usernames and passwords as the user typed them in , and send them to the command and control server set up by the criminal .
Unlike Zeus , Torpig used a botnet-as-a-service model , where a single specialised criminal was responsible for hosting the botnet infrastructure , while other criminals could run their campaigns to infect victim computers , pay a fee to use the torpig infrastructure and later retrieve the stolen credentials .
The price that criminals can ask for these credentials varies based on the type of records that they were able to steal .
For example , on the underground market there are two types of credit card records that are traded : dumpz , which contain the information that allows a criminal to clone a credit card ( i.e .
Fullz are worth more money on the black market , because they allow miscreants to purchase items online .
In this cyberenabled crime , criminals install devices on ATM machines which collect details of the cards inserted into the machines by unwitting users .
The criminal can then collect the devices to retrieve the stolen ﬁnancial credentials .
While this type of crime is serious , it is also a good example of the limitations of physical crime compared to their online counterparts : the need for physical action by the criminal limits the scale of the operation , while ﬁnancial malware operations can affect much higher numbers of victims .
Note that malware is not always needed to perform ﬁnancial fraud .
In other cases , stolen SWIFT credential of banks can be used to perform large fraudulent money transfers [ 776 ] Click fraud .
Web advertisements are the main way the Web is monetised .
A Web administrator can decide to host advertisements on his/her website , and whenever visitors view them or click on them they receive a small fee from an advertiser .
To mediate this interaction , specialised services known as ad exchanges have emerged .
Because of their easy monetisation , Web advertisements are ripe for fraud .
This results in an ad KA Adversarial Behaviour | October 2019 Page 231 The Cyber Security Body Of Knowledge www.cybok.org exchange paying criminals for ad impressions that were not ‘ genuine , ’ eventually defrauding the advertiser .
Once again , criminals are involved in an arms race with ad exchanges , who are interested in keeping fraud on their services minimal .
To help criminals generate large numbers of clicks and remain under the radar by gaining access from large numbers of IP addresses , so-called click fraud botnets have emerged .
On an infected machine , this malware would act like a regular user , browsing websites and clicking on advertisements that its owner chose .
Researchers showed that this botnet was responsible for losses to the advertising industry of approximately 100,000 USD per day [ 16 ] .
With the increasing popularity of cryptocurrencies , a new opportunity has opened up for criminals : using infected computers to mine currency .
While revealing this new monetisation for malware , the authors also concluded that these operations did not appear to be making much money , totaling at most 900 USD a day .
A more recent study , however , showed that cryptocurrency mining by botnets could be much more rewarding than previously thought .
Another emerging trend in cybercrime comprises leveraging Web browsers to mine cryptocurrencies .
Instead of installing malware on victim computers and using them for mining , miscreants add scripts to webpages and have their visitors mine cryptocurrencies .
This type of malicious activity is called cryptojacking .
, Web administrators can legitimately install them on their webpages in a similar way to advertisements ) , criminals have been caught adding them to compromised websites on multiple occasions .
The newest trend in malware is Ransomware .
The idea of malicious software that uses public key cryptography to hold the victim ’ s data hostage is not new , and it was theorised by Yung in 1996 already [ 781 ] .
In 20 years , however , the technological advancements on the malware delivery end have made it possible to reach large numbers of victims , and the introduction of anonymous payment methods such as Bitcoin has made it safer for criminals to collect these payments .
Ransomware is , at the time of writing , the gold standard for cybercriminals .
This type of malware operation has solved the monetisation problems that were so important in other types of cybercriminal schemes : the criminal does not have to convince the victim to purchase a good , like in the case of email spam , or to fall for a fraud , like in the case of phishing .
In addition , the victim is highly incentivised to pay the ransom , because the probability that the criminals have encrypted ﬁles that the user will need ( and for which they have no backup copy ) is high .
In fact , recent research was able to trace 16 million USD in payments on the Bitcoin blockchain that can be attributed to ransomware campaigns [ 782 ] .
showed that it is not uncommon for malware authors to use other techniques KA Adversarial Behaviour | October 2019 Page 232 The Cyber Security Body Of Knowledge www.cybok.org to lock the victim out of his/her computer [ 783 ] .
These techniques include setting up a password-protected bootloader and not giving the password to the user unless he/she pays .
While these techniques are likely to yield a proﬁt for the criminal , they are also easier to mitigate , as the victim ’ s ﬁles are safe on the computer and a simple clean up of the malware ( and restoring the original master boot record ) can ﬁx the problem .
The criminals can then set up services where they offer DDoS for hire .
These services are appealing for example to unscrupulous actors who want their business competitors to go ofﬂine or to online gamers who want to knock their opponents off the Internet to win the game [ 784 ] .
To hide the illicit nature of their business , these services often advertise themselves as ‘ stress testers ’ , services that a Web administrator can use to test how their Web applications perform under stress [ 784 ] .
In reality , however , these services do not check whether the customer purchasing a DDoS attack is actually the same person who owns the target domain .
Hacktivists While criminals driven by proﬁt are a big threat , not all adversaries are driven by money .
studied cyber attacks carried out by far left groups in the US and found that there was an increase in online attacks during periods that observed a decrease in physical violence from those same groups [ 787 ] .
As part of this practice , Internet users would connect to target the websites simultaneously to deplete their resources and make them unresponsive .
This was often done to protest against actions and policies by government agencies and corporations .
Twenty years later , with the increased sophistication offered by technology , hacktivist groups such as Anonymous [ 789 ] took the idea of netstrikes and made it bigger in size .
This collective became popular for launching denial of service attacks against organisations that were guilty of performing actions that did not match their moral stance , such as governments linked to the repression of the Arab Spring , credit card companies who would not make donations to entities such as Wikileaks or radical religious organisations .
The difference with traditional botnets ( and the ones used to carry out DDoS attacks in particular ) is that the user is accepted to be part of it by installing the LOIC program , and suffered law enforcement action as a consequence .
Another trend that we have been observing in recent years in the area of hack- KA Adversarial Behaviour | October 2019 Page 233 The Cyber Security Body Of Knowledge www.cybok.org tivism is the release of stolen documents into the public domain , for example , to raise awareness about secret surveillance programs by governments [ 790 ] .
As part of this activity , miscreants exploit vulnerabilities ( ranging from weak passwords to software vulnerabilities ) in the websites of organisations they disagree with , and use them to change the home page of the website to a politically-charged one .
An example of an organisation that is prominently using Web defacements to spread their message is the Syrian Electronic Army [ 792 ] , a group of hackers close to the Assad regime .
Although popular with criminals with a political agenda , Web defacement is not just their prerogative .
State actors Another type of malicious actor involved in adversarial behaviours online comprises nation states .
In the past few years , we have observed an escalation in the use of computer attacks by state actors to achieve their goals .
Broadly speaking , this type of attack differs from those performed by ﬁnancially motivated cybercriminals for two reasons : 1 .
Commodity cybercrime needs to gather as many victims as possible to maximise their proﬁts .
For instance , criminals setting up a botnet to steal ﬁnancial information from their victims will want to reach the highest possible number of victims to improve their revenue .
In this setting , the attack can be tailored to the victim ; this increases the chances of success , because of the time that can be spent designing the attack and the fact that the attack will be unique ( e.g .
Because of the need to make money , traditional cybercriminals need their attacks to be fast .
, stealing sensitive information from a government ) makes it acceptable to wait for long periods of time before ﬁnalising the attack .
In the following , we describe these three types of attacks in more detail .
Modern critical infrastructure can be disrupted by electronic means .
Research has shown that it is not uncommon for critical facilities such as power plants to have some sort of network connectivity between the computers controlling the machinery and the ones connected to the Internet [ 795 ] .
In the case of a state adversary , even having network security appliances to guard the boundary between the two networks is not enough , since , as we said , attacks can be so sophisticated and tailored that off-the shelf solutions fail to detect them [ 718 ] .
Once a piece of malware manages to get into the control network , it could make the machinery malfunction and potentially destroy it .
Even when there is a physical separation KA Adversarial Behaviour | October 2019 Page 234 The Cyber Security Body Of Knowledge www.cybok.org between the control network and the wider Internet , attacks are still possible when we are faced with adversaries with virtually unlimited resources [ 718 ] .
Allegedly , the malware was introduced into the facility by ﬁrst infecting the laptop of one of the consultants who was maintaining the machinery .
Once the malware was in the right environment , it identiﬁed the pieces of equipment that it was designed to target and sabotaged the enrichment experiments , making the centrifuges spin out of control .
To date , Stuxnet is a textbook example of the lengths to which state-sponsored attackers can go to achieve their objectives , and of the sophistication that their attacks can achieve .
Sabotage is not always linked to state actors .
Major incidents have been caused by disgruntled employees of companies who acted as insider threats , like in the case of the Maroochy Water Services [ 797 ] .
In this incident an insider whose employment had not been conﬁrmed decided to get revenge on the company by spilling sewage , causing major environmental damage [ 797 ] .
Another goal that state-sponsored actors have for their attacks is spying on opponents and prominent adversaries .
This has been done through troll accounts that acted to polarise online discussion on sensitive topics [ 803 ] .
While social networks such as Twitter have made data about accounts related to state-sponsored disinformation publicly available [ 719 , 800 ] , rigorous evidence is still missing on how these operations are carried out on the backend .
For example , the extent in which the accounts involved in disinformation are controlled by human operators as opposed to bots is not clear .
First , the criminal needs these operations to be as cost effective as possible ( and consequently make the highest possible proﬁt ) .
Second , multiple actors ( law enforcement , security companies , the users themselves ) are constantly attempting to take down these malicious operations , and the criminal has , therefore , a need to make them resilient to these takedown attempts .
To ensure that the criminals ’ needs are met in this scenario , in recent years we have witnessed a specialisation in the cybercriminal ecosystem , where different actors specialise in a speciﬁc element required for the operation to succeed ; the miscreants then trade these services with each other on the black market .
Many of the elements discussed , however , also apply to the other types of adversarial behaviours described in that section .
Afﬁliate Programmes The main goal of organised crime is to make money from their operations .
This requires not only a well-oiled technical infrastructure to make sure that their botnets operate properly but , perhaps more importantly , a working method to collect payments from victims ( or from sponsors , in the case of DoS ) , while making sure that all the actors involved in the operation get paid .
In the cybercriminal world , this is typically done through afﬁliate programmes .
An afﬁliate programme is a scheme where main organisation provides a ‘ brand ’ and all the means required to carry out orders , shipments and payments .
Afﬁliates can join the program , direct trafﬁc to the platform , and get a cut of the sales that they are responsible for .
The main difference between legitimate and criminal afﬁliate programmes is that the second category of operations typically deals with products that are considered illegal in most jurisdictions ( e.g .
Afﬁliate programmes are popular in the cybercriminal world because they mean afﬁliates do not have to set up their operations from start to ﬁnish , but rather focus on attracting trafﬁc , for example by setting up botnets and sending email spam advertising the afﬁliate marketplace .
However , afﬁliate programmes are present in most types of cyber-dependent crime , an example being the Cryptowall ransomware operation.6 In addition to providing the monetisation necessary for cybercriminal operations , afﬁliate programmes also act as facilitators for criminals to get in contact and trade the services that are needed for the operation to succeed .
Gaining access to these forums typically requires vetting by the afﬁliate programme administrators .
Infection vectors As discussed earlier , the ﬁrst step required by criminals to perform a malicious activity is often infecting their victims with malware .
To this end , the criminals need to ﬁrst expose their potential victims to the malicious content , and then have them install it on their machines ( through either deception or by exploiting a software vulnerability in their system ) .
In the following , we survey three popular methods on delivering malware to victim computers .
Note that , while other infection vectors are possible , such as physical access to a network or hijacking a wireless network , to date we are not aware of any large-scale compromise involving these infection vectors , and therefore we do not focus on them .
Possibly the oldest method of delivering malware is attaching malicious software to spam emails , disguising it as useful content that the user might want to open .
In the commoditised economy described previously , it is often the case that a criminal who wants to spread a malware infection pays another criminal who already has control of a botnet to deliver the payloads [ 716 ] .
To be successful , the content used for this infection vector needs to convince the user to click on the attachment and install it .
To this end , criminals often use deception techniques to make the content look interesting and appealing , similar to the techniques discussed for phishing [ 715 ] .
Search Engine Optimization ( SEO ) is a popular practice whereby webmasters optimise their content so that it is better indexed by search engines and appears among the ﬁrst hits for relevant searches .
Cybercriminals are also interested in having their malicious Web pages appear high in search results , because this increases the chances that potential victims will ﬁnd them and click on them .
To accomplish this , specialised criminals offer black hat SEO services .
As a result of these services , malicious websites are pushed high up in search engine rankings for keywords that are unrelated to the website [ 813 ] .
, sports and political events ) , because people will be more likely to search for keywords related to the event .
To achieve effective black hat SEO , cybercriminals compromise vulnerable websites and use them to promote their customers ’ webpages ( e.g .
Although deceptively luring users into installing malware works , having an automated method that does not require human interaction is more advantageous for cybercriminals .
The webpage contains malicious JavaScript code that will attempt to exploit a vulnerability in the user ’ s Web browser or in one of its plugins .
If successful , the Web browser will be instructed to automatically download and install the malware .
An alternative trend is purchasing Web advertisement space and serving the malicious content as part of the ad , in a practice known as malvertisement [ 815 ] .
, Internet of Things ( IoT ) devices ) , an additional opportunity provided to attackers is scanning the Internet for devices that present known vulnerabilities and exploit them to build large botnets .
Infrastructure Another important element that criminals need for their operations to succeed is where to host their infrastructure .
, where to host fraudulent shopping websites ) as well as for botnet operations .
Law enforcement and Internet Service Providers ( ISPs ) are continuously monitoring servers for evidence of malicious activity [ 806 ] , and will take them down if this activity can be conﬁrmed , which would put the criminal operation in jeopardy .
These providers are well known not to comply with law enforcement takedown requests .
KA Adversarial Behaviour | October 2019 Page 237 The Cyber Security Body Of Knowledge www.cybok.org This is made possible by either being located in countries with lax cybercrime legislation , or by the service provider operators actively bribing local law enforcement [ 759 ] .
Bulletproof hosting service providers typically charge their customers more money than a regular ISP would .
As such , they become a hotspot of illicit activity , since malicious users congregate there because of their guarantees , but legitimate users have no incentive to use them .
Despite providing higher guarantees for cybercriminals , bulletproof hosting service providers are not invincible to takedown efforts .
In particular , ISPs need to be connected to each other to be able to route trafﬁc , and an ISP that is uniquely hosting malicious content could be disconnected by the other providers without many consequences for legitimate Internet trafﬁc [ 759 ] .
Even assuming that the server was hosted by a bulletproof hosting provider , and could not therefore be taken down , the fact that the server had a unique IP address meant that it could easily be blacklisted by security companies .
To mitigate this problem , cybercriminals came up with C & C infrastructures that are redundant and more difﬁcult to take down .
This infrastructure makes the botnet more resilient , because even if some of the relays are taken down , the central C & C is still operational and additional relays can be added .
In addition , the infected computers never see the IP address of the central C & C server , making it more difﬁcult to locate and take down .
This infrastructure increases the ﬂexibility that the criminal has and reduces the cost of the operation , because the criminal does not have to spend money to install relays .
However , the botnet infrastructure becomes vulnerable to inﬁltration , whereby researchers can create fake bots , be elected as relays and are thus suddenly able to monitor and modify the trafﬁc coming from the central C & C [ 17 ] .
Both methods are effective in making the operation more resilient , but they also make the operation more expensive for the criminal to run ( i.e .
KA Adversarial Behaviour | October 2019 Page 238 The Cyber Security Body Of Knowledge www.cybok.org Specialised services In this section , we describe specialised services that help criminals to set up their operations .
In the previous section , we saw that drive-by download attacks are a powerful weapon that a cybercriminal can use to infect computers with malware without any human interaction .
The problem with effectively performing these attacks , however , is that they require an exploit to a software vulnerability in the victim ’ s system .
Since cybercriminals want to infect as many victims as possible , it is challenging to ﬁnd an exploit that can work on the systems of the majority of potential victims .
In addition to this issue , exploits do not age well , since software vendors routinely patch the vulnerabilities that they know about .
It then delivers the exploit to the victim .
These issues have created an opportunity for specialised criminals to provide services for the rest of the community .
This has led to the creation of exploit kits [ 807 ] , which are tools that collect a large number of vulnerabilities and are sold on the black market for other criminals to use .
An exploit kit is typically accessible as a Web application .
Customers can point their victims towards it by compromising websites or using malicious advertisements .
Infecting victim computers and maintaining a botnet is a complex task , and research has shown that malware operators who attempt to do so without the proper expertise struggle to make proﬁts [ 821 ] .
PPI operators are proﬁcient in setting up a botnet and having it run properly .
Other criminals can then pay the PPI operator to install malware on the infected computers on their behalf .
PPI services typically offer a good level of choice granularity to their customers , who not only choose how many infections they want to install , but also their geographical location ( with bots in developed countries costing more than infections in developing ones [ 808 ] ) .
An advantage of using PPI services is that they make their customers ’ cybercriminal operations more resilient : if their malware stops working , for example , because law enforcement has taken down the C & C servers that it uses , the criminal can resume operations by asking the PPI operator to install an updated version of their malware on the victim machines .
KA Adversarial Behaviour | October 2019 Page 239 The Cyber Security Body Of Knowledge www.cybok.org Human services In this section , we discuss the auxiliary services that are needed for an end-to-end cybercriminal operation to succeed .
Although these elements are not usually thought to be part of cybercrime , they are as important to the success of a cybercriminal operation as the more technical elements .
To protect themselves against large-scale automated account creation , however , online services widely use CAPTCHAs , which are notoriously difﬁcult for automated programs to solve .
These services take advantage of crowdsourced workers .
Once the CAPTCHA solving customer encounters a CAPTCHA , this is forwarded by the service to one of these workers , who will solve it .
This way , the customer can proceed and create the account on the online service .
In other cases , online services require whoever has created an online account to receive a code texted to a phone number and issue that code back to the service .
Since creating fake accounts is time consuming and requires the use of auxiliary services such as CAPTCHA solvers , cybercriminals have started specialising in the creation of fake accounts on multiple online services , and selling them on the black market [ 823 ] .
Accounts on different services can have different prices , depending on the ease of creating new accounts on the platform and on how aggressively the service suspends suspected fake accounts .
A problem with newly purchased fake accounts is that they do not have an established ‘ repuation ’ on the social network , thus reducing their credibility to potential victims and their reach in spreading malicious messages .
This can be mitigated by using ‘ reputation boosting ’ services , which help to build a network of contacts for accounts that otherwise would not have any .
In some cases , cybercriminals need to set up fake content to send to their victims , whether this is for spam emails , fake websites used for black hat SEO or online social network sites .
The main goal of many cybercriminal operations is to make money from their victims .
However , extracting money from an operation is not easy .
In the case of bank fraud , for example , even if the criminals obtain access to the victim ’ s bank account , they still need to transfer money to accounts under their control without being detected and apprehended .
These are people who are recruited by criminals to perform money laundering operations and make it more difﬁcult for law enforcement to track the money obtained from an illicit operation .
The mule is also told that they can keep a percentage of the amount as a payment .
Since these untraceable transactions need to be carried out in KA Adversarial Behaviour | October 2019 Page 240 The Cyber Security Body Of Knowledge www.cybok.org person by the mule , they constitute a weak point in the monetisation operation , meaning that law enforcement could identify and arrest the mule before the money is transferred .
In fact , even if stolen money is never mentioned , the mule is participating in money laundering when he/she accepts this job .
The mule is then instructed to open the packages and reship the goods to a foreign address , where they will be sold on the black market .
Payment methods As criminals need to have money transferred to them , they can use a number of different payment methods , each carrying a different level of risk and being more or less familiar to the victims .
Most transactions online are performed by credit cards .
To collect as many customers as possible , cybercriminals tend to accept credit card payments too .
Credit card processors keep track of the chargebacks that a company has on its accounts , and too many complaints from customers usually result in the company ’ s accounts being terminated .
A challenge that cybercriminals face is ﬁnding banks that are willing to process their payments .
Despite these increased fees , it is not guaranteed that the criminal operation will be safe : similar to what happens with bulletproof hosting ISPs , banks need to maintain good relations with their peers , otherwise they will be disconnected from the ﬁnancial network [ 804 ] .
Another payment method that is familiar to users is Paypal .
For this reason , Paypal is often accepted by criminals offering illicit services .
While user friendly , criminals face the issue that the platform is centralised , and Paypal can keep track of fraudulent payments and terminate the accounts that are found to be in breach of the terms of service [ 813 ] .
Other forms of payment offer more anonymity for cybercriminals , and are less risky as well as being not as well regulated .
To cash the money , these services only require a unique code and an identiﬁcation document .
Depending on the country where the criminal is located , however , the ID requirement might not be very rigorous .
These virtual currencies allowed criminals to easily make payments as they took advantage of the loose regulations in their country of origin ( e.g .
After crackdowns on these payment methods by law enforcement , KA Adversarial Behaviour | October 2019 Page 241 The Cyber Security Body Of Knowledge www.cybok.org 15 Break Into Server Exploit Vulnerability Develop Exploit Purchase Exploit Steal Password Install Keylogger Guess Password Extort From Owner Figure 7.1 : Example of an attack tree describing the action of breaking into a server .
criminals moved to other payment methods .
At the time of writing , probably the safest form of payment for cybercriminals is cryptocurrencies .
While more anonymous than other payment methods , research has shown that payments made in Bitcoin can be traced [ 810 ] .
In addition , often cryptocurrencies need to be converted into real money by criminals , and the money ceases to be anonymous at that point .
Additional concerns arise from the risks involved in making payments on cryptocurrency exchanges .
showed that it is not uncommon for Bitcoin exchanges to suffer breaches that result in losses of currency [ 829 ] .
It is , therefore , necessary for defenders to have the appropriate means to understand these operations , so that they can develop the best countermeasures .
In the following , we survey a number of models that have been proposed to model malicious operations .
These models come from a number of research areas , including computer security , criminology and war studies .
Note that for space reasons we can not discuss all the techniques that have been proposed in the literature to model attacks .
In an attack tree , the root node is the goal of the attack , and its child nodes are the ways an attacker can achieve that goal .
Going down the tree , each node becomes a sub-goal that is needed for the KA Adversarial Behaviour | October 2019 Page 242 The Cyber Security Body Of Knowledge www.cybok.org attack to succeed , and its children are possible ways to achieve it .
To do this , they have two choices : they can either exploit a vulnerability or they can obtain the password to the root account and log in using normal means .
To exploit a vulnerability , they can either develop the exploit themselves or purchase an already existing one , perhaps through an exploit kit .
If the attackers decide to use the account ’ s password to log into the server , they ﬁrst need to obtain it .
To do this , they can either install malware on the server administrator ’ s computer to log the password as they input it ( i.e .
The attack graph could then be further reﬁned with the possible ways the attacker could perform these actions ( e.g .
‘ And ’ nodes , on the other hand , represent the different steps that all need to be completed to achieve the goal .
Once the tree has been created , security analysts can annotate it to assess the system ’ s risk to the attack , for example , by marking the various attack strategies as feasible or unfeasible , by assigning likelihood scores to them or by estimating the cost for an attacker to perform a certain action .
The scores can then be propagated along the tree following speciﬁc rules [ 79 ] to assess the overall feasibility and likelihood of the attack .
While attack trees are limited to single targets , attack graphs allow to model attack actors , vectors , vulnerabilities , and assets .
Kill chains Another useful tool that can be used to model and understand attacks is kill chains .
In the military context , a kill chain is a model that identiﬁes the various phases involved in an attack.7 In the computer world , Hutchins et al .
The model is designed for operations where the attacker identiﬁes , compromises and later exploits a computer system , and , therefore , not all the phases apply to all the adversarial behaviours discussed in this document .
This phase could comprise an attacker scanning the network looking for vulnerable servers or a spammer purchasing a list of victim email addresses on the black market .
Weaponisation , when an attacker prepares the attack payload for use .
This could consist in developing a software exploit against a newly identiﬁed vulnerability or crafting an advance-fee-fraud email .
Delivery , when the attacker transmits the payload to its victim .
This could consist in setting up a malicious webserver , purchasing advertisement space to perform a malvertising attack or sending an email containing a malicious attachment .
This phase could entail a driveby download attack , or the victim being lured into clicking on a malicious attachment through deception .
Installation , when malicious software is downloaded , thus allowing the attacker to beneﬁt from the victim machine .
For each of the seven steps , Hutchins et al .
Examples of these techniques include patching vulnerabilities , setting up intrusion detection systems on the network or deceiving the attacker by setting up honeypots [ 840 ] .
Similar kill chains have been proposed by other researchers over the years .
An example is the one proposed by Gu et al .
While this model correctly depicted early botnets , it ceased to map reality when botmasters started using other methods to install their malware and monetise their infections .
This example shows that it is difﬁcult to develop models of attacker behaviour that are resilient to changes in the modus operandi of attackers .
Environmental criminology While cybercrime is a relatively new threat , physical crime has been studied by scholars for decades .
It is , therefore , interesting to investigate whether this established body of knowledge can be applied to better understand and mitigate the emerging threat of online crime .
A particular challenge that arises when we attempt to apply environmental criminology theory to cybercrime is that the concept of ‘ place ’ on the Internet is not as well deﬁned as in the real world .
In the following , we brieﬂy review the key concepts of environmental criminology , and provide some examples of how they could be applied to mitigating Internet crime .
Routine activity theory is a commonly used concept in environmental criminology , postulating that the occurrence of crime is mostly inﬂuenced by an immediate opportunity for one to commit a crime [ 843 ] .
KA Adversarial Behaviour | October 2019 Page 244 The Cyber Security Body Of Knowledge www.cybok.org These concepts could be useful for better modelling malicious activity online .
For example , research has shown that botnet activity reaches a peak during daytime , when most vulnerable computers are switched on and the victims are using them , while it drops signiﬁcantly overnight [ 716 ] .
In routine activity theory terms , this can be translated to the fact that when more potential victims are online , the opportunity for criminals to infect them increases and this results in an increase in botnet activity .
In the case of cybercrime , this model could be useful for understanding the reaction of criminals to mitigation as a rational choice , and help to model the implementation issues introduced by situational crime prevention such as displacement .
For example , when a bulletproof hosting provider is taken down by law enforcement , what factors play a part in the criminal ’ s choice of the next provider ?
Another theory , called the pattern theory of crime , allows researchers to identify various places that are related to crime .
These places are likely to attract offenders ( crime attractors ) , they generate crime by the availability of crime opportunities ( crime generators ) and they enable crime by the absence of place managers ( crime enablers ) .
Although deﬁning places in cyberspace is not as straightforward as in physical space , thinking in terms of pattern theory can help identify locations that are hotspots for cybercrime , whether they are particularly appealing targets , such as corporations storing sensitive data ( attractors ) , poorly conﬁgured systems that are easier to compromise ( generators ) or online services with poor hygiene that do not react promptly to spam/malware posted on their platforms ( enablers ) .
Identifying these hotspots can then be used to design appropriate countermeasures against the malicious activity ( e.g .
Situational crime prevention comprises a set of theories and techniques that aim to reduce crime by reducing the opportunities for crime [ 845 ] .
The ideas behind situational crime prevention are based on three main concepts , which also apply to cybercrime : • Crime is much more likely to happen in certain places ( hotspots ) .
This idea applies to the context of cybercrime .
As we have seen , criminals tend to concentrate their malicious servers in bulletproof hosting service providers , which provide them with guarantees that their operations can continue for long periods of time .
At the opposite end of the spectrum , regarding victims , criminals tend to target computers with vulnerable software conﬁgurations , which also constitute hotspots in this acception .
• Repeat victims are more likely to experience crime compared to other people .
In the context of cybercrime , the same concept applies .
Similarly , in the case of advance fee fraud , victims are likely to repeatedly fall for the fraud , because the narrative used by the criminals particularly resonates with them [ 751 ] .
In addition to the natural predisposition of victims to fall for similar scams again , criminals actively seek to contact past victims of fraud , by compiling so-called suckers lists and sharing them with each other [ 846 ] .
To reduce the opportunities for crime , situational crime prevention proposes ﬁve categories of mitigations .
In the following , we list them along with some examples of mitigations against KA Adversarial Behaviour | October 2019 Page 245 The Cyber Security Body Of Knowledge www.cybok.org cybercrime that have been proposed in the computer science literature and that can be grouped into these categories : • Increase the effort of crime .
Mitigations here include deploying ﬁrewalls and setting up automated updates for software installed on computers .
Mitigations here include blocking supicious payments or parcels , or penalising malicious search results .
Examples here include applying peer pressure to rogue ISPs and banks .
Typical mitigations in this category include running education campaigns or setting up automated redirects to divert victims who would have viewed malicious content , explain to them what happened and urge them to secure their systems .
An interesting aspect of the situational crime prevention framework is that it identiﬁes , for each mitigation , the implementation issues that arise when putting the mitigation in place [ 845 ] .
In the case of cybercrime , the two implementation issues that are most relevant are adaptation and displacement .
Adaptation embodies the fact that criminals will actively attempt to circumvent any mitigation by making their operation stealthier or more sophisticated .
This is a typical arms race that can be observed in computer security research .
When researchers started compiling blacklists of IP addresses known to belong to C & C servers , criminals reacted by developing Fast Flux .
When making payments through traditional means became more difﬁcult due to increased vetting , criminals moved on to cryptocurrencies .
Considering adaptation is important when designing mitigations against cybercrime .
Displacement represents the fact that once mitigations are put in place , criminals can simply move their operations elsewhere .
While in the physical world how far criminals can travel is dictated by practical constraints , on the Internet moving from one ‘ place ’ to another is virtually free .
Examples of displacement include criminals starting to register DNS domains with another registrar after their preferred one increased the domain price to curb misuse [ 847 ] , or a multitude of drug markets opening to ﬁll the gap left by Silk Road ’ s takedown [ 714 ] .
Displacement effects are important when planning action against cybercrime .
Generally speaking , a mitigation should make it difﬁcult for criminals to move elsewhere .
Conversely , a mitigating action that simply displaces a cybercriminal operation without affecting its effectiveness is probably not worth pursuing .
Following the discussion in this section , however , this framework could be applied to any criminal activity that happens online .
Another useful technique that can aid the analysis of malicious activities on the Internet from the ﬁeld of criminology is crime scripting [ 848 ] .
As part of this technique , researchers extrapolate the sequence of steps performed by an adversary to commit their offences .
Dissecting the various steps of an offence can be useful to better understand it and to identify potential interventions .
Crime scripting is somewhat related to kill chains , although the two techniques were developed in completely independent areas .
Modelling the underground economy as a ﬂow of capital As discussed in Section 7.1 , many malicious operations are performed by criminals with the goal of making money from their victims .
For this reason , following the ﬂow of money is a useful way to better understand malicious operations , and in particular identify bottlenecks that could be leveraged to develop mitigations against them and stop criminals [ 804 , 849 ] .
As part of this model , they introduced two elements that are needed for a cybercrime operation to run : proﬁt centres , through which victims transfer new capital into the criminal operation , and support centres , which can facilitate the criminal operation by providing several services for a fee .
Money is introduced into the ecosystem through proﬁt centres , and is then consumed by the various actors involved in it , who provide tools and services for each other .
As an example , in an email spam operation , the proﬁt centre would be victims purchasing counterfeit pharmaceuticals from an afﬁliate programme , while all the services needed by the spammers to operate ( e.g .
This model provides an interesting conceptualisation of how money ﬂows into the cybercriminal ecosystem and how wealth is divided between the different actors there .
By cross-referencing it with real world data , it can also help to form an idea of the proﬁt that each criminal is making , and of the revenue of the operation .
Another interesting aspect of tracing the cash ﬂow of cybercriminal operations is that at some point the criminals will want to cash out , which will be done using traditional payment methods ( see Section 7.2 ) .
Since these interactions happen in the physical world , it is easier for law enforcement to trace them and potentially apprehend the criminals [ 849 ] .
Attack attribution When talking about malicious activities , attribution is important .
Law enforcement is interested in understanding what criminals are behind a certain operation , and in particular attributing apparently unrelated cybercriminal operations to the same actors could help build a legal case against them .
In similar fashion , governments are interested in identifying the culprits behind the attacks that they receive .
As we discussed previously , the concept of ‘ place ’ is relative for computer attacks , and attackers can easily route their network connections through proxies or compromised machines in third countries , thus hiding their actual location .
It is reasonable to assume that the same actors will follow a similar modus operandi in their attacks , and in particular will use the same software exploits to break into their victims ’ systems .
The KA Adversarial Behaviour | October 2019 Page 247 The Cyber Security Body Of Knowledge www.cybok.org ﬁrst is that the commodisation of cybercrime services has enabled attackers to use exploit kits , which contain a large number of exploits and , therefore , increase the likelihood of an attack happening .
While advantageous for attackers , this trend means that the exploits used become a less signiﬁcant signal for identifying attackers , especially those who do not have the sophistication to exploit vulnerabilities in house ( e.g .
The exception to this trend is state-sponsored actors , who unlike traditional criminals usually have very speciﬁc targets .
For this reason , they can tailor their attacks more carefully , and even develop new exploits to hit a speciﬁc victim .
Being unique to an actor , they could be used to identify who is behind a speciﬁc attack .
An issue here is that , once an exploit is used , it could be intercepted by the victim ( or anyone on the network ) and later used against another target affected by the same vulnerability .
Recent leaks have shown that the CIA has been actively collecting exploits used by other nation states and adding them to their arsenal , thus allowing them to make it look like another country was behind any given computer attack.8 Rid et al .
Within this framework , they identiﬁed three layers of analysis that are needed to correctly perform attribution : tactical , operational and strategic .
The tactical component consists of understanding the technical aspects that composed the attack ( the how ) , the operational component consists of understanding the attack ’ s high-level characteristics architecture and the type of attacker that we are dealing with ( the what ) , while the strategic component deals with understanding the motivation behind the attack ( the why ) .
While this framework was developed with state-sponsored attacks in mind , it could be used to attribute other types of malicious activity .
CONCLUSION In this document , we presented an overview of the adversarial behaviours that exist on the Internet at the time of writing .
We surveyed various types of malicious operations , depending on the attacker ’ s motivations and capabilities , and analysed the components that are required to set up successful malicious operations .
Finally , we described a number of modelling techniques from a variety of ﬁelds ( computer science , criminology , war studies ) that can help researchers and practitioners to better model these operations .
We argued that having good models is of fundamental importance to developing effective mitigations that are difﬁcult to circumvent .
This report theorises that full protection of the information and communication infrastructure is impossible .
From a technical perspective , it would require complete and ubiquitous control and certiﬁcation , which would block or limit usefulness and usability .
From an economic perspective , the cost of protection measures and the loss related to limited use effectively require an equilibrium between openness and protection , generally in favour of openness .
From there on , the report promotes the use of detection techniques to complement protection .
The next ten years saw the development of the original theory of intrusion detection by Denning [ 852 ] , which still forms the theoretical basis of most of the work detailed in this KA .
Security Operations and Incident Management can be seen as an application and automation of the Monitor Analyze Plan Execute-Knowledge ( MAPE-K ) autonomic computing loop to cybersecurity [ 853 ] , even if this loop was deﬁned later than the initial developments of SOIM .
Autonomic computing aims to adapt ICT systems to changing operating conditions .
The loop , described in ﬁgure 8.1 , is driven by events that provide information about the current behaviour of the system .
The various sequential steps of the loop analyse the event stream ( trace ) to provide feedback to the system , changing its behaviour according to observations and policies , enabling automatic adaptation to best provide service for users .
The developments of SOIM have increased in automation and complexity over the years , as a result of our increasing reliance on the proper service delivery of the ICT infrastructure .
These developments have slowly covered most of the spectrum of the MAPE-K loop .
After nearly 40 years of research and development , the Security Operations and Incident Management domain has reached a sufﬁcient maturity to be deployed in many environments .
While early adopters were mainly located in ICT-intensive sectors such as telecoms and banking , it is ﬁnding its place in sectors that are increasingly embracing or converting to digital technologies .
Yet , research is still very active in addressing the many remaining challenges .
With respect to detection , new emerging environments driven by new technologies and services are requiring the acquisition and analysis of new data streams .
The tools , techniques and processes available today for detecting and mitigating threats also regularly fail to prevent successful attackers from penetrating and compromising ICT infrastructures , without regular users noticing .
Extremely large-scale events also occur at regular intervals , and there is a deﬁnite need for progress in terms of reaction to attacks .
The Security Operations and Incident Management knowledge area description starts by introducing some of the vocabulary , processes and architecture in section 8.1 .
It then discusses Security Information and Event Management , instantiating Analyze from a more global perspective than sensors , Plan in section 8.4 and examples of Execute .
Using the Security Orchestration , Analytics and Reporting ( SOAR ) concept , it further develops the modern aspects of the Plan and Execute activities in section 8.5 .
Section 8.1.1 establishes a few fundamental vocabulary references in the SOIM domain , and section 8.1.2 describes the deployment of these concepts in a generic ICT infrastructure .
In addition to the ICT system being protected and monitored to detect attacks , two major actors inﬂuence the evolution of the loop ; the Internet as a whole and the regulatory context in which the ICT system provides services .
The Internet is the source of both service requests and threats , but also of intelligence about these threats .
Regulatory bodies such as national agencies , and industry bodies provide additional threat and detection information and request information sharing .
Figure 8.1 : MAPE-K Autonomic computing loop instantiated to SOIM Figure 8.1 illustrates the positions of the components that carry out the SOIM workﬂows , using three partial loops .
More recently , Security Orchestration , Analytics and Reporting ( SOAR ) platforms have driven further analytics and responses , enabling more advanced and global responses to cyberthreats .
The knowledge base used in SOIM has gradually expanded over the years , as more intelligence has become necessary to detect and mitigate attacks .
The key difference between knowledge and events is time .
Events are produced and consumed , while knowledge is more stable .
The Monitor activity is essentially covered by IDSes .
The various data sources included within the scope of monitoring are described in section 8.2 .
The Analyse activity , also covered by IDSes , aims to determine whether some of the information acquired constitutes evidence of a potential attack .
However , section 8.3 illustrates that the constraints associated with real-time event processing and limited coverage require additional tools .
This is the objective of the second loop , SIEM platforms .
The text of the KA will use IDPS from now on , except when the concept is focusing on detection , where IDS will remain .
Plan activity is essentially the realm of SIEM platforms .
The deployment of these IDS sensors created the need to manage operationally large volumes of alerts , which led to the development of these SIEM platforms .
They provide both additional analysis and initial planning to respond to attacks .
We are now deploying the second generation of these SIEM platforms to accommodate increasingly large volumes of diverse data , and to provide additional processing capabilities .
Execute activity started being implemented in SIEM platforms mostly through manual processes .
Security orchestrators or dedicated components are now enabling partial automation of feedback to the ICT infrastructure , although this activity is less mature than the others .
Automation is absolutely necessary to handle the huge amounts of event data generated by modern ICT systems , and to describe the huge body of knowledge related to cyberattacks .
They all rely on a large body of knowledge , covering , for example , the conﬁguration of a monitored system , or detection signatures of many types and forms .
This is the topic of Security Orchestration , Analytics and Reporting ( SOAR ) , which aims to support better responses to threat , as well as more global information exchange .
The SOAR acronym describes an increasingly required set of functionalities extending SOIM coverage for risk and incident management .
The Security Operations and Incident Management domain assumes that there is an ICT system to be protected .
Thus , an SOIM deployment assumes a few general architectural principles on which tools and processes can be deployed .
Not all these attacks can be blocked by protection mechanisms such as ﬁrewalls .
Best practices recommend deﬁning zones of different sensitivities , to control the data exchange .
This frequently and minimally takes the form of a Demilitarised Zone ( DMZ ) located between the inside private network and the outside Internet , to serve as communication termination , exchange and increased scrutiny through monitoring .
To detect threats that are not blocked by protection mechanisms , operators deploy Intrusion Prevention Systems ( IDPS ) .
They can also be deployed at the network level ( section 8.2.1 ) , depicted as the two larger pieces of equipment with magniﬁers .
The SOIM infrastructure is shown at the bottom of ﬁgure 8.2 .
The sensors often have at least two network attachments , an invisible one in the monitored Information System network for collecting and analysing data , and a regular one in a protected speciﬁc SOIM network infrastructure , where the SIEM is installed and receives the alerts .
Analysts man consoles to receive alerts , assess their impact and deploy the appropriate mitigation actions .
Sensor management might either use this secondary network attachement as a maintenance channel for software and signature updates , or use yet another mechanism such as a virtual private network to carry out the sensor maintenance .
The SOIM domain also implies processes , which are deﬁned by the Chief Information Security Ofﬁcer and followed by analysts .
The ﬁrst process is related to alert processing , where KA Security Operations & Incident Management | October 2019 Page 255 The Cyber Security Body Of Knowledge www.cybok.org the operator , with the help of decision support techniques provided by the SIEM , will decide to ignore the alert , react to it following procedures , or escalate the alert to skilled analysts for further analysis , diagnosis and decision .
The second process is the deployment and maintenance of sensors , deciding on where to locate them , what to capture and how to maintain continuous monitoring .
The third process is reporting , particularly crucial for managed services , where the functioning of the SIEM and SOC are analysed for improvement .
CERT and ISAC entities are trusted organisations , sometimes enabling sectoral information exchange , often established and governed by regulations .
CTI is a much more fuzzy area , including open source intelligence as well as dedicated information feeds provided by commercial companies .
This is achieved ﬁrst by collecting information about the operation of these ICT infrastructures from traces with many different origins .
The ovals describe concrete implementations of these data sources .
Since it is a standardised protocol and format , it also supports log feeds provided by networking equipment , operating systems and applications .
Many data sources have been considered over the years , depending on the requirements of the use case and the detection algorithms .
Data sources broadly describe either host behaviours reporting on operating systems or applications , or network behaviours reporting communication patterns .
Data sources are event streams , traces of activity that represent the services accessed by the users of an Information System .
Data sources are inputs to sensors , which produce alerts as outputs .
In the general case , an event or a stream of events , acquired by a sensor , generates an alert that synthesises the security issue found by the sensor .
The move to external resources such as cloud providers or Internet Service Providers may limit the availability of some of the data sources , for practical reasons such as volume , or due to privacy constraints and entanglement of multiple customer data in the same trace .
It is also possible that traces from hosted environments might be compromised or be made available without the knowledge or authorisation of the customer .
8.2.1 Network trafﬁc Network data have become the de-facto standard for collecting input data for intrusion detection purposes , because of the overall reliance on networks and the ease of use of standard formats .
While the capture of packets is the most prevalent format , the scientiﬁc literature has also used other information sources for security .
Network information is sometimes not available internally and it may be necessary to rely on Internet Service Providers , for example , to identify attackers ’ addresses and routes .
The most prevalent type of network trafﬁc data is the full packet capture , exempliﬁed by the libpcap library and the tcpdump and wireshark applications .
The pcap library has been ported to many environments , and is widely available as open source , hence its success .
Numerous datasets have been made available or exchanged privately as pcaps , for almost as long as intrusion detection research has existed and needs to be evaluated .
While packet capture is widely used , it does not mean that this information is stored in sensors .
Storing pcaps require an enormous amount of storage , hence pcap ﬁles are often reserved for research datasets or forensics purposes .
Network-based sensors may offer the capability to store a few packets along with an alert when a detection occurs , generally the packet that triggered the detection and a few ones belonging to the same context ( TCP , etc . ) .
This capability is generally limited to misuse detection .
The pcap library requires the availability of a network interface that can be placed in so-called promiscuous mode , meaning that the interface will retrieve all packets from the network , even the ones that are not addressed to it .
Also , there is no need to bind an IP address to the network interface to capture trafﬁc .
This means that , in general , packet capture can occur silently and is undetectable .
Despite its popularity , there are a few issues with the pcap format that need to be considered when manipulating it .
Volume Pcap ﬁles tend to be extremely large for any practical operational use .
This often limits capture to the investigation .
Sensors generally analyse network trafﬁc on the ﬂy but do not record actual packets .
Packet size The default conﬁguration of the library acquires only the beginning ( headers ) of an IP packet .
This means that a packet trace might be limited to only header information .
KA Security Operations & Incident Management | October 2019 Page 257 The Cyber Security Body Of Knowledge www.cybok.org An incomplete or missing packet payload strongly limits detection .
Segmentation and fragmentation Information circulated on the network is recorded on a per-packet basis .
This implies that the receiving software must reconstruct the application-level data stream .
Beginnings or ends of communications might be missing .
Timestamps Network packet headers do not include any timestamp .
This is added by the capturing software and relies on an external clock .
MAC layer interpretation Capturing the MAC layer is possible , but requires a speciﬁc conﬁguration .
Interpreting of MAC layer information requires knowledge of the conﬁguration of the network segment to which the collection network interface is attached .
Capturing the MAC layer is required in order to detect attacks such as ARP poisoning .
For certain types of industrial control networks which run directly on top of the Ethernet layer , capturing trafﬁc requires adding a node and may break real-time assumptions .
Application layer interpretation The most crucial aspect of pcap analysis for cybersecurity is analysing the application layer .
IP packets are relatively autonomous bits of data .
Reliable transports , such as TCP , have inherent dynamics that need to be taken into account when analysing the data , such as the existence of a connection or not .
At the application layer , inside the TCP/IP payload , information might be inconsistent with the headers , or require an understanding of application logic , which is often hard to acquire , understand and reproduce .
TLS ensures both the authentication of the server to the client , and the conﬁdentiality of the exchange over the network .
For monitoring , the issue is the second aspect , the impossibility to analyse the payload of packets .
The classic approach to this problem is to put an additional dedicated box close to the application server ( web , mail , etc .
The HSM is responsible for establishing the TLS session before the application server provides any content .
This moves the load of establishing the TLS session outside of the application server .
TLS-protected trafﬁc is encrypted and decrypted at the HSM , and ﬂows in clear to the server .
This enables network-based IDPSes and WAFs to analyse the trafﬁc .
Due to changing requirements , new network protocols have been introduced to support the Internet of Things ( IoT ) .
Low-power communication protocols such as LORA have limitations in both packet size and the number of the packets that can be transmitted per day .
These communication protocols are used mostly today as data harvesting on a large scale .
Thus , IDPSes will need information about the context of the communication to provide useful detection .
Isosynchronous protocols in use such as PROFINET IRT have stringent requirements in terms of communication cycle time and determinism .
These protocols are typically used in manufacturing environments .
However , the strict timing requirements of such protocols require careful validation that the IDPS does not alter these requirements .
Also , this necessitates the deployment of a second communication channel for the IDPS to send alerts to a SIEM , which may be costly , technically difﬁcult and may introduce additional vulnerabilities to the system .
KA Security Operations & Incident Management | October 2019 Page 258 The Cyber Security Body Of Knowledge www.cybok.org 8.2.2 Network aggregates : Netﬂow The sheer size of packet captures has created the need to obtain a synthetic view of network activity .
This has created the need for a synthetic aggregated view of trafﬁc at a relatively low layer .
Network aggregates are mechanisms for counting packets sharing certain characteristics , such as source , destination , protocol or interface .
These counts are performed by network equipment as packets cross their interfaces .
In brief , this protocol records counters of packet headers ﬂowing through router network interfaces .
As Netﬂow was developed by network equipment providers , it is extremely well integrated in networks , and widely used for network management tasks .
It is standardised , and even though the commercial names differ , similar information is collected by the manufacturers supporting the technology .
Hence , Netﬂow is also widely used for cybersecurity tasks .
Handling packets to compute Netﬂow counters requires access to routers CPU ( central or on interface boards ) .
This signiﬁcantly reduces the performance of network equipment .
Newer routers are now able to generate netﬂow records at the hardware layer , thus limiting the performance impact .
Another alternative is to span or tap a network interface and to generate the netﬂow records independentely of the routing equipment .
Originally , to limit the CPU performance impact , operators often deploy Netﬂow in sampling mode , where only one in every several thousand packets is analysed .
Thus , the view recorded by Netﬂow might be extremely limited and may completely miss events that do not reach the scale of the sampling .
Except for large-scale Denial of Service events , it is thus difﬁcult to rely on sampled Netﬂow alone for security .
8.2.3 Network infrastructure information The networking infrastructure relies on many protocols for proper communication .
Two of its main components , the naming and the routing infrastructure , are also of signiﬁcant interest for both attacks and detection .
Reporting on routing or naming operations requires direct access to a view of the infrastructure .
Operators who participate in routing and naming usually rely on syslog to collect information .
It resolves domain names , meaningful bits of text , to IP addresses required for network communications but which are difﬁcult to remember .
In addition , naming is required for the Transport Layer Security ( TLS , RFC 8446 ) protocol and certain HTTP mechanisms such as virtual hosting .
Despite its importance , DNS has been the subject of many vulnerabilities and attacks .
The main problem with DNS is its lack of authentication in its basic form .
An attacker can thus steal a domain through fake DNS messages or responses .
The deployment of DNSSEC offers an authenticated response to DNS queries that will provide users with evidence of domain name ownership .
The DNS protocol is also a natural DDoS ampliﬁer , as it is possible for an attacker to mimic the IP address of a victim in a DNS request , thus causing the DNS server to send unsolicited trafﬁc to the victim [ 861 , 862 ] .
Another issue related to DNS is the detection of botnet activity .
While it is not the only C & C communication channel used by bot herders , DNS is attractive as a communication channel for attackers because it is one of the few protocols that is highly likely to go through ﬁrewalls , and whose payload will be unaltered .
Note that DNS is not the only protocol to be prone to DDoS ampliﬁcation attacks .
8.2.3.2 Routing Another related source of information for attacks is routing information .
Incidents in the Border Gateway Protocol routing infrastructure have been studied for some time [ 869 , 870 ] , but many of the recorded incidents are due to human error .
There are recorded instances of malicious BGP hijacks [ 871 , 872 ] , but the effort required by attackers to carry out these attacks seems , at this point in time , not be worth the gain .
8.2.4 Application logs : web server logs and ﬁles Higher up the computing stack , application logs provide an event stream that documents the activity of a speciﬁc application .
The main advantage of application logs over system logs is their similarity to reality and the precision and accuracy of the information proposed .
These logs were initially created for debugging and system management purposes , so they are textual and intelligible .
This format is a de-facto standard provided by the Apache web server and others .
While it is very similar to Syslog , there are no standards documents normalising the format .
This format is extremely simple and easy to read .
It provides information about the request ( the resource that the client is trying to obtain ) and the response of the server , as a code .
Thus , it has been widely used in Intrusion Detection Systems over the years .
The main issue with the format is the lack of information about the server , since the log ﬁle is local to the machine generating the log .
As server logs are written once the request has been served by the server , the attack has already occurred when the sensor receives the log information .
Thus , this information source does not satisfy the requirements of Intrusion Detection and Prevention Systems ( IDPS ) , which need to be hooked as interceptors to act on the data stream ( packet stream , instruction stream ) , to block the request or modify its content .
8.2.4.2 Files and documents Another source of application-level information that is particularly interesting and can be found both in transit ( in networks ) or at rest ( in systems ) comprises the documents produced by some of these applications .
The introduction of rich document formats such as PDF , Flash or ofﬁce suites , not to mention the rich HTML format used in mail exchanges today , has created a wealth of opportunity for attackers to include malware .
Exchanged over the web or via email , they constitute another trace of exchange that can reveal malicious code embedded in these documents , such as macros or javascript .
Parsing information in documents , both simple ones such as TLS certiﬁcates or complex ones such as PDF , is complex and provides attackers with a wealth of opportunity to create different interpretations of the same document , leading to vulnerabilities and malware .
At the same time , it should be acknowledged that the rich document formats are here to stay and that rich ( and thus complex ) speciﬁcations such as HTML5 need to be well written so that they can be unambiguously interpreted , thus leaving less room for attackers in the speciﬁcation itself .
Using documents as a data source is increasingly required for malware detection .
8.2.5 System and kernel logs The earliest ‘ intrusion detection ’ paper by Denning [ 852 ] already included in the model the generation of an audit trail by the system being monitored .
Operating systems generally provide logs for debugging and accounting purposes .
These logs were exploited in early designs such as Haystack .
However , Denning has already stated that most system logs are insufﬁcient for intrusion detection , as they lack the required precision .
This makes it impossible to differentiate commands with identical names at different locations , or long command names .
Another trend pursued by intrusion detection researchers and operating system designers was the creation of a speciﬁc audit trail to generate a trace of privileged user activity , as required by the Orange Book .
These speciﬁc system traces are acquired through the interception of system calls , which represent the transition between regular program execution and request to protected kernel resources .
This is typically implemented using a dedicated audit trail , as speciﬁed in the Orange book , or kernel/processor debugging accesses such as ptrace for Linux .
However , the complexity of the speciﬁcation led to divergences in the implementation of the audit trail by the different operating system vendors .
It also imposed such a performance penalty to program execution that it became impossible to operate ICT systems with the audit trail being activated .
It therefore became of little use and was quietly removed from most operating systems .
This factor has prevented the emergence of a standard system audit trail , even in certiﬁed operating systems .
Kernel logs now focus on monitoring the internal operations of an operating system , close to the hardware .
They have been integrated in the commercial world under the term ‘ endpoint protection ’ , which has become a generalised term for antivirus engines .
This addresses the general problem of protecting not only the system but also the applications , such as the browser or the mail client , which not only exchange data but also execute untrusted code provided by external sources .
They rely on dedicated interceptors that capture only the activity that they are interested in analysing .
This solves the main issue of this data source , a very ﬁne granularity that ensures everything is captured , but makes analysis and detection very difﬁcult , as it is hard to link the assembly code being executed on the processor with programs and information that a user or analyst can easily understand and react to .
Malware is the subject of the Malware & Attack Technology Knowledge Area ( Chapter 6 ) , and in the context of SOIM malware detection engines and endpoint protection tools are considered sensors .
Other logs provide higher level information , such as a report of the boot process on Unix machines , or on the main kernel activity .
8.2.6 Syslog As already mentioned in this section several times , Syslog provides a generic logging infrastructure that constitutes an extremely efﬁcient data source for many uses .
The initial source for these logs is the Syslog protocol , introduced in BSD Unix , retro-speciﬁed from existing implementations by RFC 3164.The current speciﬁcation of Syslog is provided by RFC 5424.This new speciﬁcation introduces several improvements over the original implementation .
It contains the following information in this order : Timestamp The date and time of the event creation , usually in text format with a resolution up to the second .
Hostname The name of the equipment generating the log .
It might be a fully qualiﬁed name or an IP address , or the localhost for the local machine .
Using IP addresses in private ranges or localhost may induce errors when consolidating logs .
PID The process ID of the process generating the log .
Message An ASCII 7-bit message qualifying the information , provided by the developer of the application .
Syslog also uses the notion of facility to categorise and orient logs .
This information is aggregated in different ﬁles , usually in the /var/log/ directory in Unix systems .
This facilitates transmission , as UDP can be resilient to difﬁcult network conditions and lose a few messages without losing the capability .
Many systems include a standard programming interface to implement calls to Syslog in applications .
Many , if not most , heavy SOC implementations rely on Syslog to centralise both events and alerts .
The fundamental work of Denning [ 852 ] already deﬁned the two families of data analysis techniques that have been researched , developed and commercialised over the years .
Misuse detection , detailed ﬁrst , aims to characterise malicious behaviours present in the traces in order to send an alert when the set of malicious behaviour events is recognised in the traces .
Conversely , anomaly detection aims to characterise ‘ normal ’ behaviour , and sends an alert when events in traces are not associated with normal behaviours .
In both cases , a large number of algorithms have been described in the scientiﬁc literature .
A few of these algorithms have been applied both to misuse and anomaly detection .
In SOIM processes , and as shown in ﬁgure 8.1 , analysis is performed by two components , the sensors and the SIEM platform .
The monitored Information System generates traces representative of activity , as log ﬁles or through dedicated IDPS appliances or software ( shown as looking-glass-boxes and ﬁles in ﬁgure 8.2 ) .
One or several events in each trace may trigger the generation of an alert by a sensor .
Several of these alerts , possibly coming from several sensors , may be assembled by the SIEM in incidents that need to be handled by operators .
In this section , the KA addresses the transformation of events in alerts , that may characterise malicious activity .
KA Security Operations & Incident Management | October 2019 Page 263 The Cyber Security Body Of Knowledge www.cybok.org Figure 8.4 : Analysis : from event to alert to incident 8.3.1 Misuse detection Misuse detection leverages the vast body of knowledge characterising malicious code and the vulnerabilities that this malicious code exploits .
A misuse Intrusion Detection System seeks evidence of known malicious events in the trace , and alerts when they are found , informing the analyst about the speciﬁcs of the vulnerability exploited and its impact .
The earliest Intrusion Prevention Systems in this area are antivirus engines , which capture execution traces such as system calls , library calls or assembly , identify known malicious patterns using so-called signatures that describe these malicious codes , and quarantine the associated container .
The IDPS thus seeks exploits , very speciﬁc instances of malicious codes represented as bitstrings .
Modern malicious code has evolved complex mechanisms to avoid detection , and modern anti-malware tools have become extremely complex in response , in order to create more efﬁcient representations of exploits and vulnerabilities .
The risks of generic signatures are , of course increased false positives and increased difﬁculty in understanding the precise attack .
Another branch of system analysis is UNIX system analysis , exempliﬁed by the Haystack and NIDES prototypes .
These prototypes aimed to create high-level audit trails for analysis .
The canonisation aspect of the data had a signiﬁcant impact on detection performance , and the current state of the art is focusing on assembly and binary language analysis for detection .
From a network perspective , an IDPS seeks evidence of malicious activity in multiple forms .
The malicious code can be found in the packets ’ payloads .
Malicious code can also exhibit speciﬁc network activity related to command and control , access to known addresses or KA Security Operations & Incident Management | October 2019 Page 264 The Cyber Security Body Of Knowledge www.cybok.org to known services .
The key advantage of misuse detection is the ability to document the cause of the alert , from a security perspective .
This helps the analyst decide how to further process the alert , particularly its relevance and its impact on the monitored system .
The key difﬁculty of misuse detection is the process of creating signatures , which requires time , expertise and access to the proper vulnerability information .
Frequent signature updates are required , mostly to take into account a rapidly evolving threat environment , but also to take into account errors in the initial signature , or new Indicators of Compromise which were not initially detected .
8.3.2 Anomaly detection Anomaly detection is a fundamental tool for detecting of cyber attacks , due to the fact that any knowledge about the attacks can not be comprehensive enough to offer coverage .
Anomaly detection is a domain where not only research has been extremely active , but there are several thousand patents that have been granted on the topic .
The key advantage of anomaly detection is its independence from the knowledge of speciﬁc vulnerabilities .
This theoretically enables the detection of 0-day attacks , provided that these attacks effectively show up as deviations in the traces .
Also , these methods are often computationally fast , which enables them to keep pace with the increasing volume of traces to be processed .
However , pure statistical methods highlight anomalies that are hard to understand and qualify for analysts .
The lack of precise diagnosis , and of a clear link to security ( instead of an anomaly related to another cause ) requires an in-depth understanding of both the monitored system and the detection process , which is hard to combine .
Thus , anomaly detection , while heavily marketed , must be operated with caution as a ﬁrst line of detection , because it requires strong domain knowledge to transform a diagnosed anomaly into actionable defence .
Applied to alert streams , which are richer in information , anomaly detection is often more successful in SIEMs and is implemented in newer SIEM platforms such as the ElasticsearchKibana-Logstash stack or commercial tools such as Splunk .
As the difﬁculty of creating attack signatures became more signiﬁcant , IDPS vendors also included these models in their products .
KA Security Operations & Incident Management | October 2019 Page 265 The Cyber Security Body Of Knowledge www.cybok.org 8.3.2.1 Models Anomaly detection relies on the deﬁnition of a model against which the current observations of the trace are evaluated .
Very early researchers proposed behaviour models to detect deviations from the norm .
However , the statistical models developed in early IDS prototypes such as Haystack and NIDES were not accurate enough to detect skilled attackers .
Therefore , more complex models have been developed over the years .
In network anomaly detection , the model must ﬁrst deﬁne whether it will look at multiple data points or compare a single data point to the model .
Models can also correlate between connections to detect more complex attacks spanning multiple packets .
An example of this kind of behaviour is the correlation between web trafﬁc and DNS trafﬁc .
When using regular browsers , the user is likely to perform a DNS request before accessing a website ; an anomaly could manifest itself if the web request directly addresses the website through its IP address .
Of course , in this case caching phenomena must be taken into account .
Another interesting aspect of network anomaly detection is the deﬁnition of the technique .
Unsupervised techniques look at outliers , creating clusters out of the data and using a distance to determine outliers that can not be covered in clusters .
In this technique , the selection of features , that become the coordinates for each data point , is critical .
Feature combinations must effectively differentiate between normal behaviours and attacks .
Frequent methods for creating clusters and measuring distance include k-nearest neighbors or the Mahalanobis distance .
Supervised anomaly detection techniques use labelled features to create optimal clusters .
Support Vector Machines or C4.5 are frequently used for this task .
Graph-based models represent the structure of the network and of the communication paths .
They enable a representation of network behaviour that highlights changes in communication patterns .
These techniques also offer attractive vizualisation capabilities , that enable operators to weight the exchanges between various parts of their networks , to identify anomalous communication patterns , and then to dig further in to qualify the anomaly as security relevant or not .
The choice of an anomaly model is extremely important .
In fact , many publications related to anomaly detection are made in thematic venues such as statistics , signal processing or information fusion , outside of the cybersecurity domain .
This ﬁeld of study is thus extremely rich and fundamentally multi-disciplinary .
An attack is considered to be a breach of the speciﬁcation of a system .
The key issue in this approach is to obtain a speciﬁcation that can be reliably recognised in the traces .
Bro is built up as a stack of protocol analysers , checking at each layer the coherence of the captured information with the standards , in this case the RFCs .
Further development of speciﬁcation-based detection is expected in industrial control networks [ 881 ] , where speciﬁcations are much more precise and enable the detection of perturbations .
In these networks , the behaviour is much better speciﬁed , because of the underlying control loop of the physical process that is piloted by networked controllers .
This also cre- KA Security Operations & Incident Management | October 2019 Page 266 The Cyber Security Body Of Knowledge www.cybok.org ates additional regularity that can be picked up by anomaly detection algorithms .
Alternatively , supervised learning is used to create models when ground truth is available , or unsupervised learning to let models self organise .
In both cases , it is frequently necessary to select a threshold that will separate data points considered normal from those considered outside of the model .
The application of machine learning techniques for detection is further developed in section 8.3.4 .
8.3.2.3 Adherence to use cases An important point on anomaly detection is its adherence to a use case , possibly even a speciﬁc deployment .
Malware anomaly detection has also evolved from personal computers to web malware to Android malware today [ 882 ] .
This adherence to a use case is important for creating the model , validation and testing .
It requires that from the start , operators understand the behaviour of their systems and have sufﬁcient business domain knowledge to understand why and how anomalies manifest themselves , and what their signiﬁcance is with respect to cybersecurity .
Speciﬁc care must be taken to associate the detection of anomalies with as much domain knowledge as is possible to diagnose and qualify the anomaly .
Equipment roles imply different behaviour models , and thus different qualiﬁcations for anomalies .
This adherence to use cases also prevents the deﬁnition and qualiﬁcation of generic behaviour models .
Therefore , operators deploying anomaly detection systems must prepare for a period of testing and qualiﬁcation .
It is also likely that new systems , new services , or upgrades to existing systems or services , will perturb existing models and require requaliﬁcation .
8.3.3 Blended misuse and anomaly detection In practice , it is very hard to separate anomaly detection and misuse detection , as they are often intertwined in current sensors .
For example , it is extremely useful to pre-ﬁlter input data before applying misuse detection .
This not only increases efﬁciency but also prevents false positives when a signature pattern is found in the wrong trafﬁc context [ 877 ] , for example , when a packet circulates over the network but the TCP session has not been established .
This approach organises both misuse and anomaly detection in order to leverage the strengths of both approaches and limit their drawbacks .
It also leverages the speciﬁcations of the application protocol to understand not only the syntax of the trace but also its semantic , in order to propose a better diagnosis .
KA Security Operations & Incident Management | October 2019 Page 267 The Cyber Security Body Of Knowledge www.cybok.org 8.3.4 Machine learning Another , more subtle , way of mixing anomaly and misuse detection is using machine learning techniques , and particularly supervised learning , which requires ground truth .
Machine learning basically associates an output class with a characteristics vector presented at the input .
If the machine learning algorithm requires a deﬁnition of the different classes to which it assigns the input , then the deﬁnition of the output classes ( for example , normal and attack ) in itself enables mixing anomaly and misuse detection .
There are so many research papers presenting the use of support vector machines , C4.5 , random forest , that one can only reference the best survey published so far by Chandola et al .
This is a crucial operation , as shown by the failure of the KDD dataset , as it may either remove artefacts that are necessary for detection , or introduce new ones that create false positives , as discussed in section 8.3.5 .
Also , the recent development of the smartphone ecosystem [ 892 ] , Android and its rich ecosystem of applications , with the associated malicious code , has created signiﬁcant interest in Android malware detection .
Looking further aﬁeld , there is increasing interest in using machine learning and artiﬁcial intelligence for cybersecurity , as shown by the DARPA Cyber Grand Challenge .
One can expect equal interest from attackers and thus the emergence of adversarial machine learning where , as shown for the speciﬁcs of Neural Networks , attackers can introduce irrelevant information to escape detection or to make it harder .
8.3.5 Testing and validating Intrusion Detection Systems One of the key issues for Intrusion Detection System designers is testing and validating their tools .
This issue has been around for a long time in the research community , as exposed by an early paper on the topic by McHugh [ 885 ] .
The evaluation of an IDS therefore compares the output of the detector with the ground truth known to the evaluator , but not to the detector .
True Negatives ( T N ) are normal events that exist in the trace and should not be reported in alerts by the detector .
As detectors are not perfect , there are two undesirable measures that quantify the performance of a detector .
False negatives ( F N ) , also known as miss or type II errors , are deﬁned as an attack that exists in the trace , but has not been detected by the IDS .
The ﬁrst issue is to deﬁne the criteria for detection .
In misuse detection ( section 8.3.1 ) , the IDS developer must deﬁne a set of attacks that he wants to detect and create the set of signatures that will detect them .
As most anomaly detectors use machine learning approaches , this means that the developer must obtain one or several datasets of signiﬁcant size , possibly labelled .
These datasets should , for some or all of them , include attack data .
The detector is then trained on part of the datasets , and its performance evaluated on the others .
For parametric and learning algorithms , several trials should be performed to obtain an average performance .
For example , the process by which the attack and normal trafﬁc were generated ( manual versus simulations ) created obvious differences in the packet ’ s Time To Live ( TTL ) and session duration .
These features , which are not normally distinguishable in operations , tend to be picked up by learning algorithms , inducing a signiﬁcant bias in the process with respect to T P .
Another example is the lack of distinguishing features in the SNMP trafﬁc , which leads to large F N rates .
The second issue is how to determine and present the actual success criteria of an IDS .
An unavailable or incomplete ground truth may limit its usefulness .
Another relevant aspect of evaluation is the fact that detection algorithms require the operator to select the parameter , such as thresholds or numbers of clusters .
Setting these parameters strongly inﬂuences the performance of the sensors .
A gain in one direction often decreases the performance of the other .
Depending on the detector and deﬁnition , the actual values computed during the evaluation of the detector may vary .
For example , it might be sufﬁcient for a detector to ﬁnd and report one attack event in the trace to consider it a T P , even if the attack consists of many events .
Again , the experimental validation process should be extremely detailed and peer-reviewed to ensure that it does not contain any obvious errors .
KA Security Operations & Incident Management | October 2019 Page 269 The Cyber Security Body Of Knowledge www.cybok.org Another issue is the operational qualiﬁcation of the IDS .
When testing on real trafﬁc , the evaluator may be able to approximate the F P better because real trafﬁc artefacts are always likely to trigger cases that the IDS has not encountered during validation .
As evaluation is the basis for certiﬁcation , it is no surprise that Intrusion Detection Systems are generally not certiﬁed at any security level .
The problem stems from the fact that there is a large asymmetry between the number of malicious events and the number of benign events in the trace .
The general hypothesis followed by Axelsson is that there are few attacks per day .
This may not be true anymore , but an ICT system ﬂooded with attacks is also unrealistic , unless we are concerned with Denial of Service .
Also , in the case of DDoS , malicious packets far outnumber normal trafﬁc , so the asymmetry is reversed , but still exists .
In essence , the base-rate fallacy must be addressed by IDS sensors that rely on processing large amounts of data , which is typically the case for machine-learning-based anomaly detection .
While this may sound like a theoretical issue , it has crucial implications with respect to human operators in front of a SIEM console , who have to deal with thousands of alerts , most of which are ‘ false ’ .
There is thus a signiﬁcant risk of missing an important alert and thus an incident .
This risk is even higher in MSSP settings , where operators have a limited amount of time to process alerts .
The usual process for solving this is to limit the detection to the most relevant elements .
For example , it is not necessary to look for attacks against a windows server when the monitored server is running the Linux operating system .
This tuning of the detection range can happen either before detection , by removing irrelevant signatures in the IDS , or after the fact in the SIEM by entering the proper correlation rules .
The detection tuning approach has , however , encountered limitations in recent years , because cloud platforms are more dynamic and likely to host a variety of operating systems and applications at any given point in time .
It then becomes harder to ensure proper coverage of the detection .
8.3.7 Contribution of SIEM to analysis and detection From the Analyse perspective , a SIEM aims to provide further information about malicious activity reported by sensors .
Due to the event volume and real-time nature of the detection performed by IDS sensors , these sensors usually look at a single information source in a speciﬁc location of the ICT infrastructure .
Therefore , the centralisation of alerts , which is the initial central characteristic of SIEM platforms , as described in section 8.4.1 , enables additional detection algorithms that may indicate attacks or anomalies that have not been signiﬁcantly indicated by sensors , but whose properties when aggregated are signiﬁcant .
It should be considered a decision support system and , as such , covers the Analyse and Plan activities .
From a Plan perspective , the SIEM platform aims to deﬁne the set of actions that can be performed to block an attack or mitigate its effects .
The fundamentals of Security Information and Event Management can be traced back to December 1998 , at a meeting organised by DARPA .
8.4.1 Data collection The ﬁrst objective of a SIEM platform is to collect and centralise information coming from multiple sensors into a single environment .
Several issues need to be addressed to make this happen .
First of all , there must be a communication channel between the sensors providing the alerts and the SIEM platform .
This communication channel must be strongly protected , because sensitive information may be included in the alerts .
It must also be properly sized so that there is sufﬁcient bandwidth to carry the required information .
As sensors often have limited storage capabilities , the availability of the link is essential .
Secondly , the SIEM must be able to interpret the information provided by the sensors in a coherent manner .
Given the wide range of available data sources and detection methods , this requires a lot of work to match the information from the alerts with the SIEM internal data formats .
The general approach of a SIEM platform is to deﬁne a single data structure for the alerts , often a single database table .
This means that the database contains many columns , but that inserting an alert often results in sparse ﬁlling of the columns .
Data collection is generally handled by the SIEM platform , beneﬁting from hooks from the sensors .
SIEM platform vendors generally deﬁne their own connectors and formats , handling both the issue of transport security and of data import at the same time .
Classically , communicating an alert message requires the deﬁnition of three layers : Schema The schema deﬁnes the structure of messages and the type and semantic of the attributes .
It also includes the deﬁnition or use of dictionaries .
Encoding The encoding deﬁnes how the messages and attributes are encoded to form a bitstring .
Examples of textual format include Syslog , JSON XML or YAML .
Examples of binary formats include BER , CER or BSON .
Textual formats are usually easier to process KA Security Operations & Incident Management | October 2019 Page 271 The Cyber Security Body Of Knowledge www.cybok.org because they can be read directly by humans .
Binary formats are more compact , which eases storage and transport .
Transport protocol The transport protocol describes how the alert bitstring is moved from one place to another .
Transport protocols typically take care of the access control , conﬁdentiality , compression and reliability of the communication .
The ﬁrst two , CEF and LEEF , are proprietary formats of commercial SIEM vendors , but whose speciﬁcation is at least partially open for analysis .
The next two formats ( CIM and CADF ) have been speciﬁed by the DMTF , but not speciﬁcally for cybersecurity purposes .
The last two have been speciﬁcally designed with the purpose of standardising the transmission of events or alerts .
The text in italics indicates that the speciﬁcation does not force a speciﬁc technology .
There is no guarantee of message integrity or delivery .
Its drawback is the limitation of its schema ( timestamp , origin and ASCII text string ) and the size of the message ( practically limited to 1000 bytes ) .
Syslog is widely used by network operators or for large systems such as the Olympic Games .
CEF The Common Event Format is the proprietary exchange format of the Arcsight SIEM platform .
It is oriented towards the expression of security relevant events and includes the essential information required to describe them .
This format is representative of the ﬂat structures used in SIEM platform databases .
While it has a large number of attributes , some are not sufﬁciently documented for use .
LEEF The Log Event Enhanced Format is the proprietary exchange format of the QRadar SIEM platform .
It focuses on network security events , and as such is not as rich as CEF .
It is widely used for managing distributed systems .
As it is very generic , its expressiveness for cybersecurity events is limited .
XDAS/CADF The Cloud Auditing Data Federation is still being developed , initially as XDAS , and discussions are ongoing with DMTF to include it in CADF .
It focuses on system events and cloud environments .
CEE The Common Event Expression was initiated by the MITRE corporation as a standard format for log ﬁles in computer systems .
It was developed in collaboration between US governmental entities and SIEM vendors .
It does not specify a standard , and as such its adoption by the industry has been very limited .
It is seen as complex , and in fact the speciﬁcation is large in size .
The IDMEF speciﬁcation attempts to be very precise and unambiguous , which is shown in the number of attributes , the largest of all the considered formats .
This difference in expressiveness is probably even greater , as the use of dictionaries ( enumerated types ) in the IDMEF UML design further increases its ability to represent information .
Its attempt to be exhaustive has also made some of the data structures obsolete over time .
The choice of XML messages also creates a signiﬁcant burden in transport , particularly as the IDXP transport protocol , based on BEEP , has not been widely deployed .
The broad scope of the available speciﬁcations demonstrates that at this stage , there is no consensus between SIEM vendors and sensor vendors to agree on what an alert should contain .
While many of the speciﬁcations are accessible to sensor vendors , SIEM platform vendors provide the connectors and take charge of translating the sensor information into their own formats , at the risk of missing information or misinterpreting the content .
The correlation has several objectives ; 1. to reduce the number of alerts that the analyst has to process by grouping alerts together , 2. to add contextual elements to enable more accurate and faster analysis of the group of alerts , 3. to add alerts to ongoing higher-level planning and mitigation elements so that they are handled properly , and 4. to discard alerts that are considered false positives and do not require further processing .
To meet these objectives , alert correlation can take several forms : KA Security Operations & Incident Management | October 2019 Page 273 The Cyber Security Body Of Knowledge www.cybok.org Correlation between alerts The ﬁrst kind of alert correlation aims to group together alerts from one or several sensors that correspond to the same threat .
IDPS sensors tend to have a narrow view of the data stream .
If events occur repeatedly in the trace , for example , when a malware propagates , multiple alerts will be reported to the SIEM .
Grouping alerts that correspond to the same phenomenon helps the analyst to recognise it and to judge its importance .
Correlation between alerts and the environment Another important source of knowledge is related to the context of the detection , the environment in which the sensors are located .
Information about the environment comes from many sources , the two most interesting ones being network inventory and vulnerability scans .
These two sources identify active assets and the risks they are potentially subject to .
This type of correlation is particularly interesting as it provides the analyst with information about the impact the alerts are having .
Correlation between alerts and external sources Recently , situational awareness has started to provide information about attackers and their motivations [ 902 ] .
This again provides additional information about the paths that an attacker might follow , and helps the analyst proactively to decide to block the attacker ’ s progress , instead of reacting after the event .
Incident and information exchange Another relevant trend is information exchange .
Through regulatory pressure , critical infrastructure operators are required to inform authorities when they are the victims of cybersecurity breaches .
This has been the case for banks and credit unions for a long time .
Sharing information about breaches helps others in the same domain , or using similar technologies , to protect themselves proactively .
The initial approach to alert correlation was based on rules .
A variety of languages and techniques have been used over the years by the research community , leading to exhaustive and formal models .
This led to the development of the ﬁrst generation of SIEM platforms , which combined strongly structured , highperformance SQL databases with logic engines interpreting rules .
This ﬁrst generation encountered two issues , performance as the volume of alerts increased , and the difﬁculty of creating and maintaining the rule base .
Despite performance increase and database tuning , a second generation of SIEM platforms has been developed , leveraging less-structured database technologies such as NoSQL .
This data-oriented approach has become very common today , as it is able to cope with large volumes of incoming unstructured information .
It remains to be seen whether the lack of relational structure does not introduce inconsistencies and naming confusion , impacting analysts ’ ability to diagnose and mitigate threats , and whether the focus on volume does not prevent handling rare attack phenomena such as APTs .
Thus , it is difﬁcult to identify where a speciﬁc SOC is performing well , and which areas should be improved .
As SOCs are sometimes outsourced to MSSPs , the security service level agreement must be negotiated between the customer and the service provider , and veriﬁed by the customer .
The customer may also be subject to regulations , which must be satisﬁed by the service provider as part of its contract .
It is thus necessary to measure the activity of a SOC in a way that enables measurement , comparison between industries and to the state of the art , and to decide which areas of activity should be improved .
The Information Security Indicators ( ISI ) Industry Speciﬁcation Group at ETSI develops indicators to this effect .
The approach is Europe-wide , as the ETSI ISI group is supported by members from France , Germany and Italy , as well as the network of R2GS chapters in Europe ( in addition to the countries in ETSI ISI , the UK , Luxembourg , Belgium , the Netherlands ) .
In the end , these indicators should enable a comparative measurement of SOC performance , and a general measurement of the resistance of any given organisation to threats , cyber , physical or organisational .
The ISI speciﬁcation is freely available from ETSI , and reference information charts are available from several sources .
The main difﬁculty of this approach is the ability to automatically produce the indicators , or at least a subset of them , as some indicators are of a very high level .
There is a clear reluctance to automate the last part of the loop of ﬁgure 8.1 , as system and network operators fear losing control over complex environments , although there are many reasons why it has become important to include automated mitigation in scope .
This is an extremely important area , as exempliﬁed by the Respond and Recover topics of the NIST cybersecurity framework .
8.5.1 Intrusion Prevention Systems IDPS sensors have been rapidly extended to include Execute capabilities to respond to attacks .
IDPS has the additional capability to act on the monitored stream upon detection .
This requires the ability to act as a gateway or proxy through which all exchanges will be analysed , in order to reach a benign or malicious decision .
Once a malicious decision has been reached , additional actions can be applied to the data stream , such as blocking , terminating or altering a data stream .
Of course , the additional action relies heavily on the reliability of the detection , which is why common practice limits actions to a subset of the signatures of a misuse-based sensor .
Actions executed by the sensors are linked directly to the result of detection .
As such , the Plan phase is performed through static conﬁguration , and the response to an attack is thus KA Security Operations & Incident Management | October 2019 Page 275 The Cyber Security Body Of Knowledge www.cybok.org independent of the context during which the attack occurs .
The initial deployment of network-based IDS sensors was based on passive devices , unable to act on the network .
The response was thus carried out by sending reconﬁguration actions to a ﬁrewall located upstream or downstream from the sensor , through out-of-band dedicated communications .
This mechanism induced signiﬁcant delays in responding , as the ﬁrst few packets of the attack were accepted before the rule was put in place .
There were also undesirable side effects to dynamically changing the conﬁguration of a ﬁrewall , such as losing connexion tracking .
Also , system operators are extremely attentive about maintaining stable ﬁrewall conﬁgurations , as an essential part of SRE .
Given the need to respond in real time to well-identiﬁed attacks , modern network-based IDPSes are positioned inline in the network , to couple detection and ﬁrewalling .
If malicious activity is detected by the sensor , the packet is immediately dropped or rejected , or the connection is terminated .
The advantage of this solution is that attacks are handled at line rate , as soon as they occur .
Of course , F P and F N of the detection mechanism will have a direct impact on the efﬁciency of the IDPS , denying service to legitimate users or letting attacks go through undetected .
The main drawback of the IDPS is the action in the packet layer .
This creates side effects that may leak information to an attacker .
It also requires a device to be put into the network that has the ability to break the connection , injecting another point of failure into the ICT infrastructure .
In the example of a WAF , the implementation could take the form of an external device acting as a proxy ( and/or reverse proxy ) or be implemented as an intercepting module in a web server .
More recently , inline IDPSes have been given the ability to modify the payloads of packets , under the term of ‘ virtual patching ’ .
The result is that the server receives innocuous content instead of the content , and that the response sent back to the attacker indicates that the attack has failed .
The main advantage of this approach is that it does not require breaking the ﬂow , as do application-layer sensors such as WAF or SBC .
The Arbor Networks survey of 2016 stated that half of the responding cloud infrastructure providers suffered from a loss of connectivity , which had a fundamental impact on their businesses .
The emergence of attacks compromising Internet of Things ( IoT ) infrastructures and using them for DDoS , such as Mirai , helped reach new attack volume records , although the average DDoS attacks remain relatively small at 500 Mbps .
DDoS attacks are large-scale phenomena which affect many components and operators in Internet infrastructures , from Autonomous System ( AS ) operators to cloud providers to service providers .
The move to cloud infrastructures obviously means that these cascading effects will continue .
Given their scale and impact , DDoS attacks are prime targets for automated remediation .
This has led to the emergence of dedicated DDoS mitigation service operators in cloud mode .
These service operators offer load management services , such as adding new servers to face the ﬂow , redirecting trafﬁc to other services , or selectively decreasing trafﬁc .
Classic techniques for decreasing trafﬁc include blacklisting , for example , with IP ingress ﬁltering , or at the application level using TCP Syn cookies to ensure legitimate TCP session establishment .
This helps resist DDoS attacks , although one has to acknowledge that these services will be unable to prevent or ﬁght very large-scale attacks .
At the core network , MPLS provides an interesting option to mitigate DDoS attacks [ 911 ] , as it enables bandwidth reservation and bandwidth usage control , to ensure that the legitimate trafﬁc receives sufﬁcient bandwidth and that potentially malicious trafﬁc is got rid of .
At the edge , the deployment of Software Deﬁned Networking ( SDN ) as the fundamental network control technique for cloud centres permits ﬂexibility of the network conﬁguration and control , and enables collaboration between Internet service providers and cloud infrastructure operators to mitigate DDoS attacks [ 912 ] .
Beyond networking access ( which is at this time the biggest threat ) , DoS attacks may also target computing resources , storage , or power .
The emergence of the Internet of Things , and the increasing requirement of connecting low-cost , battery-operated objects to the Internet might increase the DoS attack surface in the future .
8.5.3 SIEM platforms and countermeasures The contribution of SIEM platforms to the MAPE-K Execute activity today is limited ; once plans have been deﬁned and validated by analysts , other functions such as change-control ticketing systems take over to ensure that the deployed actions are appropriate and do not adversely impact business activity .
Internally in SOCs , analysts use ticketing systems to follow up on the progress of incident resolution and escalate issues to more skilled or specialised analysts when needed .
Ticketing systems can also serve for incident post-mortem analysis , to evaluate and improve SOC processes .
SOC analysts also interact with ticketing platforms to push change requests to other teams , in charge of network or system management .
This can even extend to security functions , for example , if the organisation has a dedicated ﬁrewall management platform .
The fact that this remains mostly a manual activity introduces a signiﬁcant delay in threat mitigation .
It also relies on system or network operators on the other side of the ticketing system to understand the requested change and effectively implement it .
However , this delay is often seen as necessary to deal with potential false positives , and to assess the effective impact on business activities , as elaborated in the following section .
KA Security Operations & Incident Management | October 2019 Page 277 The Cyber Security Body Of Knowledge www.cybok.org 8.5.4 SOAR : Impact and risk assessment Risk assessment in cybersecurity mainly focused in the past on protecting ICT assets , machines , network equipment and links .
Risk assessment methodologies focus on determining assets , analysing their vulnerabilities , and modelling cascading effects .
They enable a network or system security ofﬁcer to model the ICT environment and the associated vulnerabilities , to determine the paths an attacker might follow to compromise interesting targets .
These more complex attack graphs enable a quantiﬁcation of the likelihood that an attacker will propagate in an Information System , of the damage , and of the possible protection measures that could block the attack .
From a business perspective , attack graphs and vulnerability management technologies enable risk management and compliance with regulations .
As the impact of cyber-attacks increases , and potentially becomes a threat to human life or business continuity , regulators impose protection and detection measures to ensure that cyber-risk is properly managed in organisations .
While there are many possible protection techniques available , from identiﬁcation and authentication to ﬁltering and ﬁrewalling , the complexity and interconnectivity of complex ICT infrastructures makes it unfeasible , either technically or economically , to protect them against all possible threats .
Another aspect of attack graphs is their use for countermeasures .
Work on countermeasures has focused on technical assets , as they can be activated to block threats .
This means adding or modifying ﬁrewall rules to block unwanted trafﬁc , disabling or removing privileges of user accounts , preventing unauthorised or suspected machines of connecting to the network or the Information System , or shutting down a service or machine .
However , the deployment of countermeasures requires an impact assessment , not only at the asset level but also at the business level .
The heavy reliance of business missions on technical ICT assets means that these ﬁrewall rules or blocked accounts may have a detrimental effect on an organisation ’ s business .
This detrimental effect might even be worse than suffering an attack , at least for some time .
New models for impact assessment must take into account not only the ICT asset fabric but also the business services that they support to determine their criticality and the cost of altering their behaviour [ 916 ] .
One can not emphasise enough , as in section 8.5.3 , the importance of the processes and workﬂows associated with the set of tools implemented for SOAR .
This , for example , implies that there is a clear understanding of responsibilities in the SOC , a chain of validation when countermeasures are deployed , and an effective veriﬁcation that the mitigation is efﬁcient and has stopped the attack or its effects .
KA Security Operations & Incident Management | October 2019 Page 278 The Cyber Security Body Of Knowledge www.cybok.org 8.5.5 Site reliability engineering Another relevant aspect of threat protection and mitigation is that ICT environments have to prepare for incident management and mitigation .
As is required for safety engineering , operators have to deﬁne and deploy procedures such as activity continuity planning to ensure that they will continue to operate even when faced with certain threats [ 917 ] .
This means that operators must deploy and operate sensors up to a certain level of efﬁciency .
They must also deploy and operate protection tools such as ﬁrewall or authentication systems that might impact the performance and usual behaviour of their systems .
Also , all of this new equipment will require manpower for monitoring and maintenance .
A recent signiﬁcant change to SRE is an extension of scope .
Much , if not all , of the equipment used in any organisation will include digital technology and will require maintenance .
Many devices powering physical access control or building management will be interconnected with and accessible through the ICT infrastructure .
As such , they will be subject to similar , if not identical , attacks as the ICT infrastructure .
New maintenance models should be developed and adapted to include these IoT devices in the reliability engineering process .
The Network and Information Systems ( NIS ) European Union directive requires that all devices should be patched to remove vulnerabilities .
Depending on their computing abilities , storing and communicating security elements , these maintenance processes will be difﬁcult to develop and put into place [ 918 ] .
However , there are many systems , for example , in the transportation or health domains , where the move to digital technology must include software maintenance that is timely and secure .
This is driving increased convergence between reliability , safety and cybersecurity .
SRE teams in cyber-physical environments thus need to operate systems , monitoring them for failures and attacks , in order to ensure continuous operation .
SRE is thus also increasingly applied in pure IT environments such as cloud computing platforms , which must be robust against accidental failures such as power .
The CTI platform ( section 8.6.3 ) replaces and includes honeypots to provide a comprehensive view of malicious activity that may impact an organisation .
CERTs and ISACs are regulatory bodies with which an organisation can obtain additional information , such as the industry-speciﬁc indicator of compromise , or best practice for incident detection and handling .
KA Security Operations & Incident Management | October 2019 Page 279 The Cyber Security Body Of Knowledge www.cybok.org 8.6.1 Cybersecurity knowledge managment As described in section 8.4 , SIEM platforms are the main technical tool supporting analysts to defend Information Systems and networks .
The earliest attempt at managing cybersecurityrelated knowledge is vulnerability information sharing , formalised as CERT advisories ﬁrst and now managed through the Common Vulnerabilities and Exposures ( CVE ) dictionary , the Common Vulnerability Scoring System ( CVSS ) and databases such as the NIST National Vulnerability Database .
However , the performance of these platforms relies heavily on the information made available to the analysts manning them .
Understanding attackers has been a long-standing area of research , but there have been many recent advances in the state of the art on understanding attack processes and motivations , and on providing analysts with better information to make appropriate decisions .
CVE provides a way to reference speciﬁc vulnerabilities attached to speciﬁc versions of products .
This information is very useful for IDS signatures , because they clearly identify the targeted product .
However , they are insufﬁcient for more global processing , hence higher level classiﬁcations have been deﬁned .
The Common Vulnerability Scoring System ( CVSS ) provides a standard way to rate the impact of vulnerabilities by providing a synthetic numerical score that is easy to comprehend .
Each vulnerability is assigned a score according to six base metrics that reﬂect the intrinsic characteristics of a vulnerability , and in particular the ease with which the vulnerability can be leveraged by an attacker to impact conﬁdentiality , integrity and availability .
This base metric is modulated by three temporal metrics that indicate whether exploits ( increasing the risk ) or patches ( decreasing the risks ) are available ; these three temporal metrics evolve over time , as more information becomes available .
Finally , four temporal metrics measure the speciﬁc exposure of an organisation .
Each CVE entry is usually qualiﬁed by a CVSS score .
The Common Weakness Enumeration ( CWE ) dictionary provides a higher level structure on top of the CVE dictionary , to qualify further the kind of software weaknesses involved in the vulnerability .
It serves as an additional description of the CVE entry , to identify weaknesses that appear in multiple software tools , and to identify common mitigation and prevention strategies .
The structure of the CWE is relatively complex , and identifying commonalities accross vulnerabilities is sometimes difﬁcult .
CWE references are frequently found in CERT advisories .
CAPEC references multiple CWE entries focusing on common attributes and techniques used by attackers .
More recently , ATT & CK has been formalising operational information about attackers , to develop threat models and operational procedures for defending networks .
It is important to note that the performance of SIEM and SOAR relies on accurate and complete information being present in the knowledge base .
As such , this information must be maintained , and the appropriate links to other system or network management functions should be established to this effect .
The community commonly deﬁnes a honeypot as an Information System resource whose value lies in unauthorised or illicit use of that resource .
As such , honeypots use ‘ free ’ resources in an Information System or network to provide realistic-looking services for the outside world .
In normal use , these machines should never be accessed by legitimate users , thus any interaction is deemed to be related to malicious use .
By monitoring the attackers ’ use of the honeypot , researchers hope to obtain relevant information about attack processes and new malicious code , and to leverage this information for attack detection and mitigation .
There are several categories of honeypots .
However , as attackers and malware evolved , they became able to detect interactions that are different from the service that should be offered by the platform to which they are connected .
They have given rise to attacker analytics , from observations to statistical analysis , to what is now identiﬁed as the Indicator Of Compromise ( IoC ) , organised pieces of evidence that an attacker is trying to compromise an Information System or network .
The main hypothesis behind honeypots is that attackers will actively seek victims , while regular users will only use resources that are publicly and ofﬁcially advertised through conﬁguration , routing and naming .
This was probably true during the main period of Internet-scanning worms such as Slammer .
However , attackers have other means of silently gathering information about their targets , for example , through search engines .
The scanning is thus done by legitimate , or at least known actors , but it provides no information about the attackers .
Thus , the main premise of honeypots , that there are no false positives because all activity is malicious , can not be guaranteed .
The information collected by honeypots is provided entirely by the attackers , and they are also developing techniques to understand whether they are running in controlled environments or not .
While cloud computing has generalised the use of virtualisation , there are other tell-tale signs that indicate control and monitoring .
Today ’ s best use of honeypots is probably within sensitive data , in the form of fake email addresses and fake rows or columns in databases .
8.6.3 Cyber-threat intelligence Honeypots have shown that it is useful to observe malicious activity , to capture malware and to detect new threats before they can spread widely .
In addition to honeypots , cyber-threat intelligence has included the dimension of information sharing , as increasingly required by national authorities .
Information sharing is both the outcome of data analytics [ 926 ] and is extremely useful for defenders to better understand the risks and possibilities for protection and mitigation .
Signatures , as is generally understood , are pieces of evidence of an ongoing attack .
IoCs generalise the concept in two ways .
First , they indicate evidence of an attack being prepared or of the evidence that remains after a system has been compromised by an attacker .
While early signature sharing attempts used the Snort signature language , the YARA language has been quite widely adopted and is , for example , the support of the YARA Signature Exchange Group , a non-commercial indicator of compromise exchange platform .
In order to support and regulate information sharing , the authorities have also promoted the creation of Information Sharing and Analysis Centers ( ISAC ) .
The objective is to facilitate information sharing between persons with similar organisations and objectives .
It also brings the economic dimension to cybersecurity , analysing the beneﬁts of information sharing for organisations for better efﬁciency .
8.6.4 Situational awareness Situational Awareness is a complex subject , which has been the subject of research both from a technical and a social sciences standpoint .
Early work focused on users operating complex systems , for example , pilots in aircrafts [ 929 ] , deﬁning situational awareness as a cognitive process , the perception of the elements in the environment within a volume of time and space , the comprehension of their meaning and the projection of their status in the near future .
In the context of cyberattacks and the digital society , this deﬁnition implies that CyberSA implies the awareness of any kind of suspicious or interesting activity taking place in cyberspace [ 894 ] .
The SIEM world is undergoing profound changes through regulation and the impact of cyberattacks .
From a regulation perspective , critical infrastructure operators are required to embed detection and mitigation capabilities .
This represents the instantiation of the European NIS directive in national law .
The most recent report on a cyber-incident simulation in June 2017 indicated that progress is still required in CyberSA , but that cooperation is increasing and that information sharing is of the utmost importance for appropriate decision-making .
Hence , systems will be compromised , and it is likely that attacks will bring them down , having a signiﬁcant impact .
There have been , for example , several instances of businesses shutting down for days due to ransomware attacks , such as Wannacry .
Beyond ensuring business continuity , technical and regulatory obligations require that investigations are undertaken , following a cybersecurity compromise .
This is a mandatory step in restoring an ICT system to a reliable state .
This step is where , beyond tools and processes , the human aspects are key , particularly education , training and exercising .
It deﬁnes three broad activities that an organisation must carry out , prepare itself for incidents , handle incidents when they occur , and follow up on incidents when they are closed .
Figure 8.5 : incident management lifecycle While the incident management topic comes at the end of the KA , it leverages all the capabilities and tools that have been described in the previous sections .
Full prevention has been demonstrated to be unfeasible , for ease of use and cost reasons on one hand , and because attackers have ways and imagination beyond what system designers envisage on the other hand .
Therefore , devoting resources to prevention versus response is highly organisation-speciﬁc , but it is an important exercise that must be carried out carefully because of the consequences it has for an organisation .
On one hand , prevention will increase the operational costs of an organisation .
On the other hand , relying only on response may lead to fatal consequences where the organisation would not be able to recover from an incident .
Also , responding properly to incidents incurs costs that should not be ignored .
Risk assessment is thus an integral part of incident management .
KA Security Operations & Incident Management | October 2019 Page 283 The Cyber Security Body Of Knowledge www.cybok.org 8.7.1 Prepare : Incident management planning As shown in ﬁgure 8.5 , the ﬁrst step in incident management is to put in place the appropriate processes and capabilities before an incident occurs .
This is , in fact , a legal requirement for all critical infrastructure operators , and is established by regulations such as the EU Network and Information Systems ( NIS ) directive .
Establishing policies and procedures relies on the structure of the organisation and the sector to which it belongs .
Policies must involve higher level management , in order to properly deﬁne the scope and the organisational structure that is devoted to incident management , as well as performance and reporting procedures .
Policies must include formalised response plans that provide a roadmap for implementing the incident response capability , based on risk assessment methods .
Plans should be reﬁned in procedures , in order to deﬁne standard operating procedures that can be quickly followed by responders to concretely deﬁne the actions that need to be taken when speciﬁc situations occur .
All of these policies , plans and procedures are organisation and sector-dependent , and will be affected by different regulations .
As an example , ﬁnancial organisations have to take into account the Basel II and Sarbanes-Oxley regulations in their incident management procedures , to properly implement reporting to regulators .
An important part of this preparation activity is related to communication in many forms .
First of all , regulations now generally require that incidents are reported to the authorities , either a national CERT hosted by a national cybersecurity agency , law enforcement agencies , or a sectoral organisation such as an ISAC .
It is also important beforehand to establish trusted communication channels with technology and service providers such as software vendors and Internet service providers .
Similar channels should be set up between peers such as CISOs , to facilitate sharing of early warnings and best practices .
Transnational organisers and facilitators of exchanges include the Computer Security Incident Response Teams ( TFCSIRT ) , the Forum of Incident Response and Security Teams ( FIRST ) and the European Union Agency for Cybersecurity ( ENISA ) .
Another constituency comprises customers , media and the general public .
Organisations should be ready to communicate when cyber-security incidents affect customers , or when they become largely visible .
Therefore , we expect that the requirements of GDPR compliance will have an impact on cyber-security , as organisations realise that they have to protect and monitor their systems to comply with this regulation .
This includes practical considerations such as the decision to handle incidents internally or to subcontract , fully or partially , the tasks to qualiﬁed MSSPs , the choice of a centralised or distributed organisation for incident response , and the reporting chain .
Choosing between a centralised or a distributed structure is guided by the structure of the organisation .
A distributed structure enables better proximity ( geographical as well as functional ) between the incident responders and the business units .
However , it may increase the required coordination efforts and cost .
It requires the ability to work under pressure , both internally ( to prevent the incident from propagating or blocking the organisation ) and externally ( to deal with management , regulatory or media pressure ) .
There is thus a need for qualiﬁed personnel to practise incident KA Security Operations & Incident Management | October 2019 Page 284 The Cyber Security Body Of Knowledge www.cybok.org response exercises , as is done in the military , for example .
It also requires continuous training in order to keep up with the most recent threats .
The integration of key people with the relevant communities such as ISACs or CERTs also helps information sharing and ensures that best practices are exchanged within the right community .
Analysis is related to incident investigation , to understand the extent of the compromise and of the damage to the systems , particularly data .
If data have been lost or altered , the damage might be extremely signiﬁcant .
Therefore , the investigation must assess what exactly was compromised , and what was not , as well as the time the compromise occurred .
This is extremely difﬁcult , due to the duration of certain attacks ( months ) , the stealthy techniques attackers deploy to remain hidden ( erasing logs or systems , encrypting communications ) , and the difﬁculty of freezing and interacting with systems ( attackers detecting interaction may take very destructive action ) and gathering evidence .
Mitigation is related to the deployment of emergency measures that can contain the incident and limit its impact .
Mitigation must ﬁrst limit the damage that is brought to systems , such as information erasure or disclosure , that an attacker could trigger if he is discovered .
It must also ensure that attackers do not propagate to other systems .
Containment may include blocking network accesses in certain perimeters , or shutting down services , systems or communications .
Containment may unfortunately have an adverse impact on desirable functions .
For example , cutting network access prevents attackers from communicating with compromised systems , but also makes patching them or backing them up more difﬁcult .
It is common that mitigation measures reveal additional information about the attacker , its methods and targets .
Hence , ﬁgure 8.5 includes a closed loop between analysis and mitigation , to emphasise the fact that analysis and mitigation should be understood as feeding each other .
As already mentioned in section 8.7.1 , communication is an integral part of incident handling .
Once the extent of the damage has been established , it is necessary to alert the authorities and comply with regulations as needed .
8.7.3 Follow-up : post-incident activities The ﬁnal step in an incident response is to verify that the full extent of the compromise has been realised and to clean up the system .
Restoring a system is also connected to reliability engineering , as system integrators must plan and system operators must maintain for restoration in the case of compromise .
Another important aspect of post-incident activities is to measure the performance of the team and the procedures , in order to improve them .
Another aspect of follow-up that should be taken into account is the impact of the incident .
While major incidents generally lead to post-mortem analysis and changes in policy , low-impact incidents may be left out of the follow-up procedure .
However , it is often the case that these low-impact incidents KA Security Operations & Incident Management | October 2019 Page 285 The Cyber Security Body Of Knowledge www.cybok.org take up a major part of the resources devoted to incident management and they should be explored as well .
Lessons learned from incidents should impact incident training , to ensure that responders are up to date with attacker methods .
It should also enable information sharing with peers , so that best practices are propagated to the community as a whole , to learn from incidents beyond the ones affecting each organisation .
The objective is to understand where and why the attack came from , and in particular the motivations of the attacker .
This will help restore the system to a working state and prevent later compromise .
Some of the work on attribution has focused on malware analysis , to provide technical evidence of the source of the attack .
The objective is to ﬁnd in the malware code evidence of its roots , such as code reuse or comments that may explain the motivations of the author .
This enables the deﬁnition of malware families , which then may help deﬁne more generic IoCs to detect the propagation of malicious code even if the exact variant is not known .
Malware authors do use many techniques to make this difﬁcult , as explained in section 8.3.1 .
Other works on attribution observe network activity to extract commonalities .
Groups of attackers may share Command and Control ( C & C ) infrastructures , thus attacks may come from the same IP addresses or use the same domain names .
However , attribution is very expensive , particularly if the objective is to use forensics techniques to support legal action .
At this point in time , forensics and attribution remain an extremely speciﬁc ﬁeld and are not included in Security Operations and Incident Management , because they require expertise , tools and time beyond what SIEM analysts manning consoles can provide .
Legal action using the information gathered through forensics techniques is discussed in the Forensics key area description .
8.8 CONCLUSION The Security Operations and Incident Management domain includes many topics .
From a technical standpoint , SOIM requires the ability to observe the activity of an Information System or network , by collecting traces that are representative of this activity .
It then requires the ability to analyse these traces in real time , or almost real time , to detect malicious events included in these traces , and to send out alerts related to these events .
The deﬁnition of a malicious event depends on the analysis technique and on the data source used to perform the detection .
Once an attack is detected , it must be reported and analysed on a SIEM platform , to assess the impact of the attack and to determine the potential remedial actions that can be applied to block the attack or mitigate its effects .
From an operational standpoint , SOIM is very much a process , and the deﬁnition of this process requires strong management .
It relies on people to perform many of the tasks , from conﬁguring the detectors to analysing the alerts to deciding on remediations .
Therefore , skilled analysts are one of the cornerstones of Security Operations and Incident Management .
Another key aspect is planning , as all the tools and personnel must be in place before anything can happen .
However , the heavy reliance of our society on digital tools , as well as the regulatory context , require that these tools and processes are put in place everywhere .
From a technical perspective , it is the process of identifying and reconstructing the relevant sequence of events that has led to the currently observable state of a target IT system or ( digital ) artifacts .
The importance of digital evidence has grown in lockstep with the fast societal adoption of information technology , which has resulted in the continuous accumulation of data at an exponential rate .
Simultaneously , there has been rapid growth in network connectivity and the complexity of IT systems , leading to more complex behaviour that may need investigation .
The primary purpose of this Knowledge Area is to provide a technical overview of digital forensic techniques and capabilities , and to put them into a broader perspective with regard to other related areas in the cybersecurity domain .
The discussion on legal aspects of digital forensics is limited only to general principles and best practices , as the speciﬁcs of the application of these principles tend to vary across jurisdictions .
For example , the Knowledge Area discusses the availability of different types of evidence , but does not work through the legal processes that have to be followed to obtain them .
Historically , this involved the systematic analysis of ( samples of ) physical material in order to establish causal relationships between various events , as well as to address issues of provenance and authenticity .
The rationale behind it , Locard ’ s exchange principle , is that physical contact between objects inevitably results in the exchange of matter , leaving traces that can be analysed to ( partially ) reconstruct the event .
With the introduction of digital computing and communication , which we refer to as the cyber domain , the same general assumptions were extended largely unchallenged .
Although a detailed conceptual discussion is beyond the scope of this chapter , it is important to recognise that the presence of a persistent digital ( forensic ) trace is neither inevitable , nor is it a “ natural ” consequence of the processing and communication of digital information .
These events can be the result of human-computer interaction , such as a user launching an application , or they can be the result of the autonomous operation of the IT system ( e.g .
Explicit traces directly record the occurrence of certain types of events as part of the normal operation of the system ; most prominently , these include a variety of timestamped system and application event logs .
Implicit traces take many forms , and allow the occurrence of some events to be deduced from the observed state of the system , or artifact , and engineering knowledge of how the system operates .
For example , the presence on a storage KA Forensics | October 2019 Page 290 The Cyber Security Body Of Knowledge www.cybok.org device of a unique chunk of data that is part of a known ﬁle can demonstrate that the ﬁle was likely to have been present once , and was subsequently deleted and partially overwritten .
The observed absence of normal log ﬁles can point to a security breach during which the perpetrators wiped the system logs as a means to cover their tracks .
Although they frequently exist , these traces of cyber interactions are the result of conscious engineering decisions that are not usually taken to speciﬁcally facilitate forensics .
This has important implications with respect to the provenance and authenticity of digital evidence , given the ease with which digital information can be modiﬁed .
9.1.1 Legal Concerns and the Daubert Standard The ﬁrst published accounts of misuse and manipulation of computer systems for illegal purposes such as theft , espionage and other crimes date back to the 1960s .
During the 1970s , the ﬁrst empirical studies of computer crime were carried out using established criminological research methods .
In many jurisdictions , legal statutes related to misuse of telecommunications are separate ( and older than ) those related to computer crimes .
We use the umbrella term cybercrime to collectively refer to all crimes related to computer and telecommunications misuse ; broadly , these include the use of cyber systems to commit any type of crime , as well as the criminal targeting of cyber systems .
As is usually the case , legal systems require time to assimilate new laws and integrate them into routine law practice .
Conversely , legislation usually requires corrections , clariﬁcation and uniﬁed interpretation in response to concerns encountered in the courtroom .
In brief , the Supreme Court instructed trial judges to become gatekeepers of expert testimony , and gave four basic criteria to evaluate the admissibility of forensic evidence : 1 .
The theoretical underpinnings of the methods must yield testable predictions by means of which the theory could be falsiﬁed .
There should be a known rate of error that can be used in evaluating the results .
The methods should be generally accepted within the relevant scientiﬁc community .
The court also emphasised that these standards are ﬂexible and that the trial judge has a lot of leeway in determining the admissibility of forensic evidence and expert witness testimony .
The Daubert criteria have been broadly accepted , in principle , by other jurisdictions subject to interpretation in the context of local legislation .
In the UK , the Law Commission for England and Wales proposed in consultation paper No .
The ACPO Good Practice Guide for Digital Evidence codiﬁes four basic principles for the acquisition and handling of digital evidence : 1 .
No action taken by law enforcement agencies , persons employed within those agencies or their agents should change data which may subsequently be relied upon in court .
In circumstances where a person ﬁnds it necessary to access original data , that person must be competent to do so and be able to give evidence explaining the relevance and the implications of their actions .
An audit trail or other record of all processes applied to digital evidence should be created and preserved .
An independent third party should be able to examine those processes and achieve the same result .
The person in charge of the investigation has overall responsibility for ensuring that the law and these principles are adhered to .
These principles seek to provide operational guidance to digital forensic investigators on how to maintain the integrity of the evidence and the investigative process , such that the evidence can be used in a court of law .
In the UK , the Forensic Science Regulator mandates that any provider of digital forensic science must be “ accredited to BS EN ISO/IEC 17020:2012 for any crime scene activity and BS EN ISO/IEC 17025:2005 for any laboratory function ( such as the recovery or imaging of electronic data ) ” [ 944 ] .
ISO/IEC 17025 [ 945 ] is an international standard specifying general requirements for the competence of testing and calibration laboratories ; in other words , the certiﬁcation attests to the quality and rigour of the processes followed in performing the forensic examination .
In the US , there is no strict legal requirement for digital forensic science providers to be certiﬁed to particular standards .
Most large federal and state forensic labs do maintain ISO 17025 certiﬁcations ; as of 2019 , eighty ﬁve of them have such credentials for the processing of digital evidence .
Digital forensic techniques are also applied in a much broader range of inquiries , such as internal corporate investigations , that often do not result in formal proceedings in public court .
Despite the fact that investigations may not require the same standard of proof , forensic analysts should always follow sound forensic practices in collecting and analysing the artifacts .
This includes adherence to any judicial requirements when working with inherently personal data , which can be a non-trivial concern when the investigation is multi-jurisdictional .
In such cases , it is important to seek timely legal advice to preserve the integrity of the inquiry .
KA Forensics | October 2019 Page 292 The Cyber Security Body Of Knowledge www.cybok.org 9.1.2 Deﬁnitions In 2001 , the ﬁrst Digital Forensics Research Workshop ( DFRWS ) was organised in response to the need to replace the prevalent ad hoc approach to digital evidence with a systematic , multi-disciplinary effort to ﬁrmly establish digital forensics as a rigorous scientiﬁc discipline .
The workshop produced an in-depth report outlining a research agenda and provided one of the most frequently cited deﬁnitions of digital forensic science in the literature : [ DFRWS ] Digital forensics is the use of scientiﬁcally derived and proven methods toward the preservation , collection , validation , identiﬁcation , analysis , interpretation , documentation and presentation of digital evidence derived from digital sources for the purpose of facilitating or furthering the reconstruction of events found to be criminal , or helping to anticipate unauthorised actions shown to be disruptive to planned operations .
[ 946 ] This deﬁnition , although primarily stressing the investigation of criminal actions , also includes an anticipatory element , which is typical of the notion of forensics in operational environments , and brings it closer to incident response and cyber defence activities .
In these situations , the analysis is primarily to identify the vector of attack and the scope of a security incident ; the identiﬁcation of adversaries with any level of certainty is rare and prosecution is not the typical outcome .
In contrast , the reference deﬁnition provided by NIST a few years later [ 940 ] is focused entirely on the legal aspects of forensics , and emphasises the importance of a strict chain of custody : [ NIST ] Digital forensics ( NIST ) is considered the application of science to the identiﬁcation , collection , examination , and analysis of data while preserving the integrity of the information and maintaining a strict chain of custody for the data .
Data refers to distinct pieces of digital information that have been formatted in a speciﬁc way .
The notion of relevance is inherently case-speciﬁc , and a large part of forensic analysts ’ expertise is the ability to identify evidence that concerns the case at hand .
Frequently , a critical component of forensic analysis is the causal attribution of event sequence to speciﬁc human actors of the system ( such as users , administrators , attackers ) .
The provenance , reliability , and integrity of the data used as evidence data is of primary importance .
According to this deﬁnition , we can view every effort made to perform system or artifact analysis after the fact as a form of digital forensics .
This includes common activities such as incident response and internal investigations , which almost never result in any legal action .
On balance , only a tiny fraction of forensic analyses make it to the courtroom as formal evidence , although this should not constrain us from exploring the full spectrum of techniques KA Forensics | October 2019 Page 293 The Cyber Security Body Of Knowledge www.cybok.org for reconstructing the past of digital artifacts .
The beneﬁt of employing a broader view of forensic computing is that it helps us to identify closely related tools and methods that can be adapted and incorporated into forensics .
9.1.3 Conceptual Models In general , there are two possible approaches to rebuilding the relevant sequence of events in the analysis of a cyber system from the available data sources – state-centric , and historycentric/log-centric .
The starting point for state-centric approaches is a snapshot of the state of the system of interest ; for example , the current content of a hard drive or another storage medium .
For example , if unique pieces of a known ﬁle are on the medium , but the ﬁle is not available via the normal ﬁle system interface , the most likely explanation is that the ﬁle was once stored in the ﬁle system but was subsequently deleted ( the space was marked for reuse ) and partially overwritten by newer ﬁles .
The main constraint here is the dearth of historical data points , which limits our ability to deduce the state of the system at any given point in the past .
For example , a packet capture contains the complete history of network communications over a period of time .
Operating Systems ( OSs ) maintain a variety of monitoring logs that detail various aspects of the operation of the OS kernel and different applications ; additional auditing and security monitoring tools can provide yet more potentially relevant events .
Thus , a log-rich environment contains potentially all the relevant details to an investigation ; the challenge is to sift through the log entries , which often number in the millions , to ﬁnd and put together the relevant events .
Historically , storage has been a precious resource in computer systems , leading to software designs that emphasise space efﬁciency by updating the information in place , and keeping a minimal amount of log information .
Over the last ten to ﬁfteen years , technology advances have made storage and bandwidth plentiful and affordable , which has led to a massive increase in the amount of log data maintained by IT systems and applications .
There is a clear trend towards increasing the amount and granularity of telemetry data being sent over the network by operating systems and individual applications as part of their normal operations .
Consequently , there is a substantial need to evolve a forensic methodology such that log information takes on a correspondingly higher level of importance .
In other words , the current period marks an important evolution in digital forensic methodology , one that requires substantial retooling and methodological updates .
However , it does not provide an overall view of how forensic experts actually perform an investigation .
This is particularly important in order to build forensic tools that better support cognitive processes .
Unfortunately , digital forensics has not been the subject of any serious interest on the part of cognitive scientists and there has been no coherent effort to document forensic investigations .
Although many of the tools are different , forensic and intelligence analysis are very similar in nature - in both cases analysts have to go through a mountain of raw data to identify ( relatively few ) relevant facts and put them together into a coherent story .
The beneﬁt of using this model is that : a ) it provides a fairly accurate description of the investigative process in its own right , and allows us to map the various tools to the different phases of the investigation ; b ) it provides a suitable framework for explaining the relationships of the various models developed within the area of digital forensics ; and c ) it can seamlessly incorporate information from other lines of the investigation .
The rectangular boxes represent different stages in the information processing pipeline , starting with raw data and ending with presentable results .
The arrows indicate transformational processes that move information from one box to another .
The x axis approximates the overall level of effort required to move information from the raw to the speciﬁc processing stage .
The y axis shows the amount of structure ( with respect to the investigative process ) in the processed information for every stage .
Thus , the overall trend is to move the relevant information from the lower left-hand to the upper righthand corner of the diagram .
In reality , the processing can both meander through multiple iterations of local loops and jump over phases ( for routine cases handled by an experienced investigator ) .
External data sources include all potential evidence sources for a speciﬁc investigation such as disk images , memory snapshots , network captures and reference databases such as hashes of known ﬁles .
The shoebox is a subset of all the data that have been identiﬁed as potentially relevant , such as all the email communications between two persons of interest .
At any given time , the contents of the shoebox can be viewed as the analyst ’ s approximation of the information content that is potentially relevant to the case .
The evidence ﬁle contains only the parts that are directly relevant to the case such as speciﬁc email exchanges on a topic of interest .
The schema contains a more organised version of the evidence such as a timeline of events or a graph of relationships , which allows higher-level reasoning over the evidence .
A hypothesis is a tentative conclusion that explains the observed evidence in the schema and , by extension , could form the ﬁnal conclusion .
Once the analyst is satisﬁed that the hypothesis is supported by the evidence , the hypothesis turns into a presentation , which is the ﬁnal product of the process .
The presentation usually takes on the form of an investigator ’ s report that both speaks to the high-level conclusions that are relevant to the legal case and also documents the low-level technical steps based on which the conclusion has been formed .
loop that involves the actions taken to ﬁnd potential sources of information , and which then queries them and ﬁlters them for relevance ; and a sense-making loop in which the analyst develops – in an iterative fashion – a conceptual model that is supported by the evidence .
Analysts apply these techniques in an opportunistic fashion with many iterations , in response to both newly discovered pieces of evidence , and to high-level investigative questions .
are searched for relevant data based on keywords , time constraints and others in an effort to eliminate the vast majority of irrelevant data .
• Read and extract : Collections in the shoebox are analysed to extract individual facts and relationships that can support or disprove a theory .
• Schematize : At this step , individual facts and simple implications are organised into a schema that can help organise and identify the signiﬁcance of and relationships between a growing number of facts and events .
This is not an easy process to formalise , and most forensic tools do not directly support it .
Therefore , the resulting schemas may exist on a piece of paper , on a whiteboard or only in the mind of the investigator .
Since the overall case could be quite complicated , individual schemas may cover speciﬁc aspects of it such as the discovered sequence of events .
• Build case : From the analysis of the schemas , the analyst eventually comes up with testable theories , or working hypotheses , that can explain the evidence .
A working hypothesis is a tentative conclusion and requires more supporting evidence , as well as rigorous testing against alternative explanations .
It is a central component of the investigative process and is a common point of reference that brings together the legal and technical sides in order to build a case .
The actual presentation may only contain the part of the story that is strongly supported by the digital evidence ; weaker points may be established by drawing on evidence from other sources .
9.1.3.3 Top-Down Processes Top-down processes are analytical – they provide context and direction for the analysis of less structured data search and they help organise the evidence .
Partial or tentative conclusions are used to drive the search for supporting and contradictory pieces of evidence .
• Search for relations : Pieces of evidence in the ﬁle can suggest new searches for facts and relations on the data .
• Search for information : The feedback loop from any of the higher levels can ultimately cascade into a search for additional information ; this may include new sources , or the re-examination of information that was ﬁltered out during previous passes .
The original set is then successively modiﬁed and narrowed down before the documents are read and analysed .
The foraging loop is a balancing act between three kinds of processing that an analyst can perform- explore , enrich and exploit .
Exploration effectively expands the shoebox by including larger amounts of data ; enrichment shrinks it by providing more speciﬁc queries that include fewer objects for consideration ; exploitation is the careful reading and analysis of an artifact to extract facts and inferences .
Information foraging in this context is a highly iterative process with a large number of incremental adjustments in response to the emerging evidence .
It is the responsibility of the investigator to keep the process on target and within the boundaries of any legal restrictions .
It is the process of creating situational awareness and understanding to support decision making in the face of uncertainty – an effort to understand connections between people , places and events in order to anticipate their trajectories and act effectively .
It is important to recognize that the described information processing loops are closely tied together and often trigger iterations in either directions .
New evidence may require a new working theory , whereas a new hypothesis may drive the search for new evidence to support or disprove it .
Analysis vs. Legal Interpretation Considering the overall process from Figure 9.1 , we gain a better understanding of the roles and relationships among the different actors .
At present , digital forensic researchers and tool developers primarily provide the means to acquire the digital evidence from the forensic targets , extract ( and logically reconstruct ) data objects from it , and the essential tools to search , ﬁlter , and organize it .
It is often predicated in securing the necessary legal rulings in multiple jurisdictions , as well as the cooperation of multiple organizations .
Forensic investigators are the primary users of these technical capabilities , employing them to analyse speciﬁc cases and to present legally-relevant conclusions .
It is the responsibility of the investigator to drive the process and to perform all the information foraging and sensemaking tasks .
As the volume of the data being analysed continues to grow , it becomes ever more critical for the forensic software to offer higher levels of automation and abstraction .
Data analytics and natural language processing methods are starting to appear in dedicated forensic software , and – going forward – an expanding range of statistical and machine learning tools will need to be incorporated into the process .
Legal experts operate in the upper right-hand corner of the depicted process in terms of building/disproving legal theories .
Thus , the investigator ’ s task can be described as the translation of highly speciﬁc technical facts into a higher level representation and theory that explains them .
The explanation is almost always connected to the sequence of the actions of the people that are part of the case , such as suspects , victims , and witnesses .
In summary , investigators need not be forensic software engineers , but they must be technically proﬁcient enough to understand the signiﬁcance of the artifacts extracted from data KA Forensics | October 2019 Page 298 The Cyber Security Body Of Knowledge www.cybok.org sources , and they must be able to read the relevant technical literature ( peer-reviewed articles ) in full .
As the sophistication of the tools grows , investigators will need to have a working understanding of a growing list of data science methods that are employed by the tools in order to correctly interpret the results .
Similarly , analysts must have a working understanding of the legal landscape , and they must be able to produce a competent report and present their ﬁndings on the witness stand , if necessary .
9.1.3.7 Forensic Process The deﬁning characteristic of forensic investigations is that their results must be admissible in court .
This entails following established procedures for acquiring , storing , and processing of the evidence , employing scientiﬁcally established analytical tools and methods , and strict adherence to a professional code of practice and conduct .
Starting with the data acquisition process , an investigator must follow accepted standards and procedures in order to certify the provenance and maintain the integrity of the collected evidence .
In brief , this entails acquiring a truthful copy of the evidence from the original source using validated tools , keeping custodial records and detailed case notes , using validated tools to perform the analysis of the evidence , crossvalidating critical pieces of evidence , and correctly interpreting the results based on peerreviewed scientiﬁc studies .
As discussed in the following section , data acquisition can be performed at different levels of abstraction and completeness .
The traditional gold standard is a bit-level copy of the forensic target , which can then be analysed using knowledge of the structure and semantics of the data content .
As storage devices increase in complexity and encryption becomes the default data encoding , it is increasingly infeasible to obtain a true physical copy of the media and a ( partial ) logical acquisition may be the only possibility .
Further , local data may be treated by the courts as having higher levels of privacy protection than data shared with a third party , such as a service provider .
The notion of reproducibility is central to the scientiﬁc validity of forensic analysis ; starting with the same data and following the same process described in the case notes should allow a third party to arrive at the same result .
Processing methods should have scientiﬁcally established error rates and different forensic tools that implement the same type of data processing should yield results that are either identical , or within known statistical error boundaries .
The investigator must have a deep understanding of the results produced by various forensic computations .
Some of the central concerns include : inherent uncertainties in some of the source data , the possibility for multiple interpretations , as well as the recognition that some of the data could be fake in that it was generated using anti-forensics tools in order to confuse the investigation .
The latter is possible because most of the data item used in the forensic analysis is produced during the normal operation of the system , and is not tamperproof .
For example , an intruder with sufﬁcient access privileges can arbitrarily modify any of the millions of ﬁle timestamps potentially making timeline analysis – a core analytical technique – unreliable .
Experienced forensic analysts are alert to such issues and seek , whenever possible , to corroborate important pieces of information from multiple sources .
Forensic tool validation is a scientiﬁc and engineering process that subjects KA Forensics | October 2019 Page 299 The Cyber Security Body Of Knowledge www.cybok.org speciﬁc tools to systematic testing in order to establish the validity of the results produced .
For example , data acquisition software must reliably produce an unmodiﬁed and complete copy of the class of forensic targets it is designed to handle .
The organizational aspect of the forensic process , which dictates how evidence is acquired , stored , and processed is critical to the issue of admissibility .
Strict adherence to established standards and court-imposed restriction is the most effective means of demonstrating to the court that the results of the forensic analysis are truthful and trustworthy .
The volume of data contained by a forensic target typically far exceeds the amount of data relevant to an inquiry .
Therefore , in the early stages of an investigation , the focus of the analysis is to ( quickly ) identify the relevant data and ﬁlter out the irrelevant .
Such initial screening of the content , often referred to as triage , results in either follow up deep examination , or in deprioritisation , or removal of the target from further consideration .
Legally , there can be a number of constraints placed on the triage process based on the the case and the inherent privacy rights in the jurisdiction .
Such results are inherently less reliable than a deep examination as it is easy to create a mismatch between data attribute and actual content .
Therefore , courts may place constraints on the use of computers by convicted offenders to facilitate fast screening by ofﬁcers in the ﬁeld without impounding the device .
To be precise , the actual investigative targets are not individual pieces of hardware , but the different Operating System ( OS ) modules controlling the hardware subsystems and their respective data structures .
Our discussion takes a high level view of OS analysis – it is beyond the scope of the Knowledge Area to delve into the engineering details of how different classes of devices are analysed .
For example , smartphones present additional challenges with respect to data acquisition ; however , they are still commodity computers with the vast majority of them running on a Linux kernel .
The same applies to other classes of embedded devices , such as UAVs and vehicle infotainment systems .
Applications request resources and services from the OS via the system call interface and employ them to utilize them to accomplish a speciﬁc task .
System analysis employs knowledge of how operating systems function in order to reach conclusions about events and actions of interest to the case .
Average users have very little understanding of the type of information operating systems maintain about their activities , KA Forensics | October 2019 Page 300 The Cyber Security Body Of Knowledge www.cybok.org and usually do not have the knowledge and/or privilege level to tamper with system records thereby making them forensically useful , even if they do not ﬁt a formal deﬁnition for secure and trustworthy records .
is the primary source of evidence for most digital forensic investigations .
Although the importance of ( volatile ) memory forensics in solving cases has grown signiﬁcantly , a thorough examination of persistent data has remained a cornerstone of most digital forensic investigations .
9.2.1.1 Data Abstraction Layers Computer systems organise raw storage in successive layers of abstraction – each software layer ( some may be in ﬁrmware ) builds an incrementally more abstract data representation that is only dependent on the interface provided by the layer immediately below it .
At the lowest level , every storage device encodes a sequence of bits and it is possible , in principle , to use a custom mechanism to extract the data bit by bit .
Depending on the underlying technology , this can be an expensive and time-consuming process , and often requires reverse engineering .
One example of this process is the acquisition of mobile phone data , in some of which it is possible to physically remove ( desolder ) the memory chips and perform a true hardware-level acquisition of the content [ 958 ] .
Another practical approach is to employ engineering tools that support the hardware development process and employ , for example , a standard JTAG interface [ 959 ] – designed for testing and debugging purposes – to perform the necessary data acquisition .
In practice , the lowest level at which typical examinations are performed is the Host Bus Adapter ( HBA ) interface .
All physical media eventually fail and ( part of ) the stored data may become unavailable .
Depending on the nature of the failure , and the sophistication of the device , it may be possible to recover at least some of the data .
For example , it may be possible to replace the failed controller of a HDD and recover the content .
Such hardware recovery becomes more difﬁcult with more integrated and complex devices .
The typical HBA presents a block device abstraction – the medium is presented as a sequence of ﬁxed-size blocks , commonly consisting of 512 or 4096 bytes , and the contents of each block can be read or written using block read/write commands .
The typical data acquisition process works at the block device level to obtain a working copy of the forensic target – a process known as imaging – on which all further processing is performed .
Historically , the term sector is used to refer to the data transfer units of magnetic hard disks ; a ( logical ) block is a more general term that is independent of the storage technology and physical data layout .
The block device has no notion of ﬁles , directories or – in most cases – which blocks are considered allocated and which ones are free ; it is the ﬁlesystem ’ s task to organise the block storage into a ﬁle-based store in which applications can create ﬁles and directories with all of their relevant metadata attributes – name , size , owner , timestamps , access permissions etc .
User applications use the ﬁlesystem to store various artifacts that are of value to the end-user – documents , images , messages etc .
The operating system itself also uses the ﬁle system to store its own image – executable binaries , libraries , conﬁguration and log ﬁles , registry entries – and to install applications .
Some application artifacts such as compound documents have a complex internal structure integrating multiple artifacts of different types .
An analysis of application artifacts tends to yield the most immediately relevant results , as the recorded information most directly relates to actions and communications initiated by people .
As the analysis goes deeper ( to a lower level of abstraction ) , it requires greater effort and more expert knowledge to independently reconstruct the actions of the system .
This knowledge is particularly costly to obtain from a closed system such as Microsoft Windows , because of the substantial amount of blackbox reverse engineering involved .
Despite the cost , independent forensic reconstruction is of critical importance for several reasons : • It enables the recovery of evidentiary data not available through the normal data access interface .
• It forms the basis for recovering partially overwritten data .
• It allows the discovery and analysis of malware agents that have subverted the normal functioning of the system , thus making the data obtained via the regular interface untrustworthy .
The target machine is powered down , an exact bit-wise copy of the storage media is created , the original is stored in an evidence locker and all the forensic work is performed on the copy .
There are exceptions to this workﬂow in cases where it is not practical to shut down the target system and , therefore , a media image is obtained while the system is live .
Evidently , such an approach does not provide the same level of consistency guarantees , but it can still yield valuable insights .
The problem of consistency , also referred to as data smearing , does not exist in virtualised environments , where a consistent image of the virtual disk can be trivially obtained by using the built-in snapshot mechanism .
As already discussed , obtaining data from the lowest level system interface available and independently reconstructing higher-level artifacts is considered the most reliable approach to forensic analysis .
This results in a strong preference for acquiring data at lower levels of abstraction and the concepts of physical and logical acquisition .
Physical data acquisition is the process of obtaining the data directly from hardware media , without the mediation of any ( untrusted ) third-party software .
KA Forensics | October 2019 Page 302 The Cyber Security Body Of Knowledge www.cybok.org An increasingly common example of this approach is mobile phone data acquisition that relies on removing the physical memory chip [ 958 ] and reading the data directly from it .
More generally , getting physical with the evidence source is usually the most practical and necessary method for low-end embedded systems with limited hardware capabilities .
Physical acquisition also affords access to additional over-provisioned raw storage set aside by the storage device in order to compensate for the expected hardware failures .
As a general rule , devices offer no external means to interrogate this shadow storage area .
Chip-off techniques present their own challenges in that the process is inherently destructive to the device , the data extraction and reconstruction requires additional effort , and the overall cost can be substantial .
For general-purpose systems , tools use an HBA protocol such as SATA or SCSI to interrogate the storage device and obtain a copy of the data .
The resulting image is a block-level copy of the target that is generally referred to as physical acquisition by most investigators ; Casey uses the more accurate term pseudo-physical to account for the fact that not every area of the physical media is acquired and that the order of the acquired blocks does not necessarily reﬂect the physical layout of the device .
In some cases , it is necessary to perform additional recovery operations before a usable copy of the data is obtained .
One common example is RAID storage devices , which contain multiple physical devices that function together as a single unit , providing built-in protection against certain classes of failures .
In common conﬁgurations such as RAID 5 and 6 the content acquisition of individual drives is largely useless without the subsequent step of RAID data reconstruction .
This has two major implications : a ) the numbering of the data blocks is completely separated from the actual physical location ; and b ) it is possible for the storage controller itself to become compromised [ 961 ] , thus rendering the acquisition process untrustworthy .
These caveats notwithstanding , we will refer to block-level acquisition as being physical , in line with the accepted terminology .
Logical data acquisition relies on one or more software layers as intermediaries to acquire the data from the storage device .
The integrity of this method hinges on the correctness and integrity of the implementation of the API , or protocol .
In addition to the risk , however , there is also a reward – higher level interfaces present a data view that is closer in abstraction to that of user actions and application data structures .
Experienced investigators , if equipped with the proper tools , can make use of both physical and logical views to obtain and verify the evidence relevant to the case .
The workhorse of forensic imaging is the dd Unix/Linux general purpose command-line utility , which can produce a binary copy of any ﬁle , device partition or entire storage device .
A hardware write blocker is often installed on the target device to eliminate the possibility of operator error , which can lead to the accidental modiﬁcation of the target .
Cryptographic hashes are computed for the entire image and ( preferably ) for every block ; the KA Forensics | October 2019 Page 303 The Cyber Security Body Of Knowledge www.cybok.org latter can be used to demonstrate the integrity of the remaining evidence if the original device suffers a partial failure , which makes it impossible to read its entire contents .
The National Institute of Standards and Technology ( NIST ) maintains the Computer Forensic Tool Testing ( CFTT ) project [ 962 ] , which independently tests various basic tools , such as write blockers and image acquisition tools and regularly publishes reports on its ﬁndings .
Encryption Concerns Apart from having the technical capability to safely interrogate and acquire the content of a storage device , one of the biggest concerns during data acquisition can be the presence of encrypted data .
Modern encryption is pervasive and is increasingly applied by default to both stored data and data in transit over the network .
By deﬁnition , a properly implemented and administered data security system , which inevitably employs encryption , will frustrate efforts to acquire the protected data and , by extension , to perform forensic analysis .
There are two possible paths to obtaining encrypted data – technical and legal .
The technical approach relies on ﬁnding algorithmic , implementation , or administrative errors , which allow the data protection to be subverted .
Although it is nearly impossible to create a complex IT system that has no bugs , the discovery and exploitation of such deﬁciencies is becoming increasingly more difﬁcult and resource intensive .
The legal approach relies on compelling the person with knowledge of the relevant encryption keys to surrender them .
This is relatively new legal territory and its treatment varies across jurisdictions .
In the UK , the Regulation of Investigatory Powers Act 2000 speciﬁes the circumstances under which individuals are legally required to disclose the keys .
Disclosure may run counter the legal right against self-incrimination and in some jurisdictions , such as in the United States , it is not yet deﬁnitively resolved .
The remainder of this discussion assumes that access to the raw data is ensured by either technical , or legal means , which are beyond the scope of this knowledge area .
9.2.3 Filesystem Analysis A typical storage device presents a block device interface with Bmax number of blocks of size Bsize .
All read and write I/O operations are executed at the granularity of a whole block ; historically , the standard block size adopted by HDD manufacturers has been 512 bytes .
Regardless of the base block size , many operating systems manage storage in clusters ; a cluster is a contiguous sequence of blocks and is the smallest unit at which raw storage is allocated/reclaimed .
Thus , if the device block/sector size is 4KiB but the chosen cluster size is 16KiB , the OS will allocate blocks in groups of four .
For administration purposes , the raw drive may be split into one or more contiguous areas called partitions , each of which has a designated use and can be independently manipulated .
Partitions can further be organised into volumes – a physical volume maps onto a single partition , whereas a logical volume can integrate multiple partitions potentially from multiple devices .
Volumes present a block device interface but allow for the decoupling of the physical media organisation from the logical view presented to the operating system .
With a few exceptions , volumes/partitions are formatted to accommodate a particular ﬁle KA Forensics | October 2019 Page 304 The Cyber Security Body Of Knowledge www.cybok.org system ( ﬁlesystem ) , which organizes and manages the blocks to create the abstraction of ﬁles and directories together with their relevant metadata .
The Operating System ( OS ) , as part of its system call interface used by applications to request services , provides a ﬁlesystem API that allows applications to create , modify and delete ﬁles ; it also allows ﬁles to be grouped into a hierarchical structure of directories ( or folders ) .
As a general rule , the format and interpretation of ﬁle content is almost always outside the purview of the operating system ; it is the concern of relevant applications acting on behalf of users .
A ﬁle system ( ﬁlesystem ) is an OS subsystem that is responsible for the persistent storage and organisation of user and system ﬁles on a partition/volume .
It provides a high-level standard API such as POSIX , that is used by applications to store and retrieve ﬁles by name without any concern for the physical storage method employed or the layout of the data ( and metadata ) content .
Filesystem forensics uses knowledge of the ﬁlesystem ’ s data structures and the algorithms used to create , maintain , and delete them to : a ) extract data content from devices independently of the operating system instance which created it ; and b ) extract leftover artifacts to which the regular ﬁlesystem API does not offer access .
The ﬁrst feature is important to ensure that the data are not being modiﬁed during acquisition and that any potential security compromises do not affect the validity of the data .
The second provides access to ( parts of ) deallocated ﬁles that have not been overwritten , purposely hidden data , and an implied history of the ﬁlesystem operation – the creation/deletion of ﬁles – that is not explicitly maintained by the OS .
9.2.4 Block Device Analysis Before the OS can organise a ﬁlesystem on a raw device , it typically splits it into a set of one or more disjoint partitions .
Partitions are the basic method used for coarse-grained storage management ; they allow a single physical device to be dedicated to multiple purposes such as hosting different ﬁlesystems or separating system from user ﬁles .
If a subdivision is not needed , the entire device can be trivially allocated to a single partition .
Logical volumes allow storage capacity from different devices to be pooled transparently ( to the ﬁlesystem ) to simplify the use of available capacity .
They also enable automated blocklevel replication in the form of RAIDs [ 964 ] for enhanced performance and durability .
KA Forensics | October 2019 Page 305 The Cyber Security Body Of Knowledge www.cybok.org 9.2.5 Data Recovery & File Content Carving One of the early staples of data recovery tools was the ‘ undelete ’ functionality , which can reverse the effects of users deleting data .
The most common case is that of users deleting a ﬁle and needing to reverse the operation .
A more difﬁcult case is a HDD that has been in use for some time and that has been subsequently formatted ( e.g .
The often employed quick format command has the effect of overlaying a set of data structures that correspond to an empty ﬁlesystem ( a full format sanitizes the content of the media but can take hours to complete so it is used less frequently ) .
Thus , the normal ﬁlesystem interface , after querying these structures , will report that there are no ﬁles .
The reality is that – at that moment – only ﬁlesystem metadata has been partially overwritten , and all the data blocks representing the ﬁle content are still present on the media in full .
Unless a user has taken special measures to securely wipe a hard disk , at any given time the media contains recoverable application artifacts ( ﬁles ) that have ostensibly been deleted .
The process of restoring the artifacts is commonly accomplished by carving .
File ( content ) carving is the process of recovering and reconstructing ﬁle content directly from block storage without using the ﬁlesystem metadata .
More generally , data ( structure ) carving is the process of reconstructing logical objects ( such as ﬁles and database records ) from a bulk data capture ( disk/RAM image ) without using metadata that describes the location and layout of the artifacts .
File carving is the oldest and most commonly used , technique and its basic form is based on two simple observations : a ) most ﬁle formats have speciﬁc beginning and end tags ( a.k.a .
No fragmentation is the most typical case , as modern ﬁlesystems require extra effort to ensure sequential layout for optimal performance .
Nested content is often the result of deletion ; in the example , after the initial sequential back-to-back layout of the ﬁles , the content ahead and behind ﬁle B was deleted and replaced by A .
This case can be solved by making multiple passes – once B is carved out ( and its blocks removed from further consideration ) the content of A becomes contiguous , so a subsequent pass will readily extract it .
tween , which also determines how difﬁcult the reconstruction is ; if the content in the middle is easily distinguished from the content of the ﬁle ( e.g .
, the pieces of text in the middle of a compressed image ) then the problem is relatively easy .
Otherwise , it is ambiguous and it could be quite difﬁcult to identify the matching pieces .
Interleaved content is a more complicated version of nesting which happens when larger ﬁles are used to ﬁll the gaps created by the deletion of smaller ones .
This simple carving approach usually yields a good number of usable artifacts ; however , real data can contain a number of atypical patterns , which can lead to a large number of repetitive and/or false positive results .
One major reason is that ﬁle formats are not designed with carving in mind and rarely have robust internal metadata that connect the constituent pieces together .
Some do not even have a designated header and/or footer , and this can result in a large number of false positives , potentially producing results substantially larger in volume than the source data .
Both RAM and persistent storage are almost always allocated in multiples of a chosen minimum allocation units .
Therefore , at the end of the allocated space , there is storage capacity – slack space – that is not used by the application , but is also not available for other uses .
The application will fully use the ﬁrst three blocks , but will only use 2KiB from the last block .
This creates the potential to store data that would be inaccessible via the standard ﬁlesystem interface and can provide a simple means to hide data .
Slack space is the difference between the allocated storage for a data object , such as ﬁle , or a volume , and the storage in actual use .
KA Forensics | October 2019 Page 307 The Cyber Security Body Of Knowledge www.cybok.org Once aware of the potential for storing hidden data in slack space , it is relatively easy to identify and examine it , and this is a standard step in most investigations .
As solid state drives continue to grow in capacity and displace hard disks from an increasing proportion of operational data storage , ﬁle carving ’ s utility is set to diminish over time .
The reason lies in the fact that SSD blocks need to be written twice in order to be reused ( the ﬁrst write resets the state of the block , thereby enabling its reuse ) .
To improve performance , the TRIM and UNMAP commands were added to the ATA and SCSI command sets , respectively ; they provide a mechanism for the ﬁlesystem to indicate to the storage device which blocks need to be garbage collected and prepared for reuse .
9.3 MAIN MEMORY FORENSICS [ 966 ] The early view of best forensic practices was to literally pull the plug on a machine that was to be impounded .
The rationale was that this would remove any possibility of alerting the processes running on the host and would preempt any attempts to hide information .
Over time , experience has shown that these concerns were largely exaggerated and that the substantial and irreversible loss of important forensic information such as open connections and encryption keys was rarely justiﬁed .
It is practical to identify and enumerate all the running processes , threads and loaded systems modules ; we can obtain a copy of the individual processes ’ code , stack , heap , code , and data segments .
All this is particularly useful when analysing compromised machines , as it allows the identiﬁcation of suspicious services , abnormal parent/child relationships , and , more generally , to search for known symptoms of compromise , or patterns of attack .
It is practical for identifying any open ﬁles , shared libraries , shared memory , and anonymously mapped memory .
This is particularly useful for identifying correlated user actions and ﬁle system activities , potentially demonstrating user intent .
It is practical for identifying open and recently closed network connections and protocol information , as well as sending and receiving queues of data not yet sent or delivered , respectively .
This information could readily be used to identify related parties and communication patterns between them .
Just like the ﬁlesystem , the memory management system tends to be reactive and leaves a lot of artifact traces behind .
This is primarily an effort to avoid any processing that is not absolutely necessary for the functioning of the system ; caching disk and network data tends to leave traces in memory for a long time .
The remote operator has full control over the monitored system and can take snapshots of speciﬁc processes , or the entire system .
Live investigations are an extension of regular security preventive mechanisms , which allow for maximum control and data acquisition ; they are primarily used in large enterprise deployments .
The main conceptual problem of working on a live system is that , if it is compromised , the data acquisition and analysis results are not trustworthy ; therefore , forensic analysis is most frequently performed on a snapshot of the target system ’ s RAM .
Analysing a snapshot is considerably more difﬁcult than working with a live system , which provides access to the state of the running system via a variety of APIs and data structures .
In contrast , a raw memory capture offers no such facilities and forensic tools need to rebuild the ability to extract semantic information from the ground up .
This is a semantic gap problem , and the purpose of memory forensics is to bridge it .
The goal of the analysis is to objectively establish causal dependencies between data input and output , as a function of the user interactions with the application .
Depending on whether an application is an open or closed source and on the level of the accompanying documentation , the analytical effort required can vary from reading detailed speciﬁcations to reverse engineering code , data structures and communication protocols , to performing time-consuming black box differential analysis experiments .
Alternatively , forensic tool vendors may license code from the application vendor to gain access to the proprietary data structures .
The big advantage of analysing applications is that we have a better chance of observing and documenting direct evidence of user actions , which is of primary importance to the legal process .
Also , the level of abstraction of the relevant forensic traces tend to have a level of abstraction corresponding to a particular domain .
9.4.1 Case Study : the Web Browser Although there are at least four major web browsers in common use , after more than 20 years of development , their capabilities have converged , thus allowing us to talk about them in common terms .
At present , there are no practical barriers to maintaining a complete browsing history ( a log of visited websites ) , and making it available to users is a major usability feature ; most users rarely delete this information .
Separately , service providers such as Google and Facebook , are interested in this information for commercial reasons , and make it easy to share a browsing log with multiple devices .
Combined with the content of the local ﬁle cache , the browsing history allows an investigator to almost look over the shoulder of the user of interest as they were navigating the Web .
In particular , analysing user queries to search engines is among the most commonly employed techniques .
The search query is KA Forensics | October 2019 Page 309 The Cyber Security Body Of Knowledge www.cybok.org encoded as part of the URL , and can often provide very clear and targeted clues as to what the user was trying to accomplish .
Browsers offer the convenience of remembering auto-completing passwords and other form data ( such as address information ) .
This can be very helpful to an investigator , especially if the user is less security conscious and does not use a master password to encrypt all of this information .
The local ﬁle cache provides its own chronology of web activities , including a stored version of the actual web objects that were downloaded and shown to the user ( these may no longer be available online ) .
Although caching has become considerably less effective owing to the increased use of dynamic content , this is tempered by the large increase in available storage capacity , which places very few , if any , practical constraints on the amount of data cached .
Downloaded ﬁles are , by default , never deleted providing another valuable source of activity information .
HTML5 local storage provides a standard means for web applications to store information locally ; for example , this could be used to support disconnected operations , or to provide a measure of persistence for user input .
Accordingly , the same interface can be interrogated to reconstruct web activities .
Cookies are opaque pieces of data used by servers to keep a variety of information on the web client in order to support transactions such as web mail sessions .
In practice , most cookies are used by websites to track user behaviour , and it is well-documented that some providers go to great lengths to make sure that this information is resilient .
Some cookies are time-limited access tokens that can provide access to online accounts ( until they expire ) ; others have a parsable structure and may provide additional information .
Most local information is stored in SQLite databases , which provide a secondary target for data recovery .
9.5 CLOUD FORENSICS Cloud computing is fast emerging as the primary model for delivering information technology ( IT ) services to Internet-connected devices .
It brings both disruptive challenges for current forensic tools , methods and processes , as well as qualitatively new forensic opportunities .
It is not difﬁcult to foresee that , after an intermediate period of adjustment , digital forensics will enter a new period marked by substantially higher levels of automation and will employ much more sophisticated data analytics .
Cloud computing environments will greatly facilitate this process , but not before bringing about substantial changes to currently established tools and practices .
KA Forensics | October 2019 Page 310 Software as a Service ( SaaS ) Platform as a Service ( PaaS ) Application Application Data Data Runtime Runtime Runtime Middleware Middleware Operating System Virtualization Hardware Operating System Virtualization Hardware Customer Infrastructure as a Service ( IaaS ) Data Customer Application Cloud Service Providers Middleware Cloud Service Providers Cloud Service Providers The Cyber Security Body Of Knowledge www.cybok.org Operating System Virtualization Hardware Figure 9.3 : Layers of cloud computing environment owned by customer and cloud service provider on three service models : IaaS , PaaS , and SaaS ( public cloud ) .
9.5.1 Cloud Basics Conceptually , cloud-based IT abstracts away the physical compute and communication infrastructure , and allows customers to rent as much compute capacity as needed .
[ 141 ] The cloud is enabled by a number of technological developments , but its adoption is driven primarily by business considerations , which drive changes to how organisations and individuals use IT services .
Accordingly , it also changes how software is developed , maintained and delivered to its customers .
In actual deployments , the distinctions can be blurred and many cloud deployments ( and potential investigative targets ) incorporate elements of all of these .
The differences between the models are best understood when we consider the virtualised computing environments as a stack of layers : hardware such as storage , and networking ; virtualisation , consisting of a hypervisor allowing the installation and lifecycle management of virtual machines ; operating system , installed on each virtual machine ; middleware and runtime environment ; and application and data .
Each of the cloud models splits the responsibility between the client and the Cloud Service Provider ( CSP ) at different levels in the stack ( Figure 9.3 ) .
In a private ( cloud ) deployment , the entire stack is hosted by the owner and the overall forensic picture is very similar to the problem of investigating a non-cloud IT target .
Data ownership is clear , as is the legal and procedural path to obtain it ; indeed , the very use of the term ‘ cloud ’ in this situation is not particularly signiﬁcant to a forensic inquiry .
Figure 9.3 shows the typical ownership of layers by customer and service providers under different service models .
In hybrid deployments , layer ownership can be split between the customer and the provider , and/or across multiple providers .
Further , it can change over time , as , for example , the customer may handle the base load on private infrastructure , but burst into the public cloud to handle peak demand , or system failures .
KA Forensics | October 2019 Page 311 The Cyber Security Body Of Knowledge www.cybok.org 9.5.2 Forensic Challenges The main technical challenges to established forensic practices can be summarised as follows .
The existing forensic toolset is almost exclusively built to work with the leftover artifacts of prior computations .
It relies on algorithmic knowledge of different OS subsystems such as the ﬁlesystem in order to interpret the physical layout of the data as acquired from the device .
Physical acquisition is almost completely inapplicable to the cloud , where data moves , resources are shared and ownership and jurisdictional issues can be complicated .
Cloud service APIs are emerging as the primary new interface through which data acquisition is being performed .
The cloud is the authoritative data source .
Another important reason to query cloud services for relevant information is that they store the primary historical record of computations and interactions with users .
Most residual information on the client , such as a cloud drive is transient and often of uncertain provenance .
Instead of one monolithic piece of code , the application logic is decomposed into several layers and modules that interact with each other over well-deﬁned service interfaces .
Once the software components and their communication are formalised , it becomes easy to organise extensive logging of every aspect of the system .
Indeed , it becomes critical to have this information just to be able to debug , test and monitor cloud applications and services .
These developments point to logs ( of user and system activities ) becoming the primary source of forensic information .
The immediate implication is that much more will be explicitly known – as opposed to deduced – about the historical state of applications and artifacts .
This will require a new set of data analytics tools and will completely transform the way forensic investigations are performed .
It will also bring new challenges in terms of long-term case data preservation .
The key attribute of the client/standalone model is that practically all computations take place on the device itself .
Applications are monolithic , self-contained pieces of code that have immediate access to user input and consume it instantly with ( almost ) no traces left behind .
Since a large part of forensics comprises attributing the observed state of a system to user-triggered events , forensic research and development has relentlessly focused on two driving problems – discovering every last piece of log/timestamp information , and extracting every last bit of discarded data left behind by applications or the operating system .
The cloud model , particularly SaaS , completely breaks with this approach – the computation is split between the client and the server , with the latter performing the heavy computational lifting and the former performing predominantly user interaction functions .
Code and data are downloaded on demand and have no persistent place with regard to the client .
The direct consequence is that the vast majority of the established forensic tool chain becomes irrelevant , which points to a clear need for a different approach .
On the client ( or standalone ) device , it is easy to identify where the computations are performed and where the results/traces are stored .
The new software delivery model – Software as a Service ( SaaS ) – is subscription-based and did not start becoming practical until the widespread adoption of fast broadband access some ten to ﬁfteen years ago .
It also requires the development of new tools that can work in the new deployment environment , where the code execution is split between the server and the client devices , the primary storage interface is a service API and the application artifacts are not persistently stored on the device ( although local storage may be used as a cache ) .
Cloud drive services , such as Dropbox , Google Drive and Microsoft OneDrive are the SaaS version of the local storage device , which is central to modern digital forensics .
The problem of cloud drive acquisition , a clear ﬁrst investigative step , is a good illustration of the challenges and opportunities offered by SaaS with respect to forensics .
However , this approach offers no guarantees with respect to the accuracy and completeness of the acquisition .
The most obvious problem is that there is no guarantee that any of the clients attached to an account will have a complete copy of the ( cloud ) drive ’ s content .
As data accumulates online , it quickly becomes impractical to keep full replicas on every device ; indeed , it is likely that most users will have no device with a complete copy of the data .
Furthermore , the acquisition tool needs direct access to the cloud drive ’ s metadata to ascertain its contents ; without this information , the acquisition is of an unknown quality , subject to potentially stale and omitted data .
Most drive services provide some form of revision history ; the look-back period varies , but this is a standard feature that users expect , especially in paid services .
Although there are some analogous data sources in traditional forensics , such as archival versions of important OS data structures , the volume and granularity of the revision information in cloud application are qualitatively and quantitatively different .
Revisions reside in the cloud and clients rarely have anything but the most recent version in their cache ; a client-side acquisition will clearly miss prior revisions , and does not even have the means to identify these omissions .
The mass movement towards web-based applications means that forensics needs to learn how to deal with a new problem – digital artifacts that have no serialised representation in the local ﬁlesystem .
For example , Google Docs documents are stored locally as a link to the document which can only be edited via a web app .
Acquiring an opaque link without the actual content of the document has minimal forensic utility .
Most services provide the means to export the web app artifact in a standard format such as PDF ; KA Forensics | October 2019 Page 313 The Cyber Security Body Of Knowledge www.cybok.org however , this can only be accomplished by requesting directly from the service ( manually or via an API ) .
In summary , bringing the traditional client-side approach to drive acquisition to bear on SaaS acquisition has major conceptual ﬂaws that are beyond remediation ; a new approach is needed , one that obtains the data directly from the cloud service .
9.6.1 Finding a Known Data Object : Cryptographic Hashing The lowest common denominator for all digital artifacts is to consider them as a sequence of bits/bytes without trying to parse , or assign any semantics to them .
Despite this low level of abstraction , some crucial problems can be addressed , the most important one being to identify known content , usually ﬁles .
Cryptographic hashing is the ﬁrst tool of choice when investigating any case ; it provides a basic means of validating data integrity and identifying known artifacts .
Ideally , given a set of different inputs , the hash function will map them onto different outputs .
Hash functions are collision-resistant if it is computationally infeasible to ﬁnd two different inputs for which the output is the same .
The former is used to validate the integrity of the forensic target by comparing before-and-after results at important points in the investigation ( e.g .
, to demonstrate that the integrity of the evidence throughout the chain of custody ) whereas the latter are used to work with known ﬁles .
This involves either removing from consideration common ﬁles such as OS and application installations or pinpointing known ﬁles of interest such as malware and contraband .
Other organisations and commercial vendors of digital forensic tools provide additional hash sets of other known data .
This makes 1 A discussion on the known vulnerabilities of cryptographic hash functions is outside the scope of this text .
KA Forensics | October 2019 Page 314 The Cyber Security Body Of Knowledge www.cybok.org it possible to load a reference set of that size in the main memory and ﬁlter out , on the ﬂy , any known ﬁles in the set as data is read from a forensic target .
9.6.2 Block-Level Analysis In addition to whole ﬁles , investigators are often interested in discovering known ﬁle remnants , such as those produced when a ﬁle is marked as deleted and subsequently partially overwritten .
One routinely used method to address this problem is to increase the granularity of the hashes by splitting the ﬁles into ﬁxed-size blocks and storing the hash for each individual block .
The block size is commonly set to 4 KiB to match the minimum allocation unit used by most operating systems ’ installations .
Given a block-based reference set , a forensic target ( RAM capture or disk image ) can be treated as a sequence of blocks that can be read block by block , hashed and compared to the reference set .
In this context , we say that a block is distinct , if the probability that its exact content arises by chance more than once is vanishingly small .
If we knew for a fact that a speciﬁc block was unique and speciﬁc to a particular ﬁle , then ( in terms of evidentiary value ) ﬁnding it on a forensic target would be almost the same as ﬁnding the entire ﬁle from which it was derived .
In practice , we can not deﬁnitely know the distinctiveness of every possible data block ; therefore , we use an approximating assumption based on empirical data : “ If a ﬁle is known to have been manufactured using some high-entropy process , and if the blocks of that ﬁle are shown to be distinct throughout a large and representative corpus , then those blocks can be treated as if they are distinct .
Apart from the direct use of blocks as trace evidence for the ( past or current ) presence of known ﬁles , block hashes can be used to improve ﬁle carving results by excluding every known blocks before performing the carving process .
This can improve results by reducing gaps and eliminating certain classes of false positive results .
9.6.3 Approximate Matching A natural generalisation of the problem of ﬁnding identical data objects is to ﬁnd similar ones .
At the lowest level , artifacts can be treated as bit strings ; at the highest levels , similarity techniques could employ , for example , natural language processing and image recognition methods to provide a level of reasoning that is much closer to that of a human analyst .
With regard to the whole spectrum of similarity methods , lower-level ones are more generic and computationally affordable , whereas higher-level ones tend to be more specialised and require considerably more computational resources .
Therefore , we would expect a forensic investigation to customise its use of AM techniques based on the goals of the analysis and the target data .
In the case of containment , we compare artifacts that have a large disparity in terms of size and seek to establish whether a larger one contains ( pieces of ) a smaller one .
The difference between resemblance and containment is case-speciﬁc and the same tool may work in both cases .
However , it is important for analysts to put the tool results into the correct context and to understand the performance envelope of the tools they are using in order to correctly interpret the results .
The notion of similarity is speciﬁc to the particular context in which it is used .
An approximate matching algorithm works by deﬁning two essential elements – features and a similarity function .
Features are the atomic components derived from the artifacts through which the artifacts are compared .
Comparing two features yields a binary outcome – zero or one – indicating whether the feature match was successful or not .
The set of all the features computed by an algorithm for a given artifact constitutes a feature set .
It can be viewed as an approximate representation of the original object for the purposes of matching it with other objects .
The similarity function maps a pair of feature sets to a similarity range ; it is increasingly monotonic with respect to the number of matching features .
It is useful to consider three general classes of approximate matching algorithms .
Bytewise matching considers the objects it compares to a sequence of bytes , and makes no effort to parse or interpret them .
Consequently , the features extracted from the artifact are also byte sequences , and these methods can be applied to any data blob .
The utility of the result depends heavily on the encoding of the data .
If small changes to the content of the artifact result in small changes to the serialised format ( e.g .
Syntactic matching relies on parsing the format of an object , potentially using this knowledge to split it into a logical set of features .
For example , a zip archive or a PDF document could easily be split into constituent parts without understanding the underlying semantics .
The beneﬁt is that this results in a more accurate solution with more precisely interpretable results ; the downside is that it is a more specialised solution , requiring additional information to parse different data formats .
Semantic matching ( partially ) interprets the data content in order to derive semantic features for comparison .
Examples include perceptual hashes that can detect visually similar images , and methods of information retrieval and natural language processing that can ﬁnd similarities in the subject and content of text documents .
Researchers use a variety of terms to name the different approximate matching methods they KA Forensics | October 2019 Page 316 The Cyber Security Body Of Knowledge www.cybok.org have developed : fuzzy hashing and similarity hashing refer to bytewise approximate matching ; perceptual hashing and robust hashing refer to semantic approximate matching techniques .
Bytewise Approximate Matching algorithms are the most frequently used AM algorithms in forensics ; they follow an overall pattern of extracting a feature set and generating a similarity digest , followed by a comparison of the digests .
It often employs hashing and other techniques to minimise the footprint of the set and to facilitate fast comparison .
9.6.4 Cloud-Native Artifacts Forensic analysis of cloud systems is still in its early stages of development , but it will quickly grow in importance .
[ 975 ] Unlike traditional applications , in which the persistent state takes the form of ﬁles in a local ﬁle system , web apps download the necessary state on the ﬂy and do not rely on local storage .
Recall that a web app ’ s functionality is split between server and client components , and the two communicate via web APIs .
Conceptually , this is analogous to the process of opening and reading the content of a local ﬁle by an application installed on a device .
The main difference is that cloud artifacts are internal data structures that , unlike a ﬁle , are not readily available for analysis .
For example , internally , Google Docs ’ documents are represented as the complete history ( log ) of every editing action performed on it ; given valid credentials , this history is available via Google Docs ’ internal API .
It is also possible to obtain a snapshot of the artifact of interest in a standard format such as a PDF , via the public API .
However , this is inherently forensically deﬁcient in that it ignores potentially critical information on the evolution of a document over time .
9.7 CONCLUSION Digital forensics identiﬁes and reconstructs the relevant sequence of events that has led to a currently observable state of a target IT system or ( digital ) artifacts .
The provenance and integrity of the data source and the scientiﬁc grounding of the investigative tools and methods employed are of primary importance in determining their admissibility to a court of law ’ s proceedings .
Digital forensic analysis is applied to both individual digital artifacts such as ﬁles and to complex IT systems comprising multiple components and networked processes .
One aspect is a change of emphasis from state-centric analysis , which seeks to deduce events and actions by looking at different snapshots and applying knowledge about the system ’ s operations , to log-centric analysis , which employs explicitly collected log entries to infer the sequence of relevant ( to the inquiry ) events .
Some of the most important emerging questions in digital forensics are the analysis of the large variety of IoT devices , which are forecast to increase in number to as many as 125 billion by 2030 , and the employment of machine learning/AI in order to automate and scale up forensic processing .
The presentation is at a level needed for an instructor in a module in cryptography ; so they can select the depth needed in each topic .
Whilst not all experts in cyber-security need be aware of all the technical aspects mentioned below , we feel they should be aware of all the overall topics and have an intuitive grasp as to what they mean , and what services they can provide .
Our focus is mainly on primitives , schemes and protocols which are widely used , or which are suitably well studied that they could be used ( or are currently being used ) in speciﬁc application domains .
Cryptography by its very nature is one of the more mathematical aspects of cyber-security ; thus this chapter contains a lot more mathematics than one has in some of the other chapters .
The overall presentation assumes a basic knowledge of either ﬁrst-year undergraduate mathematics , or that found in a discrete mathematics course of an undergraduate Computer Science degree .
The chapter is structured as follows : After a quick recap on some basic mathematical notation ( Section 10.1 ) , we then give an introduction to how security is deﬁned in modern cryptography .
Then in Sections 10.6 and 10.7 we discuss the standard methodologies for performing public key encryption and public key signatures , respectively .
Then in Section 10.8 we discuss how these basic schemes are used in various standard protocols ; such as for authentication and key agreement .
All of the sections , up to and including Section 10.8 , focus exclusively on constructions which have widespread deployment .
Section 10.9 begins our treatment of constructions and protocols which are less widely used ; but which do have a number of niche applications .
These sections are included to enable the instructor to prepare students for the wider applications of the cryptography that they may encounter as niche applications become more mainstream .
The chapter assumes the reader wants to use cryptographic constructs in order to build secure systems , it is not meant to introduce the reader to attack techniques on cryptographic primitives .
Indeed , all primitives here can be assumed to have been selected to avoid speciﬁc attack vectors , or key lengths chosen to avoid them .
Further details on this can be found in the regular European Key Size and Algorithms report , of which the most up to date version is [ 977 ] .
For a similar reason we do not include a discussion of historical aspects of cryptography , or historical ciphers such as Caesar , Vigenère or Enigma .
These are at best toy examples , and so have no place in a such a body of knowledge .
They are best left to puzzle books .
The standard example of ﬁnite abelian groups of prime order used in cryptography are elliptic curves .
The group law is a classic law dating back to Newton and Fermat called the chord-tangent process .
This will be important later in Section 10.2.3 to ensure the discrete logarithm problem in the elliptic curve is hard .
Some cryptographic schemes make use of lattices which are discrete subgroups of the subgroups of Rn .
The basic design procedure is to deﬁne the syntax for a cryptographic scheme .
This gives the input and output behaviours of the algorithms making up the scheme and deﬁnes correctness .
Then a security model is presented which deﬁnes what security goals are expected of the given scheme .
Then , given a speciﬁc instantiation which meets the given syntax , a formal security proof for the instantiation is given relative to some known hard problems .
The security proof is not an absolute guarantee of security .
It is a proof that the given instantiation , when implemented correctly , satisﬁes the given security model assuming some hard problems are indeed hard .
Thus , if an attacker can perform operations which are outside the model , or manages to break the underlying hard problem , then the proof is worthless .
However , a security proof , with respect to well studied models and hard problems , can give strong guarantees that the given construction has no fundamental weaknesses .
In the next subsections we shall go into these ideas in more detail , and then give some examples of security statements ; further details of the syntax and security deﬁnitions can be found in [ 982 , 983 ] .
At a high level the reason for these deﬁnitions is that the intuitive notion of a cryptographic construction being secure is not sufﬁcient enough .
For example the natural deﬁnition for encryption security is that an attacker should be unable to recover the decryption key , or the attacker should be unable to recover a message encrypted under one ciphertext .
Whilst these ideas are necessary for any secure scheme they are not sufﬁcient .
We need to protect against an attacker aims for ﬁnd some information about an encrypted message , when the attacker is able to mount chosen plaintext and chosen ciphertext attacks on a legitimate user .
10.2.1 Syntax of Basic Schemes The syntax of a cryptographic scheme is deﬁned by the algorithms which make up the scheme , as well as a correctness deﬁnition .
The correctness deﬁnition gives what behaviour one can expect when there is no adversarial behaviour .
This process of an attacker trying to obtain a speciﬁc goal is called a security game , with the attacker winning the game , if they can break this security goal with greater probability than random guessing .
This advantage in probability over random guessing is called the adversary ’ s advantage .
The capabilities are expressed in terms of what oracles , or functions , we give the adversary access to .
The attacker is modelled as an arbitrary algorithm , or Turing machine , A , and if we give the adversary access to oracles then we write these as subscripts AO .
In our naive security game ( called OW-PASS ) the adversary has no oracles and its goal is simply to recover the message underlying a given ciphertext .
Here , negligible and polynomial time are measured in terms of a security parameter ( which one can think of as the key size ) .
Note , for OW-PASS this assumes that the message space is not bigger than the space of all possible keys .
Also note , that this is an asymptotic deﬁnition , which in the context of schemes with ﬁxed key size , makes no sense .
In such situations we require that ( t/Adv ) is greater than some given concrete bound such as 2128 , since it is believed that performing an algorithm requiring 2128 steps is infeasible even for a nation-state adversary .
In the context of encryption ( both symmetric and public key ) the above naive security goal is not seen as being suitable for real applications .
This asks the adversary to ﬁrst come up with two plaintexts , of equal length , and then the challenger ( or environment ) encrypts one of them and gives the resulting challenge ciphertext to the adversary .
In the context of a passive attack this gives an advantage statement as given in the second part of Figure 10.1 , where the two stages of the adversary are given by A1 and A2 .
In terms of encryption , the above passive attack is almost always not sufﬁcient in terms of capturing real-world adversarial capabilities , since real systems almost always give the attacker additional attack vectors .
These are a Chosen Plaintext Attack ( or CPA capability ) , in which KA Cryptography | October 2019 Page 325 The Cyber Security Body Of Knowledge www.cybok.org the adversary is given access to an encryption oracle to encrypt arbitrary messages of his choice , and a Chosen Ciphertext Attack ( or CCA capability ) , in which the adversary has both an encryption and decryption oracle .
In the case of a public key scheme the adversary always has access to an encryption oracle because it can encrypt plaintexts for itself using the public key , so in this case PASS and CPA are equivalent .
In the case of a CCA capability we restrict the decryption oracle so that the adversary may not ask of it the challenge ciphertext c∗ ; otherwise it can trivially win the security game .
Thus the advantage of an IND-CCA adversary against a public key encryption scheme would be deﬁned as the third deﬁnition in Figure 10.1 .
Other security deﬁnitions are possible for encryption ( such as Real-or-Random ) but the above are the main ones .
We make no assumption about whether the message has any meaning , indeed , the attacker wins if he is able to create a signature on any bit-string .
If the adversary is given no oracles then he is said to be mounting a passive attack , whilst if the adversary is given a tag generation ( resp .
In the latter case the ﬁnal forgery must not be one of the outputs of the given oracle .
In the case of MAC security , one may also give the adversary access to a tag veriﬁcation oracle .
However , for deterministic MACs this is implied by the CMA capability and is hence usually dropped , since veriﬁcation only involves re-computing the MAC .
Again we deﬁne an advantage and require this to be negligible in the security parameter .
For digital signatures the advantage for the UF-CMA game is given by the fourth equation in Figure 10.1 .
10.2.3 Hard Problems As explained above , security proofs are always relative to some hard problems .
These hard problems are often called cryptographic primitives , since they are the smallest atomic object from which cryptographic schemes and protocols can be built .
Such cryptographic primitives come in two ﬂavours : Either they are keyed complexity theoretic deﬁnitions of functions , or they are mathematical hard problems .
In the case of mathematical hard problems we have a similar formulation , but the deﬁnitions are often more intuitive .
It is known that the function can easily be inverted if the modulus N can be factored , but it is unknown if inverting the function implies N can be factored .
In ﬁnite abelian groups of known order ( usually assumed to be prime ) , one can deﬁne other problems .
Generally speaking , the mathematical hard problems are used to establish the security of public key primitives .
This has led designers to try to build cryptographic schemes on top of mathematical primitives which do not appear to be able to be broken by a quantum computer .
The best algorithms to solve these hard problems are lattice reduction algorithms , a nice survey of these algorithms and applications can be found in [ 985 ] .
Example : Putting the above ideas together , one may encounter statements such as : The public key encryption scheme XYZ is IND-CCA secure assuming the RSA-problem is hard and AES is a PRP .
This statement tells us that any attack against the XYZ scheme must either be against some weakness in the implementation , or must come from some attack not captured in the IND-CCA model , or must come from solving the RSA-problem , or must come from showing that AES is not a PRP .
10.2.4 Setup Assumptions Some cryptographic protocols require some setup assumptions .
These are assumptions about the environment , or some data , which need to be satisﬁed before the protocol can be considered secure .
Another setup assumption is the existence of a string ( called the Common Reference String or CRS ) available to all parties , and which has been set up in a trusted manner , i.e .
such that no party has control of this string .
Other setup assumptions could be physical , for example , that the algorithms have access to good sources of random numbers , or that their internal workings are not susceptible to an invasive attacker , i.e .
10.2.5 Simulation and UC Security The above deﬁnitions of security make extensive use of the notion of indistinguishability between two executions .
Indeed , many of the proof techniques used in the security proofs construct simulations of cryptographic operations .
A simulation is an execution which is indistinguishable from the real execution , but does not involve ( typically ) the use of any key material .
Another method to produce security models is the so-called simulation paradigm , where we ask that an adversary can not tell the simulation from a real execution ( unless they can solve some hard problem ) .
This paradigm is often used to establish security results for more complex cryptographic protocols .
executions of one instance of the protocol in one environment .
To cope with arbitrarily complex executions and composition of cryptographic protocols an extension to the simulation paradigm exists called the Universal Composability ( UC ) framework .
However , the fact that it does not provide IND-CPA security is obvious , as the encryption scheme is determinisitic .
The scheme is unsuitable in almost all modern environments as one requires a key as long as the message and the key may only be used once ; hence the name one-time pad .
10.3.2 Secret Sharing Secret sharing schemes allow a secret to be shared among a set of parties so that only a given subset can reconstruct the secret by bringing their shares together .
The person who constructs the sharing of the secret is called the dealer .
The set of parties who can reconstruct the secret are called qualiﬁed sets , with the set of all qualiﬁed sets being called an access structure .
Any set which is not qualiﬁed is said to be an unqualiﬁed set , and the set of all unqualiﬁed sets is called an adversary structure .
The access structure is usually assumed to be monotone , in that if the parties in A can reconstruct the secret , then so can any super-set of A .
Many secret sharing schemes provided information-theoretic security , in that any set of parties which is unqualiﬁed can obtain no information about the shared secret even if they have unbounded computing power .
Here we allow any subset of t+1 parties to reconstruct the secret , whereas any subset of t parties is unable to learn anything .
Reconstruction of the value s from a subset of more than t values si can be done using Lagrange interpolation .
Replicated secret sharing is a second popular scheme which supports any monotone access structure .
Given a boolean formula deﬁning who should have access to the secret , one can deﬁne a secret sharing scheme from this formula by replacing all occurrences of AND with + and all occurrences of OR with a new secret .
Replicated secret sharing is the scheme obtained in this way when putting the boolean formulae into Conjunctive Normal Form .
An adversary structure is said to be Qi if no set of i unqualiﬁed sets have union the full set of players .
they take as input a secret key , whilst in practice one often considers hash functions which are unkeyed .
As explained in the introduction we will not be discussing in this report cryptanalysis of symmetric primitives , we will only be examining secure constructions .
However , the main two techniques for attacks in this space are so-called differential and linear cryptanalysis .
Despite their names such functions should not be thought of as an encryption algorithm .
The design of block ciphers is a deep area of subject in cryptography , analogous to the design of number theoretic one-way functions .
Much like number-theoretic one-way functions , cryptographic constructions are proved secure relative to an associated hard problem which a given block cipher is assumed to satisfy .
It is also assumed that inverting this permutation is also easy ( if the key is known ) .
In which case we require the block cipher is a PRF .
One can never prove that a block cipher is a PRP , so the design criteria is usually a task of building a mathematical construction which resists all known attacks .
The main such attacks which one resists are so-called linear cryptanalysis , where one approximates non-linear components within the block cipher by linear functions , and differential cryptanalysis , where one looks at how two outputs vary on related input messages , e.g .
The design of a block cipher is made up of a number of simpler components .
There are usually layers of simple ﬁxed permutations , and layers of table lookups .
There are two main techniques to design block ciphers .
Despite this , the Feistel constructions still maintain the overall invertibility of the block cipher construction .
In general , the Feistel construction requires more rounds than the Substitution-Permutation network construction .
The DES algorithm dates from the 1970s , and the key size is now considered far too small for any application .
The AES algorithm has hardware support on many microprocessors , making operations using AES much faster than using other cryptographic primitives .
Readers who wish to understand more about the design of the AES block cipher referred to [ 989 ] .
the codomain of the function is essentially unbounded .
However , the stream cipher is usually reserved for constructions which are special-purpose and for which the hardware complexity is much reduced .
Clearly , a stream cipher can not be a permutation , but we require that no polynomial time adversary can distinguish oracle access to the stream cipher from oracle access to a uniformly random function with inﬁnite co-domain .
The design of stream ciphers is more ad-hoc than that of the design of block ciphers .
In addition , there is less widespread adoption outside speciﬁc application areas .
The interested reader is referred to the outcome of the eStream competition for details of speciﬁc ad-hoc stream cipher designs [ 990 ] .
10.4.3 Hash Functions Hash functions are much like block ciphers in that they should act as PRFs .
Since a PRF needs to be keyed to make any sense in theoretical tracts , a hash function is usually a keyed object .
In practice , we often require an unkeyed object , in which case one considers the actual hash function used to have an implicit inbuilt ﬁxed key , and have been chosen from a function family already .
The above methodology requires a method to pad the initial input block to encode the length , and it suffers from a number of practical issues .
For example , there are obvious length extension attacks ( namely a hash on a message m can be extended to a hash on mkm0 without knowing the whole of m ) which render the use of such hash functions problematic in some applications .
In the ﬁrst phase , one enters data into the sponge state and , in the second phase , one squeezes data out from the sponge .
The size of c is directly related to the security of the construction .
Further details on sponge constructions , and the further objects one can construct from them , and the SHA-3 design in particular can be found at the Keccak web page [ 991 ] .
10.4.3.3 Random Oracle Model Many cryptographic constructions are only secure if one assumes that the hash function used in the construction behaves ‘ like a random oracle ’ .
Such constructions are believed to be secure in the real world , but theoretically , they are less pleasing .
One can think of a proof of security in the random oracle model as a proof in which we allow the attacker to have their usual powers ; however , when they ( or any of the partners they are attacking ) call the underlying hash function the call is made to an external party via an oracle call .
it does not use any algorithm to generate the random values .
All that is required is that if the input is given to the oracle twice , then the same output is always returned .
This clearly does not capture attacks in which the adversary makes clever use of exactly how the hash function is deﬁned etc , and how this deﬁnition interacts with other aspects of the scheme/protocol under analysis .
However , this modelling methodology has proved remarkably good in enabling cryptographers to design schemes which are secure in the real world .
To provide such symmetric cryptographic constructions , one needs a scheme , which takes the primitive and then utilizes this in a more complex construction to provide the required cryptographic service .
In the context of symmetric encryption , these are provided by modes of operation .
10.5.1 Modes of Operation Historically , there have been four traditional modes of operation to turn a block cipher into an encryption algorithm .
In recent years , the CTR mode has also been added to this list .
Thus , modern systems use modes which provide this level of security , also enabling additional data ( such as KA Cryptography | October 2019 Page 334 The Cyber Security Body Of Knowledge www.cybok.org session identiﬁers ) to be tagged into the encryption algorithm .
Such algorithms are called AEAD methods ( or Authenticated Encryption with Associated Data ) .
In such algorithms , the encryption primitive takes as input a message to be encrypted , plus some associated data .
Decryption will only work if both the key is correct and the associated data is what was input during the encryption process .
The simplest method to obtain an AEAD algorithm is to take an IND-CPA mode of operation such as CBC or CTR , and then to apply a MAC to the ciphertext and the data to be authenticated , giving us the so-called Encrypt-then-MAC paradigm .
In such a construction , it is important that the MAC is applied to the ciphertext as opposed to the message .
Thus , new constructions of AEAD schemes have been given which are more efﬁcient .
The most widely deployed of these is GCM ( or Galois Counter Mode ) , see Figure 10.4 , which is widely deployed due to the support for this in modern processors .
KA Cryptography | October 2019 Page 335 The Cyber Security Body Of Knowledge www.cybok.org One time AEAD constructions , otherwise known as DEMs , can be obtained by simply making the randomized AEAD deterministic by ﬁxing the IV to zero .
10.5.2 Message Authentication Codes Message authentication codes can be produced in roughly the same manner as modes of operation .
In particular , the standard MAC function is to utilize CBC mode with a zero-IV , and then to output the ﬁnal ciphertext block as the MAC tag , thus producing a deterministic MAC function .
On its own , even with suitable padding of the message , this is only secure when used with ﬁxed length messages .
For example , the ﬁnal CBC ciphertext block is then passed through another application of the underlying block cipher , but using a different key .
The GCM AEAD method of the previous section can be thought of as an Encrypt-then-MAC construction , with the IND-CPA encryption being CTR mode , and the MAC function being a function called GMAC .
Although this is rarely used on its own as a MAC function .
Hash functions can also be used to construct MAC functions .
The most famous of these is HMAC which is a construction designed for use with Merkle–Damgård-based hash functions .
Since Merkle–Damgård-based hash functions suffer from length extension attacks , the HMAC function requires two applications of the underlying hash function .
As HMAC is designed speciﬁcally for use with Merkle–Damgård-based hash functions , it makes no-sense to use this construction when using a sponge based hash function such as SHA-3 .
In this function , the sponge construction is used to input a suitably padded message , then the required MAC output is taken as the squeezed output of the sponge ; whereas as many bits as squeezed are as needed for the MAC output .
10.5.3 Key Derivation and Extendable Output Functions The security deﬁnition of a deterministic MAC is essentially equivalent to the deﬁnition that the output of the MAC function is indistinguishable from a random string , if one does not know the underlying secret key .
As such , MAC functions can be used for other cryptographic operations .
Such functions are called KDFs or XOFs ( for Key Derivation Function and Extendable Output Function ) .
Usually , one uses the term KDF when the output is of a ﬁxed length , and XOF when the output could be of an arbitrary length .
Such functions can take an arbitrary length input string , and produce another arbitrary length output string which is pseudo-random .
There are three main constructions for such functions ; one based on block ciphers , one on the Merkle–Damgård hash functions , and one based on sponge-based hash functions .
The constructions based on a block cipher are , at their heart , using CBC-MAC , with a zero key to compress the input string into a cryptographic key and then use the CTR mode of operation KA Cryptography | October 2019 Page 336 The Cyber Security Body Of Knowledge www.cybok.org under this key to produce the output string .
As one can imagine , the functions based on Keccak are simpler—one simply inputs the suitably padded message into the sponge and then squeezes as many output bits out as required .
Special KDFs can also be deﬁned which take as input a low entropy input , such as a password or PIN , and produce a key for use in a symmetric algorithm .
These password based key derivation functions are designed to be computationally expensive , so as to mitigate problems associated to brute force attacking of the underlying low entropy input .
10.5.4 Merkle-Trees and Blockchains An application of cryptographic hash functions which has recently come to prominance is that of using Merkle-Trees and by extension blockchains .
The root node is then publicly published .
Merkle-Trees enable efﬁcient demonstration that a leaf node is contained in the tree , in that one simply presents the path of hashes from the leaf up to the root node .
Thus veriﬁcation is logarithmic in the number of leaf nodes .
Merkle-Trees can verify any form of stored data and have been used in various protocols such as version control systems , such as Git , and backup systems .
A block chain is a similar structure , but now the data items are aligned in a chain , and each node hashes both the data item and a link to the previous item in the chain .
Block chains are used in cryptocurrencies such as Bitcoin , but they have wider application .
The key property a blockchain provides is that ( assuming the current head of the chain is authenticated and trusted ) the data provides an open distributed ledger in which previous data items are immutable , and the ordering of data items is preserved .
The encryption algorithm uses the public key , whilst the decryption algorithm uses the secret key .
The standard security requirement for public key encryption is that the scheme should be IND-CCA .
Note that since the encryption key is public we have that IND-PASS is the same as IND-CPA for a public key encryption scheme .
KA Cryptography | October 2019 Page 337 The Cyber Security Body Of Knowledge www.cybok.org 10.6.1 KEM-DEM Philosophy In general , public key encryption schemes are orders of magnitude less efﬁcient than symmetric key encryption schemes .
Whereas , a DEM , or Data Encryption Mechanism , is essentially the same as an INDCCA symmetric encryption scheme , which has key space K. Since a DEM is only ever used once with the same key , we can actually use a weaker notion of IND-CCA encryption for the DEM , in which the adversary is not given access to an encryption oracle ; which means the DEM can be deterministic .
It is usual for the syntax of the encapsulation algorithm to not take any input , bar the randomness , and then to return both the ciphertext and the key which it encapsulates .
10.6.2 Constructions based on RSA The simplest public key encryption scheme is the RSA scheme , which is based on the difﬁculty of factoring integers .
Note that given the pk only , ﬁnding the secret key sk is provably equivalent to factoring N .
It is not believed that inverting the RSA map is equivalent to factoring , so inversion of this map is identiﬁed as a separate problem ( the RSA problem ) .
At the time of writing , one should select p and q to be primes of at least 1536 bits in length to obtain suitable security .
There are many historic ways of using the RSA function as a public key encryption scheme , many of which are now considered obsolete and/or insecure .
The two recommended methodologies in using RSA for encryption are RSA-OAEP and RSA-KEM ; which are both IND-CCA secure in the random oracle model .
OAEP , or Optimized Asymmetric Encryption Padding , is a method to use the RSA function directly as an IND-CCA public key encryption algorithm .
10.6.3 Constructions based on Elliptic Curves Elliptic Curve Cryptography , or ECC , uses the fact that elliptic curves form a ﬁnite abelian group .
In terms of encryption schemes , the standard method is to use ECIES ( Elliptic Curve Integrated Encryption Scheme ) to deﬁne a public key , KEM which is IND-CCA in the random oracle model , assuming the DDH problem in the subgroup of the elliptic curve being used .
For ECIES , the KeyGen algorithm is deﬁned as follows .
KA Cryptography | October 2019 Page 339 The Cyber Security Body Of Knowledge www.cybok.org 10.6.4 Lattice-based Constructions A major problem with both RSA and ECC primitives is that they are not secure against quantum computers ; namely , Shor ’ s algorithm will break both the RSA and ECC hard problems in polynomial time .
Hence , the search is on for public key schemes which would resist the advent of a quantum computer .
The most prominent of these so-called post-quantum schemes are those based on hard problems on lattices .
In particular , the NTRU schemes and a variety of schemes based on the Learning With Errors ( LWE ) problem , and its generalisation to polynomial rings , known as the Ring-LWE problem .
There are other proposals based on hard probles in coding theory , on the difﬁculty of computing isogenies between elliptic curves and other constructs .
This binding of public key with an entity is done via means of a so called digial certiﬁcate .
This certiﬁcate is issued by a certiﬁcate authority , and utilizes the second main public key construct ; namely a digital signature .
Just as with public key encryption algorithms , modern digital signature algorithms are based either on the RSA problem or a variant of the discrete logarithm problem ; hence the reader is also directed again to [ 981 ] for more advanced details .
For post-quantum security , there are a number of proposals based on lattice constructions ; but none have yet been widely accepted or deployed at the time of writing this document .
The prototypical digital signature scheme given in text-books is loosely called RSA-FDH , where FDH stands for Full Domain Hash .
Despite the close relationship to RSA-FDH , the above signature scheme has no proof of security , and hence a more modern scheme is usually to be preferred .
10.7.1 RSA-PSS The modern way to use the RSA primitive in a digital signature scheme is via the padding method called PSS ( Probabilistic Signature Scheme ) .
each application of the signing algorithm on the same message will produce a distinct signature , and it has a proof of security in the random oracle model relative to the difﬁculty of solving the RSA problem .
The two most well known of these are the DSA ( Digital Signature Algorithm ) method and a method due to Schnorr .
The former has widespread deployment but establishing security via security proofs uses less well-accepted assumptions , whereas the latter is less deployed but has well-established security proofs .
We will describe both algorithms in the context of elliptic curves .
The key difference in the two algorithms is not the signing and veriﬁcation equations ( although these do affect performance ) , but the fact that , with the Schnorr scheme , the r value is also entered into the hash function to produce e. This small distinction results in the different provable security properties of the two algorithms .
A key aspect of both EC-DSA and Schnorr signatures is that they are very brittle to exposure of the per-message random nonce k. If only a small number of bits of k leak to the attacker with every signing operation , then the attacker can easily recover the secret key .
Almost all cryptographic protocols make use of the primitives we have already discussed ( encryption , message authentication , secret sharing ) .
In this section , we discuss the two most basic forms of protocol , namely authentication and key agreement .
10.8.1 Authentication Protocols In an authentication protocol , one entity ( the Prover ) convinces the other entity ( the Veriﬁer ) that they are who they claim to be , and that they are ‘ online ’ ; where ‘ online ’ means that the verifying party is assured that the proving party is actually responding and it is not a replay .
In the symmetric key setting , both the prover and the veriﬁer hold the same secret key , whilst in the public key setting , the prover holds the private key and the veriﬁer holds the public key .
In both settings , the veriﬁer ﬁrst encrypts a random nonce to the prover , the prover then decrypts this and returns it to the veriﬁer , the veriﬁer checks that the random nonce and the returned value are equivalent .
N =m The encryption scheme needs to be IND-CCA secure for the above protocol to be secure against active attacks .
10.8.1.2 Message Authentication-Based Protocols These also operate in the public key or the symmetric setting .
In these protocols , the veriﬁer sends a nonce in the clear to the prover , the prover then produces a digital signature ( or a MAC in the symmetric key setting ) on this nonce and passes it back to the veriﬁer .
In the following diagram we give the public key/digital signature based variant .
The simplest example is the Schnorr identiﬁcation protocol , based on the hardness of computing discrete logarithms .
One should note the similarity of this protocol to the Schnorr signature scheme above .
10.8.2 Key Agreement Protocols A key agreement protocol allows two parties to agree on a secret key for use in subsequent protocols .
The security requirements of key agreement protocols are very subtle , leading to various subtle security properties that many deployed protocols may or may not have .
The basic security requirements are • The underlying key should be indistinguishable from random to the adversary , or that at least it should be able to be used in the subsequent protocol without the adversary breaking the subsequent protocol .
• Each party is assured that only the other party has access to the secret key .
in the standard application of Transport Layer Security ( TLS ) to web browsing protocol ) , one only requires this property of one-party , in which case we are said to only have one-way authentication .
This is a protocol that requires trusted parties to relay and generate secret keys from one party to another .
It is most suited to closed corporate networks .
On the public internet , protocols like Kerberos are less useful .
More advanced properties required of modern public key-based protocols are as follows .
• Key Conﬁrmation : The parties know that the other party has received the same secret key .
Sometimes this can be eliminated as the correct execution of the subsequent protocol using the secret key provides this conﬁrmation .
This later process is called implicit key conﬁrmation .
current conversations are still secure in the future .
Variations on the theme of key agreement protocols include group key agreement , which enables a group of users to agree on a key , or password based key agreement , in which two parties only agree on a ( high entropy ) key if they also agree on a shared password .
10.8.2.1 Key Transport The most basic form of key agreement protocol is a form of key transport in which the parties use public key encryption to exchange a random key .
To derive the ﬁnal secret in TLS , further nonces were exchanged between the parties ( to ensure that both parties were alive and the key was fresh ) .
Finally , key conﬁrmation was provided by the entire protocol transcript being hashed and encrypted under the master secret ( the so-called FINISHED message ) .
In TLS , the resulting key is not indistinguishable from random as the encrypted FINISHED message provides the adversary with a trivial check to determine whether a key is real or not .
However , the protocol can be shown to be secure for the purposes of using the master secret to produce a secure bi-directional channel between the server and the client .
A more basic issue with the above protocol is that it is not forward-secure .
To obtain mutual authentication , the message ﬂow of QA is signed by Alice ’ s public key and the message ﬂow of QB is signed KA Cryptography | October 2019 Page 345 The Cyber Security Body Of Knowledge www.cybok.org by Bob ’ s public key .
The adversary does not learn the secret , but does convince Bob he is talking to another entity .
The one-way authenticated version of Difﬁe–Hellman key agreement is the preferred method of key agreement in modern TLS deployments , and is the only method of key agreement supported by TLS 1.3 .
However , it also prevents the protocol from producing keys which are indistinguishable from random , as mentioned above .
In this protocol , the Difﬁe– Hellman derived key is used to encrypt the signatures , thus ensuring the signatures can not be stripped off the messages .
In addition , the signatures are applied to the transcript so as to convince both receiving parties that the other party is ‘ alive ’ .
Most of these advanced protocols are either based on the simpler components described in this section and/or on the encryption and signature schemes with special properties discussed in the next section .
KA Cryptography | October 2019 Page 346 The Cyber Security Body Of Knowledge www.cybok.org 10.9.1 Oblivious Transfer While Oblivious Transfer ( OT ) is at the heart of many advanced protocols , it is a surprisingly simple primitive which enables one to accomplish various more complex tasks .
The output of the protocol should be the message mb for the Receiver , and the Sender obtains no output .
This passively secure protocol can be implemented as follows .
10.9.2 Private Information Retrieval and ORAM A Private Information Retrieval ( PIR ) protocol is one which enables a computer to retrieve data from a server held database , without revealing the exact item which is retrieved .
However , in PIR we do not insist that the user does not learn anything else about the servers data , we only care about privacy of the user query .
In addition protocols for PIR are meant to be run many times , and we are interested in hiding the total set of access patterns , i.e .
The goal of PIR protocols is to obtain greater efﬁciency than the trivial solution of the server sending the user the entire database .
An Oblivious Random Access Memory ( ORAM ) protocol is similar but now we not only allow the user to obliviously read from the server ’ s database , we also allow the user to write to the database .
So as to protect the write queries the server held database must now be held in an encrypted form ( so what is written can not be determined by the server ) .
where data is written to and read from , needs to be hidden from the server .
The concept is used in many places in cryptography , to construct signature schemes , to attest ones identity , and to construct more advanced protocols .
Of course , protocols with small p to start with are going to be more efﬁcient .
Namely , the Prover simply sends over the witness w which the Veriﬁer then veriﬁes .
In a zero-knowledge proof , we obtain the same goal , but the Veriﬁer learns nothing bar the fact that x ∈ L. To formally deﬁne zero-knowledge , we insist that there is a ( probabilistic polynomial time ) simulator S which can produce protocol transcripts identical to the transcripts produced between a Veriﬁer and an honest Prover ; except the simulator has no access to the Prover .
This implies that the Veriﬁer can not use the transcript to perform any other task , since what it learned from the transcript it could have produced without the Prover by simply running the simulator .
A zero-knowledge proof is said to be perfect zero-knowledge if the distribution of transcripts produced by the simulator is identical to those produced between a valid prover and veriﬁer .
KA Cryptography | October 2019 Page 348 The Cyber Security Body Of Knowledge www.cybok.org If the two distributions only can not be distinguished by an efﬁcient algorithm we say we have computational zero-knowledge .
the Veriﬁer can keep resetting the Prover to a previous protocol state and continue executing ) can extract the underlying witness w. This implies that the Prover must ‘ know ’ w since we can extract w from it .
A non-interactive zero-knowledge proof is one in which there is no message ﬂowing from the Veriﬁer to the Prover , and only one message ﬂowing from the Prover to the Veriﬁer .
Traditionally these are applied to speciﬁc number theoretic statements , such to show knowledge of a discrete logarithm ( see the next section on Σ-protocols ) , however recently so called Succinct NonInteractive Arguments of Knowledge ( SNARKs ) have been developed which enable such noninteractive arguments for more complex statements .
Such SNARKs are ﬁnding applications in some blockchain systems .
Namely , the simulator computes things in the wrong order .
This is done by rewinding the prover to just after it has sent its ﬁrst message .
, xn ) of these inputs without revealing any information about the xi to each other , bar what can be deduced from the output of the function f .
In statically secure protocols , this set is deﬁned at the start of the protocol , but remains unknown to the honest parties .
In an adaptively secure protocol , the set can be chosen by the adversary as the protocol progresses .
An MPC protocol is said to be passively secure if the parties in A follow the protocol , but try to learn data about the honest parties ’ inputs from their joint view .
In an actively secure protocol , the parties in A can arbitrarily deviate from the protocol .
it outputs the correct answer if all parties follow the protocol .
the dishonest parties should learn nothing about the inputs of the honest parties .
In the case of active adversaries , a protocol is said to be robust if the honest parties will obtain the correct output , even when the dishonest parties deviate from the protocol .
A protocol which is not robust , but which aborts with overwhelming probability when a dishonest party deviates , is said to be an actively secure MPC protocol with abort .
They are also further characterized by the properties of the set A .
All of these protocols are achieved using secret sharing schemes .
The interesting case of two party computation is done using the Yao protocol .
This protocol has one party ( the Circuit Creator , also called the Garbler ) ‘ encrypting ’ a boolean function gate by gate using a cipher such as AES , the circuit is then sent to the other party ( called the Circuit Evaluator ) .
The Evaluator then obtains the ‘ keys ’ for their input values from the Creator using Oblivious Transfer , and can then evaluate the circuit .
Modern MPC protocols have looked at active security with abort in the case of t < n. The modern protocols are divided into a function-dependent ofﬂine phase , which requires public key functionality but which is function independent , then a function-dependent online phase which mainly uses information-theoretic primitives .
Since information theoretic primitives are usually very fast , this means the time-critical online phase can be executed as fast as possible .
We recap the main variants below , giving for each one the basic idea behind their construction .
The public key is usually determined by an entity called a Group Manager , during an interaction with the group members .
Given a group signature s , one can not tell which secret key signed it , although one is guaranteed that one did .
Most group signature algorithms have a special entity called an Opener who has some secret information which enables them to revoke the anonymity of a Signer .
This last property ensures one can identify group members who act dishonestly in some way .
A group signature scheme can either support static or dynamic groups .
In a static group signature scheme , the group members are ﬁxed at the start of the protocol , when the public key is ﬁxed .
In a dynamic group signature scheme the group manager can add members into the group as the protocol proceeds , and ( often ) revoke members as well .
An example of this type of signature scheme which is currently deployed is the Direct Anonymous Attestation ( DAA ) protocol ; which is essentially a group signature scheme in which the Opener is replaced with a form of user controlled linkability ; i.e .
a signer can decide whether two signatures output by the speciﬁc signer can be linked or not .
The Receiver knows the signature was produced by someone in the ring , but not which member of the ring .
However , the Signer is not allowed to know which message is being signed .
For example , the Signer may be simply notarising that something happened , but does not need to know precisely what .
Security requires that the Signer should not learn anything about any message passed to it for signing , and the user should not obtain the signature on any message other than those they submitted for signing .
Usually , a certiﬁcate is a digitally signed statement containing the public key and the associated user identity .
So , when sending a message to Alice the Sender is sure that Alice is the legitimate holder of public key pk .
Identity Based Encryption ( IBE ) is an encryption scheme which dispenses with the need for certiﬁcate authorities , and certiﬁcates .
However , to enable Alice to decrypt , we must have a trusted third party , called a Key Generation Centre , which can provide Alice with her secret key .
This third party uses its knowledge of the ‘ system ’ secret key to be able to derive Alice ’ s secret key .
Whilst dispensing with certiﬁcates , an IBE system inherently has a notion of key escrow ; the Key Generation Centre can decrypt all messages .
10.10.5 Linearly Homomorphic Encryption In a linearly homomorphic encryption scheme one can perform a number of linear operations on ciphertexts , which result in a ciphertext encrypting a message having had the same operations performed on the plaintext .
Such encryption algorithms can never be IND-CCA secure , as the homomorphic property produces a trivial malleability which can be exploited by a CCA attacker .
However , they can have applications in many interesting areas .
For example , one can use a linearly homomorphic encryption scheme to add up votes in a digitally balloted election for two candidates , where each vote is an encryption of either the message zero or one .
KA Cryptography | October 2019 Page 352 The Cyber Security Body Of Knowledge www.cybok.org 10.10.6 Fully Homomorphic Encryption Fully Homomorphic Encryption ( or FHE ) is an extension to linearly homomorphic encryption , in that one can not only homomorphically evaluate linear functions , but also non-linear ones .
In particular , the ability to homomorphically evaluate both addition and multiplication on encrypted data enables one to ( theoretically ) evaluate any function .
Applications of FHE which have been envisioned are things such as performing complex search queries on encrypted medical data etc .
All existing FHE schemes are highly inefﬁcient .
Thus only very simple functions can be evaluated in suitable time limits .
Obviously , if the set of functions are all multi-variate polynomials of degree one , then the SHE scheme is a linear homomorphic encryption scheme .
10.11 IMPLEMENTATION ASPECTS There are two aspects one needs to bear in mind with respect to cryptographic implementation .
In terms of security the main concern is one of side-channel attacks .
These can be mounted against both hardware implementations , for example cryptographic circuits implemented on smart-cards , or against software implementations running on commodity processors .
Any measurable difference which occurs when running an algorithm on one set of inputs versus another can lead to an attack .
Such measurements may involve timing differences , power comsumption differences , differences in electromagnetic radiation , or even differences in the sound produced by the fan on the processor .
It is even possible to mount remote sidechannel attacks where one measures differences in response times from a remote server .
To protect against such side-channel attacks at the hardware level various techniques have been proposed including utilizing techniques based on secret-sharing ( called masking in the side-channel community ) .
every execution path takes the same amount of time ) , indeed having multiple execution paths can itself lead to attacks via power-analysis .
To enable increased performance it is becoming increasingly common for processor manufacturers to supply special instructions to enable improvements to cryptographic algorithms .
This is similar to the multi-media extensions which have been common place for other applications for some decades .
An example of this is special instructions on x86 chips to perform operations related to AES , to perform GCM-mode and to perform some ECC operations .
number theoretic constructions , are particularly expensive in terms of computational resources .
Thus it is common for these speciﬁc algorithms to be implemented in low level machine code , which is tuned to a speciﬁc architecture .
However , this needs to be done with care so as to take into account the earlier mentioned side-channel attacks .
Finally an implementation can also be prone to fault attacks .
These are attacks in which an attacker injects faults ( either physical faults on hardware , or datagram faults into a protocol ) .
KA Cryptography | October 2019 Page 353 The Cyber Security Body Of Knowledge www.cybok.org Defences against such attacks need to be considered including standard fault tolerent computing approaches in hardware , and full input validation in all protocols .
Further topic speciﬁc reading is given by references to the main bibliography .
Further topic speciﬁc reading is given in the bibliography .
KA Cryptography | October 2019 Page 355 The Cyber Security Body Of Knowledge www.cybok.org KA Cryptography | October 2019 Page 356 Chapter 11 Operating Systems and Virtualisation Herbert Bos Vrije Universiteit Amsterdam 357 The Cyber Security Body Of Knowledge www.cybok.org INTRODUCTION In this Knowledge Area , we introduce the principles , primitives and practices for ensuring security at the operating system and hypervisor levels .
We shall see that the challenges related to operating system security have evolved over the past few decades , even if the principles have stayed mostly the same .
For instance , when few people had their own computers and most computing was done on multi-user ( often mainframe-based ) computer systems with limited connectivity , security was mostly focused on isolating users or classes of users from each other1 .
Even the entities to isolate have remained , by and large , the same .
We will refer to them as security domains .
Although we may have added trusted execution environments and a few other security domains in recent years , we still have the kernel , user processes and virtual machines as the main security domains today .
, in embedded devices ) do not have any notion of security domains whatsoever , but most distinguish between multiple security domains such as the kernel , user processes and trusted execution environments .
However , we shall see that protecting such traditional , coarse-grained resources is not always enough and it may be necessary to explicitly manage the more low-level resources as well .
Recall that Saltzer and Schroeder ’ s Principle of Least Common Mechanism [ 8 ] states that every mechanism shared between security domains may become a channel through which sensitive data may leak .
Indeed , all of the above shared resources have served as side channels to leak sensitive information in attack scenarios .
For brevity , we mainly use the term operating system and processes in the remainder of this knowledge area and refer to hypervisors and VMs explicitly where the distinction is important2 .
While security goes beyond the operating system , the lowest levels of the software stack form the bedrock on which security is built .
For instance , the operating system may be capable of executing privileged instructions not available to ordinary user programs and typically offers the means to authenticate users and to isolate the execution and ﬁles of different users .
While it is up to the application to enforce security beyond this point , the operating system guarantees that non-authorised processes can not access its ﬁles , memory , CPU time , or other resources .
These security guarantees are limited by what the hardware can do .
Targeted publications about developments in threats and solutions for virtualised environments have appeared elsewhere [ 999 ] 2 KA Operating Systems and Virtualisation | October 2019 Page 358 The Cyber Security Body Of Knowledge www.cybok.org The security offered by the operating system is also threatened by attacks that aim to evade the system ’ s security mechanisms .
For instance , if the operating system is responsible for the separation between processes and the operating system itself gets compromised , the security guarantees are void .
Thus , we additionally require security of the operating system .
After explaining the threat model for operating system security , we proceed by classifying the different design choices for the underlying operating system structure ( monolithic versus microkernel-based , multi-server versus libraryOS , etc . ) .
, which we then discuss in relation to fundamental security principles and models .
Next , we discuss the core primitives that operating systems use to ensure different security domains are properly isolated and access to sensitive resources is mediated .
Finally , we describe important techniques that operating systems employ to harden the system against attacks .
Not because they are not important , but because they are beyond OS control and would require a knowledge area of their own .
Table 11.1 lists some of the threats and attack methods that we do consider .
The simplest way to compromise the system is to inject a malicious extension into the heart of the operating system .
To maintain their hold on the system in a stealthy manner regardless of what the operating system or hypervisor may do , the attackers may further infect the system ’ s boot process ( e.g .
, by overwriting the master boot record or the Uniﬁed Extensible Firmware Interface ( UEFI ) , ﬁrmware ) —giving the malicious code control over the boot process on every reboot , even before the operating system runs , allowing it to bypass any and all operating system level defenses [ 1005 ] .
Besides using Trojans , attackers frequently violate the security properties without any help from the user , by exploiting vulnerabilities .
For instance , they commonly abuse vulnerabilities in the software , such as memory errors [ 1003 ] to change code pointers or data in the operating system and violate its integrity , conﬁdentiality or availability .
By corrupting a code pointer , they control where the program resumes execution after the call , jump or return instruction that uses the corrupted code pointer .
Changing data or data pointers opens up other possibilities , such as elevating the privilege level of an unprivileged process to ‘ root ’ ( giving all-powerful ’ system ’ privileges ) or modifying the page tables to give a process access to arbitrary memory pages .
Likewise , they may use such bugs to leak information from the operating system by changing which or how much data is returned for a system call , or a network request .
Since bits in memory chips are organised in rows and packed very closely together , accessing a bit in one row may cause the neighbouring bit in the ad- KA Operating Systems and Virtualisation | October 2019 Page 359 The Cyber Security Body Of Knowledge www.cybok.org Attack Description Malicious extensions Attacker manages to convince the system to load a malicious driver or kernel module ( e.g .
Bootkit Attacker compromises the boot process to gain control even before the operating system gets to run .
Memory errors ( software ) Spatial and temporal memory errors allow attackers ( local or remote ) to divert control ﬂow or leak sensitive information .
Memory corruption ( hardware ) Vulnerabilities such as Rowhammer in DRAM allow attackers ( local or remote ) to modify data that they should not be able to access .
Uninitalised data leakage The operating system returns data to user programs that is not properly initialised and may contain sensitive data .
, a size value is used once to allocate a buffer and later to copy into that buffer ) and the value changes between the two uses .
Side channels ( hardware ) Attackers use access times of shared resources such as caches and TLBss to detect that another security domain has used the resource , allowing them to leak sensitive data .
Side channels ( speculative ) Security checks are bypassed in speculative or out-of-order execution and while results are squashed they leave a measurable trace in the micro-architectural state of the machine .
Side channels ( software ) Example : when operating systems / hypervisors use features such as memory deduplication , attackers can measure that another security domain has the same content .
Table 11.1 : Known attack methods / threats to security for modern operating systems KA Operating Systems and Virtualisation | October 2019 Page 360 The Cyber Security Body Of Knowledge www.cybok.org jacent row to leak a small amount of charge onto its capacitor—even though that bit is in a completely different page in memory .
We do not know in advance which , if any , of the bits in a row will ﬂip , but once a bit ﬂips , it will ﬂip again if we repeat the experiment .
If attackers succeed in ﬂipping bits in kernel memory , they enable attacks similar to those based on software-based memory corruption .
For instance , corrupting page tables to gain access to the memory of other domains .
The double fetch is an important problem for an operating system and occurs when it uses a value from userspace twice ( e.g .
Security issues such as memory corruption arise if there is a race between the operating system and the attacker , and the attacker changes the userspace value in between the two accesses and makes it smaller .
It is similar to a Time Of Check Time Of Use ( TOCTOU ) attack , except that the value modiﬁed is used twice .
In addition to direct attacks , adversaries may use side channels to leak information indirectly , for instance by means of cache sidechannels [ 1009 ] .
There are many variants , but a common one consists of attackers ﬁlling a cache set with their own data or code and then periodically accessing these addresses .
If any of the accesses is signiﬁcantly slower , they will know that someone else , presumably the victim , also accessed data/code that falls in the same cache set .
Now assume that the victim code calls functions in a secret dependent way .
For instance , an encryption routine processes a secret key bit by bit and calls function foo if the bit is 0 , and bar if it is 1 , where foo and bar are in different cache sets .
By monitoring which cache sets are used by the side channel , the attackers quickly learn the key .
For performance , modern CPUs may execute instructions ahead of time— before the preceding instructions have been completed .
For instance , while waiting for the condition of a conditional branch to be resolved , the branch predictor may speculate that the outcome will be ‘ branch taken ’ ( because that was the outcome for the last n times ) , and speculatively execute the instructions corresponding to the taken branch .
If it turns out that it was wrong , the CPU will squash all the results of the speculatively executed instructions , so that none of the stores survive in registers or memory .
However , there may still be traces of the execution in the micro-architectural state ( such as the content of caches , TLBs and branch predictors that are not directly visible in the instruction set architecture ) .
For instance , if a speculative instruction in a user program reads a sensitive and normally inaccessible byte from memory in a register and subsequently uses it as an offset in a userspace array , the array element at that offset will be in the cache , even though the value in the register is squashed as soon as the CPU discovers that it should not have allowed the access .
The attacker can time the accesses to every element in the array and see if one is signiﬁcantly faster ( in the cache ) .
The offset of that element will be the secret byte .
In other words , the attacker can use a cache side channel to extract the data that was accessed speculatively .
More recent attacks show that the hardware vulnerabilities related to speculation and outof-order execution may be more disastrous than we thought .
The Foreshadow attack [ 1012 ] abuses the fact that Intel CPUs read from the Level 1 cache under speculative execution whenever a memory page is marked as not present—without properly checking the ownership of the data at that physical address .
Worse , the vulnerability known as Rogue In-Flight Data ( RIDL ) [ 1013 ] ( that attackers can exploit without privileges , even from JavaScript in browsers ) and without caring about addresses , shows that Intel CPUs constantly feed speculatively KA Operating Systems and Virtualisation | October 2019 Page 361 The Cyber Security Body Of Knowledge www.cybok.org executing instructions with data from arbitrary security domains all the time , via a variety of temporary micro-architectural buffers .
Mitigating these attacks require not just changes in the hardware but also deep and often complex involvement of the operating system .
For instance , the operating system may need to ﬂush caches and buffers that could leak data , provide guarantees that no speculation takes place across certain branches , or schedule different security domains on separate cores , etc .
Indeed , side channels need not be hardware related at all .
For instance , memory deduplication and page caches , both implemented in the operating system , are well-known sources for side channels .
Focusing on the former for illustration purposes , consider a system that aggressively deduplicates memory pages : whenever it sees two pages with the same content , it adjusts the virtual memory layout so that both virtual pages point to the same physical page .
This way , it needs to keep only one of the physical pages to store the content , which it can share in a copy-on-write fashion .
In that case , a write to that page takes longer ( because the operating system must copy the page again and adjust its page table mappings ) , which can be measured by an attacker .
So , if a write to page takes signiﬁcantly longer , the attacker knows that some other program also has a copy of that content—a side channel that tells the attacker something about a victim ’ s data .
In many of the side channels , the issue is a lack of isolation between security domains in software and in hardware ( e.g .
It is important to realise that domain isolation issues extend to the hardware/software interface .
For conﬁdentiality in particular , information leaks may be subtle and seemingly innocuous , and still lead to serious security problems .
For instance , the physical or even virtual addresses of objects may not look like very sensitive information , until we take into account code reuse [ 1016 ] or Rowhammer [ 1006 ] attacks that abuse knowledge of the addresses to divert control ﬂow to speciﬁc addresses or ﬂip speciﬁc bits .
As for the origin of the attacks , they may be launched from local code running natively on the victim ’ s machine in user space , ( malicious ) operating system extensions , scripting code fetched across the network and executed locally ( such as JavaScript in a browser ) , malicious peripherals , or even remote systems ( where attackers launch their exploit across the network ) .
In some cases , we explicitly extend the attacker model to include malicious operating systems or malicious hypervisors as well .
These attackers may be relevant in cloud-based systems , where the cloud provider is not trusted , or in cases where the operating system itself has been compromised .
In these cases , the goal is to protect the sensitive application ( or a fragment thereof ) , possibly running in special hardware-protected trusted execution environments or enclaves , from the kernel or hypervisor .
A useful metric for estimating the security of a system is the attack surface [ 1017 ] —all the different points that an attacker can reach and get data to or from in order to try and compromise the system .
For instance , for native code running locally , the attack surface includes all the system calls the attacker can execute as well as the system call ’ s arguments and return values , together with all the code implementing the system calls , which the attacker can reach .
For remote attackers , the attack surface includes the network device drivers , part of the network stack , and all the application code handling the request .
For malicious devices , KA Operating Systems and Virtualisation | October 2019 Page 362 The Cyber Security Body Of Knowledge www.cybok.org the attack surface may include all the memory the device may access using DMA or the code and hardware functions with which the device may interact .
Note , however , that the exposure of more code to attackers is only a proxy metric , as the quality of the code differs .
In an extreme case , the system is formally veriﬁed so that a wide range of common vulnerabilities are no longer possible .
The main role of these lowest layers of the software stack with respect to security is to provide isolation of security domains and mediation of all operations that may violate the isolation .
In the ideal case , the operating system shields any individual process from all other processes .
For instance , peripheral processes should not be able to access the memory allocated to the primary process , learn anything about the activities related to that primary process except those which the process chooses to reveal , or prevent the process from using its allocated resources , such as CPU time indeﬁnitely .
Some operating systems may even regulate the information ﬂows such that top secret data can never leak to processes without the appropriate clearance , or classiﬁed data can not be modiﬁed by processes without the appropriate privilege levels .
Digging a little deeper , we can distinguish between control and data plane operations and we see that isolation in operating systems involves both .
In memory isolation , the operating systems operate at the control plane when it conﬁgures the MMU ( memory management unit ) , which is then responsible for the isolation without much involvement by the operating system .
In most other interactions , for instance when operating on arguments of system calls provided by unprivileged security domains , an operating system operates at both planes .
The lack of separation between the planes may easily lead to vulnerabilities—for instance , when the operating system decides to reuse memory pages that previously belonged to one security domain ( with access isolation enforced by the MMU ) in another domain without properly overwriting the ( possibly sensitive ) data on that page .
There are many ways to design an operating system .
Early operating systems worked this way , but so do many embedded systems today .
In this case , there is little to no isolation between the different components in the system and an application can corrupt the activities of the File System ( FS ) , the network stack , drivers , or any other component of the system .
11.1 ( b ) shows the conﬁguration of most modern general-purpose operating systems , where most of the operating system resides in a single security domain , strictly isolated from the applications , while each application is also isolated from all other applications .
Since almost every component of the operating system runs in a single security domain , the model is very efﬁcient because the components interact simply by func- KA Operating Systems and Virtualisation | October 2019 Page 363 The Cyber Security Body Of Knowledge www.cybok.org tion calls and shared memory .
The model is also safe as long as every component is benign .
Often written by third parties and more buggy than the core operating system code , extensions running in the single security domain of the operating system may compromise the security of the system completely .
Interestingly , the boundary between the kernel and other security domains in such systems is often a bit fuzzier now that operating systems can bypass the kernel for , say , high-speed networking , or implement non performance critical operating system components as user processes .
Examples include the File System in User Space ( FUSE ) in UNIX operating systems and the User Mode Driver Framework ( UMDF ) in Windows .
Even so , most of the operating system functionality still forms a single monolithic security domain .
The conﬁguration is potentially less efﬁcient than the previous model , because all the interactions between different components of the operating system involve Inter-Process Communication ( IPC ) .
In addition , the operating system functions as a distributed system and anyone who has ever built a distributed system knows how complicated the problems may get .
The common view is that microkernel-based multi-server designs have security and reliability advantages over monolithic and single-domain designs , but incur somewhat higher overheads—the price of safety .
The libOS contains code that is typically part of the operating system , but is directly included with the application .
This conﬁguration allows applications to tailor the operating system exactly according to their needs and leave out all the functionality they were not going to use anyway .
On the one hand , they do not have the extreme separation of operating system components .
On the other , they allow the ( library ) operating system code to be much smaller and less complex—it only has to satisfy the needs of this one application .
Moreover , the library can not compromise isolation : it is part of this application ’ s trusted computing base and no other .
The debate about which design is better goes back to the famous ﬂame war between Andrew S. Tanenbaum and Linus Torvalds in 1992 .
In January 1992 , Tanenbaum criticised the design for its lack of portability , and also took aim at Linux ’ s monolithic design , claiming Linux was obsolete from the outset .
Torvalds responded with his own criticism of MINIX .
This heated exchange contained increasingly sophisticated arguments , many of which still stand today , so much so that the question of who won the debate remains unanswered .
That said , Linux has become wildly popular and few people would consider it obsolete .
It is also clear that ideas from multi-server systems such as MINIX have been incorporated into existing operating systems and hypervisor-based systems .
Interestingly , at the time of writing even MINIX itself is running in hundreds of millions of Intel processors as a miniature operating system on a separate microprocessor known as the Management Engine .
In addition , now that the CPUs in modern systems are increasingly elaborate System on a Chips ( SoCs ) , the hardware itself is starting to look like a distributed system and some researchers explicitly advocate designing the operating system accordingly , with a focus on message passing rather than memory sharing for communication [ 1026 ] .
The situation for virtualised environments , in general , is comparable to that of operating systems .
We have already seen that in one extreme case , the entire virtual machine with the application and a stripped-down operating system can form a single domain .
A more common case is to have a hypervisor at the lowest level supporting one or more operating systems such as Linux or Windows in a virtual machine .
In other words , these hypervisors provide each of the operating systems with the illusion that they run on dedicated hardware .
At the other end of the spectrum , we ﬁnd the entire system decomposed into separate , relatively small , virtual machines .
Indeed , some operating systems , such as QubesOS completely integrate the concepts of virtualisation and operating systems by allowing individual user processes to be isolated in their own virtual machines .
Finally , as we have already seen , Unikernels are popular in virtualised environments , on top of hypervisors .
Incidentally , one of the drawbacks of virtual machines is that each operating system image uses storage and adds redundancy , as every system will think that it is the king of the hardware mountain , while in reality it is sharing resources .
The con- KA Operating Systems and Virtualisation | October 2019 Page 365 The Cyber Security Body Of Knowledge www.cybok.org tainers are isolated from each other as much as possible and have their own kernel name spaces , resource limits , etc .
, but ultimately share the underlying operating system kernel , and often binaries and libraries .
However , if we ignore the management aspects for a moment , virtual machines are often perceived as more secure than containers , as they partition resources quite strictly and share only the hypervisor as a thin layer between the hardware and the software .
On the other hand , some people believe that containers are more secure than virtual machines , because they are so lightweight that we can break applications into ‘ microservices ’ with well-deﬁned interfaces in containers .
Moreover , having fewer things to keep secure reduces the attack surface overall .
A ﬁnal class of operating systems explicitly targets small and resource constrained devices such as those found in the Internet of Things ( IoT ) .
While everybody has a different opinion on what IoT means and the devices to consider range from smartphones to smart dust , there is a common understanding that the most resource constrained devices should be part of it .
For such devices , even stripped down general-purpose operating systems may be too bulky and operating systems are expected to operate in just a few kilobytes .
As an extreme example , popular IoT operating systems such as RIOT can be less than 10 KB in size and run on systems ranging from 8-bit microcontrollers to general-purpose 32-bit CPUs , with or without advanced features such as Memory Management Units ( MMUs ) , etc .
The abundance of features and application isolation that we demand from operating systems such as Windows and Linux may be absent in these operating systems , but instead there may be support for functionality such as real-time schedule or low-power networking which are important in many embedded systems .
Since we are interested in the security guarantees offered by the operating system , we will assume that there are multiple security domains .
In the next section , we will elaborate on the advantages and disadvantages of the different designs from the viewpoint of well-established security principles .
Our focus will be on the security of the design and the way in which we can stop attacks , but not before observing that there is more to security at this level .
While Saltzer and Schroeder ’ s security principles are arguably the most well-known , we should mention that others have since added to the list .
For instance , important additions that we discuss in this text include the Principle of Minimising the Amount of Trusted Code ( the Trusted Computing Base ) and the Principle of Intentional Use [ 1032 ] .
11.3.1 Security principles in operating systems From a security perspective , the walls between different security domains should be as high and as thick as possible—perfect isolation .
Any interaction between domains should be subject to rigorous mediation , following the Principle of Complete Mediation , and security domains should have as few mechanisms ( especially those involving a shared state such as global variables ) in common as possible , adhering to the Principle of Least Common Mechanism .
For instance , given a choice between adding a shared procedure with global variables to the operating system kernel and making it available in a user-space library that behaves in an isolated manner for each process , we should choose the latter option , assuming it does not increase the code size too much or violate any other principles or constraints .
In other words , only explicitly authorised domains should have access to a resource .
The principles of Least Common Mechanism and Economy of Mechanism also suggest that we should minimise the amount of code that should be trusted , the Trusted Computing Base ( TCB ) .
Since studies have shown that even good programmers introduce between 1 and 6 bugs per 1000 lines of code , assuming the complexity of the code is similar , a small TCB translates to fewer bugs , a smaller attack surface and a better chance of automatically or manually verifying the correctness of the TCB with respect to a formal speciﬁcation .
With respect to the designs in Fig .
All mechanisms are ‘ common ’ and there is virtually no concept of fail-safe defaults or rigorously enforced mediation .
For the monolithic OS design , the situation is a little better , as at least the operating system is shielded from the applications and the applications from each other .
However , the operating system itself is still a single security domain , inheriting the disadvantages of Fig .
The extreme decomposition of the multi-server operating system is more amenable to enforcing security : we may enforce mediation between individual operating components in a minimalsize microkernel with fail-safe defaults .
Much of the code that is in the operating system ’ s security domain in the other designs , such as driver code , is no longer part of the TCB .
Unikernels are an interesting alternative approach : in principle , the operating system code and the application run in a single domain , but the libOS code is as small as possible ( Economy of Mechanism ) and the mechanism common to different applications is minimised .
Resource partitioning can also be mediated completely at the Unikernel level .
For a Unikernel application , the TCB consists only of the underlying hypervisor/Exokernel and the OS components it decides to use .
Moreover , the library implementing the OS component is only in this application ’ s TCB , as it is not shared by others .
In particular , there have been endless discussions about open source ( which is one way to adhere to the principle ) versus closed source and their merits and demerits with respect to security .
The advantage of an open design is that anybody can study it , increasing the probability of ﬁnding bugs in general and vulnerabilities in particular3 .
A similar observation was made by Auguste Kerckhoffs about crypto systems and is often translated as that one should not rely on security by obscurity .
After all , the obscurity is unlikely to last forever and when the bad people ﬁnd a vulnerability before the good people do , you may have a real problem .
The counter argument is that with an open design , the probability of them ﬁnding the bug is higher .
In contrast , there is little doubt that a design with a strict decomposition is more in line with the Principle of Least Privilege and the Principle of Privilege Separation than one where most of the code runs in a single security domain .
Speciﬁcally , a monolithic system has no true separation of privileges of the different operating system components and the operating system always runs with all privileges .
In other words , the operating system code responsible for obtaining the process identiﬁer of the current process runs with the power to modify page tables , create root accounts , modify any ﬁle on disk , read and write arbitrary network packets , and crash the entire system at any time it sees ﬁt .
Multi-server systems are very different and may restrict what calls individual operating system components can make , limiting their powers to just those privileges they need to complete their job , adhering to the Principle Of Least Authority ( POLA ) with different components having different privileges ( Principle of Privilege Separation ) .
Unikernels offer a different and interesting possibility for dealing with this problem .
While most of the components run in a single domain ( no privilege separation or POLA ) , the operating system is stripped down to just the parts needed to run the application , and the Unikernel itself could run with just the privileges required for this purpose .
Of course , however important security may be , the Principle of Psychological Acceptability says that in the end the system should still be usable .
Given the complexity of operating system security , this is not trivial .
While security hardened operating systems such as SELinux and QubesOS offer clear security advantages over many other operating systems , few ordinary users use them and even fewer feel conﬁdent to conﬁgure the security settings themselves .
11.3.2 Security models in operating systems An important question in operating systems concerns the ﬂow of information : who can read and write what data ?
In the 1970s , the US military faced a situation where many users with different clearance levels would all be using the same mainframe computers—requiring a solution known as Multi-Level Security .
How could they ensure that sensitive information would never leak to non-authorised personnel ?
If it adheres to the model designed by David Bell and Leonard LaPadula , a system can handle multiple levels of sensitive information ( e.g .
, the clearance to access unclassiﬁed and secret , but not top secret data ) 3 On the other hand , researchers have encountered security bugs that are years or sometimes decades old , even in security critical open source software such as OpenSSL or the Linux kernel , suggesting that the common belief that `` given enough eyeballs , all bugs are shallow ” ( also known as Linus ’ Law ) does not always work ﬂawlessly .
KA Operating Systems and Virtualisation | October 2019 Page 368 The Cyber Security Body Of Knowledge www.cybok.org and keep control over the ﬂow of sensitive information .
In other words , a subject with clearance level secret may create secret or top secret documents , but not unclassiﬁed ones , as that would risk leaking secret information .
Strict enforcement of this model prevents the leakage of sensitive information to non-authorised users .
Just like in Bell-LaPadula , objects and subjects have a number of levels of integrity and the model ensures that subjects at lower levels can not modify data at higher levels .
Bell-LaPadula and Biba are access control models that the operating system applies when mediating access to resources such as data in memory or ﬁles on disk .
Speciﬁcally , they are Mandatory Access Control ( MAC ) models , where a system-wide policy determines which users have the clearance level to read or write which speciﬁc documents , and users are not able to make information available to other users without the appropriate clearance level , no matter how convenient it would be .
A less strict access control model is known as Discretionary Access Control ( DAC ) , where users with access to an object have some say over who else has access to it .
For instance , DAC may restrict access to objects based on a user or process identity or group membership .
More importantly , DAC allows a user or process with access rights to an object to transfer those rights to other users or processes .
Having only this group-based DAC makes it hard to control the ﬂow of information in the system in a structured way .
However , it is possible to combine DAC and MAC , by giving users and programs the freedom to transfer access rights to others , within the constraints imposed by MAC policies .
While intuitively simple , RBAC allows one to implement both DAC and MAC access control policies .
While it never became very popular , many of its security innovations can still be found in the most popular operating systems today .
Even if some features were not invented directly by the Multics team , their integration in a single , working , security-oriented OS design was still novel .
Indeed , in many ways , the mandatory access control in Multics , added at the request of the military , is a direct software implementation of the Bell-LaPadula security model .
Finally , Multics made sure that its many small software components were strongly encapsulated , accessible only via their published interfaces where mediation took place .
If any of this sounds familiar , this is not surprising , as Jerome Saltzer was one of the Multics team leaders .
There is no doubt that Multics was very advanced and perhaps ahead even of some modern operating systems , but this was also its downfall—the system became so big and so complex that it arguably violated the Principle of Psychological Acceptability for at least some of its developers .
Frustrated , Ken Thomson and Dennis Ritchie decided to write a new and much simpler operating system .
Like all major general purpose operating systems in use today , it relied on a small number of core primitives to isolate its different security domains .
So what are these major isolation primitives ?
First , the operating system has to have some way of authenticating users and security domains so it can decide whether or not they may access certain resources .
To isolate the different security domains , the operating system also needs support for access control to objects , such as ﬁles .
In addition , it needs memory protection to ensure that a security domain can not simply read data from another domain ’ s memory .
Finally , it needs a way to distinguish between privileged code and non-privileged code , so that only the privileged code can conﬁgure the desired isolation at the lowest level and guarantee mediation for all operations .
11.4.1 Authentication and identiﬁcation Since authentication is the topic of the Authentication , Authorisation & Accountability ( AAA ) Knowledge Area ( Chapter 13 ) , we will just observe that to determine access rights , an operating system needs to authenticate its users and that there are many ways to do so .
Traditionally , only usernames and passwords were used for this purpose , but more and more systems nowadays use other methods ( such as smartcards , ﬁngerprints , iris scans , or face recognition ) —either instead of passwords or as an additional factor .
For every user thus authenticated , the operating system maintains a unique user id .
Similarly , most operating systems attach some identity to each of the processes running on behalf of the user and track the ownership and access rights of the ﬁles they use .
For instance , it gives every running process a unique process id and also registers the id of the users on whose behalf it runs ( and thus the groups in which the user resides ) .
Finally , it tracks which user owns the executing binary .
Note that the user owning the binary and the user running the binary need not be the same .
For instance , the administrator can create and own a collection of system programs that other users may execute but not modify .
Several modern operating systems resort to hardware to protect such sensitive data .
For instance , they may use a Trusted Platform Module ( TPM ) to ensure credentials such as disk encryption keys are cryptographically sealed , or employ a separate VM for the credential store , so that even a compromised VM will not get direct access to the credentials .
KA Operating Systems and Virtualisation | October 2019 Page 370 The Cyber Security Body Of Knowledge www.cybok.org 11.4.2 Access control lists Given these identities , the operating system is equipped to reason about which user and which process is allowed to perform which operations on a speciﬁc object : access control .
Conceptually , an ACL is a table containing users and data blocks that speciﬁes for each data block which users have which kind of access rights .
Most modern operating systems have adopted some variant of ACLs , typically for the ﬁle system4 .
Let us look at an example .
Moreover , every user can be in one or more groups .
The owning user and all users in group cybok have permissions to read , write , and execute the ﬁle , while all other users can read and execute ( but not write ) it .
These basic UNIX ﬁle permissions are quite simple , but modern systems ( such as Linux and Windows ) also allow for more extensive ACLs ( e.g .
Whenever someone attempts to read , write or access a ﬁle , the operating system veriﬁes whether the appropriate access rights are in the ACL .
Moreover , the access control policy in UNIX is typically discretionary , because the owning user is allowed to set these rights for others .
Besides DAC , Multics also implemented MAC and , while it took a long time to reach this stage , this is now also true for many of the operating systems that took their inspiration from Multics ( namely most popular operating systems today ) .
Linux even offers a framework to allow all sorts of access control solutions to be plugged in , by means of so-called ‘ reference monitors ’ that vet each attempt to execute a security sensitive operation and , indeed , several MAC solutions exist .
While the tuple already ( correctly ) suggests that SELinux also supports RBAC , there is signiﬁcant ﬂexibility in what to use and what to avoid .
For instance , many deployed systems use only the domain string for MAC and set username and role to the same value for all users .
Besides processes , resources such as ﬁles , network ports , and hardware 4 which in most cases also follows the hierarchical design pioneered in Multics .
KA Operating Systems and Virtualisation | October 2019 Page 371 The Cyber Security Body Of Knowledge www.cybok.org resources also have such SELinux contexts associated with them .
Given this conﬁguration , system administrators may deﬁne system-wide policies for access control on their systems .
Mandatory access control in systems such as SELinux revolves around a single system-wide policy that is set by a central administrator and does not change .
They do not allow untrusted processes to deﬁne and update their own information control policy .
In other words , any process can create security labels and classify and declassify data .
11.4.3 Capabilities So far , we have assumed that access control is implemented by means of an ACL or access matrix , where all information is kept to decide whether a process P may access a resource R. After authenticating the users and/or looking up their roles or clearance levels , the reference monitor decides whether or not to grant access .
Unlike ACLs , capabilities do not require a per-object administration with the exact details of who is allowed to perform what operation .
Instead , the users present a capability that in itself proves that the requested access is permitted .
According to Dennis and Van Horn , a capability should have a unique identiﬁer of the object to which it pertains , as well as the set of access rights provided by the capability .
Possession of the capability grants all the rights speciﬁed in it and whenever a process wants to perform an operation on an object , it should present the appropriate capability .
Conversely , users do not have access to any resources other than the ones for which they have capabilities .
Moreover , Peter Neumann argues that the access control should be explicit and adhere to the Principle of Intentional Use [ 1032 ] , by explicitly authorising only what is really intended , rather than something that is overly broad or merely expedient .
Adherence to the principle helps to avoid the accidental or unintended use of rights that may lead to security violations in the form of a ’ confused deputy ’ ( in which a security domain unintentionally exercises a privilege that it holds legitimately , on behalf of another domain that does not and should not ) .
Of course , it should be impossible to forge capabilities , lest users give themselves arbitrary access to any object they want .
In the latter case , the capability may be handled by the process itself , but any attempt to modify it in an inappropriate manner will be detected [ 1044 ] .
KA Operating Systems and Virtualisation | October 2019 Page 372 The Cyber Security Body Of Knowledge www.cybok.org Capabilities are very ﬂexible and allow for convenient delegation policies .
On the other hand , in some situations , it may not be desirable to have capabilities copied and spread arbitrarily .
Comparing ACLs and capabilities , we further observe that ACLs are typically based on users ( ‘ the user with id x is allowed to read and write ’ ) , while capabilities can be extremely ﬁnegrained .
For instance , we may use different capabilities for sending and receiving data .
Following the Principle of Least Authority , running every process with the full power of the user , compared to running a process with just the power of the capabilities it acquires , is less secure .
Running with the authority of the user who started the program , as is often the case in modern operating systems , is known as a form of ambient authority and much more likely to violate the Principle of Least Authority than ﬁne-grained capabilities that equip a process only with the privileges it needs .
Moreover , capabilities do not even allow a process to name an object unless it has the appropriate capability , while ACLs should permit the naming of any object by everyone , as the access check only occurs when the process attempts the operation .
Finally , ACLs may become very large with growing numbers of users , access rights , and objects .
On the other hand , revoking a particular access right for a particular user in an ACL is easy : just remove a permission in the appropriate table entry .
For instance , we could make the capabilities point to an indirect object , which in turn points to the real object .
To invalidate the capability ( for all users/processes ) the operating system could then invalidate that indirect object .
But what to do if we only want to revoke the capability in a subset of processes ?
While there are solutions , revocation of capabilities remains the most difﬁcult part .
However , it did have a great impact on subsequent work , as Maurice Wilkes of the University of Cambridge learned about capabilities during several visits to Chicago and wrote about it in his book on time-sharing systems .
Back in the UK , this book was picked up by an engineer at Plessey which built the fully functional Plessey System 250 ( with explicit hardware support for capability-based addressing ) .
Maurice Wilkes himself went on to build the Cambridge CAP computer together with Roger Needham and David Wheeler [ 1047 ] .
CAP was the ﬁrst computer to demonstrate the use of secure capabilities .
This machine ensured that a process could only access a memory segment or other hardware if it possessed the required capabilities .
Finally , in the 1980s , the Amoeba distributed operating systems explored the use of cryptographically protected capabilities that could be stored and handled by user processes [ 1044 ] .
KA Operating Systems and Virtualisation | October 2019 Page 373 The Cyber Security Body Of Knowledge www.cybok.org Nowadays , many major operating systems also have at least some support for capabilities .
In 1997 , Linux adopted very limited capability support ( sometimes referred to as ‘ POSIX capabilities ’ ) , but this was different from the capabilities deﬁned by Dennis and Van Horn ( with less support for copying and transferring capabilities ) .
Recognising that UNIX ﬁle descriptors and Windows handles are almost capabilities already , an interesting effort to merge capabilities and UNIX APIs is the Capsicum project [ 1050 ] by the University of Cambridge and Google , where the capabilities are extensions of UNIX ﬁle descriptors .
An outgrowth of Capsicum is Capability Hardware Enhanced RISC Instructions ( CHERI ) , a hardware-software project that transposes the Capsicum capability model into the CPU architecture .
11.4.4 Physical access and secure deletion It is important to observe that access restrictions at the level of the operating system do not necessarily translate to the same restrictions at the physical level .
Thus , an attacker that reads raw disk blocks with no regard for the ﬁle system may still be able to access the data .
It turns out that securely deleting data on disk is not trivial .
Naive deletion , for instance , by overwriting the original content with zeros , is not always sufﬁcient .
For instance , on some magnetic disks , data on the disk ’ s tracks leaves ( magnetic ) traces in areas close to the tracks and a clever attack with sufﬁcient time and resources may use these to recover the content .
Moreover , the operating system may have made copies of the ﬁle that are not immediately visible to the user , for instance , as a backup or in a cache .
All these copies need to be securely deleted .
The situation for Solid State Drives ( SSDs ) is no better , as SSDs have their own ﬁrmware that decides what to ( over ) write and when , beyond the control of the OS .
For most operating systems , truly secure deletion , in general , is beyond the operating system ’ s capabilities and we will not discuss it further in this knowledge area , except to say that full disk encryption , a common feature of modern operating systems , helps a lot to prevent ﬁle recovery after deletion .
11.4.5 Memory protection and address spaces Access control is only meaningful if security domains are otherwise isolated from each other .
For this , we need separation of the security domains ’ data according to access rights and a privileged entity that is able to grant or revoke such access rights .
We will look at the isolation ﬁrst and talk about the privileges later , when we introduce protection rings .
A process should not normally be able to read another process ’ data without going through the appropriate access control check .
Multics and nearly all of the operating systems that followed ( such as UNIX and Windows ) isolate information in processes by giving each process ( a ) its own processor state ( registers , program counter etc . ) .
Whenever the operating system decides to execute process P2 at the expense of 5 Other L4 variants , such as the L4 Fiasco kernel from Dresden , also supported capabilities .
The MMU ‘ walks ’ the page tables to ﬁnd the physical address of the page .
Only if a page is ‘ mapped ’ on a process ’ page tables can the process address it , assuming it is present and the process has the appropriate access rights .
Next , it loads P2 ’ s processor states from memory into the CPU , adjusts the bookkeeping that determines which parts of the physical memory are accessible , and starts executing P2 at the address indicated by the program counter that it just loaded as part of the processor state .
Most modern operating systems keep track of the memory bookkeeping by means of page tables , as illustrated in Fig .
For each process , they maintain a set of page tables ( often containing multiple levels organised as a directed acyclic graph6 ) , and store a pointer to the top level page table in a register that is part of the processor state and that must be saved and restored on a context switch .
Since two processes may both store data at address 0x10000 , say , but should not be allowed to access each others ’ data , there has to be a mapping from the virtual addresses each process uses to the physical addresses used by the hardware .
It is like a game of basketball , where each side may have a player with the number 23 , but that number is mapped onto a different physical player for each team .
This is where the page tables comes in .
We divide each of the virtual address spaces into ﬁxed size pages and use the page table structure to map the address of the ﬁrst byte of a virtual page onto a physical address .
The processor often uses multiple levels of translation .
6 While it is often helpful to think of page table structures as trees , different branches may point to the same leave nodes .
KA Operating Systems and Virtualisation | October 2019 Page 375 The Cyber Security Body Of Knowledge www.cybok.org In the example in Fig .
11.2 , it uses the ﬁrst nine bits of the virtual address as an index in the top level page table ( indicated by a control register that is part of the processor state ) to ﬁnd an entry containing the physical address of the next level page table , which is indexed by the next nine bits , and so on , until we reach the last level page table , which contains the physical address of the physical page that contains the virtual address .
The last 12 bits of the virtual address are simply the offset in this page and point to the data .
Paging allows the ( total ) size of the virtual address spaces of the processes to be much larger than the physical memory available in the system .
First , a process typically does not use all of its possibly gigantic address space and only virtual pages that are in actual use need backing by physical pages .
Second , if a process needs more memory to store some data and no physical pages are free at that moment ( for instance , because they are already in use by other processes , or they are backing some other virtual pages of this process ) , the operating system may swap the content of these pages to disk and then re-use the physical page to store the new data .
A key consequence of this organisation is that a process can only access data in memory if there is a mapping for it in its page tables .
Whether this is the case , is controlled by the operating system , which is , therefore , able to decide exactly what memory should be private and what memory should be shared and with whom .
If the mapping of virtual to physical for a speciﬁc address is not in the small but very fast cache known as the Transaction Lookaside Buffer ( TLB ) , the MMU will look for it by walking the page tables and then triggering an interrupt if the page containing the address is not mapped .
The MMU will also trigger interrupts if the page is currently not in memory ( swapped to disk ) , or , more relevant to security , if the user does not have the required privilege to access this memory .
We will have more to say about privileges later .
Page tables are the main way modern operating systems control access to memory .
Unlike pages , segments have an arbitrary length and start at an arbitrary address .
Given a virtual address , the MMU uses the current value in the corresponding segment selector as an index in a so-called descriptor table .
The entry in the descriptor table contains the start address and length of the segment , as well as protection bits to prevent code without the required privilege level to access it .
In case there is only segmentation and no paging , the resulting address is the original virtual address added to the start of the segment and that will be the physical address , and we are done .
However , both the GE-645 mainframe computer used for Multics and the more modern x86-32 allow one to combine segmentation and paging .
In that case , the virtual address is ﬁrst translated into a so-called linear address using the segment descriptor table and that linear address is then translated into a physical address using the page table structure .
KA Operating Systems and Virtualisation | October 2019 Page 376 The Cyber Security Body Of Knowledge www.cybok.org This is as complicated as it sounds ; none of the popular modern operating systems still use segmentation .
In fact , the 64-bit version of the Intel x86 no longer even supports full segmentation , although some vestiges of its functionality remain .
On the other hand , complicated multi-level address translation is still quite common in virtualised environments .
Here , the hypervisor tries to give virtual machines the illusion that they are running all by themselves on real hardware , so the MMU translates a virtual address ﬁrst to what is known as a guest physical address ( using page tables ) .
11.4.6 Modern hardware extensions for memory protection Also , while segmentation is mostly dead , there are many other forms of hardware support for memory protection beyond paging .
For instance , many machines have had support for buffer bounds checking and some date back a quarter of a century or more .
To illustrate the corresponding primitives , however , we will look at what is available in modern general purpose processors , focusing mostly on the Intel x86 family .
The point here is not whether we think this processor is more important or even that feature X or Y will be very important in the future ( which is debatable and hard to predict ) , but rather to illustrate that this is still a very active area for hardware development today .
As a ﬁrst example , consider the somewhat ill-fated Intel Memory Protection Extensions ( MPX ) that enhance Intel ’ s workhorse processors with functionality to ensure that array pointers can not stray beyond the array boundaries ( stopping vulnerabilities such as buffer overﬂows from being exploited ) .
For this purpose , a small set of new registers can store the lower and upper bounds of a small number of arrays , while prior to de-referencing the pointer , new MPX instructions check the value of the array pointer for boundary violations .
Even in systems that use MPX only in userspace , the operating system plays a role , for instance , to handle the exception that the hardware throws when it encounters a buffer boundary violation .
MPX was heavily criticised for having too few of these bounds registers , leading to much performance overhead .
In addition , MPX does not support multi-threading , which may result in data races in legacy code .
One might say that MPX is a good example of an attempt by a hardware vendor to add new features for memory safety to their CPUs that is unfortunately not always successful .
Intel MPK allows one to set four previously unused bits in the PTE ( Fig .
In addition , it adds a new 32-bit register containing 2 bits for each key to indicate whether reading and writing is allowed for pages tagged with that key .
MPK allows developers to partition the memory in a small number ( in this case 16 ) protection domain and , for instance , allow only a speciﬁc crypto library to access cryptographic keys .
Again , Intel was actually late to the party , as similar features existed in a variety of processors since the 1960s .
9 KA Operating Systems and Virtualisation | October 2019 Page 377 The Cyber Security Body Of Knowledge www.cybok.org cesses may update the value of the register , only privileged operating system code can tag the memory pages with keys .
The idea is simple yet powerful .
Tags are generally not very large , say 4 bits , so they can be stored in the top-most byte of the 64-bit pointer value which we do not really use anyway ( in fact , ARM supports a top-byte-ignore feature that makes the hardware explicitly mask out the top most byte ) .
Whenever the program allocates N bytes of memory , the allocator rounds up the allocation to multiples of 16 bytes and assigns a random tag to it .
It also assigns the same tag to the pointer to the memory .
From now on , dereferencing the pointer is only permitted if the tag in the pointer matches that of the memory to which it refers—effectively stopping most spatial and temporal memory errors .
Instead , they have a much simpler Memory Protection Unit ( MPU ) which serves only to protect memory , in a way that resembles the MPK functionality discussed above .
In MPU designs , the operating systems deﬁne a number of memory regions with speciﬁc memory access permissions and memory attributes .
Meanwhile , the MPU monitors all the processor ’ s memory accesses ( including instruction fetches and data accesses ) and triggers an exception on detecting an access violation .
Note that in the above , we have assumed that the operating system needs protection from untrusted user applications .
A special situation arises when the operating itself is not trusted .
Perhaps you are running a security-sensitive application on a compromised operating system , or in the cloud , where you are not sure you want to trust the cloud provider .
In the general case , you may want to protect your data and applications without trusting any other software .
For instance , the code running in an SGX enclave is intended to be a part of a normal user process .
The memory it uses is always encrypted as soon as it leaves the processor .
Moreover , SGX offers hardware support to perform attestation , so that a ( possibly remote ) party can verify that the code is running in an enclave and that it is the right code .
ARM TrustZone , on the other hand , isolates the ‘ normal world ’ that runs the normal operating system and user applications , from a ‘ secure world ’ that typically runs its own , smaller operating system as a well as a small number of security sensitive applications .
Code in the normal world can call code in the secure world in a way that resembles the way applications call into an operating system .
One interesting application of special environments such as ARM TrustZone ( or Intel ’ s SMM mode , discussed later ) is to use it for runtime monitoring of the integrity of a regular operating system—hopefully detecting whatever stealthy malware or rootkit compromised it before it can do some serious damage .
Although aspects of these trusted environments clearly overlap with operating system security , we consider them mostly beyond the scope of this knowledge area .
Switching gears again , it may be the case that the operating system is ﬁne , but the hardware is not .
Malicious or faulty hardware may use the system ’ s Direct Memory Access ( DMA ) to read or overwrite sensitive data in memory that should be inaccessible to them .
Unfortunately for the user , it is hard to be sure that what looks like , say , a display cable or power adapter , does not also contain some malicious circuitry designed to compromise the computer [ 1057 ] .
As a partial remedy , most architectures nowadays come with a special MMU for data transferred to and from devices .
This hardware , called an IOMMU , serves to map device virtual addresses to physical addresses , mimicking exactly the page-based protection illustrated in Fig .
In other words , devices may access a virtual memory address , which the IOMMU translates to an actual physical address , checks for permissions and stops if the page is not mapped in for the device , or the protection bits do not match the requested access .
While doing so provides some measure of protection against malicious devices ( or indeed drivers ) , it is important to realise that the IOMMU was designed to facilitate virtualisation and really should not be seen as a proper security solution .
Since updating the IOMMU page tables is a slow operation , it is not uncommon for operating systems to delay this operation and batch it with other operations .
The result is that there may be a small window of time during which the device still has access to the memory page even though it appears that these rights have already been revoked .
Finally , we can observe that the increasing number of transistors per surface area enables a CPU vendor to place more and more hardware extensions onto their chips , and the ones discussed above are by no means the only security-related ones in modern processors .
Additional examples include cryptographic units , memory encryption , instructions to switch extended page tables efﬁciently , and pointer authentication ( where the hardware detects modiﬁcation of pointer values ) .
There is no doubt that more features will emerge in future generations and operating systems will have to adapt in order to use them in a meaningful way .
11.4.7 Protection rings Among the most revolutionary ideas introduced by Multics was the notion of protection rings—a hierarchical layering of privilege where the inner ring ( ring 0 ) is the most privileged and the outer ring is the least privileged [ 1036 ] .
Accordingly , untrusted user processes execute in the outer ring , while the trusted and privileged kernel that interacts directly with the hardware executes in ring 0 , and the other rings could be used for more or less privileged system processes .
Protection rings typically assume hardware support , something most general purpose processors offer today , although the number of rings may differ .
However , as we shall see , the story becomes slightly confusing , because some modern processors have also introduced more and different processor modes .
For now , we simply observe that most regular operating systems use only two rings : one for the operating system and one for the user processes .
Whenever less privileged code needs a function that requires more privileges , it ‘ calls into ’ the KA Operating Systems and Virtualisation | October 2019 Page 379 The Cyber Security Body Of Knowledge www.cybok.org lower ring to request the execution of this function as a service .
Thus , only trusted , privileged code may execute the most sensitive instructions or manipulate the most sensitive data .
Unless a process with fewer privileges tricks more privileged code into doing something that it should not be doing ( as a confused deputy ) , the rings provide powerful protection .
The original idea in Multics was that transitioning between rings would occur via special call gates that enforce strict control and mediation .
For instance , the code in the outer ring can not make a call to just any instruction in the inner ring , but only to predeﬁned entry points where the call is ﬁrst vetted to see if it and its arguments do not violate any security policy .
While processors such as the x86 still support call gates , few operating systems use them , as they are relatively slow .
Many operating systems place the arguments to the system call in a predeﬁned set of registers .
Like the call gates , the traps and system call instructions also ensure that the execution continues at a predeﬁned address in the operating system , where the code inspects the arguments and then calls the appropriate system call function .
Besides the user process calling into the operating system , most operating systems also allow the kernel to call into the user process .
If the user process registered a handler for the signal , the operating system will stop the current execution of the process , storing all its processor states on the process ’ stack in a so-called signal frame , and continue execution at the signal handler .
When the signal handler returns , the process executes a sigreturn system call that makes the operating system take over , restore the processor state that is on the stack and continue executing the process .
The boundary between security domains , such as the operating system kernel and user space processes is a good place to check both the system calls themselves and their arguments for security violations .
Likewise , Windows and UNIX-based operating systems have to check the arguments of many system calls .
Consider , for instance , the common read and write system calls , by which a user requests the reading of data from a ﬁle or socket into a buffer , or the writing of data from a buffer into a ﬁle or socket , respectively .
Before doing so , the operating system should check if the memory to write from or read into is actually owned by the process .
After executing the system call , the operating system returns control to the process .
Here also , the operating system must take care not to return results that jeopordise the system ’ s security .
For instance , if a process uses the mmap system call to request the operating system to map more memory into its address space , the operating system should ensure that the memory pages it returns no longer contain sensitive data from another process ( e.g .
Zero intialisation problems can be very subtle .
For instance , compilers often introduce padding bytes for alignment purposes in data structures .
Since these padding bytes are not visible at the programming language level at all , the compiler may see no reason to zero initialise them .
However , a security violation occurs when the operating system returns such KA Operating Systems and Virtualisation | October 2019 Page 380 The Cyber Security Body Of Knowledge www.cybok.org a data structure in response to a system call and the unitialised padding contains sensitive data from the kernel or another process .
Incidentally , even the signalling subsystem in UNIX systems that we mentioned earlier is an interesting case for security .
Recall that the sigreturn takes whatever processor state is on the stack and restores that .
Now assume that attackers are able to corrupt the stack of the process and store a fake signal frame on the stack .
If the attackers are then also able to trigger a sigreturn , they can set the entire processor state ( with all the register values ) in one fell swoop .
As also mentioned earlier , the situation regarding the protection rings is slightly more confusing these days , as recent CPUs offer virtualisation instructions for a hypervisor , allowing them to control the hardware accesses at ring 0 .
To do so , they have added what , at ﬁrst sight , looks like an extra ring at the bottom .
It also indicates that operating systems in their respective virtual machines can keep executing ring 0 instructions natively .
For the sake of completeness , we should mention that things may get even more complex , as some modern processors still have other modes .
When a system boots , the ﬁrmware is in control of the hardware and prepares the system for the operating system to take over .
However , when SMM is enabled , the ﬁrmware regains control when a speciﬁc interrupt is sent to the CPU .
For instance , the ﬁrmware can indicate that it wants to receive an interrupt whenever the power button is pressed .
In that case , the regular execution stops , and the ﬁrmware takes over .
It may , for instance , save the processor state , do whatever it needs to do and then resume the operating system for an orderly shutdown .
ME is a completely autonomous system that is now in almost all of Intel ’ s chipsets ; it runs a secret and completely independent ﬁrmware on a separate microprocessor and is always active : during the booting process , while the machine is running , while it is asleep , and even when it is powered off .
As long as the computer is connected to power , it is possible to communicate with the ME over the network and , say , install updates .
While very powerful , its functionality is largely unknown except that it runs its own small operating system11 which researcher found contained vulnerabilities .
The additional processors that accompany the main CPU ( be it the ME or related ones such as Apple ’ s T2 and Google ’ s Titan chips ) raise an interesting point : is the operating system running on the main CPU even capable of meeting today ’ s security requirements ?
KA Operating Systems and Virtualisation | October 2019 Page 381 The Cyber Security Body Of Knowledge www.cybok.org 11.4.9 Low-end devices and the IoT Many of the features described above are found , one way or another , in most general-purpose processor architectures .
Simple microcontrollers typically have no MMUs , and sometimes not even MPUs , protection rings , or any of the advanced features we rely on in common operating systems .
Nevertheless , the embedded nature of the devices makes it hard to check or even test their security and , wherever they play a role in security sensitive activities , security by means of isolation/containment and mediation should be enforced externally , by the environment .
For instance , we can use formal veriﬁcation to ensure that certain classes of bugs can not be present in the software or hardware , and that the system is functionally correct [ 1049 ] .
Scaling the veriﬁcation to very large systems is still challenging , but the ﬁeld is advancing rapidly and we have now reached the stage that important components such as a microkernel , ﬁle systems and compilers have been veriﬁed against a formal speciﬁcation .
Veriﬁcation of other components may be desirable , but is not essential for isolation .
Of course , the veriﬁcation itself is only as good as the underlying speciﬁcation .
If you get that wrong , it does not matter if you have veriﬁed it , you may still be vulnerable .
Despite our best efforts , however , we have not been able to eradicate all security bugs from large , real-world systems .
To guard themselves against the types of attacks described in the threats model , modern operating systems employ a variety of solutions to complement the above isolation and mediation primitives .
We distinguish between ﬁve different classes of protection : information hiding , control ﬂow restrictions , partitioning , code and data integrity checks , and anomaly detection .
11.5.1 Information hiding One of the main lines of defense in most current operating systems consists of hiding whatever the attackers may be interested in .
Speciﬁcally , by randomising the location of all relevant memory areas ( in code , heap , global data and stack ) , attackers will not know where to divert the control ﬂow , nor will they be able to spot which addresses contain sensitive data , etc .
Soon , similar efforts appeared in other operating systems and the ﬁrst mainstream operating systems to have ASLR enabled by default were OpenBSD in 2003 and Linux in 2005 .
However , these early implementations only randomised the address space in user programs and randomisation did not reach the kernel of major operating systems , under the name of Kernel ASLR ( KASLR ) , until approximately a KA Operating Systems and Virtualisation | October 2019 Page 382 The Cyber Security Body Of Knowledge www.cybok.org decade after it was enabled by default in user programs .
The idea of KASLR is simple , but there are many non-trivial design decisions to make .
In particular , what portion of the address do we randomise ?
In other words , we need at most 512 guesses to ﬁnd the kernel code .
If attackers ﬁnd a vulnerability to divert the kernel ’ s control ﬂow to a guessed address from a userspace program and each wrong guess leads to a system crash , it would sufﬁce to have userspace access to a few hundred machines to get it right at least once with high probability ( although many machines will crash in the process ) .
Another important decision is what to randomise .
Most implementations today employ coarse-grained randomisation : they randomise the base location of the code , heap or stack , but within each of these areas , each element is at a ﬁxed offset from the base .
This is simple and very fast .
However , once attackers manage to get hold of even a single code pointer via an information leak , they know the addresses for every instruction .
It is no surprise that these information leaks are highly valued targets for attackers today .
For instance , it is possible to randomise at the page level or the function level .
If we shufﬂe the order of functions in a memory area , even knowing the base of the kernel code is not sufﬁcient for an attacker .
Indeed , we can go more ﬁne-grained still , and shufﬂe basic blocks , instructions ( possibly with junk instructions that never execute or have no effect ) or even the register allocations .
Many ﬁne-grained randomisation techniques come at the cost of space and time overheads , for instance , due to reduced locality and fragmentation .
For instance , research has shown that heap allocations , globals and even variables on the stack can be scattered around memory .
Of course , doing so will incur a cost in terms of performance and memory .
Considering KASLR , and especially coarse-grained KASLR , as our ﬁrst line of defense against memory error exploits would not be far off the mark .
Numerous publications have shown that KASLR can be broken fairly easily , by leaking data and/or code pointers from memory , side channels , etc .
By ensuring that attackers can not divert control to code of their choosing , we make it much harder to exploit memory errors , even if we do not remove them .
Conceptually , CFI is really simple : we ensure that the control ﬂow in the code always follows the static control ﬂow graph .
For instance , a function ’ s return instruction should only be allowed to return to its callsite , and an indirect call using a function pointer in C , or a virtual function in C++ , should only be able to target the entry point of the legitimate functions that it should be able to call .
To implement this protection , we can label all the legitimate targets KA Operating Systems and Virtualisation | October 2019 Page 383 The Cyber Security Body Of Knowledge www.cybok.org for an indirect control transfer instruction ( returns , indirect calls and indirect jumps ) and add these labels to a set that is speciﬁc for this instruction .
At runtime , we check whether the control transfer the instruction is about to make is to a target that is in the set .
For instance , rather than restricting a function ’ s return instruction to target-only legitimate call sites that could have called this function , it may target any call site .
On modern machines , some forms of CFI are ( or will be ) even supported by hardware .
Not to be outdone , ARM provides pointer authentication to prevent illegitimate modiﬁcation of pointer values—essentially by using the upper bits of a pointer to store a Pointer Authentication Code ( PAC ) , which functions like a cryptographic signature on the pointer value ( and unless you get the PAC right , your pointer is not valid ) .
Unfortunately , CFI only helps against attacks that change the control ﬂow—by corrupting control data such as return addresses , function pointers and jump targets—but is powerless against non-control data attacks .
, by setting the effective user id to that of the root user ) .
However , if restrictions on the control ﬂow are such a success in practice , you may wonder if similar restrictions are also possible on data ﬂow .
, an instruction that reads from memory ) which store instructions may legitimately have produced the data , and we label these instructions and save these labels in a set .
At runtime we remember , for each byte in memory , the label of the last store to that location .
When we encounter a load instruction , we check if the last store to that address is in the set of legitimate stores , and if not , we raise an alarm .
Unlike CFI , DFI has not been widely adopted in practice , presumably because of the signiﬁcant performance overheads .
Besides the structural decomposition of a system in different security domains ( e.g , into processes and the kernel ) protected by isolation primitives with or without hardware support , there are many additional techniques that operating systems employ to make it harder for attackers to compromise the TCB .
In this section , we discuss the most prominent ones .
To prevent code injection attacks , whereby the attackers transfer control to a sequence of instructions they have stored in memory areas that are not meant to contain code such as the stack or the heap , operating systems today draw a hard line between code and data [ 1062 ] .
Every page of memory is either executable ( code pages ) or writable , but not both at the same time .
In the absence of code injection , attackers interested in diverting the control ﬂow of the program are forced to reuse code that is already present .
Similar mechanisms are used to make KA Operating Systems and Virtualisation | October 2019 Page 384 The Cyber Security Body Of Knowledge www.cybok.org sensitive data in the kernel ( such as the system call table , the interrupt vector table , etc . ) .
All major operating systems support this mechanism , typically relying on hardware support ( the NX bit in modern processors12 ) —even if the details differ slightly , and the name may vary from operating system to operating system .
Preventing the kernel from accessing userspace .
We have already seen that operating systems use the CPU ’ s protection rings to ensure that user processes can not access arbitrary data or execute code in the operating system , in accordance with the security principles by Saltzer & Schroeder , which prescribe that all such accesses be mediated .
However , sometimes we also need to protect the other direction and prevent the kernel from blindly accessing ( or worse , executing ) things in userspace .
To see why this may be bad , consider an operating system where the kernel is mapped into every process ’ address space and whenever it executes a system call , it executes the kernel code using the process ’ page tables .
The reason is that doing so is efﬁcient , as there is no need to switch page tables when executing a system call , while the kernel can efﬁciently access all the memory .
Also since the kernel pages have the supervisor ( S ) bit set , there is no risk that the user process will access the kernel memory .
However , suppose the kernel has a bug that causes it to de-reference a function pointer that under speciﬁc circumstances happens to be NULL .
The most likely thing to happen is that the kernel crashes .
After all , the kernel is trying to execute code on a page that is not valid .
But what if a malicious process deliberately maps a page at address 0 , and ﬁlls it with code that changes the privileges of the current process to that of root ?
In that case , the kernel will execute the code , with kernel privileges .
It should now be clear that the kernel should probably not blindly execute process code .
Nor should it read blindly from user data .
After all , an attacker could use it to feed malicious data to the kernel instructions .
To prevent such accesses , we need even more isolation than that provided by the default rings .
SMEP and SMAP are enabled by setting the appropriate bits in a control register .
As soon as they are on , any attempt to access or transfer control to user memory will result in a page fault .
Of course , this also means that SMAP should be turned off explicitly whenever the kernel needs to access user memory .
In particular , they were forced to abandon the single address space ( where the kernel executes in the address space of the process ) , because of the Meltdown out-of-order execution side channel from Table 11.1 .
For instance , it wrongly assumes that load instructions have the privilege to read the data they access , the outcome of a branch is the same as the previous time a branch at a similar address was executed , or the data needed for a load instruction is probably the data in this temporary CPU buffer that was just written .
However , even if any of these assumptions are wrong , the CPU can recover by squashing the results of the code that was executed out-of-order or speculatively .
Before the CPU realises things are not well after all and this byte should not be accessible , the attackers have already used the byte to read a particular element in a large array in their own process ’ address space .
Although the CPU will eventually squash all the results , the damage is already done : even though the byte can not be read directly , the index of the array element that is in the cache ( and is , therefore , measurably faster to access than the other elements ) must be the kernel byte .
To remedy this problem on somewhat older processors that do not have a hardware ﬁx for this vulnerability , operating systems such as Linux use a design that completely separates the page tables of the kernel from those of the processes .
In other words , the kernel also runs in its own address space , and any attempt by an out-of-order instruction to read a kernel address will fail .
The kernel can still map in the pages of the user process and thus access them if needed , but the permissions can be different .
For other vulnerabilities based on speculative execution ( such as Spectre and RIDL ) , the ﬁx is more problematic .
Often , multiple different spot solutions are used to patch the most serious issues .
For instance , after a bounds check that could be inﬂuenced by untrusted users , we may want to insert special instructions to stop speculation completely .
Likewise , operating systems such as Windows try to `` gang schedule `` only code that belongs to the same security domain on the same core ( so that leaking from on thread to another on the same core is less of an issue ) , while others such as OpenBSD disable hyperthreading altogether on Intel processors .
However , it is unclear how complete the set of patches will be , while we are waiting for the hardware to be ﬁxed .
Partitioning micro-architectural states Sophisticated side channel attacks build on the aggressive resource sharing in modern computer systems .
Multiple security domains share the same cache , the same TLB , the same branch predictor state , the same arithmetic units , etc .
Sharing is good for efﬁciency , but , as indicated by the Principle of Least Common Mechanism , they also give rise to side channels .
To prevent such attacks , operating systems may need to sacriﬁce some of the efﬁciency and partition resources even at ﬁne granularity .
For instance , by means of page colouring in software or hardware-based cache allocation technology , an operating system may give different processes access to wholly disjointed portions of the cache ( e.g .
Unfortunately , partitioning is not always straightforward and currently not supported for many low-level resources .
11.5.4 Code and data integrity checks One way to reduce the exploitability of code in an operating system , is to ensure that the code and/or data is unmodiﬁed and provided by a trusted vendor .
For instance , for many years Windows has embraced driver signing .
Some newer versions have taken this a step further and use a combination of hardware and software security features to lock a machine down , ensuring that it runs only trusted code/apps—a process referred to by Microsoft as ‘ Device Guard ’ .
Even privileged malware can not easily get non-authorised apps to run , as the machinery to check whether to allow an app to run sits in a hardware-assisted virtualised environment .
Most code signing solutions associate digital signatures associated with the operating system extensions allow the operating system to check whether the code ’ s integrity is intact and the vendor is legitimate .
KA Operating Systems and Virtualisation | October 2019 Page 386 The Cyber Security Body Of Knowledge www.cybok.org However , what about the code that checks the signature and , indeed , the operating system itself—are we sure that this has not been tampered with by a malicious bootkit ?
Ensuring the integrity of the system software that is loaded during the booting involves a number of steps , mostly related to the multiple steps in the boot process itself .
From the earliest commercial computers onward , booting involved multiple stages .
It would execute ( part of ) this word to load even more instructions , and then start executing these instructions as the `` boot program `` .
In general , securely booting devices starts with an initial ‘ root of trust ’ which initiates the booting process and is typically based in hardware , for instance , a microcontroller that starts executing software from internal , immutable memory , or from internal ﬂash memory that can not be reprogrammed at all , or only with strict authentication and authorisation checks .
As an example , modern Apple computers use a separate processor , the T2 Security Chip , to provide the hardware root of trust for secure boot among other things , while Google has also developed a custom processor for this called the Titan .
We will now discuss how a hardwareroot of trust helps to verify that a system booted securely .
Booting general-purpose computers typically starts with the ﬁrmware which initiates a sequence of stages that ends with a fully booted system .
For instance , the ﬁrmware may load a special bootloader program which then loads the operating system kernel which in turn may load additional boot drivers until ﬁnally the operating system is fully initialised and ready to interact with the user or applications .
All of these stages need protection .
Secure boot veriﬁes whether the boot loaders were signed with the appropriate key , i.e .
, using keys that agree with the key information that is stored in the ﬁrmware .
This will prevent loaders and drivers without the appropriate signatures from gaining control of the system .
The bootloader can now verify the digital signature of the operating system kernel before loading it .
Next , the kernel veriﬁes all other components of the operating system ( such as boot drivers and possibly integrated anti-malware software ) before starting them .
By starting the anti-malware program before other drivers , it can subsequently check all these later components , and extend the chain of trust to a fully initialised operating system .
The next problem is : how do we know that this is the case ?
In other words , how do we know that the system really did boot securely and we can trust whatever is displayed on the screen ?
The trick here is to use attestation , whereby a ( remote ) party can detect any changes that have been made to our system .
Remote attestation typically uses special hardware such as a Trusted Platform Module ( TPM ) that serves as a root of trust and consists of verifying , in steps , whether the system was loaded with the ‘ right ’ kind of software .
These registers are not for writing to directly , but rather for extending .
Now , if we want to extend it further , say with Z , the TPM again calculates the hash of KA Operating Systems and Virtualisation | October 2019 Page 387 The Cyber Security Body Of Knowledge www.cybok.org Z and the value currently in PCR-0 and stores the outcome in PCR-0 .
We can now extend this further and create an arbitrarily long “ hash chain `` .
The values in the PCRs can serve as evidence that the system is in a trustworthy state .
Specifically , the ﬁrst code that executes when you boot your system is ﬁrmware boot code that is sometimes referred to as the Core Root of Trust for Measurements ( CRTM ) or BIOS boot block .
This code will ‘ measure ’ the full ﬁrmware by generating a hash of its content which it sends to the TPM to extend PCR-0 , before it starts executing it .
Next , the ﬁrmware that is now executing will measure the next component of the boot process and again store the value in a PCR of the TPM ( e.g .
A remote party can now verify whether the system booted securely by asking the TPM for a ‘ quote ’ : a report of a set of PCR values currently in PCRs ( together with a nonce supplied by the remote party ) , that is signed with the TPM ’ s private Attestation Identity Key that never leaves the TPM ( and derives from a hardcoded key that was created at manufacturing time ) .
As the public key is well-known , anyone can verify that the quote came from the TPM .
Upon receiving the quote and after verifying that it came from the TPM and that it was fresh , the remote party knows that the booting process could only have followed the steps that created these hashes in the PCRs .
If they correspond to the hashes of known and trusted code , the remote party knows that the system booted securely .
Code and data integrity checking may well continue at runtime .
For instance , the hypervisor may provide functionality to perform introspection of its virtual machines : is the code still the same , do the data structures still make sense ?
The VMI functionality may reside in the hypervisor itself , although it could be in a separate application .
Besides the code , common things to check in VMI solutions include the process list ( is any rootkit trying to hide ?
For instance , a system that crashes hundreds of times in a row could be under attack by someone who is trying to break the system ’ s address space layout randomisation .
Of course , there is no hard evidence and just because an anomaly occurred does not mean there is an attack .
Anomaly detection systems must strike a balance between raising too many false alarms , which are costly to process , and raising too few , which means it missed an actual attack .
In this section , we brieﬂy discuss databases as an example of how operating system security principles , issues and solutions are applied to other domains [ 1068 ] .
Security in database systems follows similar principles as those in operating systems with authentication , privileges , access control and so on KA Operating Systems and Virtualisation | October 2019 Page 388 The Cyber Security Body Of Knowledge www.cybok.org as prime concerns .
The same is true for access control , where many databases offer discretionary access control by default , and role-based and mandatory access control for stricter control to more sensitive data .
Representing each user as a security domain , the questions we need to answer concern , for instance , the user ’ s privileges , the operations that should be logged for auditing , and the resource limits such as disk quota , CPU processing time , etc .
Note that sometimes users who do not have access to a database except by means of a speciﬁc SQL query may craft malicious inputs to elevate their privileges in so-called SQL injection attacks [ 1069 ] .
While database-level access control limits who gets access to which elements of a database , it does not prevent accesses at the operating system level to the data on disk .
For this reason , many databases support transparent data encryption of sensitive table columns on disk— often storing the encryption keys in a module outside the database .
In an extreme case , the data in the database may be encrypted while only the clients hold the keys .
While sophisticated cryptographic solutions ( such as homomorphic encryption ) exist , they are quite expensive and simpler solutions are commonly used .
For instance , sometimes it is sufﬁcient to store the hash of a credit card number , say , instead of the actual number and then query the database for the hash .
Of course , in that case , only exact matches are possible—as we can not query to see if the value in the database is greater than , smaller than , or similar to some other value ( nor are aggregated values such as averages or sums possible ) .
The problem of querying encrypted databases is an active ﬁeld of research and beyond the scope of this Knowledge Area .
While security and access control in regular databases is non-trivial already , things get even more complex in the case of Outsourced Databases ( ODBs ) , where organisations outsource their data management to external service providers [ 1070 ] .
Speciﬁcally , the data owner creates and updates the data at an external database provider , which then deals with the client ’ s queries .
In addition to our earlier concerns about conﬁdentiality and encryption , questions that arise concern the amount of trust to place in the provider .
Can the data owner or the querying client trust the provider to provide data that was created by the original data owner ( authenticity ) , unmodiﬁed ( integrity ) , and fresh results to the queries ?
Conceptually , it is possible to guarantee integrity and authenticity by means of signatures .
More advanced solutions based on authenticated data structures are also commonly advocated , such as Merkle hash trees .
In Merkle hash trees , originally used to distribute authenticated public keys , leaf nodes in the tree contain a hash of their data value ( the database record ) , each non-leaf node contains a hash of the hashes of its children , and the root node ’ s hash is signed and published .
All that is needed to verify if a value in a leaf node is indeed part of the original signed hash tree is the hashes of the intermediate nodes , which the client can quickly verify with a number of hashes proportional to the logarithm of the size of the tree .
Of course , range queries and aggregation are more involved and researchers have proposed much more complex schemes than Merkle hash trees , but these are beyond the scope of this knowledge area .
The take-away message is that with some effort we can guarantee authenticity , integrity and freshness , even in ODBs .
Interestingly , many of these innovations in security do not originally come from the operating system vendors or large open source kernel teams , but rather ‘ from the outside ’ —sometimes academic researchers , but in the case of operating system security , also often from independent groups such as GRSecurity and the PaX Team .
For instance , the PaX Team introduced ASLR as early as 2001 , played a pioneering role in making data areas non-executable and executable sections non-writable , as well as in ensuring the kernel can not access/execute user memory .
Surprisingly , where you might think that the major operating systems would embrace these innovations enthusiastically , the opposite is often true and security measures are adopted inconsistently .
The main reason is that nothing is free and a slow-down or increase in power consumption because of a security measure is not very popular .
The Linux kernel developers in particular have been accused of being obsessed with performance and having too little regard for security .
However , when the situation is sufﬁciently pressing , there is no other way than to deal with the problem , even if it is costly .
Research often focuses on methods that signiﬁcantly raise the bar for attackers , at an acceptable overhead .
CONCLUSION In this Knowledge Area , we addressed security issues at the lowest levels of the software stack : the operating system and the hypervisor .
Operating system / hypervisor security involves both the security of the operating system / hypervisor and the security guarantees offered by the operating system / hypervisor .
Unfortunately , the attack surface of a modern operating system or hypervisor is often large and threats of increasing sophistication involving both software and hardware call for increasingly powerful defenses also involving software and hardware .
Many of the principles of operating system design are useful across many application domains and are commonly applied in other areas , such as database management systems .
As with most domains , we saw that design decisions at the operating system/hypervisor level are a trade-off between security and performance—a balancing act that often slows down the adoption of security measures .
Expanding on the above , the distributed resources are typically dispersed ( for example , in an Azure or Amazon Cloud , in Peer-to-Peer Systems such as Gnutella or BitTorrent , or in a Blockchain implementation such as Bitcoin or Ethereum ) to provide various features to the users .
These include geo-proximate and low-latency access to computing elements , highbandwidth and high-performance resource access , and especially highly-available uninterrupted services in the case of resource failure or deliberate breaches .
The overall technical needs in a distributed system consequently relate to the orchestration of the distributed resources such that the user can transparently access the enhanced services arising from the distribution of resources without having to deal with the technical mechanisms providing the varied forms of distributed resource and service orchestrations .
Consequently , distributed systems security addresses the threats arising from the exploitation of vulnerabilities in the attack surfaces created across the resource structure and functionalities of the distributed system .
This Knowledge Area ﬁrst introduces the different classes of distributed systems categorising them into two broad categories of decentralised distributed systems ( without central coordination ) and the coordinated resource/services type of distributed systems .
Subsequently , each of these distributed system categories is expounded for the conceptual mechanisms providing their characteristic functionalities prior to discussing the security issues pertinent to these systems .
The better one understands how functionality is distributed , the better one can understand how systems can be compromised and how to mitigate the breaches .
The KA also discusses some technology aspects as appropriate along with providing references for following up the topics in greater depth .
While a spectrum of deﬁnitions exists in literature , distributed systems can be broadly classiﬁed by the coordination schema linking the resources or by the speciﬁcation of the services utilising them .
One broad class is of decentralised control where the individual resources primarily interact with their “ neighbouring ” resources .
The other broad category links the distributed resources via communication processes , such as message passing , to realise varied forms of virtual centralised/coordinated control .
Thus , based on such communication and coordination models , distributed systems can be categorised into the following two broad classes .
For example , systems such as Kademlia , Napster , Gnutella , and many other distributed ﬁle and music sharing/storage systems , wireless sensor networks as well as online gaming systems fall in this category .
We will utilise these two coordination abstractions throughout this chapter .
The Google File System , Amazon Web Services , Azure , and Apache Cassandra are simple examples of this class .
While this class may appear to be both broad and diverse , the coordination abstraction ( for either resources or services ) directly characterises the type of distributed system into these two sub-classes .
In both cases , these systems are typically coordinated via communication exchanges and coordination services with the intended outcome of providing a “ virtually centralised system ” where properties such as causality , ordering of tasks , replication handling , and consistency are ensured .
KA Distributed Systems Security | October 2019 Page 395 The Cyber Security Body Of Knowledge www.cybok.org Notes : There are many nuances of security in distributed systems .
One viewpoint focuses on the concepts and mechanisms to provide security in a distributed system where the resources and services are dispersed .
, the dispersal of keys versus a centralised key store or the use of Virtual Machines ( VMs ) to partition and isolate resources and applications .
However , it also discusses the latter viewpoints given that the dispersed security mechanisms typically execute on dispersed resources logically resulting in the need for the above mentioned classes of Decentralised or Coordinated clustering .
It is worth highlighting that a distributed system architecture is often an aggregation of multiple layers where each layer builds upon the services provided by the layer below and coordinated services offered across the distribution .
, naming , time synchronisation , distributed ﬁle systems are assembled through the interaction of different components and services running on individual devices .
Higher layers build upon the lower layers and services to provide additional functionalities and applications .
Interactions across the different components of the distributed system at each level are provided by middleware frameworks that support many different communication styles : message passing , Remote Procedure Calls ( RPCs ) , distributed object platforms , publish-subscribe architectures , enterprise service bus .
Distributed applications are thus realised in a layered ( or tiered ) fashion through the interactions and coordination of distributed components and services .
Within these architectures , decentralisation and coordination at each layer may differ resulting in hybrid compositions of decentralisation and coordination patterns .
12.1.2 Classes of Vulnerabilities & Threats Vulnerabilities refer to design or operational weaknesses that allow a system to be potentially compromised by an attacker .
Analogously , a threat reﬂects the potential or likelihood of an attacker causing damage or compromising the system .
Consequently , the vulnerabilities of a distributed system are broadly grouped based on the functional blocks therein deﬁning the distributed system .
Logically , these functional blocks and their operations also constitute the threat/attack surface for the systems where an attacker/adversary can exploit a vulnerability to compromise the system .
At a high level , the attack surface relates to the compromises of the physical resources , the communication schema , the coordination mechanisms , the provided services themselves , and the usage policies on the data underlying the services .
The following outlines the general functionalities that will be progressively detailed in the subsequent sections as relevant to the speciﬁc distributed system model .
This can include the sourcing of data and the access rights to read/write and use data over the lifetime of a service .
The potential threats and consequent attacks include masquerading or spooﬁng of identity to gain access rights to the data .
, depletion of computing resources and communication channels ) leading to the inaccessibility and unavailability of the distributed resources/services .
It is worth emphasising that resource distribution often entails more points for access control , and also more information transported in the system to support access control thus increasing the attack surface of the system ( see the Authentication , Authorisation & Accountability ( AAA ) Knowledge Area ( Chapter 13 ) for a discussion of authentication and authorisation in distributed systems ) .
Here , authorisation may be speciﬁed in terms of the user and/or resource identity including the use of login names and passwords .
Thus , an activity that involves tampering with the identity constitutes a likely threat .
12.1.2.2 Data Transportation The network level threats span routing , message passing , the publish-subscribe modalities of resource interaction , event based response triggering , and threats across the middleware stack .
A typical example is the Man In The Middle ( MITM ) attack where the attacker inserts itself between the victim ’ s browser and the web server to establish two separate connections between them .
This enables the attacker to actively record all messages and selectively modify data without triggering a suspicious activity alarm if the system does not enforce endpoint authentication .
KA Distributed Systems Security | October 2019 Page 397 The Cyber Security Body Of Knowledge www.cybok.org 12.1.2.3 Resource Management and Coordination Services This critical group encompasses the spectrum of threats to the mechanisms ( typically middleware protocols ) that provide the coordination of resources .
The threats to conﬁdentiality include information leakage threats such as Side Channel Attacks or Covert Channel Attacks .
Any delay or denial of data access constitutes a threat to Availability .
Integrity aspects concern any compromise of data correctness such as the violation of data consistency as observed by the distributed participants .
Consequently , addressing the security of the data elements of a distributed system requires consideration of the threats mentioned above across resources , access control , data transportation , and coordination services as well as data threats in the form of malicious applications , code , and viruses ( see the Malware & Attack Technology Knowledge Area ( Chapter 6 ) ) .
Section Organisation Based on this overview , the subsequent sections progressively outline the security approaches for distributed systems as split into the above mentioned classes of decentralised and coordination based systems .
In order to understand the security issues relevant to each class , the sections also provide a basic overview of the underlying distributed system concepts along with pointers for further reading .
This is followed by the exposition of coordinated distributed system models in Section 12.4 , and by a discussion of the corresponding security aspects in Section 12.5 .
Their popularity is driven by the characteristic P2P features of scalability , decentralised coordination , and low cost .
Scalability implies that no changes to the protocol design are needed with increasing numbers of peers .
Furthermore , the decentralised P2P system designs promote inherent resilience against individual peer failures or other disruptions .
The peer population itself represents the service provisioning infrastructure of the system .
Thereby , potential service consumers are required to partake in resource provisioning avoiding the need for dedicated data centres .
Originally , P2P systems were ( in ) famous for their support of ﬁle sharing applications such as eMule or KaZaA , though their usage is now common in applications such as social networks , multimedia content distribution , online games , internet telephony services , instant messaging , the Internet of Things , Car-to-Car communication , Supervisory Control and Data Acquisition ( SCADA ) systems , and wide area monitoring systems .
As discussed in later sections , distributed ledgers also utilise some aspects of P2P operations .
These system designs directly correlate with the application categories introduced in the previous section , i.e .
, unstructured protocols are mostly suitable for ( large scale and scalable ) data dissemination , whereas structured ones are usually applied for efﬁciency of data discovery .
The emergent hybrid P2P protocol designs combine aspects from both unstructured and structured ones within an integrated P2P system .
These partly contradict the conceptual P2P principle that considers all peers as equal in the sense of service provisioning .
In order to support the discussion of security in P2P systems , the next subsections provide an introductory level technical overview on P2P protocols .
We provide a brief overview of the P2P protocol categories in regard of the overlay topology , resources discovery , and message passing .
While the set of peers do not have any characteristic topology linking them , their implicit topology is usually embedded within the physical communication underlay network topology and often unveils tree or mesh like sub-graphs , which allow for low latency message exchange , e.g .
, in single source streaming media data dissemination with various consumers as leaf nodes .
Meshes are the more generic case , for example , in applications with multiple sources and sinks such as in ﬁle sharing applications .
2 https : //freenetproject.org/ In the sense that data and information is stored and exchanged with integrity and privacy preserving techniques to address freedom of expression and speech concerns .
This feature supports scalable dissemination but scales poorly for resource discovery or reproducible routing paths .
Peers nevertheless maintain an identiﬁer to allow independence of the underlay network address .
Resources are discovered using search algorithms on the overlay graph .
These options are often combined according to the requirements of the application .
The communication across peers is via messages .
, using an underlay network connection between two peers , but this usually requires that the peers explicitly know the peer address and route .
When the destination peer for the message to be sent is unknown , messages are piggybacked alongside a resource discovery operation .
All peers maintain lists ( direct routing tables with addresses or hashed addresses ) with contact information about other peers .
Hence , messaging works efﬁciently and the network does not suffocate from address-search messages .
The efﬁciency of such lists depends on the liveness of the peers .
Hence , the listed peers are periodically pinged for liveness and removed when no reply is received .
Structured topologies often appear as ring structures with shortcuts , which forms a basis for scalable and efﬁcient operations such as resource discovery and message passing .
The salient characteristics are efﬁciency of node discovery and efﬁciency of routing that uses information on the P2P structure and topology .
As this aspect has security implications , we brieﬂy detail these operations .
Distance computations are crucial for the lookup mechanism and data storage responsibilities .
The distance function and its properties differ among protocol implementations .
Data discovery is realised by computing the key of an easy-to-grasp resource identiﬁer such as a distinctive name/key and subsequently requesting that key and its data from one of the responsible peers .
If peers do not know each other , then no direct connection can be set up and the destination peer ’ s location needs to be determined to conduct routing .
To this end , an overlay lookup mechanism aims to steadily decrease the address space distance towards the destination on each iteration of the lookup algorithm until the identiﬁer can be resolved .
This design KA Distributed Systems Security | October 2019 Page 400 The Cyber Security Body Of Knowledge www.cybok.org approach turns out to be very efﬁcient and promotes scalability .
Once the lookup has successfully retrieved the destination ’ s underlay network address , messages can be exchanged .
Lookup variants include iterative or recursive algorithms as well as parallelised queries to a set of closest neighbour peers .
In other words , routing tables usually provide more storage for closer peers than more distant ones .
Moreover , routing tables keep only information about live and reachable peers , therefore peers are periodically pinged .
In structured protocols , maintenance is more expensive as the topological structure needs to be retained , e.g .
, newly joined peers have to be put into the appropriate peer ’ s routing tables or leaving/unresponsive peers have to be replaced by live ones in many peers ’ routing tables .
12.2.3 Hybrid P2P Protocols Hybrid variants of P2P protocols integrate elements from unstructured and structured schemas , as their principal intent is data discovery and data dissemination .
BitTorrent was originally a classical unstructured protocol but now has been extended with structured P2P features to provide a fully decentralised data discovery mechanism .
On the other hand , architectural requirements often need to be considered to fully utilise the capacity of hybrid P2P protocols .
An example would be establishing how the data discovery is transmitted among the servers and how it is reported back to the user [ 1086 ] .
Similar considerations apply to other streaming overlay approaches .
These can include a layered design of structured and unstructured overlays .
Usually , the category with fewer peers represented the back-end part of the hierarchical system , whereas the multitude of peers act as front-end peers that process service requests at the ﬁrst level and only forward requests to the back-end when they can not fulﬁll the service request in the ﬁrst place .
This improves the look-up performance and also generates fewer messages in the network .
This design has proven successful , for example , in the eDonkey ﬁle sharing system or in Super P2P models such as KaZaA where a selected peer acts as a server to a subset of clients .
To facilitate this discussion , we outline the functional elements of a P2P system that help the reader relate the security implications for speciﬁc systems or application cases .
Subsequently , we assess the risks stemming from attacks to plan the requisite mitigation .
that are accessible through the service interface of the P2P protocol .
This functionality relates to the network level .
This functional element may be accessible at either the network level or locally on the peer ’ s host machine .
We will refer to these two elements as P-OP and P-DS , in the following subsections where we discuss the speciﬁc P2P attacks .
Whenever a deﬁnition refers to authentication , we assume that peers are implicitly authenticated on joining the overlay network .
P2P protocols may may use admission control systems or may be open to arbitrary peers .
12.3.1 Attack Types We now present the different attacks that are speciﬁc to P2P systems .
Besides the well known ( distributed ) denial of service attacks which apply to P2P as well as to other systems , most attacks exploit fundamental P2P features such as message exchange based decentralised coordination and especially that each peer has only a partial ( local ) view of the entire system .
Consequently , attackers aim to trick other peers by providing incorrect data or collude to create partitions that hide views of the system from good nodes .
We now enumerate some representative security attacks and relate them to their corresponding impact on Conﬁdentiality , Integrity and Availability ( CIA ) .
Some examples of attacks are further discussed in Section 12.3.2 along with corresponding mitigation approaches .
In P2P architectures , the attacker aims to decrease the overlay network ’ s service availability by excessively sending messages to a speciﬁc set of peers and thereby negatively affecting the P-OP functionality .
For example , benign peers may be impaired by an excessive maintenance workload .
Moreover , DoS and DDoS attacks can have a negative impact on bandwidth usage and resource provisioning which may result in degraded services .
The trafﬁc was traced back to “ over a thousand different Autonmous Systems ( ASNs ) across tens of thousands of unique endpoints ” participating in the attack .
Collusion refers to the fact that a sufﬁciently large subset of peers colludes to carry out a strategy which targets the P2P services and thereby negatively affects the POP functionality .
The typical attack aims to override control mechanisms such as those for reputation or trust management , or bandwidth provisioning .
The Sybil and Eclipse attacks , discussed later on , are based on attackers colluding to create network partitions to hide system state information from good nodes .
Consequences of pollution attacks are the proliferation of polluted content resulting in service impairments .
, adding advertisement at a single peer that subsequently spreads this polluted content to other peers .
This includes either illicit changing of , deletion of or denying access to data .
White washing attacks are especially dangerous for P2P systems that use reputation based systems since they allow a peer with a bad reputation to leave the system , and subsequently re-join as a benign user .
Routing attacks play an important role in composite attacks , such as the Eclipse attack which obstructs a good node ’ s view of the rest of the system .
, by returning bogus information to benign peer lookup requests .
The compromise of the routing table in Pastry , often used in online social networks , is a typical routing attack .
Through this attack , adversaries reduce the outgoing trafﬁc load of their peers by lying about their data provisioning .
This is also an infringement on integrity and affects the P-OP functionality .
This attack is especially relevant in streaming media P2P applications which rely on the collaboration of peers .
They 4 https : //www.wired.com/story/github-ddos-memcached KA Distributed Systems Security | October 2019 Page 403 The Cyber Security Body Of Knowledge www.cybok.org consider the insertion into the overlay of peers that are controlled by one or several adversaries .
Furthermore , P2P applications may consider system users as legal entities and consequently restrict the amount of peers per user to the amount of allowed votes for that entity .
Hence , an imbalance results in terms of the expected amount of peers per user .
Sybil attacks may be a precursor for many of the previously described attacks .
Prominent Sybil attacks include the compromise of the BitTorrent DHT and the Sybil attack on the Tor anonymisation network .
Essentially , a good peer is surrounded by a colluding group of malicious peers that either partially or fully block the peer ’ s view of the rest of the system .
The consequence is that the malicious nodes can either mask or spoof the node ’ s external interactions .
An example of an Eclipse attack on Bitcoin is discussed in Section 5 .
The adversarial collusion of malicious peers is a key factor to launch these attacks resulting in signiﬁcant disruption .
Several of the observed attacks are known from other system architectures such as client-server models while others are new ones or compositions of various attacks .
The difference from comparable attacks in client-server system architectures is that P2P overlay networks may grow very large and adversaries have to correspondingly adapt their efforts , i.e .
, they need to scale up the fraction of malicious peers accordingly , thereby requiring a substantial amount of coordination to execute an effective collusion strategy .
These attacks vary depending upon whether the attacker has direct or indirect network access via a P2P overlay .
The latter requires attackers to properly join the network prior to the attack .
- Churn relates to the effects of peers joining and leaving in an overlay .
Churn attacks consider artiﬁcially induced churn with potentially high peer join/leave rates to cause bandwidth consumption due to the effort needed to maintain the overlay structure .
12.3.2 Attacks and their Mitigation We present some example attacks along with the approaches used to mitigate them .
These three mechanisms allow the implementation of various downstream mechanisms .
Limiting the number of routing paths and/or protecting the paths using ( high overhead ) cryptographic approaches are alternate approaches to mitigating routing attacks .
Sybil and Eclipse Scenarios : Sybil attacks occur where the attacker could launch an attack with a small set of malicious peers and subsequently gather multiple addresses , which allows malicious peers to fake being a larger set of peers .
However , the attack relies on the assumption of the existence of a single path towards the victim that can be manipulated by the attacker .
In such attacks , mitigation relies on using a centralised authority that handles peer enrolments or admission .
Extending this concept , adding certiﬁcates ( issued by a common Certiﬁcate Authority ) to peers ’ network IDs while joining the network is another possibility .
Other mitigation techniques to prevent malicious entities from selecting their own network IDs could entail a signing entity using public key cryptography .
Buffer Map Cheating Scenarios : Other disruptions could be used to attack the KAD P2P network [ 1084 ] , which is a Kademlia based network , through ﬂooding peer index tables close to the victim with false information as a simplistic taLEA variant .
A KAD network crawler is introduced to monitor the network status and detect malicious peers during a LEA .
However , a high overhead is incurred if each peer uses such a mechanism to detect malicious entities .
This becomes impractical as the overlay size increases .
KA Distributed Systems Security | October 2019 Page 405 The Cyber Security Body Of Knowledge www.cybok.org Divergent lookups have been proposed as an alternate taLEA mitigation technique where the disjoint path lookups avoid searching the destination peer ’ s proximity to skip the wasteful querying of malicious peers under taLEA assumptions .
Routing Scenarios : Mitigation mechanisms to handle routing attacks consider assigning multiple paths for each lookup using disjoint paths though at the cost of high message overhead .
Alternatives include the use of cryptographic schemes to protect the paths .
However , P2P is a decentralised coordination environment where implementing a centralised service to support the coordination of system wide cryptographic signatures is hard to realise .
The aforementioned security mechanisms increase the resilience of P2P systems against the various attacks .
Naturally , these mechanisms are resilient only until a critical mass of colluding malicious peers is reached .
In addition , some of these mechanisms require cryptographic support or the identiﬁcation of peers .
These requirements may interfere with application requirements such as anonymity , heterogeneity , or resource frugality .
While it is tempting to deﬁne each type of distributed system discretely ( i.e .
Firstly , there is the case where a service is replicated on a distributed resources platform ( or infrastructure ) to enable geo-dispersed access to users while sustaining the required type of consistency speciﬁcations on the service .
The Cloud and many distributed Client-Server systems fall in this category .
The alternate approach addresses distributed services ( versus platforms ) where the dispersed service participants interact to yield the collective distributed service for given consistency requirements .
For example , transactional databases and distributed ledgers fall in such a category of strong consistency .
Web crawlers , searches , or logistics applications may well work with weak consistency speciﬁcations .
Overall , these constitute the two broad classes of distributed systems in the coordinated resource pooling mode , namely the classes of resource-coordination and service-coordination , as based on their characteristic coordination schema although their functionality and deﬁnitions often overlap .
In the subsequent subsections , in order to contextualise distributed systems security , we ﬁrst detail the basic distributed concepts along with the coordination schema based on them .
This is followed by outlining the characteristic systems in each of the resource and service co- KA Distributed Systems Security | October 2019 Page 406 The Cyber Security Body Of Knowledge www.cybok.org ordination models .
This forms the basis behind the general set of disruptions/vulnerabilities relevant to both classes of coordinated distributed systems .
We then outline the threats and security implications speciﬁc to each class of systems .
A Note on Technologies Underlying Distributed Platforms : The introduction emphasised that the focus of this KA is on security in distributed systems rather than the use of distribution towards providing security .
Expanding on this topic , it is worth commenting on alternate perspectives related to the “ design and realisation ” of distributed platforms and services .
This design oriented perspective tends to emphasise the architecture of distributed systems , distributed services and their construction .
This perspective typically focuses on ( a ) establishing security requirements , ( b ) realisation approaches on how to meet given security requirements at each level of abstraction , and ( c ) considers a distributed system as a layered architecture where each layer builds upon the primitives offered at the layer below and from distributed services .
Also from this perspective , the security requirements of the applications must be met by complementing and building upon what is offered at the lower layers and services .
The composition of such subsystems/solutions is often achieved through the use of trade-offs ( and also threat ) analysis that tend to cover some and not all of the requirements and thus determining relative strengths and weaknesses .
As the architectures and realisation fundamentally underlie the KA premise of providing security in distributed systems , the reader is encouraged to refer to this literature .
The following section returns the focus back on distributed system concepts , and especially the fundamental concepts of the coordination class of distributed systems .
Distributed systems are often structured in terms of services to be delivered to clients .
Each service comprises and executes on one or more servers and exports operations that the clients invoke by making requests .
Although using a single , centralised server appears tempting , the resulting service resident on a server can only be as fault tolerant as the server hosting it .
Typically , in order to accommodate server failures , the servers are replicated , either physically or logically , to ensure some degree of independence across server failures with such isolation .
Subsequently , replica management protocols are used to coordinate client KA Distributed Systems Security | October 2019 Page 407 The Cyber Security Body Of Knowledge www.cybok.org interactions across these server replicas .
Naturally , the handling of client failures or client compromises ( including their role in launching attacks via malicious code or viruses ) also needs to be considered .
We now outline a basic set of distributed system concepts that also constitute the basis of the security considerations therein .
12.4.1 Systems Coordination Styles In order for the distributed resources and services to meaningfully interact , the synchronisation basis across them , in physical time or in logical order , needs to be speciﬁed .
The synchronisation applies at both the network and process levels .
Synchronous : All components of a distributed system are coordinated in time ( as lock step or rounds ) to be synchronised with each other .
Examples include typical safety-critical systems such as aircraft ﬂy-by-wire control where predictability and guaranteed real-time responsiveness is desired .
Asynchronous : Separate entities take steps in arbitrary order and operate at different speeds .
The ordering of events needs to be ensured through collective interactions .
Partially synchronous : Some restrictions apply on ordering of actions but no lock-step synchronisation is present .
Typical examples are SCADA control systems or high-value transactional stock systems where timeliness has implications on the service correctness .
12.4.2 Reliable and Secure Group Communication Group communication addresses the communication schema available to ensure reliable delivery of messages across the distributed entities .
These can be simple point-to-point direct messaging supported by appropriate acknowledgements ( ACKS and NACKS ) for reliable delivery .
In these approaches , the channels and messages can be encrypted or cryptographically signed though this entails higher transmission and processing overheads .
KA Distributed Systems Security | October 2019 Page 408 The Cyber Security Body Of Knowledge www.cybok.org 12.4.3 Coordination Properties The utility of a distributed system comes from a coordinated orchestration of the dispersed resources to yield a collectively meaningful capability .
Prior to discussing the variety of commonly used coordination schemas in Section 12.4.4 , we ﬁrst present the base deﬁnitions of Consensus , Group Membership and Consistency .
Consensus Informally , consensus pertains to achieving an agreement on values .
For example , the values could be data or process IDs .
Agreement : All good processes agree on the same value .
Group Membership and Consistency : Membership is a key “ service ” property in distributed systems that determines the set of constituent resources and also the nature of the agreement achieved on the set of valid participants ( static , dynamic , quorum membership ) and the data .
From a security perspective , this often relates to the integrity property for the service .
Note that the underlying assumption is always that the constituent processes can be modelled as deterministic state machines .
That is , performing a speciﬁc sequence of actions always leads to the same state .
• Strong consistency models : In these models the participants must agree on one consistent order of actions to take .
Hence , the processes are guaranteed to reach a consistent state under the assumption of determinism .
Strict Consistency : In strict consistency there are no constraints on the observed order of actions as long as it is consistent across all the participants .
Linearisability : The linearisability model is essentially strict consistency with the additional constraint that the observed order of actions corresponds to their real time order .
Strong consistency models are widely used in high risk contexts where any inconsistencies in the data may lead to dire consequences .
In these situations , consistency is more valued than availability and enforcing strong consistency constraints results in more delays in the systems due to the frequent synchronisation .
• Weak Consistency Models : In these models , the participants do not necessarily observe the same order of actions .
This can lead to inconsistent states depending on the nature of the additional constraints that the observed orders have to satisfy .
Sequential Consistency : Sequential consistency is met if the order in which the actions are performed by a certain process corresponds to their original order .
In order words , the sequential execution order of every process is preserved .
Causal Consistency : Causal consistency is achieved by categorising actions into those causally related/dependent and those that are not .
In this case only the order of causally related actions has to be preserved .
Two events are causally related if they both access the same data object and at least one of them is a write event .
Eventual Consistency : In eventual consistency there are no special constraints that have to be satisﬁed by the order of observer actions .
The idea behind this concept is that the participants will eventually converge to a consistent state either by observing equivalent orders of actions or by resorting to costly conﬂict resolution mechanisms .
Systems with weaker consistency models became popular with the advent of the Internet where wide scale web servers had to accommodate a large number of users .
To achieve this , such systems sacriﬁce strong consistency guarantees to achieve higher availability for their user base .
12.4.4 Replication Management and Coordination Schema : The Basis Behind Attack Mitigation A fundamental challenge for developing reliable distributed systems is to support the cooperation of the dispersed entities required to execute a common task , even when some of these entities , or the communication across them , fails .
There is a need to ensure ordering of the service actions and to avoid partitions of the distributed resources in order to result in an overall “ coordinated ” group of resources .
The state machine replication or state machine approach [ 1118 ] is a general method for implementing a fault-tolerant service by replicating servers and coordinating client interactions with server replicas .
The approach also provides a framework for understanding and designing replication management protocols .
The essential system abstraction is that of a state machine such that the outputs of the state machine are fully determined by the sequence of requests it processes independent of time or other activity in the system .
It should be noted that ideally one would like to collectively attain high availability , consistency and also full coordination to eliminate any partitioning of the set of distributed resources .
Naturally , security attacks attempt to compromise these elements of CAP .
Replication and Coordination In order to provide coherent and consistent behaviour ( in value and order ) , distributed resources use various types of replica management , i.e .
This is a key coordination mechanism that characterises the functionality of any distributed system .
The factors determining the speciﬁc mechanism depend on the type of system synchronisation model , the type of group communication and especially the nature of the perturbations ( faults or attacks ) being considered .
The commit protocols for database transactions are relevant here as are the schemes for credential management and PKI infrastructures providing veriﬁed access control .
Paxos To avoid the situation of distributed entities conducting uncoordinated actions or failing to respond , Paxos [ 1120 ] , a group of implicit leader-election protocols for solving consensus in an asynchronous setup , has been developed .
Paxos solves the consensus problem by giving all the participants the possibility to propose a value to agree upon in an initial phase .
In the second phase , if a majority agrees on a certain value , the process that had proposed the value implicitly becomes the leader , and agreement is achieved .
The same process is repeated for the next value to achieve consensus on a sequence of values .
The protocol is known not to provide liveness only under very speciﬁc circumstances as described in [ 1120 ] .
In this case , processes continue to propose values indeﬁnitely and remain blocked in the initial phase as no majority can be formed and progress is never made .
However , this situation rarely occurs in practice and Paxos remains one of most widely used coordination protocols .
Since only a majority is necessary in the second phase to reach consensus , the protocol is additionally tolerant to crashes even in the case of recovery .
This is remarkable since , as long as the majority of the processes has not failed , consensus can be reached .
KA Distributed Systems Security | October 2019 Page 411 The Cyber Security Body Of Knowledge www.cybok.org is an excellent read of the experiences of implementing Paxos at Google for the Chubby ﬁle system .
While there exists a variety of implementations of the Paxos protocol , it is notoriously known for being hard to implement and build middleware upon it due to its inherent complexity .
RAFT has recently gained in popularity due to its simpler design .
Paper [ 1122 ] explains the motivation behind the development of the RAFT protocol and how it works by comparing it with Paxos .
Byzantine Fault Tolerance ( BFT ) Attacks and other deliberate disruptions do not necessarily follow the semantics of benign omissions , timing or crashes .
In order to tolerate arbitrarily malicious behavior , Byzantine Fault Tolerance ( BFT ) protocols use coordinated replication to guarantee the correct execution of operations as long as at most a third of processes is compromised and exhibits arbitrary ( i.e .
In BFT , processes exchange the values they have received from each other in rounds .
The number of rounds necessary to reach consensus is determined by the number of compromised participants there are in the system [ 1123 ] .
Note that since the protocol operates in rounds , it is classiﬁed as a synchronous coordination protocol .
It has been shown in [ 1124 ] as the FLP impossibility result that it is impossible to reach consensus in the case of asynchronous communication .
Due to the necessity of synchronous communication and the rather higher overhead of message exchange required to deal with Byzantine failures , BFT protocols are applied mostly in speciﬁc critical applications .
It is also important to emphasize that BFT is expensive not only for the message complexity over the number of rounds needed .
From a security viewpoint , for its ability to tolerate arbitrary malicious behaviors , the BFT protocols constitute an appealing building block for the construction of intrusion tolerant systems .
It is worth making the observation that these protocols consider the number of compromised entities .
When faced with a malicious attacker identical replicas are not sufﬁcient because they exhibit the same vulnerabilities .
A malicious adversary who can compromise one replica can easily compromise the others if they are identical .
Hence , as a specialised form of consensus , a distributed coordinator directed algorithm is required to coordinate all the processes that participate in a distributed atomic transaction on whether to commit or abort ( roll back ) the transaction .
The protocol proceeds with a broadcast query from a leader to all the clients to commit .
This is followed by an acknowledgment ( commit or abort ) from each client .
The protocol achieves its goal even in many cases of failure ( involving either process , network node , or communication failures among others ) , and is thus widely used .
An approach based on logging protocol states is used to support recovery .
The classical 2PC protocol provides limited support for the coordinator failure that can lead to inconsistencies .
The 3PC protocol is essentially an extension of the BFT protocol and adds a third communication phase to assist the leader with the decision for an abort .
This entails a higher messaging and logging overhead to support recovery .
In practice , systems use either BFT for its simplicity or the Paxos protocol for its robustness .
The disruptions can be from improper design , arising from operational conditions or deliberate attacks .
Resource compromises or disruptions form the basic attack targets .
However , the functionality of a distributed system emerges from the interactions across the distributed resources .
These span the range of direct message exchanges or via middleware architectures such as pub-sub or event based triggering among others .
KA Distributed Systems Security | October 2019 Page 413 The Cyber Security Body Of Knowledge www.cybok.org As the distributed systems primarily rely on message passing for both data transportation and coordination , we group the perturbations at the level of message delivery6 .
The manifestation of these perturbations on the system operations results in deviations from the speciﬁed behavior of the system .
Crashes and denial-of-service also fall in this group as they typically manifest as disruptions of the proper temporal delivery of messages by obstructing access to the communication channels or resources .
The manipulation of the content of messages manifests as Byzantine behavior .
This attack is only viable if a set of resources use the exchange messages to build their global view of the system .
, a mixture of correct and incorrect values ) to different groups of resources to result in partitions of system state views .
Thus , based on different values received by different nodes , the individual nodes are unable to constitute a “ consistent ” and correct view of the system state .
, distributed ledgers in Blockchains ) determines the type of breach of the functionality .
Relating to the groups of vulnerabilities , a Byzantine attack can abuse access control , message delivery and coordination services , or the data itself ( viruses , compromised mobile code , worms ) to compromise the system .
Furthermore , attacks often entail multiple simultaneous occurrences that involve a combination of timing , value , persistence , and dispersed locations , potentially due to collusion between multiple attacking entities .
Attacks and Implications On this general background , we now detail the two prominent classes of distributed systems as based on the coordination schema ( resource- and service-coordination ) .
This will also form the system grouping for considering the security manifestations of attacks .
We use the classical CIA ( Conﬁdentiality , Integrity , and Availability ) terminology though the implications of these terms often differ according to the type of system and services .
For each class , the speciﬁcation of its functionality determines the type of attack and the resultant compromise that detrimentally affects the delivery of services .
Similarly , attacks aim to subvert the assumptions behind the functionality of resources , the services , and the underlying coordination schema .
In the following subsection , we enumerate some attack scenarios for the resources/infrastructure and services/application classes of coordination .
Given the immense diversity of types of resource and services based distributed systems , the purpose of these examples is only to illustrate some potential scenarios .
It is also worth highlighting that often a resource attack does not harm the resource per se but primarily affects the service executing on the resource .
12.5.1 The Resource Coordination Class – Infrastructure View This class of “ virtualised resource access ” primarily deals with the coordination of a group of computing and communication resources to provide an ensemble of highly-available , highlyreliable “ platform ” of diverse shared resources to the user .
but is agnostic to the actual mechanisms providing the on-demand access to the resources , scalability , physical characteristics , and geo-location/distribution of the underlying resources .
The basic resource replication simply provides a pool of resources to support high-availability access .
However , the resource replication schema provides only the “ capabilities ” to support the services executing on it .
Integrity is relevant corresponding to the service speciﬁcations .
For instance , VMs need to provide the speciﬁed level of isolation without information leakage .
Each replicated server has the same set of data , and any time the data is updated , a copy is updated across the replicated servers to provide consistency on data .
This will be the basis of the Service Coordination class discussed later on .
We brieﬂy present the Cloud and Client-Server models that constitute prominent examples of the class of distributed resources .
The Cloud Model The Cloud , in all its manifestations , is representative of the resource coordination model as essentially a “ resources platform ” for services to execute on .
There are multiple types of Clouds offering varied types of services ranging across emphasis on high-performance , low-latency access or high-availability amongst many other properties .
It is the speciﬁc resource coordination schema dictated by the speciﬁcations of the desired services based on which the Cloud “ platform ” provides structured access to the Cloud resources .
The chosen coordination schema correspondingly supports the type of desired capabilities , for example , access to specialised computing resources and/or resource containers such as physical or virtual machines each offering differing isolation guarantees across the containers .
The user speciﬁed services execute on the Cloud resources , which are managed by the Cloud service provider .
The coordination schema , as a centralised or distributed resource manager , handles the mapping and scheduling of tasks to resources , invoking VMs , health monitoring of resources , fault-handling of failed resources such that the user transparently obtains KA Distributed Systems Security | October 2019 Page 415 The Cyber Security Body Of Knowledge www.cybok.org sustained access to the resources as per the contractual Service Level Agreements ( SLAs ) speciﬁed on the Cloud resources .
The multitude of Cloud models , architectures , and services existing in practice makes it difﬁcult to project a single notion of Cloud security .
Each speciﬁc resource coordination model is characterized by the types of resource types in the Cloud model , the type of computing architecture as well as the desired functionalities within the Cloud .
These include , as a non-exhaustive list , the desired types of resource fault handling , the chosen approach for handling of service bursts , the type of schemas implemented for resource federation and migration , for task orchestration , scheduling , the desired degree of concurrent access , the supported levels of multi-tenancy etc .
However , from a security perspective , it is useful to de-construct the Cloud into its architectural and functional components that result in the Cloud ’ s attack surface to consider .
Analogous to the infrastructure view of a data center being an aggregation of computing and storage resources , the Cloud is an aggregation of geo-dispersed resources that are available on-demand to the user .
The exact composition of the resources , their location or the mechanisms collating the aggregated resources is transparent to the user .
These functional blocks , the physical Cloud resources along with the interfaces across them directly constitute the attack surface of the Cloud .
Both servers and clients are replicated to either provide a characteristic collective distributed service or for fault tolerance .
Note that we are referring to Client-Server architecture as a resources platform or infrastructure and not the Client-Server services per se .
The functionality of a Client-Server infrastructure is derived from the speciﬁcations of the services using the Client-Server model and from the requisite coordination schema underlying it .
KA Distributed Systems Security | October 2019 Page 416 The Cyber Security Body Of Knowledge www.cybok.org Attackability Implications ( and Mitigation Approaches ) on Resource Coordination We now outline some example scenarios for the Cloud though they analogously apply to the Client-Server and other resource models as well .
- Compromise of Resources : Such attacks impact the Availability of the basic resources .
Mitigation : Protection can be obtained by using access control schemes ( including Firewalls ) to limit external access to services and network resources .
Authorisation processes are set up for granting of rights along with access control mechanisms that verify the actual rights of access [ 1135 ] .
Consequently , it can be protected using techniques such as encryption .
As the speciﬁcation of a distributed service includes the speciﬁcation of both normal and anomalous behavior on the use of the data providing the service , this protection is considered under the services class .
The implication here is on Availability for the resources and on Integrity for the services .
The implication on the resources is on Availability , though both the Integrity and Conﬁdentiality of the data/service are affected .
These are complemented by periodic or random ID authentication queries .
The periodic checking of system state is used to establish the sanity of IDs .
- Compromise of VM : The typical manifestation is of information leakage from the VM via a Covert Channel Attack or Side Channel Attack or similar attacks .
The consequence is the violation of Integrity and Conﬁdentiality of the services provisioned by the VM .
There are three aspects to be considered here as the detection of leakage , the system level where the leakage transpires , and the handling of leakage .
Taint analysis is a powerful technique for data level detection .
As covert/side-channel attacks often happen at the hardware level and are inﬂuenced by the schedulers , the use of detectors employing hardware performance counters is a generally used technique as advocated in [ 1136 ] .
System level handling of VM compromises often starts from the level of tightening the speciﬁcation of trust assumptions and validating them being upheld using analytical , formal , or experimental stress techniques .
Hypervisors are commonly used for the enforcement of VM operations .
When the scheduler is affected and this results in an anomalous task or resource allocation , such a deviation ( on an incorrect resource allocation ) can be detected through Access Control .
In the case of a malicious takeover of the scheduler , the likely resultant inconsistencies across the system KA Distributed Systems Security | October 2019 Page 417 The Cyber Security Body Of Knowledge www.cybok.org state or resource-task bindings can be ﬁltered by the coordination schema whose job is to maintain a consistent state .
Such attacks typically impact Availability and Integrity .
Mitigation : As mentioned in the attack description , Access Control and coordination constructs are used to check the consistency of the system state for any observed mis-match to the legitimate or allowed set of resource allocations .
This can be used identify corruptions of the scheduler .
Mitigation : Approaches similar to scheduler compromise mitigation are used here .
If backup brokers are part of the design , that is a typical fall back , otherwise , system stops are often the solution .
- Compromise on Communication : As communication is a core functionality to achieve resource coordination , this has strong implications on the resources to stay coordinated and directly impacts Availability .
fundamentally compromises the functionality of the system .
- Compromise on Monitoring and Accounting : With incorrect information on the state of the system and/or services , this can lead to compromise of Conﬁdentiality , Integrity , and Availability .
Mitigation : State consistency schemes are the typical mechanism utilised here .
It is worth mentioning that the replication and coordination concepts presented in Sections 12.4 and 12.4.4 form the basis of the mitigation approaches .
The very purpose of the replication management is to obtain consistent system states to circumvent disruptions .
12.5.2 The Services Coordination Class – Applications View The service coordination model focuses on the speciﬁc characteristics of the services that determine the degree/type of coordination relevant to supporting that service .
For example , a database hosted on a Cloud necessarily requires the provision of integrity in the form of ACID7 properties along with liveness .
Distributed storage , such as KVS ( Key Value Store ) or transactional database services , may require varied levels of consistency or linearisability where the desired level of integrity may depend on the level of data-access latency feasible in the system .
The broad class of Web services to include Web crawlers and search engines may require weak or partial consistency as per CAP .
On the other hand , Blockchains or ledger queries , that provide distributed crypto based consensus , have strong consistency ( and traceable auditing ) as a key requirement with lesser demands on latency .
Thus , it is the speciﬁcation of the service ( KVS , Database , Blockchain ) that determines the nature of the coordination schema for the distributed resources platform .
It is useful to note that many of these services utilise the Client-Server paradigm though our interest here is at the services level .
Such services typically enable authentication ( either proving server authenticity to a client , or mutually authenticating both client and server ) over insecure networks , based on various cryptographic protocols .
Authentication services commonly act as trusted third party for interacting entities in a distributed system .
Storage/KVS This is a diverse set of services starting from register level distributed read-writes that entail strong consistency with very low latency .
Another general model is Key Value Store ( KVS ) where data is accessed via keys/pointers/maps with simple read , write , delete types of semantics .
In KVS , the data is represented as a collection of key-value pairs , such that each possible key appears at most once in the collection with a focus on fast access times ( up to a constant access time ) .
The key-value model is one of the simplest non-trivial data models , and richer data models are often implemented as extensions with speciﬁed properties .
For example , an ordered model can be developed that maintains the keys in a lexicographic order to efﬁciently retrieve selective key ranges .
Key-value stores can use consistency models ranging from eventual consistency to strict consistency .
The requirements are consistency as in banking where all the debit and credit transactions are ( strongly or weakly ) serializable for consistency .
On the other hand , a number of data mining and information lookup transactions only require weaker nuances of consistency .
For example , an information lookup process can work with physically partitioned data centers resulting in stale or inconsistent information as long as they are eventually reconcilable within some speciﬁcation of the service requirements .
The speciﬁcation of the type and degree of perturbations and level of consistency the services are designed to be resilient to determines the speciﬁc coordination schema to use .
Additionally , in the case of weaker consistency models , the user is required to deal with any stale data that might have been retrieved from the database .
This is problematic to achieve in a distributed system where the participating entities do not trust each other and are potentially untrustworthy .
Blockchains provide a decentralised , distributed , and public ledger that is used to record transactions across many computers so that the record can not be altered retroactively without also altering all subsequent blocks .
Such alterations require the consensus of the network and can therefore not be performed unilaterally by an attacker .
This also allows the participants to verify and audit transactions inexpensively .
Blockchains form the foundation for numerous cryptocurrencies , most notable Bitcoin .
The aforementioned properties KA Distributed Systems Security | October 2019 Page 419 The Cyber Security Body Of Knowledge www.cybok.org arise from the fact that each block incorporates a cryptographic hash of the previous block and a timestamp .
If a block in the chain is altered without also altering all subsequent blocks , the hash of the following block will no longer match , making the tampering on the Blockchain detectable .
Peers in such a network participate in a protocol for validating newly submitted blocks .
Blockchains are also examples of widely deployed systems exhibiting high tolerance to Byzantine failures .
The generic Blockchain concept allows participation by any entity ( permission-less systems , public blockhains ) and does not include any access restrictions .
This is the case for the blockchains underlying many widely used cryptocurrencies such as Bitcoin .
This is effective as a means of preventing service abuses such as spam since the required work is typically hard to perform but easy to verify , leading to asymmetric requirements for service requester and provider .
However , PoW schemes also lead to high energy usage and , depending on the chosen work requirement , may lead to unreasonably high barriers of entry .
This is the case , for instance , in certain cryptocurrencies , where meaningful participation requires custom hardware designed for the speciﬁc type of work required .
To avoid these shortcomings , alternative approaches relying on Proof-of-Stake ( PoS ) are in development but not as mature as PoW-based schemes and not widely deployed .
As a note , Blockchains represent an interesting combination of decentralised resources using the P2P model for the resource coordination and the coordination schema of consensus for its service functionality .
Overall , service integrity , in terms of consensus as supported by requisite liveness , is the key characteristic of the service coordination model .
This contrasts with the resource coordination class where resource accessibility and availability were the dominant drivers/considerations .
Attackability Implications ( and Mitigation Approaches ) on Service Coordination The services and applications constitute a very broad class to cover , both for the type of attacks and the diversity of services where the functional speciﬁcation of the service determines the type and degree of the impact on security .
In most cases the breach on Integrity , along with on Conﬁdentiality , is the ﬁrst class impact with impact on Availability following as a consequence .
Some examples of breaches for the coordination schema and service types are mentioned below .
Note : The mitigation schemes applicable here are the same as described in Section 12.5.1 that essentially result from the basic replication management and coordination concepts presented in Sections 12.4 and 12.4.4 .
The very purpose of replication based coordination , at the resource or the service level , is to prevent compromises by discrete attacks up to the KA Distributed Systems Security | October 2019 Page 420 The Cyber Security Body Of Knowledge www.cybok.org threshold of severity type and the number of disruptions the replication schema is designed to handle .
Compromise of Key distribution in PKI : The authentication processes supporting the distribution of public keys is compromised affecting service Integrity and Conﬁdentiality .
Compromise of Data at Rest : This is analogous to the breach of resources in the resource coordination model as applicable to storage systems .
Compromise of Data in Motion : This has varied consistency and latency consequences that compromise the Integrity depending on the speciﬁcations of the services .
As both liveness and safety are violated , the Integrity of the transaction is compromised .
It is worth noting that a DoS attack may not affect consistency .
lie in this category where , although latency is important , it is the Integrity ( as deﬁned by the consistency of the ledger ) that is the primary property to preserve .
As Ledgers constitute a popular service , we discuss it to illustrate aspects of both attack surfaces and assumptions .
Blockchains ensure the security of data by not providing a single point of attack .
The ledger is stored in multiple copies on a network of computers .
Each time an authorised participant ( for example in a permissioned system ) submits a transaction to the ledger , the other participants conduct checks to ensure that the transaction is valid , and such valid transactions ( as blocks ) are added to the ledger chain .
Consensus ensures a consistent view of the sequence of transactions and the collated outcome .
The cryptographic basis of the hash , on each block , is expected to avoid tampering , and the Proof of Work notion is designed to mitigate the effect of DoS attacks .
Compromising these involves the compromise of stored cryptographic keys and the hash .
While theoretically safe , such systems may turn out to be vulnerable to emergent technologies such as quantum computing .
Similarly , the consensus property can be compromised via an Eclipse attack [ 1139 ] for Bitcoin , and also in general cases where there exists the potential to trick nodes into wasting computing power .
Nodes on the Blockchain must remain in constant communication in order to compare data .
An attacker that can take control of a node ’ s communication and spoof other nodes into accepting false data to result in wasted computing or conﬁrming fake transactions can potentially breach consensus .
Mixed transactions : As implied in the label , this combines short and large transactions .
The security implications depend on the type of services .
As an example , we outline two service KA Distributed Systems Security | October 2019 Page 421 The Cyber Security Body Of Knowledge www.cybok.org groups , namely : - E-commerce supporting transactions : The core requirements here are ACID properties that entail strong consistency and no partitions .
Any compromises affect the Integrity of the service .
- Informational systems : Services such as Webcrawlers , Data Retrieval for applications such as Uber or informational queries for shopping can handle ( both network and data ) partitions of data to operate on stale cached data .
The attack may lead to redundant computations on the searches or slightly stale information but Integrity is not violated as long as the semantics of Weak , Relaxed , or Eventual consistency , as applicable for the service speciﬁcation , are sustained .
Also informational queries have mixed latency requirements .
For example , the small latency within a local data center and higher-tolerable latency across geodispersed data centers may deﬁne the degree of attack tolerance until both Availability and Integrity are compromised .
CONCLUSIONS The intent of this chapter has been to outline how distributed systems work , and how the mechanisms supporting the operations of such systems open security issues in them .
Very often the expectation is that classical security techniques will directly apply in a distributed systems context as well .
However , this is often not the case and the better one understands the conceptual basis of a distributed system , the better one can understand and provide for its security .
The KA discussed the functional categorisation of distributed systems into two major classes : decentralised and coordinated control .
The operations for each class were elaborated leading to the security implications resulting from the different speciﬁcs underlying distributed systems .
The focus is on synchronisation and consensus though it provides a comprehensive and mathematically rigorous coverage of distributed systems concepts from an algorithms viewpoint .
It also provides an excellent coverage of cryptographic primitives .
Although it predates the development of Ledgers , most of the concepts behind them are covered in this book .
Group Communication & Replication Birman [ 1072 ] — This is an excellent book that combines concepts with an emphasis on the actual development of distributed systems .
The case studies provide valuable insights on practical issues and solutions .
An insightful coverage of P2P systems also appears in this book .
Security Engineering Anderson [ 1030 ] — This book makes for excellent reading on the realisation of distributed system from a security perspective especially for naming services and multi-level security .
While not a distributed systems book , it still provides valuable insights on how threat modeling is conducted in practice .
This KA will present the general foundations of access control and some signiﬁcant instantiations that have emerged as IT kept spreading into new application areas .
It will survey modes of user authentication and the way they are currently deployed , authentication protocols for the web , noting how new use cases have led to a shift from authentication to authorisation protocols , and the formalisation of authentication properties as used in today ’ s protocol analysis tools .
On accountability , the focus is on the management and protection of audit logs .
The surveillance of logs to detect attacks or inappropriate behaviour is described in the Security Operations & Incident Management Knowledge Area ( Chapter 8 ) while the examination of evidence following a breach of policy or attack is covered in the Forensics Knowledge Area ( Chapter 9 ) .
Throughout the KA , we will ﬂag technical terms that appear in more than one meaning in the academic and the trade literature .
In other cases , IT systems exhibit such a degree of ﬂexibility – also by design – that additional measures need to be taken to limit undesirable behaviour in accordance with the given circumstances .
As noted by Lessig , this can be done by code in the system that excludes behaviour , which will violate certain rules , or it can be done by codes of conduct that the users of the system are expected to adhere to [ 1140 ] .
In the latter case , disciplinary or legal processes deal with those that had broken the rules .
Readers acquainted with the mores of academic writing may now expect deﬁnitions of core terms , maybe some reﬁnement of terminology , and then an overview of the latest approaches in achieving authentication , authorisation , and accountability .
As will be shown , this approach fails at the ﬁrst hurdle .
These three terms are overloaded to an extent that provides ample space for confusion and dispute .
For example , authorisation stands both for the setting of rules and for checking compliance with those very rules .
Readers should thus be cautious when studying the literature on this Knowledge Area .
Changes in the way IT is being used create their own challenges for taxonomies .
How closely should terms be tied to the environment in which they ﬁrst emerged ?
There is a habit in the trade and research literature of linking terms exclusively to a notional ‘ traditional ’ instantiation of some generic concept , and inventing new fashionable terms for new environments , even though the underlying concepts have not changed .
KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 426 The Cyber Security Body Of Knowledge www.cybok.org 13.2 CONTENT This KA ﬁrst addresses authorisation in the context of access control and presents the main ﬂavours of access control in use today .
The section on access control in distributed systems explains concepts used when implementing access control across different sites .
The KA then moves to authentication , touching on user authentication and on authentication in distributed systems , and concludes with a discussion of logging services that support accountability .
We will follow this lead and present authorisation in the context of access control , starting with an introduction to the concepts fundamental for this domain , followed by an overview of different policy types .
Code-based access control , mobile security , and Digital Rights Management will introduce new paradigms to access control , without changing its substance .
We will then present design options for policy enforcement and discuss delegation and some important theoretical foundations of access control .
13.3.1 Access Control Access control is “ the process of granting or denying speciﬁc requests .
This process needs the following inputs • Who issued the request ?
• Which rules are applicable when deciding on the request ?
The word suggests that requests always come from a person .
This is inaccurate for two reasons .
The question thus becomes , “ for whom or what is the process speaking for when making the request ?
” “ What is requested ” is frequently given as a combination of an action to be performed and the object on which the action is to be performed .
The rules are logical expressions that evaluate to a decision .
In the elementary case , the decision is permit or deny .
When policies get more elaborate , there may be reasons for adding an indeterminate decision .
A decision may also prescribe further actions to be performed , sometimes called obligations .
KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 427 The Cyber Security Body Of Knowledge www.cybok.org 13.3.1.1 Core Concepts The term ’ security policy ’ is used both for the general rules within an organisation that stipulate how sensitive resources should be protected , and for the rules enforced by IT systems on the resources they manage .
Sterne had coined the terms organisational policies and automated policies to distinguish these two levels of discourse [ 1141 ] .
When setting security policies , principal stands for the active entity in an access request .
When policies directly refer to users , as was the case in the early stages of IT security , user identities serve as principals .
Access control based on user identities is known as IdentityBased Access Control ( IBAC ) .
In security policies that refer to concepts such as roles or to the program that issues a request , the principal is a role or a program .
Principal may then generally stand for any security attribute associated with the issuer of a request .
Subject stands for the active entity making a request when a system executes some program .
A subject speaks for a principal when the runtime environment associates the subject with the principal in an unforgeable manner .
The original example for creating a subject that speaks for a principal is user log-in , spawning a process running under the user identity of the person that had been authenticated .
The research literature does not always maintain this distinction between principals and subjects and one may ﬁnd security policies referring to subjects .
In practice , subjects have considerably shorter lifetimes than user identities .
Processes that control industrial plants are a rare example of subjects that could live forever , but could be killed by system crashes .
Object is the passive entity in an access request .
Access operations deﬁne how an object may be accessed by a subject .
Access operations can be as elementary as read , write , execute in Linux , they can be programs such as setuid programs in Linux , and they can be entire workﬂows as in some ﬂavours of UCON ( Section 13.3.1.8 ) .
Access rights express how a principal may access an object .
In situations where there is a direct match between access operations and access rights , the conceptual distinction between access operations and access rights may not be maintained .
Permission is frequently used as a synonym for access right .
” Other systems , such as Windows , make a distinction between access rights and privileges , using privilege speciﬁcally for the right to access system resources and to perform systemrelated tasks .
Operating systems and databases often have a range of system privileges that are required for system administration .
The reference monitor ( more details in Section 13.3.2.2 ) is the component that decides on access requests according to the given policy .
The rules specify the access rights a principal has on an object .
Conceptually , a policy could then be expressed as an Access Control Matrix with rows indexed by principals and columns indexed by objects [ 1135 ] .
Access Control Lists ( ACLs ) stored with the objects correspond to the columns of this matrix ; capabilities stored with principals correspond to the rows of this matrix ( also see the Operating Systems & Virtualisation Knowledge Area ( Chapter 11 ) ) .
Discretionary Access Control ( DAC ) and Mandatory Access Control ( MAC ) are two core policies formulated in the 1970s in the context of the US defence sector .
Discretionary access control policies assign the right to access protected resources to individual user identities , at the discretion of the resource owner .
In the literature , DAC may generically refer to policies set by resource owners but also to policies referring directly to user identities , i.e .
Mandatory access control policies label subjects and objects with security levels .
The set of security levels is partially ordered , with a least upper bound and a greatest lower bound operator .
Policies of the latter type are also known as multi-level security policies and as lattice-based policies .
Operations can be well-formed transactions with built-in integrity checks that mediate the access to objects .
Users are assigned roles and are authorised to execute the operations linked to their active role .
Separation of Duties ( SoD ) refers to policies that stop single users from becoming too powerful .
Examples for SoD are rules stating that more than one user must be involved to complete some transaction , rules stating that a user permitted to perform one set of transactions is not permitted to perform some other set of transactions , the separation between front ofﬁce and back ofﬁce in ﬁnancial trading ﬁrms is an example , or rules stating that policy administrators may not assign permissions to themselves .
Static SoD rules are considered during user-role assignment , dynamic SoD must be enforced when a role is activated .
Many commercial systems support some ﬂavour of role-based access control , without necessarily adhering to the formal speciﬁcations of RBAC published in the research literature .
RBAC is an elegant and intuitive concept , but may become quite messy in deployment as suggested by comments in an empirical study on the use of RBAC [ 1152 ] .
Practitioners note KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 429 The Cyber Security Body Of Knowledge www.cybok.org that RBAC works as long as every user has only one role , or that “ the enormous effort required for designing the role structure and populating role data ” constitutes an inhibitor for RBAC .
This is a generic deﬁnition of access control that no longer reserves a special place to the user or to the user ’ s role , reﬂecting how the use of IT systems has changed over time .
Access control may be performed in an application or in the infrastructure supporting the application .
Access control in an infrastructure uses generic attributes and operations .
The Linux access control system may serve as an example .
Access control in an application uses application-speciﬁc attributes and operations .
, the hash of an executable ) , or to other properties of the executable , rather than to the identity of the user who had launched the executable .
The reference monitor in CBAC typically performs a stack walk to check that all callers have been granted the required access rights .
Controlled invocation is implemented through assert statements ; a stack walk for an access right will stop at a caller that asserts this right .
13.3.1.6 Mobile Security Smartphones typically have a single owner , hold private user data , offer communication functions ranging from cell phone to NFC , can observe their surroundings via camera and microphone , and can determine their location , e.g .
On smartphones , apps are the principals for access control .
The objects of access control are the sensitive data stored on a phone and the sensitive device functions on a phone .
Access control on a smartphone addresses the privacy requirements of the owner and the integrity requirements of the platform .
Normal permissions do not raise privacy or platform integrity concerns ; apps do not need approval when asserting such permissions .
Dangerous permissions can impact privacy and need user approval .
Up to Android 6.0 , users had to decide whether to authorise a requested permission when installing an app .
User studies showed that permissions were authorised too freely due to a general lack of understanding and risk awareness , see e.g .
Signature permissions have an impact on platform integrity KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 430 The Cyber Security Body Of Knowledge www.cybok.org and can only be used by apps authorised by the platform provider ; app and permission have to be signed by the same private key .
Uncontrolled copying of digital content such as games , movies or music would seriously impair the business models of content producers and distributors .
These parties hence have an interest in controlling how their content can be accessed and used on their customers ’ devices .
Policies can regulate the number of times content can be accessed , how long content can be sampled for free , the number of devices it can be accessed from , or the pricing of content access .
DRM turns the familiar access control paradigm on its head .
DRM imposes the security policy of an external party on the system owner rather than protecting the system owner from external parties .
Superdistribution captures the scenario where data are distributed in protected containers and can be freely redistributed .
Labels specifying the terms of use are attached to the containers .
The data can only be used on machines equipped with a so-called Superdistribution Label Reader that can unpack the container and track ( and report ) the usage of data , and enforce the terms of use [ 1158 ] .
The search for such a tamper resistant enforcement mechanism was one of the driving forces of Trusted Computing .
The level of tamper resistance required depends on the anticipated threats .
Enclaves in Intel SGX are a solution in system software .
Document readers that do not permit copying implement this concept within an application .
Remote attestation can be used with security policies that are predicated on the software running on a remote machine .
In the FIDO Universal Authentication Framework ( FIDO UAF ) just the model of the authenticator device is attested .
For a brief period , it was fashionable to use Digital Rights Management as the generic term subsuming ‘ traditional ’ access control as a special case .
Such actions may have to be performed before , during or after an access happens .
, time of day when a policy permits access only during ofﬁce hours or the location of the machine access is requested from .
Examples for the latter are policies permitting certain requests only when issued from the system console , giving access only from machines in the local network , or policies that consider the country attributed to the IP KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 431 The Cyber Security Body Of Knowledge www.cybok.org address a request comes from .
Usage control may also include provisions for what happens after an object is accessed , e.g .
, that a document can be read but its content can not be copied or adjustment of attributes after an access has been performed , e.g .
In another interpretation , ‘ traditional ’ access control deals with the elementary access operations found at an infrastructure level while usage control addresses entire work ﬂows at the application level .
In telecom services , usage control may put limits on trafﬁc volume .
For a given request , a decision has to be made about whether the request complies with the policy , which may need additional information from other sources .
Finally , the decision has to be conveyed to the component that manages the resource requested .
In the terminology of XACML , this involves • Policy Administration Points where policies are set , • Policy Decision Points where decisions are made , • Policy Information Points that can be queried for further inputs to the decision algorithm , • Policy Enforcement Points that execute the decision .
13.3.2.1 Delegation and Revocation Delegation and granting of access rights both refer to situations where a principal , or a subject , gets an access right from someone else .
The research literature does not have ﬁrm deﬁnitions for those terms , and the trade literature even less so .
Granting tends to be used in a generic sense ; granted access rights often refer to the current access rights of a subject that delivers a request to a reference monitor .
Delegation is sometimes , but not always , used more narrowly for granting short-lived access rights during the execution of a process .
For example , XACML distinguishes between policy administration and dynamic delegation that “ permits some users to create policies of limited duration to delegate certain capabilities to others ” [ 1163 ] .
A second possible distinction lets delegation refer only to the granting of access rights held by the delegator , while granting access also includes situations where a managing principal assigns access rights to others but is not permitted to exercise those rights itself .
Rights may not always be granted in perpetuity .
The grantor may set an expiry date on the delegation , a right may be valid only for the current session , or there may be a revocation mechanism such as the Online Certiﬁcate Status Protocol ( OCSP ) for X.509 certiﬁcates ( see Section 13.4.1 ) .
OCSP is supported by all major browsers .
Revocation lists are suitable when online checks are not feasible and when it is known in advance where a granted right may be consumed .
In its original deﬁnition , the reference monitor was the abstract machine mediating all accesses by subjects to objects .
The security kernel was a trustworthy implementation of the reference monitor .
There has been some interpretation creep since .
, the Security Reference Monitor in Windows , would actually be the security kernel from above , and TCB is today sometimes used in a limited sense to stand only for the security kernel .
• It authenticates any evidence supplied by the subject with an access request .
Traditionally , the user identity the subject was speaking for was authenticated .
• It evaluates the request with respect to the given policy .
However , authorisation also stands for the process of setting a security policy ; principals are authorised to access certain resources .
This overloads the term authorisation , applying it both to principals and to requests , but with different meanings .
Figure 13.1 represents the view of access control adopted in operating systems research around 1990 .
In Section 13.5.3.4 , authorisation will stand for the granting of access rights to principals .
The decision algorithm executed by the reference monitor has to identify the applicable policies and rules , and try to collect the evidence those rules refer to from Policy Information Points .
For situations where more than one rule is applicable for a given request , rule combining algorithms specify the ﬁnal decision .
13.3.2.3 Types of Reference Monitors Schneider describes three types of reference monitors [ 1145 ] : • Reference monitors that only see the system calls to protected resources , but not the entire program executed .
• Reference monitors that can see the entire program and analyse its future behaviour before making an access control decision .
• Instructions guarding all security relevant operations are in-lined into the program ; in all other respects the in-lined program should behave as before .
Such models can be used in a formal security analysis to show that a lower-level speciﬁcation faithfully implements the model .
The mandatory access control policies state that a subject can only read objects at its own or at a lower level ( no read up ) .
, keeping separate entries at the different security levels , is used to prevent integrity checks from causing information leaks .
BLP was highly inﬂuential in computer security into the 1990s .
The access rules are the dual of the BLP model , no read down and no write up , but have no predecessors in the world of paper documents .
The low watermark policies in Biba introduce dynamic policies ( mutable in the terminology of UCON , Section 13.3.1.8 ) that adapt the integrity level of an object depending on the integrity level of the subject performing the access operation .
This model captures the way data are processed in enterprise systems .
The Chinese Wall model [ 1167 ] formalises dynamic conﬂict of interest policies that apply in ﬁnancial consultancy businesses when working for clients that are commercial competitors .
Hence , the act of accessing data for one client dynamically removes permissions to access data from other clients in the relevant conﬂict-of-interest class .
This problem is undecidable in general , but may be decidable under certain restrictions .
13.3.3.2 Enforceable Policies Schneider has examined the relationship between different kinds of security policies and different kinds of reference monitors [ 1145 ] .
Security policies are deﬁned as predicates over execution traces , taking a broader view than Section 13.3.1.2 where rules applied to individual access operations .
Policies that only consider the given execution trace are called properties .
Information ﬂow policies that require an execution trace to be indistinguishable from some benign execution trace are thus not properties .
It is shown that only safety properties can be enforced by execution monitors ( see Section 13.3.2.3 ) .
The calculus for access control in distributed systems [ 1170 ] was developed as a formal speciﬁcation for parts of the Digital Distributed Systems Security Architecture .
In such an architecture , cryptographically secured sessions can be established between parties .
For example , when a session is established with a principal on some other machine , the session key can be treated as a subject for access control that speaks for that principal .
Any distributed system needs mechanisms for securely transmitting access requests , attributes , policies , and decisions between nodes .
These mechanisms are largely based on cryptography .
The requirement for mechanisms that identify and retrieve all policies relevant for a given request may become more pronounced than in centralised settings .
In federated systems where several organisations collaborate , security policies can be set by different parties .
This demands some common understanding of the names of principals , attributes , and attribute values so that policies issued by one party can be used in decisions by some other party .
Arriving at such a common understanding adds to the practical challenges for RBAC listed in Section 13.3.1.3 .
We ﬁrst introduce core concepts for this domain .
Federated Access Control and the use of cryptography in access control are explored further .
13.4.1 Core Concepts The literature on access control in distributed systems uses the following related terms , but the distinction between those terms is ﬂuid .
Examples for credentials are passwords or ﬁngerprints .
The emphasis is on evidence submitted to the decision algorithm .
For example , in operating systems the access token contains the security credentials for a login session .
The emphasis is on conveying the result of an access decision to some enforcement point .
So-called bearer tokens are not tied to a speciﬁc subject and can be used by anyone in possession of the token .
Identity certiﬁcates bind user identities to public veriﬁcation keys .
Attribute certiﬁcates bind user identities to access rights .
Attribute certiﬁcates correspond closely to ACL entries .
The client browser sends HTTP requests ; the server returns result pages .
The browser represents the page internally in the document object in the Document Object Model ( DOM ) .
Security policies specify which resources a script in a web page is allowed to access , or which servers an XMLHttpRequest may refer to .
Web applications are thus the principals in access control .
By convention , principal names are the domain names of the server hosting an application ; the policy decision point ( cf .
The prototype policy for web applications is the Same-Origin-Policy ( SOP ) , stating that a script may only connect back to the origin it came from or that an HTTP cookie is only included in requests to the domain that had placed the cookie .
Two pages have the same origin if they share protocol , host name and port number .
Certain actions may be exempt from the same origin policy .
For example , a web page may contain links to images from other domains , reﬂecting a view that images are innocuous data without malign side effects .
, policies for cookies that also consider the directory path .
There is also the option to set the HttpOnly ﬂag in a Set-Cookie HTTP response header so that the cookie can not be accessed by client side scripts .
Domain owners publish SPF policies in their DNS zone .
An SMTP server can then use the domain part of the MAIL FROM identity to look up the policy and consult this policy to check whether the IP address of the SMTP client is authorised to send mail from that domain .
13.4.2.1 Cross-site Scripting Cross-site scripting attacks on web applications can be treated as cases of failed authentication in access control .
The browser lets all scripts that arrive in a web page speak for the origin of that page .
A browser would then run a script injected by the attacker in the context of an origin other than the attacker ’ s .
The web server conveys a policy to the browser that characterises the scripts authorised to speak for that server [ 1173 ] .
Typically , this is done by specifying a directory path on the web server where authorised scripts ( and other web elements ) will be placed .
The use of CSP in practice has been examined in [ 1177 ] , observing that the unsafe-inline directive disabling CSP for all pages from a given domain was widely used .
A new security mechanism is deployed but quickly disabled because it interferes too much with established practices .
Moreover , CSP had an inherent vulnerability related to callbacks .
Callbacks are names of scripts passed as arguments to other ( authorised ) scripts , but arguments are not covered by CSP .
In strict CSP policies , the server declares a nonce in the CSP policy it sends to the client as the script source .
The server also includes this nonce as an attribute in all scripts fetched by the client .
The client ’ s browser only accepts scripts that contain this nonce as an attribute .
Nonces must only be used once and must be unpredictable .
Mashup designers initially had to ﬁnd ways of circumventing the SOP enforced by the browsers .
When a script requests a connection to a target other than its own origin , the browser asks the target to authorise the connection request .
The decision at the target considers evidence supplied by the browser , such as the origin of the script or user credentials associated with the request .
CORS speciﬁes a set of HTTP headers to facilitate this exchange .
Preﬂight Requests include an Access-Control-Request-Method header that informs the target about the access intended .
The response lists methods and headers the target grants to the given origin .
CORS requests are by default sent without user credentials .
The target can set the Access-Control-Allow-Credentials : true header to indicate that user credentials may be provided with requests to access a resource .
The target must also specify an origin in the Access-Control-Allow-Origin header .
Otherwise , the browser will not pass on the target ’ s response to the script that had made the request .
13.4.3 Federated Access Control When organisations join to form a federated security domain , the import of identities , credentials , policy rules , and decisions from different contexts ( name spaces ) becomes an important security issue .
A federation may have several Policy Administration Points where policies are deﬁned , Policy Decision Points where decisions on access requests are made , Policy Enforcement Points where the decisions are enforced , and Policy Information Points where additional evidence required for evaluating an access request can be obtained .
Trust management as originally conceived in PolicyMaker [ 1171 ] refers to access control systems for such scenarios .
Federated identity management deals with the management of digital identities in a federation , and in particular with single sign-on in a federation .
The Binder policy language is based on Datalog .
Binder contexts are identiﬁed by public keys and export statements by signing them with the corresponding private key .
The decision algorithm is monotonic ; presenting more evidence can not reduce the access rights granted .
13.4.4 Cryptography and Access Control Access control mechanisms in an operating system implement a logical defence .
Access requests passed via the reference monitor will be policed .
This includes requests for direct memory access .
However , data are stored in the clear and a party with physical access to the storage medium can retrieve the data and thus bypass logical access control .
When solutions for the protection of unclassiﬁed but sensitive data were evaluated in the U.S. in the 1970s , it was decided that encrypting the data was the best way forward .
Access control would then be applied to the keys needed to unlock the data .
Storing data in encrypted form protects their conﬁdentiality but creates a key management challenge .
Policies are logical predicates over attributes , represented as access structures .
The Key Generator is thus in a position to recreate private keys .
From the corresponding access structure , the Key Generator creates a private decryption key .
In both variants , decryption is possible if and only if the given attribute set satisﬁes the given access structure .
A study of the feasibility of ABE in realistic dynamic settings had concluded that the overheads incurred by those schemes were still prohibitive [ 1180 ] .
Efﬁcient encryption and decryption do not necessarily imply an efﬁcient access control system .
Access rights could then be granted directly to the public veriﬁcation key without the need to bind the public key to some other principal .
The right to further delegate an access right is controlled by a delegation ﬂag .
Cryptographic keys are rarely suitable principals for access control , however .
They would need to have an obvious meaning in the application domain that provides the context for a given security policy .
In most cases , cryptographic keys would be subjects speaking for some principal .
Some applications have adopted biometric authentication as an alternative .
Authentication in distributed systems often entails key establishment .
Some security taxonomies thus reduce authentication to a ‘ heartbeat ’ property to separate authentication from key establishment .
The design of authentication protocols is a mature area in security research with good tool support for formal analysis .
Standard protocols such as Kerberos , SAML , or OAuth are deployed widely today .
We will give a brief overview of identity management before moving to password-based and biometric user authentication .
We then cover authentication protocols from the NeedhamSchroeder protocol via Kerberos and SAML to OAuth 2.0 , observing that OAuth 2.0 is more KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 438 The Cyber Security Body Of Knowledge www.cybok.org of an authorisation protocol than an authentication protocol .
We conclude with an overview of formalisations of authentication properties that serve as the basis for a formal analysis of authentication protocols .
This includes operational aspects when creating and deleting electronic identities .
On creation , one question is how strongly electronic identities must be linked to persons .
In some sensitive areas , strong links have to be established and documented .
In other areas , electronic identities need not to be tied to a person .
Privacy by design implies that such applications should use electronic identities that can not be linked to persons .
Identity management may also link access rights to an electronic identity , either directly or via some layer of indirection such as a role .
Care has to be taken that this is done on all systems where this identity had been registered .
Electronic identities exist at different layers .
There are identities for internal system purposes , such as user identities in an operating system .
These identities must be locally unique and could be created by system administrators ( Linux ) .
This can lead to problems when an identity is taken out of use and re-assigned later .
The new user may get unintended access to resources the predecessor had access to .
When organisations merge , collisions between identities may arise that identity management then must address .
The probability for one of the problems just mentioned to arise is then negligible , but when a user account is re-created , a new random identity is assigned so access rights have to be reassigned from scratch .
Electronic identities such as user names and email addresses could be random strings , but it is often preferable to assign understandable identities .
Email addresses can be taken out of use and re-assigned later , but a user may then receive emails intended for its previous owner .
Web applications often use email addresses as electronic identities .
This is convenient for contacting the user , and it is convenient for users as they do not have to remember a new identity .
There are alternatives , such as FIDO UAF ( Section 13.5.2.3 ) , where electronic identities are randomly created public keys and a back channel for resetting passwords is not required as no passwords are used .
A person using different identities with different organisations may want to manage how identities are revealed to other parties .
Subjects can be associated with security attributes when they are created or during their lifetime .
Authentication can then be viewed as the service that validates the security attributes of a subject when it is created .
When subjects are created due to some user action , and when their security attributes depend on the corresponding user identity , user authentication has to give a reasonable degree of assurance that the user identity linked to the subject belongs to the user who had triggered the creation of the subject .
The degree of assurance ( strength of authentication ) should be commensurate with the severity of the risk one wants to mitigate .
Authentication ceremony refers to the steps a user has to go through to be authenticated .
There are access control systems where the security attributes of a subject persist throughout the lifetime of that subject .
Many operating systems adopt this approach .
Policy changes do not affect active processes , but the lifetime of subjects is limited , which limits the period when the new policy is not applied consistently .
When the focus moves from the subject to individual requests , authentication can be viewed as the service that checks the validity of the security attributes submitted with the request to the decision algorithm .
13.5.2.1 Passwords When passwords are employed for user authentication , protective measures at the system side include the storing of hashed ( Unix , Linux ) or encrypted ( Windows ) passwords , the salting of passwords , and shadow password ﬁles that move sensitive data out of world-readable password ﬁles .
Protective measures at the user side include guidance on the proper choice and handling of passwords , and security awareness programs that try to instil behaviour that assures the link between a person and a principal .
Recommendations in this area are changing .
The Digital Identity Guidelines published by NIST build on assessments of the observed effectiveness of previous password rules and reﬂect the fact that users today have to manage passwords for multiple accounts [ 1188 ] .
The new recommendations advise • against automatic password expiry ; passwords should only be changed when there is a reason ; • against rules for complex passwords ; password length matters more than complexity ; • against password hints or knowledge-based authentication ; in an era of social networks too much information about a person can be found in public sources ; • to enable “ show password while typing ” and to allow paste-in password ﬁelds .
Biometrics are an alternative that avoids the cognitive load attached to password-based authentication .
Fingerprint and face recognition are the two main methods deployed for biometric user authentication , known as veriﬁcation in that domain .
Biometric features must be sufﬁciently unique to distinguish between users , but ﬁngerprints or faces can not be considered as secrets .
Biometric features are thus better treated as public information when conducting a security analysis and the process of capturing the features during authentication has to offer an adequate level of liveness detection , be it through supervision of that process or through device features .
Employing biometrics for user authentication makes the following assumptions : • The biometric features uniquely identify a person ; face , ﬁngerprints , and iris patterns may serve as examples .
• The features can be conveniently captured in operational settings .
• The features can not be spoofed during user authentication .
During authentication , a new template is captured , features are extracted and compared with the reference values .
A user is authenticated if the number of matching features exceeds a given threshold .
This process may fail for various reasons : • Failure to capture : this may happen at registration when it is not possible to extract a sufﬁcient number of features , or during authentication .
• False rejects : the genuine user is rejected because the number of matches between reference features and extracted features is insufﬁcient .
Liveness detection tries to ensure that templates are captured from the very person that is being authenticated [ 1190 ] .
Biometric authentication based on face recognition or ﬁngerprints is used increasingly at automated border control gates [ 1191 ] .
Possession of the device is then necessary for successful authentication , which is thus based on “ something you have ” .
A token could be a small hand-held device with an LED display for showing an OTP that the user enters in a log-in form ; RSA SecureID and YubiKey are examples for this type of token .
Some e-banking services use this type of token for account holder authentication .
With PhotoTAN devices , the challenge is sent as a QR code to the user ’ s computer and scanned from the screen by the PhotoTAN device .
When authentication is based on a secret shared between token and server , different tokens must be used for different servers .
The same token can be used for different servers , but with different keys .
The response is veriﬁed using the public key registered with the server .
In some applications , possession of the token is sufﬁcient for user authentication .
It will depend on the threat model whether ‘ weak ’ authentication in the ﬁrst stage and ‘ strong ’ authentication in the second stage can provide adequate security .
Apps on smartphones can provide the same functionality as authentication tokens , but smartphones are not dedicated security devices .
User authentication may then be compromised via attacks on the smartphone .
This may become even easier when smartphones come with a secondary authentication mechanism for use when a device is partially locked , with a less onerous but also less secure authentication ceremony .
This creates a conﬂict between the interests of smartphone manufacturers who value ease-of-use of a communications device , and the interests of the providers of sensitive applications searching for a security token .
Here , special pens or writing pads need to be deployed .
Smartphones come with various sensors such as touch screens and microphones that are being utilised for behavioural authentication today .
The requirements on behavioural authentication are the same as those listed in Section 13.5.2.2 : • The behavioural features uniquely identify a person .
• The features can be conveniently captured in operational settings .
• The features can not be spoofed during user authentication .
Advocates of continuous authentication promise minimum friction , maximum security .
Behavioural authentication does not inconvenience the user with authentication ceremonies , but variations in user behaviour may cause false rejects .
Security depends on the strength of liveness detection .
For example , will voice recognition detect synthesised speech or a very proﬁcient human voice imitator ?
Without a precise threat model , behavioural authentication can only offer uncertain security guarantees .
There is a growing research literature on different modes of behavioural authentication .
Criteria for assessing the actual contributions of this research include sample size and composition , whether longitudinal studies have been performed , the existence of an explicit threat model and resistance to targeted impersonation attempts .
The two factors could be a password and an authentication token for computing Transaction Authentication Numbers ( TANs ) uniquely tied to the content of a transaction .
The token could be a separate device ; if the device is tied to one payment service only , customers would have to carry multiple devices with them .
For devices that can be used with several services , some level of prior standardisation is required .
The token could be a smartphone registered with the service ; customers could then install apps for several services on the same device .
This approach has been favoured by many banks .
However , when passwords ( or PINs ) and TANs are handled by the same device , the two mechanisms are no longer independent , reducing the security gains claimed for 2FA .
In contrast to the European Trust Services and Electronic identiﬁcation regulation ( eID Directive - Regulation ( EU ) No 910/2014 ) that speciﬁes requirements on secure signature creation devices , PSD2 does not impose security requirements on the devices used for user authentication but wants “ to allow for the use of all common types of devices ( such as computers , tablets and mobile phones ) for carrying out different payment services ” .
KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 443 The Cyber Security Body Of Knowledge www.cybok.org 13.5.3 Authentication in Distributed Systems When methods for user authentication in distributed systems were ﬁrst designed , an authenticated session took the place of a process speaking for the user .
Authenticated sessions were constructed on the basis of cryptographic keys .
In the terminology of Section 13.3.1 , those session keys became the subjects of access control , and key establishment became a core feature of the user authentication process .
Client and server share secret keys with the authentication server respectively .
The client does not have to share individual long term secrets with all servers it wants to access , it needs just one shared secret with the authentication server .
The authentication server issues a session key to client and server , and has to be trusted to properly authenticate the client and the server .
Most major operating systems have since adopted ( variations of ) Kerberos for user authentication .
From this password , the client and the KAS derive a symmetric encryption key .
In its response to a client request 1 the KAS sends an encrypted session key to the client , together with a ticket containing that session key encrypted under a key shared between the KAS and the server 2 .
If the correct password is entered at the client , the session key can be decrypted .
Client and server now share the session key , and the server can return an authenticator constructed with the session key 4 .
With the session key and the TGT , the client then requests a ticket for the resource server .
The TGS checks the TGT and can apply an access control policy to decide whether to issue a ticket for use with the server .
If the request is approved , the TGS issues another session key and a ticket encrypted under a secret key shared between TGS and server .
Meta-protocols specify high-level message ﬂows that can be bound to various underlying protocols such as Kerberos .
Applications that use SAML for authentication then need not be aware of the underlying protocol used .
The speciﬁcation of SAML messages and assertions is based on XML .
An authentication assertion has to include the name of the identity provider and the user identity , but this is insufﬁcient .
This was shown to be the case by an attack against the implementation of Service Provider-initiated single sign-on with Redirect/POST Bindings used at that time in Google Applications [ 1197 ] .
In this implementation , authentication assertions included just the two aforementioned ﬁelds .
A malicious Service Provider could ask a user for authentication at a speciﬁc Identity Provider ( step 0 in Figure 13.3 ) and then re-use the assertion to impersonate the user with another Service Provider that relied on the chosen Identity Provider and where the user was known by the same user identity , e.g .
The speciﬁcation of SAML Redirect/POST Bindings includes the Service Provider ’ s ID and a request ID issued by the Service Provider in the authentication assertion .
Hence , a Service Provider would only accept an assertion issued in reaction to a pending authentication request .
It was conceived as a federated single sign-on protocol where the relying party decides how to use assertions when making decisions according to its own security policy .
In the practical deployment of SAML , parsing XML documents – the price to be paid for employing a meta-protocol – can create non-trivial overheads and can introduce security vulnerabilities .
Furthermore , the advent of smartphones has made it easier to access the internet from mobile user devices , removing one of the reasons for introducing a meta-protocol between web services and the underlying IT systems .
Clients have to be registered with the AS .
They will receive a public client ID and a client secret shared with the AS .
This secret is used for establishing secure sessions between the client and the AS .
Proper deﬁnition of the redirect_URIs is primarily a matter for the client , and can also be enforced by the AS .
Weak settings are open to exploitation by attackers .
The user agent then typically conveys the authorisation request and the user ’ s authorisation to the AS 2 .
A secure session between the user agent and the AS is required , and may already exist if the user has logged in previously at the AS .
If authorisation is granted , an authorisation grant is returned to the user agent 3 , which will pass it on to the redirect_URI given by the client 4 .
The client then posts the authorisation grant and a redirect URI to the AS 5 .
It is assumed that the AS can authenticate this message as coming from the client .
If the request is valid , the AS returns an access token to the redirect URI provided , where the token can be used to retrieve the resource from the resource server 6 .
Authorisation requests and authorisation grants are linked via a request ID , called state in OAuth .
Omitting the request ID or using a ﬁxed value had introduced vulnerabilities in applications using OAuth , see e.g .
- client ( app ) Page 446 The Cyber Security Body Of Knowledge www.cybok.org There is a fundamental switch in focus compared to SSO protocols such as Kerberos and SAML despite a considerable degree of similarity in the message ﬂows .
In an OAuth 2.0 protocol run the user is no longer the party requesting access to a resource owned by someone else , but the party granting access to resources owned by the user .
Several assumptions about pre-existing trust relationships between parties have to be met for OAuth to be secure .
Conversely , one can not take for granted that the OAuth security properties still hold when the protocol is deployed in a new setting .
OpenID Connect puts user authentication back into the OAuth 2.0 message ﬂow .
The client application now doubles as a relying party , and the authorisation server becomes an authentication & authorisation server that issues digitally signed id tokens ( authentication assertions in SAML diction ) .
An id token contains the name of the issuer , the name of the authenticated user ( called subject ) , the intended relying party ( called audience ) , the nonce that had been sent with the authentication request , an indicator of authentication strength , and other ﬁelds .
13.5.4 Facets of Authentication We have sketched how user authentication in distributed systems ﬁrst integrated session and key establishment with the process of verifying a user ’ s identity , and later established authorisation practices to access a user ’ s resources .
In communication security , peer entity authentication refers to the process of verifying the identity of the peer in a connection and data origin authentication to the process of verifying the origin of individual data items .
To differentiate between these aspects , the term key establishment was introduced in communication security towards the end of the 1980s for the ﬁrst aspect .
Entity authentication stood for what was left .
The authenticity of the entity can be ascertained only for the instance of the authentication exchange ” .
Note that this deﬁnition does not distinguish between internal and external entities .
When prover and veriﬁer share a secret , the veriﬁer sends an unpredictable challenge to the prover who constructs its response as a function of the challenge and the shared secret .
For example , HTTP digest authentication uses the hash of the challenge , a password , and further data that binds authentication to a particular HTTP request .
With a public key encryption scheme , the veriﬁer could encrypt the challenge under the prover ’ s public key ; a response constructed from the decrypted challenge would authenticate the prover .
The latter mechanism is used with Trusted Platform Modules ( TPMs ) where successful decryption of data encrypted under the public endorsement key of a TPM authenticates the TPM .
In both cases , the veriﬁer needs an authentic copy of the prover ’ s public veriﬁcation key .
When users are identiﬁed by arbitrary public keys , no Public Key Infrastructure is required and the public key could be set directly in a registration phase .
In this protocol , a malicious prover could decrypt a challenge and reuse it in a protocol run with a third party pretending to be the original veriﬁer ; the third party would then respond to the veriﬁer although the veriﬁer is not engaged in a protocol run with the third party [ 1187 ] .
This scenario would amount to an attack if the mismatch in the assumptions about a protocol run is security relevant .
The attack would be detected if the identities of prover and veriﬁer are included in all messages .
Note that in this ‘ attack ’ the veriﬁer still correctly concludes that the prover is alive .
• Agreement : whenever the veriﬁer ( initiator ) concludes a protocol run apparently with a given prover , the prover had also been engaged in a protocol run , apparently with that veriﬁer , and responder and receiver agree on a speciﬁed set of data items pertaining to a protocol run , and each protocol run of the veriﬁer corresponds to a unique protocol run of the prover .
Correspondence properties are intensional properties well suited for protocol analysis using model checking .
This line of research had reversed the earlier decision to separate pure entity authentication from agreeing on session keys and again added agreement on certain data items to authentication .
KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 448 The Cyber Security Body Of Knowledge www.cybok.org 13.5.4.3 Authentication as Veriﬁed Association Returning to a holistic view on authentication , one could use this as a general term for mechanisms that create a new subject and associate it with evidence relevant for access decisions .
If this route is taken , verifying the identity of a user becomes just a special case of authentication .
There would , furthermore , be merit in distinguishing between association with internal and external entities .
The latter case is an instance of the ‘ difﬁcult and error prone ’ problem of faithfully representing aspects of the physical world within an IT system .
The veracity of such representations can not be guaranteed by cryptographic means alone .
Public keys can then be interpreted as subjects for the purpose of access control .
The checks performed by a certiﬁcate authority before it issues a certiﬁcate would then amount to authentication of an external entity .
13.5.4.4 Authentication for Credit or for Responsibility Authentication may serve the purpose of giving credit to an entity for actions it has performed , or of establishing which entity is responsible for an action [ 1206 ] .
In the ﬁrst case , an attack amounts to earning undeserved credits and authentication is broken if the attacker succeeds in making a victim perform actions under the attacker ’ s identity .
In the second case , an attack amounts to deﬂecting responsibility to someone else and authentication is broken if the attacker succeeds in performing actions under the victim ’ s identity .
18 ] Accountability has been deﬁned as “ the security goal that generates the requirement for actions of an entity to be traced uniquely to that entity .
This deﬁnition invites investigations into psychology to determine what makes an effective deterrent , investigations into legal matters to determine the standard of evidence demanded in a court of law , and technical investigations into the collection , protection , and analysis of evidence .
This Knowledge Area will focus on those technical aspects .
We will cover the technical prerequisites for accountability .
We will brieﬂy explore potential conﬂicts between privacy and accountability , describe current activities in distributed logging of events , and refer to some related terms that overlap with accountability .
Such a process may be a regular audit that checks whether an organisation complies with existing regulations .
It might represent a technical audit that scans logs in search for signs of a cyber attack .
It may also be an investigation triggered by an incident that tries to identify the vulnerabilities exploited , or an investigation that tries to identify the parties responsible .
In all cases , the quality of the evidence is decisive .
The aforementioned processes make use of logs of events .
The nature of the events depends on the activity that is being monitored .
13.6.1.1 Audit Policies Accountability is only as strong as the quality of evidence collected during operations .
System administrators may set audit policies that deﬁne which events will be logged .
Examples for such events are successful and failed authentication attempts , and decisions on sensitive access requests .
Operating systems and audit tools provide menus to guide administrators through this task .
Access control policies that specify as obligations that certain requests must be logged also inﬂuence which evidence is collected .
13.6.1.2 Preserving the Evidence Accountability is only as strong as the protection of the evidence collected during operations .
Attackers could try to hide their traces by deleting incriminating log entries once they have acquired sufﬁcient privileges .
They could then modify audit policies so that future actions are not recorded , but should not be able to tamper with the evidence already collected .
Tamper resistance could rely on physical measures like printing the log on an endless paper reel or writing the log to WORM ( Write-Once , Read-Many ) memory like an optical disk .
Tamper resistance could be supported by cryptography .
, because the log ﬁle has run out of space .
Is it then acceptable to overwrite old entries or should the system be stopped until proper auditing is again enabled ?
This conﬂict between availability and accountability has to be resolved .
13.6.1.3 Analysing the Evidence Audit logs can create large volumes of data and many entries are not security relevant so that automated processing is required .
Known attack patterns can be detected by their signatures .
Machine learning techniques can help to detect anomalies .
Visualisation techniques try to draw the administrators ’ attention to the most relevant events .
KA Authentication , Authorisation & Accountability ( AAA ) | October 2019 Page 450 The Cyber Security Body Of Knowledge www.cybok.org 13.6.1.4 Assessing the Evidence Accountability is only as strong as the method of user authentication when legal or disciplinary actions are to be supported .
This relates to technical aspects of the authentication mechanism and also to user resilience to phishing and social engineering attacks .
Telling users not to fall for obvious phishing attacks is easy , but a well-designed spear phishing attack will not be obvious .
Accountability is only as strong as the organisational security policies on connecting devices , e.g .
USB tokens , to internal systems , and policies on access to external web sites .
Accountability is only as strong as the defences against software vulnerabilities that can be exploited to run code under a user identity without the user being aware of that fact , e.g .
13.6.2 Privacy and Accountability Privacy rules can have an impact on the events that may be logged .
Employment law may , for example , limit how closely a company monitors its employees , which might make it difﬁcult to achieve accountability when rules have been broken .
Sometimes , there are technical resolutions to such conﬂicts between legal goals .
Take the example of a company that is not permitted to log which external websites employees connect to : when an external site is attacked from within the company network , it is desirable that the perpetrator can be held accountable .
To achieve both goals , the company gateway would log for outgoing requests only the internal IP address and the port number used with the global IP address .
There is thus no record of visited websites .
If an attack is reported , the website affected can provide the port number the attack came from , establishing the link between the internal IP address and the visited site .
Certiﬁcate Transparency is a logging service for the issuers of TLS certiﬁcates .
Participating Certiﬁcate Authorities record the issuance of certiﬁcates with this service .
Domain owners can scan the log for certiﬁcates for their domain that they had not asked for , i.e .
This service was introduced in reaction to attacks where such misissued certiﬁcates had been used to impersonate the domain affected , and makes issuers accountable to domain owners .
Private subdomains are subdomains created for internal use only .
When a certiﬁcate for a private subdomain is requested , the certiﬁcate will be recorded in the Certiﬁcate Transparency log disclosing the existence of the private subdomain to the public [ 1212 ] .
13.6.3 Distributed Logs Logs may be kept to hold the users of a system accountable .
Logs may be kept to hold the owner of a system accountable .
Alternatively , logs could be kept in a distributed system run by independent nodes where there are sufﬁcient barriers to forming alliances that can take over the system .
The nodes maintaining the log need to synchronise their versions of the log .
The overheads for synchronisation , or consensus , depend on the failure model for the nodes and for the communication network , and on the rules for joining the distributed system .
The recent interest in blockchains extends to this type of logging solutions .
This goal is not necessarily achieved by logging mechanisms ; they may protect the entries recorded , but may record entries that have already been manipulated .
Intrusion detection does not have the requirement for actions of an entity to be traced uniquely to that entity .
The focus will be more on detecting attacks than detecting the attacker .
The deﬁnition given subsumes both the accountability of legal persons and technical investigations into security breaches .
The standards of evidence may be higher in the ﬁrst case .
Tracing actions uniquely to an entity leads to cyber attribution , the process of tracking and identifying the perpetrators of a cyber attack .
Circumstantial evidence such as similarity in malware may be used in this process , and mis-attribution due to false ﬂag operations is an issue .
Calling for DRM to protect the intellectual property of content owners , because digital content can be copied so easily , but assuming that malware can not be copied would be incongruous .
APPLYING THE KNOWLEDGE IT security mechanisms should not be deployed for their own sake but for a reason .
The reason has to come from an application in need of protection .
An organisational policy would capture the protection requirements and then be implemented by an automated policy ( Section 13.3.1.1 ) .
The policies governing access to classiﬁed paper documents are an example .
These speciﬁc circumstances may have raised the unwarranted expectation that this approach would work in general .
The fact that these policies were applied in highly hierarchical organisations and were fairly stable are further points worth noting .
Their observations can be summarized under the headings of translation ( from organisational to automated policies ) and automation .
Any translation has to start from a source document , in our case an organisational policy .
The translator will face problems when the source is ambiguous or inconsistent .
This situation is more likely to arise in organisations with a matrixed structure , where several entities are setting policies , than in strictly hierarchical organisations .
Moreover , the wider the language gap between the source document and the destination document , the more difﬁcult translation becomes , and the more difﬁcult it is to ascertain that the translation meets the spirit of the source .
Removing discretion adds rules that do not have a counterpart in the organisational policy .
Creating an automated policy is then more than translation , it becomes an exercise in creative writing in the spirit of the organisational policy .
To do this job well , the writer needs a good understanding of the applications and their workﬂows , on top of proﬁciency in the target language ( the domain of IT experts ) .
Automated policies based on naïve assumptions easily become denial-of-service attacks on the user .
As a related point , there is a tension between the competing goals of keeping a policy simple – which may be feasible in an organisational policy that leaves room for discretion – and of requiring the ( automated ) policy to cater for a variety of different contexts .
This explains why in many cases the number of rules created to cater for exceptions to the general rules ends up being overwhelming .
Points that span organisational and automated policies are the handling of dynamic policy changes and the analysis of the side-effects of policy rules in highly complex systems .
The literature on security operations has to say more about the points raised in this section than the research literature on IT security , which has a habit of abstracting problems to a point where much of the awkward issues encountered in real life have disappeared [ 1213 ] , and then confusing its simpliﬁed models with reality .
Similar disconnects between application experts and infrastructure experts exist within the IT domain .
Organisations may then opt for open policies that provide no protection but allow the dynamic applications to run , or applications writers may explore workarounds accepted by the automated policy but still defeating its spirit .
CONCLUSIONS Access control has kept adapting to the changing applications of IT systems .
Access control was originally conceived for the protection of sensitive data in multi-user and multi-level secure systems .
Access control without user identities was literally unthinkable .
Applications have since changed and some require new modes of access control .
One could then reserve ‘ access control ’ for the original setting and invent new terms for each new ﬂavour of access control .
DRM may serve as an example .
User identities have lost their prominence along this way .
Authentication originally stood for the service that links external entities like human users to internal actions in the IT system ; today , it may also denote the service that veriﬁes evidence associated with access requests that are submitted for evaluation by a decision algorithm .
Design and analysis of cryptographic authentication protocols for distributed systems is a mature knowledge area .
Cryptographic solutions for other aspects of access control are often more of academic than of practical interest .
Accountability services build on tamper resistant records of events .
The evidence collected may serve as input for technical investigations that try to establish how an attack was conducted and to identify its effects .
The evidence collected may also be used in disciplinary processes that deal with situations where rules were broken at the level of the persons implicated .
Privacy rules may put limits on the events that are recorded , and the nature of the events recorded may reduce privacy in ways not anticipated .
18 ] Page 454 IV Software Platform Security 455 Chapter 14 Software Security Frank Piessens KU Leuven 457 The Cyber Security Body Of Knowledge www.cybok.org INTRODUCTION The purpose of this Software Security chapter is to provide a structured overview of known categories of software implementation vulnerabilities , and of techniques that can be used to prevent or detect such vulnerabilities , or to mitigate their exploitation .
This overview is intended to be useful to academic staff for course and curricula design in the area of software security , as well as to industry professionals for the veriﬁcation of skills and the design of job descriptions in this area .
Let us start by deﬁning some terms and concepts , and by deﬁning the scope of this chapter .
A ﬁrst key issue is what it means for software to be secure ?
One possible deﬁnition is that a software system is secure if it satisﬁes a speciﬁed or implied security objective .
The security objective of such a system could include the following requirements : • Pictures posted by a user can only be seen by that user ’ s friends ( conﬁdentiality ) • A user can like any given post at most once ( integrity ) • The service is operational more than 99.9 % of the time on average ( availability ) Different security requirements can be at odds with each other , for instance , locking down a system on the appearance of an attack is good for conﬁdentiality and integrity of the system , but bad for availability .
A security failure is a scenario where the software system does not achieve its security objective , and a vulnerability is the underlying cause of such a failure .
The determination of an underlying cause is usually not absolute : there are no objective criteria to determine what vulnerability is responsible for a given security failure or where it is located in the code .
One might say that the vulnerability is in the part of the code that has to be ﬁxed to avoid this speciﬁc security failure , but ﬁxes can be required in multiple places , and often multiple mitigation strategies are possible where each mitigation strategy requires a different ﬁx or set of ﬁxes .
In practice however , most software systems do not have precise explicit security objectives , and even if they do , these objectives are not absolute and have to be traded off against other objectives such as performance or usability of the software system .
Hence , software security is often about avoiding known classes of bugs that enable speciﬁc attack techniques .
There are well-understood classes of software implementation bugs that , when triggered by an attacker , can lead to a substantial disruption in the behaviour of the software , and are thus likely to break whatever security objective the software might have .
These bugs are called implementation vulnerabilities even if they are relatively independent from application- or domain-speciﬁc security objectives like the example objectives above .
This document , the Software Security KA , covers such implementation vulnerabilities , as well as countermeasures for them .
Many other aspects are relevant for the security of software based systems , including human factors , physical security , secure deployment and procedural aspects , but they are not covered in this chapter .
The impact of security on the various 1 Other common information security requirements like non-repudiation or data authentication can be seen as instances or reﬁnements of integrity from a software perspective .
But from other perspectives , for instance from a legal perspective , the semantics of these requirements can be more involved .
Security issues speciﬁc to software running on the web or mobile platforms are discussed in the Web & Mobile Security Knowledge Area ( Chapter 15 ) .
The remainder of this chapter is structured as follows .
Instead , the topic discusses how categories of vulnerabilities can often be deﬁned as violations of a partial speciﬁcation of the software system , and it is unlikely that a useful complete taxonomy of such partial speciﬁcations would exist .
The discussion of countermeasures for implementation vulnerabilities is structured in terms of where in the lifecycle of the software system they are applicable .
Topic 14.2 ( Prevention ) discusses how programming language and Application Programing Interface ( API ) design can prevent vulnerabilities from being introduced during development in software programmed in that language and using that API .
In addition , defensive coding practices can contribute to the prevention of vulnerabilities .
It is important to note , however , that some countermeasure techniques could in principle be applied in all three phases , so this is not an orthogonal classiﬁcation .
For instance , a speciﬁc dynamic check ( say , an array bounds check ) could be mandated by the language speciﬁcation ( Prevention , the countermeasure is built in by the language designer ) , could be used as a testing oracle ( Detection , the countermeasure is used by the software tester ) or could be inlined in the program to block attacks at run-time ( Mitigation , the countermeasure is applied on deployment ) .
Implementation vulnerabilities play an important role in cybersecurity and come in many forms .
The Common Vulnerabilities and Exposures ( CVE ) is a publicly available list of entries in a standardised form describing vulnerabilities in widely-used software components , and it lists close to a hundred thousand such vulnerabilities at the time of writing .
Implementation vulnerabilities are often caused by insecure programming practices and inﬂuenced by the programming language or APIs used by the developer .
This ﬁrst topic covers important categories of implementation vulnerabilities that can be attributed to such insecure programming practices .
Existing classiﬁcations of vulnerabilities , such as the Common Weakness Enumeration ( CWE ) , a community-developed list of vulnerability categories , are useful as a baseline for vulnerability identiﬁcation , mitigation and prevention , but none of the existing classiﬁcations have succeeded in coming up with a complete taxonomy .
Hence , the categories discussed in this ﬁrst topic should be seen as examples of important classes of vulnerabilities , and not as an exhaustive list .
They were selected with the intention to cover the most common KA Software Security | October 2019 Page 459 The Cyber Security Body Of Knowledge www.cybok.org implementation vulnerabilities , but this selection is at least to some extent subjective .
Speciﬁc categories of implementation vulnerabilities can often be described as violations of a ( formal or informal ) speciﬁcation of some sub-component of the software system .
Such a speciﬁcation takes the form of a contract that makes explicit what the sub-component expects of , and provides to its clients .
On violation of such a contract , the software system enters an error-state , and the further behaviour of the software system is typically behaviour that has not been considered by the system developers and is dependent on system implementation details .
Attackers of the system can study the implementation details and exploit them to make the system behave in a way that is desirable for the attacker .
, these languages have constructs for allocating memory cells that can subsequently be assigned to , or read from by the program , and then deallocated again .
The programming language deﬁnition speciﬁes how to use these constructs correctly : for instance , allocation of n memory cells will return a reference to an array of cells that can then be accessed with indices 0 to n − 1 until the reference is deallocated ( freed ) again .
Some programming languages implement this contract defensively , and will throw an exception if a client program accesses memory incorrectly .
Other programming languages ( most notably , C and C++ ) leave the responsibility for correctly allocating , accessing and deallocating memory in the hands of the programmer , and say that the behaviour of programs that access or manage memory incorrectly is undeﬁned .
Such languages are sometimes called memory unsafe languages , and bugs related to memory management ( memory management vulnerabilities ) are a notorious source of security bugs in these languages .
• A temporal vulnerability is a bug where the program accesses memory that was once allocated to the program , but has since been deallocated .
As such , the observed behaviour of a program with a vulnerability will depend on the actual implementation of the language .
Memory management vulnerabilities are particularly dangerous from a security point of view , because in many implementations mutable memory cells allocated to the program are part of the same memory address space where also compiled program code , and runtime metadata such as the call stack are stored .
In such implementations , a memory access by the program that violates the memory management contract can result in an access to compiled program code or runtime metadata , and hence can cause corruption of program code , program control ﬂow and program data .
An attack consists of providing input to the program to trigger the vulnerability , which makes the program violate the memory management contract .
The attacker chooses the input such that the program accesses a memory cell of interest to the attacker : KA Software Security | October 2019 Page 460 The Cyber Security Body Of Knowledge www.cybok.org • In a code corruption attack , the invalid memory access modiﬁes compiled program code to attacker speciﬁed code .
• In a data-only attack , the invalid memory access modiﬁes other data variables of the program , possibly resulting in increased privileges for the attacker .
• In an information leak attack , the invalid memory access is a read access , possibly resulting in the exﬁltration of information , either application secrets such as cryptographic keys , or runtime metadata such as addresses which assist prediction of the exact layout of memory and hence may enable other attacks .
Because of the practical importance of these classes of attacks , mitigation techniques have been developed that counter speciﬁc attack techniques , and we discuss these in Topic 14.4 .
14.1.2 Structured Output Generation Vulnerabilities Programs often have to dynamically construct structured output that will then be consumed by another program .
Examples include : the construction of SQL queries to be consumed by a database , or the construction of HTML pages to be consumed by a web browser .
One can think of the code that generates the structured output as a sub-component .
The intended structure of the output , and how input to the sub-component should be used within the output , can be thought of as a contract to which that sub-component should adhere .
For instance , when provided with a name and password as input , the intended output is a SQL query that selects the user with the given name and password from the users database table .
A common insecure programming practice is to construct such structured output by means of string manipulation .
The output is constructed as a concatenation of strings where some of these strings are derived ( directly or indirectly ) from input to the program .
This practice is dangerous , because it leaves the intended structure of the output string implicit , and maliciously chosen values for input strings can cause the program to generate unintended output .
A structured output generation vulnerability is a bug where the program constructs such unintended output .
This is particularly dangerous in the case where the structured output represents code that is intended to include provided input as data .
Maliciously chosen input data can then inﬂuence the generated output code in unintended ways .
The name ‘ injection ’ refers to the fact that exploitation of these vulnerabilities will often provide data inputs KA Software Security | October 2019 Page 461 The Cyber Security Body Of Knowledge www.cybok.org that cause the structured output to contain additional code statements , i.e .
exploitation injects unintended new statements in the output .
Structured output generation vulnerabilities are relevant for many different kinds of structured outputs : • A SQL injection vulnerability is a structured output generation vulnerability where the structured output consists of SQL code .
These vulnerabilities are particularly relevant for server-side web application software , where it is common for the application to interact with a back-end database by constructing queries partially based on input provided through web forms .
• A command injection vulnerability is a structured output generation vulnerability where the structured output is a shell command sent by the application to the operating system shell .
This list is by no means exhaustive .
Several factors can contribute to the difﬁculty of avoiding structured output generation vulnerabilities : • The structured output can be in a language that supports sublanguages with a signiﬁcantly different syntactic structure .
An important example of such a problematic case is HTML , that supports sublanguages such as JavaScript , CSS and SVG .
• The computation of the structured output can happen in different phases with outputs of one phase being stored and later retrieved as input for a later phase .
Structured output generation vulnerabilities that go through multiple phases are sometimes referred to as stored injection vulnerabilities , or more generally as higher-order injection vulnerabilities .
Attack techniques for exploiting structured output generation vulnerabilities generally depend on the nature of the structured output language , but a wide range of attack techniques for exploiting SQL injection or script injection are known and documented .
14.1.3 Race Condition Vulnerabilities When a program accesses resources ( such as memory , ﬁles or databases ) that it shares with other concurrent actors ( other threads in the same process , or other processes ) , the program often makes assumptions about what these concurrent actors will do ( or not do ) to these shared resources .
Such assumptions can again be thought of as part of a speciﬁcation of the program .
This speciﬁcation is no longer a contract between two sub-components of the program ( a caller and a callee ) , but it is a contract between the actor executing the program and its environment ( all concurrent actors ) , where the contract speciﬁes the assumptions made on how the environment will interact with the program ’ s resources .
For instance , the speciﬁcation can say that the program relies on exclusive access to a set of resources for a speciﬁc interval of KA Software Security | October 2019 Page 462 The Cyber Security Body Of Knowledge www.cybok.org its execution : only the actor executing the program will have access to the set of resources for the speciﬁed interval .
Violations of such a speciﬁcation are concurrency bugs , also commonly referred to as race conditions , because a consequence of these bugs is that the behaviour of the program may depend on which concurrent actor accesses a resource ﬁrst ( ‘ wins a race ’ ) .
Concurrency , and the corresponding issues of getting programs correct in the presence of concurrency , is an important sub-area of computer science with importance well beyond the area of cybersecurity [ 1218 ] .
Concurrency bugs often introduce nondeterminism : the behaviour of a program will depend on the exact timing or interleaving of the actions of all concurrent actors .
In adversarial settings , where an attacker controls some of the concurrent actors , the attacker may have sufﬁcient control on the timing of actions to inﬂuence the behaviour of the program such that a security objective is violated .
A very common instance is the case where the program checks a condition on a resource , and then relies on that condition when using the resource .
If an attacker can interleave his/her own actions to invalidate the condition between the check and the time of use , this is called a Time Of Check Time Of Use ( TOCTOU ) vulnerability .
Race condition vulnerabilities are relevant for many different types of software .
, programs that run with more privileges than their callers , for instance , operating system services ) often need to check some condition on a ﬁle , before performing an action on that ﬁle on behalf of a less privileged user .
Failing to perform check and action atomically ( such that no concurrent actor can intervene ) is a race condition vulnerability : an attacker can invalidate the condition between the check and the action .
• Races on the session state in web applications : web servers are often multi-threaded for performance purposes , and consecutive HTTP requests may be handled by different threads .
Hence , two HTTP requests belonging to the same HTTP session may access the session state concurrently .
Failing to account for this is a race condition vulnerability that may lead to corruption of the session state .
14.1.4 API Vulnerabilities An Application Programming Interface , or API , is the interface through which one software component communicates with another component , such as a software library , operating system , web service , and so forth .
Almost all software is programmed against one or more pre-existing APIs .
An API comes with an ( explicit or implicit ) speciﬁcation/contract of how it should be used and what services it offers , and just like the contracts we considered in previous subsections , violations of these contracts can often have signiﬁcant consequences for security .
If the client of the API violates the contract , the software system again enters an error-state , and the further behaviour of the software system will depend on implementation details of the API , and this may allow an attacker to break the security objective of the overall software system .
KA Software Security | October 2019 Page 463 The Cyber Security Body Of Knowledge www.cybok.org Of course , some APIs are more security sensitive than others .
A broad class of APIs that are security sensitive are APIs to libraries that implement security functionality like cryptography or access control logic .
This is particularly challenging for cryptographic libraries : if a cryptographic library offers a ﬂexible API , then correct use of that API ( in the sense that a given security objective is achieved ) is known to be hard .
There is substantial empirical evidence [ 1219 ] that developers frequently make mistakes in the use of cryptographic APIs , thus introducing vulnerabilities .
An orthogonal concern to secure use is the secure implementation of the cryptographic API .
It is common , however , in computer science to model the execution of programs abstractly , in terms of the execution of code on an abstract machine whose semantics is deﬁned mathematically ( with varying levels of rigour ) .
In fact , it is common to model execution of programs at many different levels of abstraction , including , for instance , execution of assembly code on a speciﬁed Instruction Set Architecture ( ISA ) , execution of Java bytecode on the Java Virtual Machine , or execution of Java source code according to the Java language speciﬁcation .
Each subsequent layer of abstraction is implemented in terms of a lower layer , but abstracts from some of the effects or behaviours of that lower layer .
For instance , an ISA makes abstraction from some physical effects such as electro-magnetic radiation or power consumption , and the Java Virtual Machine abstracts from the details of memory management .
A side-channel is an information channel that communicates information about the execution of a software program by means of such effects from which the program ’ s code abstracts .
Some side-channels require physical access to the hardware executing the software program .
Other side-channels , sometimes called software-based side-channels can be used from software running on the same hardware as the software program under attack .
A covert channel is an information channel where the attacker also controls the program that is leaking information through the sidechannel , i.e .
It was demonstrated that , unless an implementation carefully guards against this , side-channels based on power consumption or execution time can easily leak the cryptographic key used during the execution of an encryption algorithm .
This breaks the security objectives of encryption for an attacker model where the attacker can physically monitor the encryption process .
But side-channels are broadly relevant to software security in general .
The execution of assembly code written in the ISA will have effects on the micro-architectural state ; for instance , an effect could be that some values are copied from main memory to a cache .
The ISA makes abstraction of these effects , but under attacker models where the attacker can observe or inﬂuence these micro-architectural effects , they constitute a side-channel .
But side-channels can also constitute an integrity threat in case the attacker can modify the software ’ s execution state by relying on lower layer effects .
Such attacks are more commonly referred to as fault injection attacks .
Physical fault-injection attacks can use voltage or clock glitching , extreme temperatures , or electromagnetic radiation to induce faults .
Software-based fault-injection uses software to drive hardware components of the system outside their speciﬁcation range with the objective of inducing faults in these components .
A famous example is the Rowhammer attack that uses maliciously crafted memory access patterns to trigger an unintended interaction between high-density DRAM memory cells that causes memory bits to ﬂip .
14.1.6 14.1.6.1 Discussion Better connection with overall security objectives needs more complex speciﬁcations We have categorised implementation vulnerabilities as violations of speciﬁc partial speciﬁcations of software components .
However , the connection to the security objective of the overall software system is weak .
It is perfectly possible that a software system has an implementation vulnerability , but that it is not exploitable to break a security objective of the system , for instance , because there are redundant countermeasures elsewhere in the system .
Even more so , if a software system does not have any of the implementation vulnerabilities we discussed , it may still fail its security objective .
To have stronger assurance that the software system satisﬁes a security objective , one can formalise the security objective as a speciﬁcation .
During the design phase , on decomposition of the system in sub-components , one should specify the behaviour of the subcomponents such that they jointly imply the speciﬁcation of the overall system .
With such a design , the connection between an implementation vulnerability as a violation of a speciﬁcation on the one hand , and the overall security objective of the system on the other , is much stronger .
We discuss one illustration of additional complexity .
For the vulnerability categories we discussed ( memory management , structured output generation , race conditions and API vulnerabilities ) , the corresponding speciﬁcations express properties of single executions of the software : a given execution either satisﬁes or violates the speciﬁcation , and the software has a vulnerability as soon as there exists an execution that violates the speciﬁcation .
There are , however , software security objectives that can not be expressed as properties of individual execution traces .
A baseline speciﬁcation of this security objective for deterministic sequen- KA Software Security | October 2019 Page 465 The Cyber Security Body Of Knowledge www.cybok.org tial programs goes as follows : label the inputs and outputs of a program as either public or conﬁdential , and then require that no two executions of the software with the same public inputs ( but different conﬁdential inputs ) have different public outputs .
The intuition for looking at pairs of executions is the following : it might be that the program does not leak conﬁdential data directly but instead leaks some partial information about this data .
If collected along multiple runs , the attacker can gather so much information that eventually relevant parts of the conﬁdential original data are , in fact , leaked .
The above speciﬁcation effectively requires that conﬁdential inputs can never inﬂuence public outputs in any way , and hence can not leak even partial information .
But an information ﬂow speciﬁcation is more complex than the speciﬁcations we considered in previous sections because one needs two executions to show a violation of the speciﬁcation .
They can also be understood as violations of a speciﬁcation , but this is now a speciﬁcation that talks about multiple executions of the software system .
14.1.6.2 Side channel vulnerabilities are different Side channel vulnerabilities are by deﬁnition not violations of a speciﬁcation at the abstraction level of the software source code : they intrinsically use effects from which the source code abstracts .
However , if one develops a model of the execution infrastructure of the software that is detailed enough to model side channel attacks , then side channel vulnerabilities can again be understood as violations of a partial speciﬁcation .
One can choose to locate the vulnerability in the execution infrastructure by providing a speciﬁcation for the execution infrastructure that says that it should not introduce additional communication mechanisms .
Alternatively , one can reﬁne the model of the source code language to expose the effects used in particular side channel attacks , thus making it possible to express side-channel vulnerabilities at the source code level .
Dealing with general software side-channel vulnerabilities is not yet well understood , and no generally applicable realistic countermeasures are known .
, prevent concurrent executions on the same hardware , but that then contradicts other goals such as optimised hardware utilisation .
14.1.6.3 Vulnerabilities as faults The classiﬁcation of vulnerabilities by means of the speciﬁcation they violate is useful for understanding relevant classes of vulnerabilities , but is not intended as a complete taxonomy : there are a very large number of partial speciﬁcations of software systems that contribute to achieving some security objective .
Vulnerabilities can , however , be seen as an instance of the concept of faults , studied in the ﬁeld of dependable computing , and a good taxonomy of faults has been developed in that ﬁeld [ 1089 ] .
The most effective approaches eradicate categories of vulnerabilities by design of the programming language or API .
The general idea is the following .
We have seen in Topic 14.1 that many categories of implementation vulnerabilities can be described as violations of a speciﬁcation of some subcomponent .
Let us call an execution of the software system that violates this speciﬁcation , an erroneous execution , or an execution with an error .
Untrapped errors are particularly dangerous , because the further behaviour of the software system after an untrapped error can be arbitrary , and an attacker might be able to steer the software system to behaviour that violates a security objective .
Hence , designing a language or API to avoid errors , and in particular untrapped errors , is a powerful approach to prevent the presence of vulnerabilities .
For instance , languages like Java effectively make it impossible to introduce memory management vulnerabilities : a combination of static and dynamic checks ensures that no untrapped memory management errors can occur .
This effectively protects against the attack techniques discussed in 14.1.1 .
It is , however , important to note that this does not prevent the presence of memory-management bugs : a program can still access an array out of bounds .
But the bug is no longer a vulnerability , as execution is terminated immediately when such an access occurs .
One could argue that the bug is still a vulnerability if one of the security objectives of the software system is availability , including the absence of unexpected program termination .
In cases where choice or redesign of the programming language or API itself is not an option , speciﬁc categories of vulnerabilities can be made less likely by imposing safe coding practices .
This topic provides an overview of these techniques that can prevent the introduction of vulnerabilities .
14.2.1 Language Design and Type Systems A programming language can prevent categories of implementation vulnerabilities that can be described as violations of a speciﬁcation by : 1. making it possible to express the speciﬁcation within the language , and 2. ensuring that there can be no untrapped execution errors with respect to the expressed speciﬁcation .
KA Software Security | October 2019 Page 467 The Cyber Security Body Of Knowledge www.cybok.org 14.2.1.1 Memory management vulnerabilities A programming language speciﬁcation inherently includes a speciﬁcation of all the memory allocation , access and deallocation features provided by that language .
A programming language is called memory-safe if the language deﬁnition implies that there can be no untrapped memory management errors .
Languages like C or C++ are not memory-safe because the language deﬁnition allows for implementations of the language that can have untrapped memory management errors , but even for such languages one can build speciﬁc implementations that are memory-safe ( usually at the cost of performance ) .
A language can be made memory-safe through a combination of : 1. the careful selection of the features it supports : for instance , languages can choose to avoid mutable state , or can choose to avoid dynamic memory allocation , or can choose to avoid manual deallocation by relying on garbage collection , 2. imposing dynamic checks : for instance , imposing that every array access must be bounds-checked , and 3. imposing static checks , typically in the form of a static type system : for instance , objectﬁeld access can be guaranteed safe by means of a type system .
Programming languages vary widely in how they combine features , dynamic and static checks .
Pure functional languages like Haskell avoid mutable memory and rely heavily on static checks and garbage collection .
Dynamic languages like Python rely heavily on dynamic checks and garbage collection .
Rust , for instance , uses a type system that allows the compiler to reason about pointers statically , thus enabling it to insert code to free memory at places where it is known to no longer be accessible .
This comes at the expense of some decreased ﬂexibility when it comes to structuring program code .
14.2.1.2 Structured output generation vulnerabilities An important cause for structured output generation vulnerabilities is that the programmer leaves the intended structure of the output implicit , and computes the structured output by string manipulation .
A programming language can help prevent such vulnerabilities by providing language features that allow the programmer to make the intended structure explicit , thus providing a speciﬁcation .
The language implementation can then ensure that no untrapped errors with respect to that speciﬁcation are possible .
A ﬁrst approach is to provide a type system that supports the description of structured data .
This approach has been worked out rigorously for XML data : the programming language supports XML documents as ﬁrst class values , and regular expression types [ 1227 ] support the description of the structure of XML documents using the standard regular expression operators .
A type-correct program that outputs an XML document of a given type is guaranteed to generate XML output of the structure described by the type .
A second approach is to provide primitive language features for some of the common use cases of structured output generation .
By writing the query as an expression ( as opposed to building a SQL query by concatenating strings ) , the intended structure of KA Software Security | October 2019 Page 468 The Cyber Security Body Of Knowledge www.cybok.org the query is explicit , and the LINQ provider that compiles the query to SQL can provide strong guarantees that the generated query has the intended structure .
14.2.1.3 Race condition vulnerabilities Race condition vulnerabilities on heap allocated memory are often enabled by aliasing , the existence of multiple pointers to the same memory cell .
If two concurrent threads both hold an alias to the same cell , there is the potential of a race condition on that cell .
The existence of aliasing also leads to temporal memory-management vulnerabilities , when memory is deallocated through one alias but then accessed through another alias .
The notion of ownership helps mitigate the complications that arise because of aliasing .
The essence of the idea is that , while multiple aliases to a resource can exist , only one of these aliases is the owner of the resource , and some operations can only be performed through the owner .
An ownership regime puts constraints on how aliases can be created , and what operations are allowed through these aliases .
By doing so , an ownership regime can prevent race condition vulnerabilities , or it can support automatic memory management without a garbage collector .
For instance , a simple ownership regime for heap allocated memory cells might impose the constraints that : ( 1 ) aliases can only be created if they are guaranteed to go out of scope before the owner does , ( 2 ) aliases can only be used for reading , and ( 3 ) the owner can write to a cell only if no aliases currently exist .
This simple regime avoids data races : there can never be a concurrent read and write on the same cell .
It also supports automatic memory management without garbage collection : a heap cell can be deallocated as soon as the owner goes out of scope .
Of course , this simple regime is still quite restrictive , and a signiﬁcant body of research exists on designing less restrictive ownership regimes that can still provide useful guarantees .
An ownership regime can be enforced by the programming language by means of a type system , and several research languages have done this with the objective of preventing data races or memory management vulnerabilities .
The Rust programming language , a recent systems programming language , is the ﬁrst mainstream language to incorporate an ownership type system .
14.2.1.4 Other vulnerabilities Many other categories of vulnerabilities can , in principle , be addressed by means of programming language design and static type checking .
These approaches have until now mainly been integrated in research prototype languages .
SPARK is an example of a real-world language that has implemented information ﬂow analysis in the compiler .
KA Software Security | October 2019 Page 469 The Cyber Security Body Of Knowledge www.cybok.org 14.2.2 API Design The development of software not only relies on a programming language , it also relies on APIs , implemented by libraries or frameworks .
Just like language design impacts the likelihood of introducing vulnerabilities , so does API design .
The base principle is the same : the API should be designed to avoid execution errors ( where now , execution errors are violations of the API speciﬁcation ) , and in particular untrapped execution errors .
It should be difﬁcult for the programmer to violate an API contract , and if the contract is violated , that should be trapped , leading , for instance , to program termination or to well-deﬁned error-handling behaviour .
These libraries offer fat pointers ( where pointers maintain bounds information and check whether accesses are in bound ) , garbage collection ( where manual deallocation is no longer required ) , or smart pointers ( that support an ownershipregime to safely automate deallocation ) .
• Several libraries providing less error-prone APIs to do structured output generation for various types of structured output and for various programming languages have been proposed .
Examples include Prepared Statement APIs that allow a programmer to separate the structure of a SQL statement from the user input that needs to be plugged into that structure , or library implementations of language integrated query , where query expressions are constructed using API calls instead of using language syntax .
These libraries use simpliﬁcation ( at the cost of ﬂexibility ) , secure defaults , better documentation and the implementation of more complete use-cases ( for instance , include support for auxiliary tasks such as key storage ) to make it less likely that a developer will make mistakes .
Design by contract makes the contract of an API explicit by providing preconditions and post-conditions , and in defensive programming these preconditions will be checked , thus avoiding the occurrence of untrapped errors .
A programming language API also determines the interface between programs in the language and the surrounding system .
For instance , JavaScript in a browser does not expose an API to the local ﬁle system .
As a consequence , JavaScript programs running in the browser can not possibly access the ﬁle system .
Such less privileged APIs can be used to contain or sandbox untrusted code ( see Section 14.4.3 ) , but they can also prevent vulnerabilities .
Object capability systems [ 1229 ] take this idea further by providing a language and API that supports structuring code such that each part of the code only has the privileges it really needs ( thus supporting the principle of least privilege ) .
The design of cryptographic APIs that keep cryptographic key material in a separate protection domain , for instance in a Hardware Security Module ( HSM ) comes with its own challenges .
Such APIs have a security objective themselves : the API to a HSM has the objective KA Software Security | October 2019 Page 470 The Cyber Security Body Of Knowledge www.cybok.org of keeping the encryption keys it uses conﬁdential – it should not be possible to extract the key from the HSM .
The HSM API has an API-level vulnerability if there is a sequence of API calls that extracts conﬁdential keys from the HSM .
Note that this is an API design defect as opposed to the implementation defects considered in Topic 1 .
14.2.3 Coding Practices The likelihood of introducing the various categories of vulnerabilities discussed in Topic 14.1 can be substantially reduced by adopting secure coding practices .
Coding guidelines can also help against vulnerabilities of a more generic nature that can not be addressed by language or API design , such as , for instance , the guideline to not hard-code passwords .
Secure coding practices can be formalised as collections of rules and recommendations that describe and illustrate good and bad code patterns .
A ﬁrst approach to design such coding guidelines is heuristic and pragmatic : the programming community is solicited to provide candidate secure coding rules and recommendations based on experience in how things have gone wrong in the past .
These proposed rules are vetted and discussed by the community until a consensus is reached that the rule is sufﬁciently appropriate to be included in a coding standard .
For critical systems development , more rigorous and stricter coding standards have been developed .
The MISRA guidelines [ 1231 ] have seen widespread recognition and adoption for development of critical systems in C. The SPARK subset of Ada [ 1226 ] was designed to support coding to enable formal veriﬁcation of the absence of classes of vulnerabilities .
Also , speciﬁc side-channel vulnerabilities can be addressed by coding rules , for instance avoiding control ﬂow or memory accesses that depend on secrets can prevent these secrets from leaking through cache-based or branch-predictor based side-channels .
When they are not enforced by a type system , ownership regimes for safely managing resources such as dynamically allocated memory can also be the basis for programming idioms and coding guidelines .
For instance , the Resource Acquisition Is Initialisation ( RAII ) idiom , move semantics and smart pointers essentially support an ownership regime for C++ , but without compiler enforced guarantees .
An important challenge with secure coding guidelines is that their number tends to grow over time , and hence programmers are likely to deviate from the secure practices codiﬁed in the KA Software Security | October 2019 Page 471 The Cyber Security Body Of Knowledge www.cybok.org guidelines .
Hence , it is important to provide tool support to check compliance of software with the coding rules .
Topic 14.3.1 discusses how static analysis tools can automatically detect violations against secure coding rules .
Techniques to detect vulnerabilities must make trade-offs between the following two good properties that a detection technique can have : • A detection technique is sound for a given category of vulnerabilities if it can correctly conclude that a given program has no vulnerabilities of that category .
An unsound detection technique on the other hand may have false negatives , i.e .
, actual vulnerabilities that the detection technique fails to ﬁnd .
• A detection technique is complete for a given category of vulnerabilities , if any vulnerability it ﬁnds is an actual vulnerability .
An incomplete detection technique on the other hand may have false positives , i.e .
it may detect issues that do not turn out to be actual vulnerabilities .
This is typically done by static checking of the program code while making suitable abstractions of the executions to make the analysis terminate .
Achieving completeness can be done by performing actual , concrete executions of a program that are witnesses to any vulnerability reported .
This is typically done by dynamic detection where the analysis technique has to come up with concrete inputs for the program that trigger a vulnerability .
A very common dynamic approach is software testing where the tester writes test cases with concrete inputs , and speciﬁc checks for the corresponding outputs .
In practice , detection tools can use a hybrid combination of static and dynamic analysis techniques to achieve a good trade-off between soundness and completeness .
It is important to note , however , that some detection techniques are heuristic in nature , and hence the notions of soundness and completeness are not precisely deﬁned for them .
For instance , heuristic techniques that detect violations of secure coding practices as described in 14.2.3 are checking compliance with informally deﬁned rules and recommendations , and it is not always possible to unambiguously deﬁne the false positives or false negatives .
Static and dynamic program analysis techniques are widely studied in other areas of com- KA Software Security | October 2019 Page 472 The Cyber Security Body Of Knowledge www.cybok.org puter science .
This Topic highlights the analysis techniques most relevant to software security .
Another important approach to detection of vulnerabilities is to perform manual code review and auditing .
When using tool-supported static detection , it makes sense to adjust such subsequent code review and other veriﬁcation activities .
For instance , if static detection is sound for a given category of vulnerabilities , then one might consider not to review or test for that category of vulnerabilities in later phases .
14.3.1 Static Detection Static detection techniques analyse program code ( either source code or binary code ) to ﬁnd vulnerabilities .
Opposed to dynamic techniques , the static ones have the advantage that they can operate on incomplete code that is not ( yet ) executable , and that in a single analysis run they attempt to cover all possible program executions .
Roughly speaking , one can distinguish two important classes of techniques , that differ in their main objective .
14.3.1.1 Heuristic static detection First , there are static analysis techniques that detect violations of rules that are formal encodings of secure programming-practice heuristics .
The static analysis technique builds a semantic model of the program , including , for instance , an abstract syntax tree , and abstractions of the data ﬂow and control ﬂow in the program .
Based on this model , the technique can ﬂag violations of simple syntactic rules such as , do not use this dangerous API function , or only use this API function with a constant string as ﬁrst parameter .
An important indicator for the presence of vulnerabilities is the fact that ( possibly malicious ) program input can inﬂuence a value used in a risky operation ( for instance , indexing into an array , or concatenating strings to create a SQL query ) .
Taint analysis ( sometimes also called ﬂow analysis ) is an analysis technique that determines whether values coming from program inputs ( or more generally from designated taint sources ) can inﬂuence values used in such a risky operation ( or more generally , values ﬂowing into a restricted sink ) .
The same analysis can also be used to detect cases where conﬁdential or sensitive information in the program ﬂows to public output channels .
Many variants of static taint analysis exist .
To reduce the number of false positives , a taint analysis can take into account sanitisation performed by the program .
Tainted values that were processed by designated sanitisation functions ( that are assumed to validate that the values are harmless for further processing ) have their taint removed .
An important challenge is that taint analyses must be conﬁgured with the right sets of sources , sinks and sanitisers .
In practice , such conﬁgurations currently often occur manually although some recent works have added tool assistance in which , for instance , machine learning is used to support security analysts in this task .
KA Software Security | October 2019 Page 473 The Cyber Security Body Of Knowledge www.cybok.org 14.3.1.2 Sound static veriﬁcation Second , there are static analysis techniques that aim to be sound for well-deﬁned categories of vulnerabilities ( but usually in practice still make compromises and give up soundness to some extent ) .
For categories of vulnerabilities that can be understood as speciﬁcation or contract violations , the main challenge is to express this underlying speciﬁcation formally .
Once this is done , the large body of knowledge on static analysis and program veriﬁcation developed in other areas of computer science can be used to check compliance with the speciﬁcation .
The three main relevant techniques are program veriﬁcation , abstract interpretation and model checking .
Program veriﬁcation uses a program logic to express program speciﬁcations , and relies on the programmer/veriﬁer to provide an adequate abstraction of the program in the form of inductive loop invariants or function pre- and post-conditions to make it possible to construct a proof that covers all program executions .
For imperative languages with dynamic memory allocation , separation logic [ 1233 ] is a program logic that can express absence of memorymanagement and race-condition vulnerabilities ( for data races on memory cells ) , as well as compliance with programmer provided contracts on program APIs .
Checking of compliance with a separation logic speciﬁcation is typically not automatic : it is done by interactive program veriﬁcation where program annotations are used to provide invariants , pre-conditions and post-conditions .
However , if one is interested only in absence of memory management vulnerabilities , these annotations can sometimes be inferred , making the technique automatic .
Abstract interpretation is an automatic technique where abstraction is made from the concrete program by mapping the run-time values that the program manipulates to adequate ﬁnite abstract domains .
For imperative programs that do not use dynamic allocation or recursion , abstract interpretation is a successful technique for proving the absence of memory management vulnerabilities automatically and efﬁciently .
Model checking is an automatic technique that exhaustively explores all reachable states of the program to check whether none of the states violates a given speciﬁcation .
Because of the state explosion problem , model checking can only exhaustively explore very small programs , and in practice techniques to bound the exploration need to be used , for instance , by bounding the number of times a program loop can be executed .
Bounded model checking is no longer sound , but can still ﬁnd many vulnerabilities .
Most practical implementations of these analysis techniques give up on soundness to some extent .
In order to be both sound and terminating , a static analysis must over-approximate the possible behaviours of the program it analyses .
Real programming languages have features that are hard to over-approximate without leading to an unacceptable number of false positives .
This makes the implementation unsound , but more useful in the sense that it reduces the number of false positives .
KA Software Security | October 2019 Page 474 The Cyber Security Body Of Knowledge www.cybok.org 14.3.2 Dynamic Detection Dynamic detection techniques execute a program and monitor the execution to detect vulnerabilities .
14.3.2.1 Monitoring For categories of vulnerabilities that can be understood as violations of a speciﬁed property of a single execution ( See Topic 14.1.6 ) , complete detection can be performed by monitoring for violations of that speciﬁcation .
For other categories of vulnerabilities , or when monitoring for violations of a speciﬁcation is too expensive , approximative monitors can be deﬁned .
It is , in principle , possible to build complete monitors , but typically at a substantial cost in time and memory .
Modern C compilers include options to generate code to monitor for memory management vulnerabilities .
In cases where a dynamic analysis is approximative , like a static analysis , it can also generate false positives or false negatives , despite the fact that it operates on a concrete execution trace .
For structured output generation vulnerabilities , a challenge is that the intended structure of the generated output is often implicit , and hence there is no explicit speciﬁcation that can be monitored .
For instance , a monitor can use a ﬁne-grained dynamic taint analysis [ 1232 ] to track the ﬂow of untrusted input strings , and then ﬂag a violation when untrusted input has an impact on the parse tree of generated output .
Monitoring for race conditions is hard , but some approaches for monitoring data races on shared memory cells exist , for instance , by monitoring whether all shared memory accesses follow a consistent locking discipline .
14.3.2.2 Generating relevant executions An important challenge for dynamic detection techniques is to generate executions of the program along paths that will lead to the discovery of new vulnerabilities .
These techniques are often described by the umbrella term fuzz testing or fuzzing , and can be classiﬁed as : • Black-box fuzzing , where the generation of input values only depends on the input/output behaviour of the program being tested , and not on its internal structure .
Many different variants of black-box fuzzing have been proposed , including ( 1 ) purely random testing , where input values are randomly sampled from the appropriate value domain , KA Software Security | October 2019 Page 475 The Cyber Security Body Of Knowledge www.cybok.org ( 2 ) model-based fuzzing , where a model of the expected format of input values ( typically in the form of a grammar ) is taken into account during generation of input values , and ( 3 ) mutation-based fuzzing , where the fuzzer is provided with one or more typical input values and it generates new input values by performing small mutations on the provided input values .
• White-box fuzzing , where the internal structure of the program is analysed to assist in the generation of appropriate input values .
The main systematic white-box fuzzing technique is dynamic symbolic execution .
Dynamic symbolic execution executes a program with concrete input values and builds at the same time a path condition , a logical expression that speciﬁes the constraints on those input values that have to be fulﬁlled for the program to take this speciﬁc execution path .
By solving for input values that do not satisfy the path condition of the current execution , the fuzzer can make sure that these input values will drive the program to a different execution path , thus improving coverage .
14.4 MITIGATING EXPLOITATION OF VULNERABILITIES [ 1214 , 1235 ] Even with good techniques to prevent introduction of vulnerabilities in new code , or to detect vulnerabilities in existing code , there is bound to be a substantial amount of legacy code with vulnerabilities in active use for the foreseeable future .
Hence , vulnerability prevention and detection techniques can be complemented with techniques that mitigate the exploitation of remaining vulnerabilities .
An important objective for these techniques is to limit the impact on performance , and to maximise compatibility with legacy programs .
14.4.1 Runtime Detection of Attacks Runtime monitoring of program execution is a powerful technique to detect attacks .
In principle , program monitors to detect vulnerabilities during testing ( discussed in 14.3.2 Dynamic Detection ) could also be used at runtime to detect attacks .
For instance , dynamic taint analysis combined with a dynamic check whether tainted data inﬂuenced the parse tree of generated output has also been proposed as a runtime mitigation technique for SQL injection attacks .
But there is an important difference in the performance requirements for monitors used during testing ( discussed in Topic 14.3 ) and monitors used at runtime to mitigate attacks .
For runtime detection of attacks , the challenge is to identify efﬁciently detectable violations of properties that are expected to hold for the execution trace of the program .
A wide variety of techniques are used : • Stack canaries detect violations of the integrity of activation records on the call stack , and hence detect some attacks that exploit memory management vulnerabilities to modify a return address .
• No Execute ( NX ) data memory detects attempts to direct the program counter to data memory instead of code memory and hence detects many direct code injection attacks .
KA Software Security | October 2019 Page 476 The Cyber Security Body Of Knowledge www.cybok.org • Control-Flow Integrity ( CFI ) is a class of techniques that monitors whether the runtime control ﬂow of the program complies with some speciﬁcation of the expected control ﬂow , and hence detects many code-reuse attacks .
On detection of an attack , the runtime monitor must react appropriately , usually by terminating the program under attack .
Termination is a good reaction to ensure that an attack can do no further damage , but it has of course a negative impact on availability properties .
14.4.2 Automated Software Diversity Exploitation of vulnerabilities often relies on implementation details of the software under attack .
For instance , exploitation of a memory management vulnerability usually relies on details of the memory layout of the program at runtime .
A SQL injection attack can rely on details of the database to which the SQL query is being sent .
Hence , a generic countermeasure to make it harder to exploit vulnerabilities is to diversify these implementation details .
This raises the bar for attacks in two ways .
First , it is harder for an attacker to prepare and test his/her attack on an identical system .
An attack that works against a web server installed on the attacker machine might fail against the same web server on the victim machine because of diversiﬁcation .
Second , it is harder to build attacks that will work against many systems at once .
Instead of building an exploit once , and then using it against many systems , attackers now have to build customised exploits for each system they want to attack .
The most important realisation of this idea is Address Space Layout Randomization ( ASLR ) , where the layout of code , stack and/or heap memory is randomised either at load or at runtime .
Such randomisation can be coarse-grained , for instance , by just randomly relocating the base address of code , stack and heap segments , or ﬁne-grained where addresses of individual functions in code memory , activation records in the stack , or objects in the heap are chosen randomly .
The research community has investigated many other ways of automatically creating diversity at compilation time or installation time [ 1235 ] , but such automatic diversiﬁcation can also bring important challenges to software maintenance as bug reports can be harder to interpret , and software updates may also have to be diversiﬁed .
14.4.3 Limiting Privileges The exploitation of a software vulnerability inﬂuences the behaviour of the software under attack such that some security objective is violated .
By imposing general bounds on what the software can do , the damage potential of attacks can be substantially reduced .
Sandboxing is a security mechanism where software is executed within a controlled environment ( the ‘ sandbox ’ ) and where a policy can be enforced on the resources that software in the sandbox can access .
Sandboxing can be used to conﬁne untrusted software , but it can also be used to mitigate the impact of exploitation on vulnerable software : after a successful exploit on the software , an attacker is still conﬁned by the sandbox .
The generic idea of sandboxing can be instantiated using any of the isolation mechanisms that modern computer systems provide : the sandbox can be a virtual machine running under the supervision of a virtual-machine monitor , or it can be a process on which the operating system imposes an access control policy .
The Java Runtime Environment implements a sandboxing mechanism intended to contain untrusted Java code , or to isolate code from different stakeholders within the same Java Virtual Machine , but several signiﬁcant vulnerabilities have been found in that sandboxing mechanism over the years [ 1236 ] .
Compartimentalisation is a related but ﬁner-grained security mechanism , where the software itself is divided in a number of compartments and where some bounds are enforced on the privileges of each of these compartments .
This again requires some underlying mechanism to enforce these bounds .
For instance , a compartimentalised browser could rely on operating system process access control to bound the privileges of its rendering engine by denying it ﬁle system access .
Exploitation of a software vulnerability in the rendering engine is now mitigated to the extent that even after a successful exploit , the attacker is still blocked from accessing the ﬁle system .
To mitigate side-channel vulnerabilities , one can isolate the vulnerable code , for instance , on a separate core or on separate hardware , such that the information leaking through the side channel is no longer observable for attackers .
14.4.4 Software Integrity Checking Under the umbrella term Trusted Computing , a wide range of techniques have been developed to measure the state of a computer system , and to take appropriate actions if that state is deemed insecure .
A representative technique is Trusted Boot where measurements are accumulated for each program that is executed .
One can then enforce that access to secret keys , for instance , is only possible from a state with a speciﬁed measurement .
CONCLUSIONS Software implementation vulnerabilities come in many forms , and can be mitigated by a wide range of countermeasures .
Table 14.1 summarises the relationship between the categories of vulnerabilities discussed in this chapter , and the relevant prevention , detection and mitigation techniques commonly used to counter them .
KA Software Security | October 2019 Page 478 The Cyber Security Body Of Knowledge www.cybok.org Vulnerability category Prevention Detection Mitigation Memory management vulnerabilities memory-safe languages , fat/smart pointers , coding rules many static and dynamic detection techniques stack canaries , NX , CFI , ASLR , sandboxing Structured output generation vulnerabilities regular expression types , LINQ , Prepared Statements taint analysis runtime detection Race condition vulnerabilities ownership types , coding guidelines static and dynamic detection sandboxing API vulnerabilities contracts , usable APIs , defensive API implementations runtime checking of pre- and post-conditions , static contract veriﬁcation compartimentalisation Side channel vulnerabilities coding guidelines static detection isolation Table 14.1 : Summary overview Acknowledgments The insightful and constructive comments and feedback from the reviewers and editor on earlier drafts have been extremely valuable , and have signiﬁcantly improved the structure and contents of this chapter , as have the comments received during public review .
24 Deadly Sins of Software Security is a more recent and updated book by mostly the same authors .
KA Software Security | October 2019 Page 480 The Cyber Security Body Of Knowledge www.cybok.org The Art of Software Security Assessment [ 1217 ] Even if this is a book that is primarily targeted at software auditors , it is also a very useful resource for developers .
It has clear and detailed descriptions of many classes of vulnerabilities , including platform-speciﬁc aspects .
However , another sensible , and different , interpretation of the term is that it is about protecting the software code itself , for instance , against reverse engineering of the code , against extraction of secrets from the code , or against undesired tampering with the code before or during execution .
Obfuscation , watermarking and tamperprooﬁng are examples of techniques to protect software against such attacks .
Surreptitious Software is a rigorous textbook about this notion of software security .
OWASP Resources The Open Web Application Security Project ( OWASP ) is a not-for-proﬁt , volunteer-driven organisation that organises events and offers a rich set of resources related to application security and software security .
They offer practice-oriented guides on secure development and on security testing , as well as a collection of tools and awareness raising instruments .
KA Software Security | October 2019 Page 481 The Cyber Security Body Of Knowledge www.cybok.org KA Software Security | October 2019 Page 482 Chapter 15 Web & Mobile Security Sascha Fahl Leibniz University Hannover 483 The Cyber Security Body Of Knowledge www.cybok.org 15.1 INTRODUCTION The purpose of this Knowledge Area is to provide an overview of security mechanisms , attacks and defences in modern web and mobile ecosystems .
This overview is intended for use in academic courses and to guide industry professionals interested in this area .
Web and mobile security have become the primary means through which many users interact with the Internet and computing systems .
Hence , their impact on overall information security is signiﬁcant due to the sheer prevalence of web and mobile applications ( apps ) .
Covering both web and mobile security , this Knowledge Area emphasises the intersection of their security mechanisms , vulnerabilities and mitigations .
Both areas share a lot in common and have experienced a rapid evolution in the features and functionalities offered by their client side applications ( apps ) .
Web and mobile client apps typically interact with server side application interfaces using web technologies .
This second phenomenon , also sometimes called webiﬁcation , equally affects both web and mobile ecosystems .
Web browsers were mostly used to render and display static websites without dynamic content .
The focus on the server-side prevailed even with the rise of early scripting languages such as Perl and PHP .
Similarly to web browsers , early mobile devices had limited functionality and were mostly used to make calls or send SMS .
Mobile security back then focused on access control , calls and SMS security .
The rise of modern web and mobile platforms brought notable changes .
A signiﬁcant amount of web application code is no longer executed on the server-side but runs in the browser .
Web browser support for Java , Adobe Flash , JavaScript and browser plugins and extensions brought many new features to the client , which prompted a drastic change of the attack surface on the web .
Adobe Flash browser plugins are known for being an attractive target for attackers .
In response to these new threats , browser vendors and website developers and operators took measures .
Smartphones and tablets are equipped with sensors , including motion , GPS and cameras .
They have extensive computing power , storage capacity and are connected to the Internet 24-7 .
Modern Android and iOS devices run full-blown operating systems and increasingly feature-rich and complex application frameworks .
Mobile apps can request access to all the devices ’ resources and sensors using permission based access control , and process highly sensitive user information .
Modern web and mobile ecosystems are the primary drivers for the rise of appiﬁcation and the `` there is an app for everything `` motto sums up many of the technological and security developments in recent years .
The appiﬁcation trend resulted in millions of apps ranging from simple ﬂashlight apps to online social network apps , from online banking apps to mobile and browser-based games .
It also sparked the merging of technologies and security mechanisms used in web and mobile applications .
Web browsers and mobile apps communicate with back-end services often using web focused technologies .
Both web-browsers and mobile applications tend to primarily exchange Hypertext Markup Language ( HTML ) , JSON and XML documents and both make extensive use of the JavaScript programming language , on the server- and the client-side .
Webiﬁcation describes the conversion to these web technologies .
The sheer amount of applications in modern web and mobile ecosystems also impacted the software distribution model , which moved away from website downloads to centralised application stores , which allow developers to publish , advertise and distribute their software , and users to download new apps and app updates .
The centralised software distribution had a positive impact on update frequencies and speed for both web and mobile .
This Knowledge Area focuses on the appiﬁcation trend and an introduction to the core technologies of the webiﬁcation phenomenon .
Figure 15.1 provides an overview of the entities involved and their interactions .
Software and content isolation are crucial security mechanisms and aim to protect apps and websites from malicious access .
While isolation is understood in relation to traditional operating systems ( cf .
Modern web and mobile platforms introduced new forms of access control based on permission dialogues .
Web and mobile applications make extensive use of the HTTP and HTTPS protocols .
While software updates are equally important in traditional computer systems , the centralisation1 of web and mobile ecosystems , introduces new challenges and opportunities .
Section 15.3 ﬁrst covers phishing and clickjacking attacks and defenses .
Both affect web and mobile clients and exploit human difﬁculties in correctly parsing URLs or identifying changes in the visual appearance of web-sites .
As feature-rich web and mobile clients store sensitive data , we will then discuss client-side storage security issues and mitigations .
We discuss SQL and command injection attacks that allow malicious users to manipulate database queries to storage backends of web applications and commands that are executed .
This is followed by a discussion of cross-site scripting and cross-site request forgery attacks and common server-side misconﬁgurations that might lead to vulnerable service backends .
Overall , the discussion of client- and server-side security challenges aims to serve as the underlining of the natural split between entities in web and mobile ecosystems .
Additionally , the chosen aspects illustrate the difference between the web and mobile world from other ecosystems .
The information presented in this section is intended to serve as a foundation to better understand the security challenges in the following sections .
Similar to other software products and computer systems , mobile operating systems and applications and web browsers as well as web servers may contain exploitable bugs .
1 There are only a limited number of widely used web browsers and application stores .
KA Web & Mobile Security | October 2019 Page 486 The Cyber Security Body Of Knowledge www.cybok.org 15.2.1 Appiﬁcation Over the last ten years , the rise of mobile devices and ubiquitous Internet access have changed the way software is produced , distributed and consumed , altering how humans interact with computer devices and with software installed on the devices .
While regular Internet browsers have been the dominant way of accessing content on the web in the pre-mobile era , the concept of appiﬁcation signiﬁcantly changed the way users access content online [ 1244 ] .
Appiﬁcation describes the phenomenon of moving away from a web-based platform to access most digital tools and media online with a web-browser through mobile applications with highly specialised , tiny feature sets .
As mobile devices grew to become the primary interface for web access worldwide [ 1251 ] , the number of apps rose enormously over the last decade .
“ There is an app for everything ” became the mantra of appiﬁed software ecosystems , which produced numerous applications for all sorts of use cases and application areas .
Many apps look like native local desktop or mobile applications .
However , they are often ( mobile ) web applications that communicate with back end services , which then outsource computation and storage tasks to the client .
The shift towards appiﬁcation had a signiﬁcant impact on web and mobile security creating more security challenges on the client-side .
The rise of appiﬁcation also impacted the developer landscape .
Due to the more extensive tool and framework support , the market entrance barrier is lower in appiﬁed ecosystems .
This attracts more inexperienced developers , and has negative consequences for web and mobile security in general ( cf .
The Rise of the Citizen Developer The appiﬁcation trend attracts many non-professional software developers called citizen developers .
Many of them do not have a software engineering education but make use of multiple simple APIs and tools available to build apps for different platforms .
Generated apps tend to be vulnerable to reconﬁguration and code injection attacks and rely on an insecure infrastructure .
15.2.2 Webiﬁcation Modern web and mobile platforms gave rise to another phenomenon .
In addition to conventional web applications targeting regular web browsers , mobile web applications are more frequently built using these web technologies .
In particular , mobile web applications make heavy use of the JavaScript language .
This section gives a brief introduction to the most essential technologies needed to explain vulnerabilities and mitigations later in the KA .
Address bars in modern browser User Interfaces ( UIs ) use the URLs to illustrate the remote address of a rendered document .
A fully qualiﬁed absolute URL string consists of several segments and contains all the required information to access a particular resource .
The resource path format is built on top of Unix directory semantics .
In practice , it is used to address an HTML anchor element for in-document navigation .
15.2.2.2 Hypertext Transfer Protocol The Hypertext Transfer Protocol ( HTTP ) is the most widely used mechanism to exchange documents between servers and clients on the web .
While HTTP is mostly used to transfer HTML documents , it can be used for any data .
An HTTP client initiates a session by sending an HTTP request to an HTTP server .
The server returns an HTTP response with the requested ﬁle .
The remaining request header consists of zero or more name : value pairs .
The request header is terminated with a single empty line .
HTTP clients may pass any additional content to the server .
Although the content can be of any type , clients commonly send HTML content to the server , e. g. to submit form data .
The HTTP server responds to the request with a response header followed by the requested content .
Additional response header lines are optional .
The header ends with a single empty line followed by the actual content of the requested resource .
Similar to the request content , the content may be of any type but is often an HTML document .
Although cookies were not part of the original HTTP RFC [ 1243 ] , they are one of the most important protocol extensions .
Cookies allow remote servers to store multiple name=value pairs in client storage .
Cookies are a popular mechanism to maintain sessions between clients and servers and to authenticate users .
HTTP is request-response based and neatly ﬁts unidirectional data transfer use cases .
However , for better latency and more effective use of bandwidth , bidirectional network connections are needed .
Bidirectional connections not only allow clients to pull data from the server , but also the server to push data to the client at any time .
WebSocket connections start with a regular HTTP request that includes an Upgrade : WebSocket header .
After the WebSocket handshake is completed , both parties can send data at any time without having to run a new handshake .
The HTML syntax is fairly straightforward : a hierarchical tree structure of tags , name=value tag parameters and text nodes form an HTML document .
The Domain Object Model ( DOM ) deﬁnes the logical structure of an HTML document and rules how it is accessed and manipulated .
However , competing web browser vendors introduced all sorts of custom features and modiﬁed the HTML language to their wishes .
The many different and divergent browser implementations resulted in only a small portion of the websites on the Internet adhering to the HTML standard ’ s syntax .
Hence , implementations of HTML parsing modes and error recovery vary greatly between different browsers .
The HTML syntax comes with some constraints on what may be included in a parameter value or inside a text node .
Whenever they are used for a different purpose , such as parts of substrings of a text , they need to be escaped .
To avoid undesirable side effects , HTML provides an entity encoding scheme .
However , the failure to properly apply the encoding to reserved characters when displaying user-controlled information may lead to severe web security ﬂaws such as cross-site scripting ( cf .
The primary goal of CSS was to provide a straightforward and simple text-based description language to supersede the many vendor-speciﬁc HTML tag parameters that lead to many inconsistencies .
However , similar to divergent HTML parsing implementations , different browsers also implement different CSS parsing behavior .
CSS allows HTML tags to be scaled , positioned or decorated without being limited by the original HTML markup constraints .
Similar to HTML tag values , values inside CSS can be user-controlled or provided externally , which makes CSS crucial for web security .
It runs both client-side in web browsers and server-side as part of web applications .
The language is meant to be interpreted at runtime and has a C-inspired syntax .
JavaScript supports a classless object model , provides automatic garbage collection and weak and dynamic typing .
Instead , some limited predeﬁned interfaces are provided by native code inside the browser .
The following discussion will focus on client JavaScript in web browsers .
Every HTML document in a browser is given its JavaScript execution context .
However , execution contexts are strictly isolated from each other in general .
Script processing consists of three phases : Parsing validates the script syntax and translates it to an intermediate binary representation for performance reasons .
The code has no effect until parsing is completed .
Blocks with syntax errors are ignored , and the next block is parsed .
Function Resolution registers all named , global functions the parser found in a block .
All registered functions can be reached from the following code .
Execution runs all code statements outside of function blocks .
While JavaScript is a very powerful and elegant scripting language , it brings up new challenges and security issues such as Cross-Site Scripting vulnerabilities ( cf .
It is a stack-based virtual machine language and mainly aims to execute at native speed on client machines .
Code written in WebAssembly is memory safe and beneﬁts from all security features provided by regular code associated with a website .
Additionally , WebAssembly code can access JavaScript code running in the same origin container and provide its functionality to JavaScript code from the same origin .
Developers can integrate apps with HTML and JavaScript and beneﬁt from portability advantages .
WebViews run in the context of regular mobile apps and allow a rich two-way interaction with the hosted web content .
Mobile apps can invoke JavaScript from within the web content , and monitor and intercept events in the web content .
At the same time , speciﬁc JavaScript APIs allow WebView apps to interact with content and sensors outside the WebView context .
App-to-web attacks , allow malicious apps to inject JavaScript into hosted WebViews with the goal to exﬁltrate sensitive information or trick WebViews into navigating to and presenting users with untrusted and potentially malicious websites .
Web-to-app attacks inject untrusted web content into an app and leverage an app ’ s JavaScript bridge to the underlying host app .
Both the appiﬁcation and webiﬁcation phenomena led to a new way of software distribution .
Instead of decentralised download sources , centralised application stores which are illustrated in the next section emerged .
15.2.3 Application Stores Application stores are centralised digital distribution platforms that organise the management and distribution of software in many web and mobile ecosystems .
Famous examples are the Chrome web store for extensions for the Chrome browser , Apple ’ s AppStore for iOS applications , and Google Play for Android applications .
Users can browse , download , rate and review mobile applications or browser plugins and extensions .
Developers can upload their software to application stores that manage all of the software distribution challenges , including the provision of storage , bandwidth and parts of the advertisement and sales .
Most of the software available in ecosystems that have application stores is distributed through the stores .
Application stores allow providers to control which applications are available in their stores , which allows them to ban particular applications .
Whilst this can give rise to accusations of censorship , the deployment of security vetting techniques has helped to signiﬁcantly reduce the amount of malicious software available in stores [ 1263 ] and to reduce the number of applications that suffer from vulnerabilities due to the misuse of security APIs by developers [ 421 ] .
Deployed security vetting techniques include static and dynamic analysis applied to application binaries and running instances of applications .
In addition to security vetting techniques , application stores require applications to be signed by developer or application store keys .
In Android , application signing does not rely on the same public key infrastructures used on the web .
Instead , developers are encouraged to use self-signed certiﬁcates and required to sign application updates with the same key to prevent malicious updates [ 1265 ] .
The application signing procedure on iOS devices requires apps to be signed by Apple .
Unsigned apps can not be installed on iOS devices .
Application stores not only allow developers and users centralised access to software publication , distribution and download , they also enable users to rate and review published applications .
User rating and reviews are intended to help other users make more informed download decisions , but KA Web & Mobile Security | October 2019 Page 491 The Cyber Security Body Of Knowledge www.cybok.org they also have a direct connection to application security .
Impact of User Ratings and Reviews on Application Security Nguyen et al .
They found that the presence of security- and privacy-related user reviews for applications are contributing factors to future security-related application updates .
15.2.4 Sandboxing Both modern mobile and browser platforms make use of different sandboxing techniques to isolate applications and websites and their content from each other ( cf .
This also aims to protect the platform against malicious applications and sites .
Each application or website runs in its own process 2 .
By default , isolated processes can not interact with each other and can not share resources .
15.2.4.1 Application Isolation Modern mobile platforms provide each application with their sandbox running in a dedicated process and their own ﬁle-system storage .
Mobile platforms take advantage of underlying operating system process protection mechanisms for application resource identiﬁcation and isolation .
Security is enforced through standard operating system facilities , including user and group IDs as well as security contexts .
By default , sandboxing prevents applications from accessing each other and only allows limited access to operating system resources .
To access protected app and operating system resources inter-app communication through controlled interfaces is required .
15.2.4.2 Content Isolation Content isolation is one of the major security assurances in modern browsers .
The main idea is to isolate documents based on their origin so that they can not interfere with each other .
The core idea behind SOP is that two separate JavaScript execution contexts are only allowed to manipulate a document ’ s DOM if there is an exact match between the document host and the protocol , DNS name and port numbers3 .
Similar to JavaScript-DOM-interaction , the SOP limits the JavaScript XMLHttpRequest capabilities to only issue HTTP requests to the origin of the host document .
One major ﬂaw of SOP is that it relies on DNS instead of IP addresses .
Attackers who can intentionally change the IP address of a DNS entry can therefore circumvent SOP security guarantees .
The protocol , DNS name and port number triple is called origin .
Since code that enforces the same-origin-policy occasionally contains security bugs , modern browsers introduced a second line of defence : websites are rendered in their own processes that run in a sandbox .
A CSP is primarily intended to prevent code injection attacks such as XSS ( cf .
This allows malicious scripts to be executed in clients ’ browsers .
CSP allows web developers and server operators to limit the number of origins that browsers should consider to be trusted sources of content – including executable code and media ﬁles .
A CSP can be used so that servers can globally disable code execution on the client .
Compatible browsers will then only execute code or load media ﬁles from trusted origins .
Example : Content Security Policy Header The following CSP allows users of a web application to include images from any origin , but to restrict media data ( audio or video media ) to the trusted trusted-media.com domain .
The control of access to resources on a traditional computer system requires the accurate deﬁnition of all involved security principals and the protected resources in the system .
Finally , an access control system requires a non-bypassable and trusted mechanism to evaluate access requests ( the reference monitor ) and sound security policies that deﬁne the appropriate course of action for all access requests .
Based on the security policies , the reference monitor can decide whether it grants access or denies access ( cf .
Modern mobile and web platforms deviate from conventional computer systems in multiple ways : KA Web & Mobile Security | October 2019 Page 493 The Cyber Security Body Of Knowledge www.cybok.org 15.2.5.1 The Security Principals Traditional computer systems are primarily multi-user systems with human users and processes running on their behalf .
Modern mobile and web platforms extend conventional multiuser systems to also consider all involved developers that have their applications installed on the system as security principals .
User-level processes can then extend this OS functionality and implement their own access control mechanisms .
Like conventional computer systems , modern mobile and web platforms build on top of OS low-level access control mechanisms .
Additionally , the extensive frameworks on top of which applications are developed and deployed , provide extended interfaces .
Modern web and mobile platforms use Inter-Process Communication ( IPC ) for privilege separation and compartmentalisation between apps and between apps and the operating system instead of allowing direct access to resources .
Access control mechanisms on calling processes are used to protect IPC interfaces .
All processes that share the same privilege level have the same set of permissions and can access the same resources .
Modern mobile and web platforms make a clear distinction between system and third-party applications : access to security- and privacy-critical resources is only granted to designated processes and third-party applications have , by default , no access to critical resources .
If such access is required , application developers must request permissions from a set commonly available to all third-party applications .
Most permissions allow developers to use designated system processes as deputies to access protected sensitive resources .
Those system processes serve as reference monitors and enforce access control policies .
15.2.5.4 Different Permission Approaches Mobile and web platforms implement distinct permission approaches .
While application developers have to request both normal and dangerous permissions to grant their applications access to the respective resources , the levels differ for application users .
Normal permissions are granted silently without any application user interaction .
However , whenever applications require dangerous permissions , the underlying mobile or web platform presents users with permission dialogues .
While earlier Android versions showed users a list of all the necessary permissions of an application at install time , modern mobile platforms and browsers present permission dialogues at run-time .
A permission dialog usually is shown the ﬁrst time an application requests access to the corresponding resource .
Application users can then either grant or deny the application access 4 Depending on the system , more levels may be implemented .
Modern permission-based access control systems allow greater ﬂexibility and control for both developers and users .
found that Android applications developers tend to request more permissions for their applications than needed [ 1248 ] .
In the web , web servers or applications exchange information with browsers .
In both cases , HTTPS should always be used for secure network connections between clients and servers .
To establish secure network connections , the web public key infrastructure is used .
Using the web PKI and X.509 certiﬁcates , clients and servers can authenticate each other and exchange cryptographic key material for further encrypted information transport .
This KA will not provide further details on how the authentication process and the key exchange procedures work in detail ( cf .
Rather , it gives an overview of aspects speciﬁc to web and mobile platforms .
HTTPS is the most widely deployed secure network protocol on the web and mobile .
It overlays HTTP on top of the TLS protocol to provide authentication of the server , and integrity and conﬁdentiality for data in transit .
While HTTPS offers mutual authentication of servers and clients based on X.509 certiﬁcates , the primary use is the authentication of the accessed server .
Similar to TLS , HTTPS protects HTTP trafﬁc against eavesdropping and tampering by preventing man-in-the-middle attacks .
Since HTTPS encapsulates HTTP trafﬁc , it protects URLs , HTTP header information including cookies and HTTP content against attackers .
However , it does not encrypt the IP addresses and port numbers of clients and servers .
While HTTPS can hide the information exchanged by clients and servers , it allows eavesdroppers to learn the top-level domains of the websites browsers that users visit , and to identify the backend servers that mobile apps communicate with .
Both web browsers and mobile apps authenticate HTTPS servers by verifying X.509 certiﬁcates signed by Certiﬁcate Authorities CAs .
Browsers and mobile apps come with a list of pre-installed certiﬁcate authorities or rely on a list of pre-installed CAs in the host operating system .
A pre-installed certiﬁcate authority list in modern browsers and on modern mobile platforms typically contains hundreds of CAs .
However , common reasons for warning messages are invalid certiﬁcates , certiﬁcates that were issued for a different hostname , network errors between the client and server and errors on the client such as misconﬁgured clocks [ 1274 ] .
Browsers use coloured indicators in the address bar to display the security information for a website .
CSS or JavaScript ﬁles ) over an HTTP connection6 and sites that use an invalid certiﬁcate but for which the user clicked through a warning are displayed as insecure .
In contrast , users of mobile , non-browser apps can not easily verify whether an application uses the secure HTTPS protocol with a valid certiﬁcate .
No visual security indicators similar to those used in browsers are available .
Instead , users have to trust application developers to take all the necessary security measures for HTTPS connections .
As of 2019 , most of the popular websites support HTTPS , and the majority of connections from clients to servers in the web and mobile applications use HTTPS to protect their users against man-in-the-middle attacks .
To further increase the adoption of HTTPS , server operators are encouraged to use HTTPS for all connections and deploy HTTP Strict Transport Security ( HSTS ) [ 1276 ] .
Additionally , browser users can install extensions and plugins to rewrite insecure HTTP URLs to secure HTTPS URLs [ 1277 ] if possible , and mobile application frameworks make HTTPS the default network protocol for HTTP connections .
Rogue Certiﬁcate Authorities and Certiﬁcate Transparency The web PKI allows every trusted root certiﬁcate authority to issue certiﬁcates for any domain .
While this allows website operators to freely choose a CA for their website , in the past some CAs have issued fraudulent certiﬁcates for malicious purposes .
Nobody has been charged for the attack .
Certiﬁcate transparency provides a tamper proof data structure and monitors all certiﬁcate issuance processes of participating CAs .
While it can not prevent fraudulent certiﬁcate issuance , it improves the chances of detection .
Clients can verify the correct operation of the certiﬁcate transparency providers and should only connect to websites that use X.509 certiﬁcates that include a signed certiﬁcate timestamp .
Certiﬁcate transparency is supported by most major certiﬁcate authorities and browser vendors .
KA Web & Mobile Security | October 2019 Page 497 The Cyber Security Body Of Knowledge www.cybok.org 15.2.7 Authentication Authentication in the web and on mobile platforms is an important security mechanism designed to enable human users to assert their identity to web applications , mobile devices or mobile apps .
Authentication goes hand in hand with authorisation which describes the speciﬁcation of access privileges to resources .
The speciﬁed access privileges are later on used to grant or deny access to resources for authenticated users .
This section will not give a detailed overview of authentication and authorisation concepts ( cf .
In the HTTP context , authentication generally refers to the concept of verifying the identity of a client to a server , e. g. , by requiring the client to provide some pre-established secrets such as username and password with a request .
This section highlights two widely used authentication methods on the web , Basic HTTP authentication , and the more frequently used HTTP Form-based HTTP authentication .
It does not rely on session identiﬁers or cookie data .
Nor does the Basic HTTP authentication scheme require the setup of dedicated login pages , as all major browsers provide an integrated login form .
An example exchange between server and client is shown in Figure 15.5 .
The Basic authentication scheme is not secure , as the credentials are transmitted after a simple Base64 encoding , which is trivial to reverse .
Hence , login credentials are transmitted in plain text across the network , which allows attackers or network observers to easily steal the credentials .
Therefore , Basic HTTP authentication should not be used without additional enhancements that ensure conﬁdentiality and integrity such as HTTPS .
Form-based HTTP authentication in which websites use a form to collect login credentials is a widely prevalent form of authentication in modern web and mobile applications .
For this KA Web & Mobile Security | October 2019 Page 498 The Cyber Security Body Of Knowledge www.cybok.org scheme , an unauthenticated client trying to access restricted content is shown an HTMLbased web form that prompts for their credentials .
The server validates the form data and authenticates the client on successful validation .
Similar to Basic authentication , Form-based authentication exposes user credentials in plain text if not protected by HTTPS .
15.2.7.2 Mobile Device Authentication Mobile devices deploy a variety of authentication mechanisms to unlock devices , grant users access , and protect their data from illegitimate access .
The most common mechanisms for mobile device authentication are passwords , PINs , patterns and biometric features .
Users can use common alphanumeric passwords , including special characters .
Modern mobile devices allow users to authenticate using biometric features , including ﬁngerprint and facial recognition .
They found empirical evidence that users tend to choose biased patterns , e. g. , users typically started in the upper left corner and selected three-point long straight lines .
In addition to users choosing weak unlock patterns , the mechanism is vulnerable to shoulder surﬁng attacks ( see Section 15.3.3 ) .
, IDs of items added to the shopping cart in an online shop ) is stored by the client .
Cookies allow clients and servers to include their unique session identiﬁers in each HTTP request-response , avoiding the need for repeated authentication .
Cookie-based authentication allows clients to re-establish sessions every time they send requests to the server with a valid cookie .
Hijackers who post valid session cookies can connect to the attacked server with the privileges of the authenticated victim .
Cookies can also be used to track users across multiple sessions by providers .
15.2.9 Passwords and Alternatives Passwords are the most widely deployed mechanism to let users authenticate to websites and mobile applications and protect their sensitive information against illegitimate access online .
They are the dominant method for user authentication due to their low cost , deployability , convenience and good usability .
Since humans tend to struggle memorising many different complicated passwords , they often choose weak passwords and re-use the same password for multiple accounts .
Weak passwords can easily be guessed by attackers ofﬂine or online .
One compromised online account results in all other accounts protected with the same password as vulnerable .
While password guidelines in the past frequently recommended the use of complex passwords , current guidelines state that requiring complex passwords actually weakens password security and advise against policies that include password complexity [ 1285 , 1286 ] .
Online service providers deploy various countermeasures to address security issues with weak passwords and password re-use : KA Web & Mobile Security | October 2019 Page 500 The Cyber Security Body Of Knowledge www.cybok.org 15.2.9.1 Password Policies Password policies are rule sets to encourage users to choose stronger passwords .
Some password policies also address the memorability issue .
15.2.9.2 Password Strength Meters Password Strength Meters ( PSMs ) pursue the same goal as password policies and aim to encourage the choice of stronger passwords .
Hence , service providers can use extensions to simple passwords to increase authentication security .
15.2.9.3 Password Managers Password managers can help users generate , store and retrieve strong passwords .
Strong passwords are generated and stored using secure random number generators and secure encryption .
They come as locally installable applications , online services or local hardware devices .
While they can help users use more diverse and stronger passwords , their effect on overall password security is limited due to usability issues [ 1291 ] .
So in addition to a password , users need to have their device at hand to receive a one-time token to authenticate successfully .
WebAuthn is supported by most modern webbrowsers and mobile operating systems .
OAuth uses secure tokens instead of requiring users to provide login credentials such as usernames and passwords .
On behalf of their users , OAuth service providers provide access tokens that authorise speciﬁc account information to be shared with third-party applications .
Large providers of online services such as Google or Facebook can act as identity providers to authenticate users , thus helping users to reduce the number of login credentials and accounts .
While such protocols aim to provide improved security , the correct and secure implementation of such complex protocols was shown to be error-prone and might allow malicious users to run impersonation attacks [ 1296 ] .
15.2.10 Frequent Software Updates Frequent software updates are a fundamental security measure and particularly crucial for web and mobile platforms .
This section discusses the different components in the web and mobile ecosystems that require regular updates , the different update strategies , and their pros and cons .
Traditionally , browser and mobile device updates required their users to install updates manually whenever new versions were available .
Users had to keep an eye on software updates and were responsible for downloading and installing new releases .
This approach was error-prone and resulted in many outdated and insecure deployed software components .
Most of the critical components on modern web and mobile platforms have short release cycles .
Web browsers , including Google Chrome and Mozilla Firefox , implement auto-update features and frequently push new versions and security patches to their users .
Mobile platforms also provide automatic application updates for third-party apps .
While this approach generally results in quicker updates and the timely distribution of security patches , automatic mobile application updates are only enabled by default for devices connected to WiFi .
Mobile operating system update behaviour heavily depends on the platform .
In particular , many non-Google Android devices suffer from outdated and insecure operating system versions .
Overall , modern web and mobile platforms recognised the disadvantages of non-automatic KA Web & Mobile Security | October 2019 Page 502 The Cyber Security Body Of Knowledge www.cybok.org software updates and now provide automatic or semi-automatic platform or application updates in most cases .
Outdated Third Party Libraries While frequent software updates are crucial in general , updates of third-party libraries is a particularly important security measure for software developers who need to patch their own code and distribute updates , while also tracking vulnerabilities in libraries they use and updating them for better security .
[ 1298 ] conducted a measurement study of third-party library update frequencies in Android applications and found that a signiﬁcant number of developers use outdated libraries , exposing their users to security issues in the affected third party libraries .
[ 1299 ] conducted a similar study for JavaScript libraries in web applications and also found many websites that include outdated and vulnerable libraries .
It discusses issues in both modern web browsers and mobile devices .
The illustrated security issues highlight aspects that have dominated security discussions in recent years .
We focus on attacks that exploit weaknesses in the interaction between users and web browsers and mobile apps .
We then discuss challenges resulting from the trend of storing more and more information on the client instead of the server .
Finally , we discuss physical attacks that do not focus on exploiting software or human vulnerabilities , but exploit weak points in mobile devices .
15.3.1 Phishing & Clickjacking This section presents two prevalent issues that exploit user interface weaknesses of both web and mobile clients .
Phishing and clickjacking rely on issues humans have with properly verifying URLs and the dynamic content of rendered HTML documents .
15.3.1.1 Phishing Phishing attacks are fraudulent attacks that aim to steal sensitive information , including login credentials and credit card numbers from victims [ 1302 ] .
Common types of phishing attacks use email , websites or mobile devices to deceive victims .
Attackers disguise themselves as trustworthy parties and send fake emails , show fake websites or send fake SMS or instant messages .
Attackers can use successfully stolen login credentials or credit card numbers to impersonate victims and access important online accounts .
Successful phishing attacks may result in identity theft or loss of money .
Attackers commonly forge websites that appear legitimate to trick users into believing they are interacting with the genuine website .
To initiate a phishing attack , attackers plant manipulated links on users via email , a website or any other electronic communication .
The manipulated link leads to a forged website that appears to belong to the genuine organisation behind the website in question .
Attackers often spoof online social media , online banking or electronic payment provider websites .
They trick victims into following manipulated links using misspelled URLs , subdomains or homograph attacks .
To make forged websites look even more authentic , some phishers alter a browser ’ s address bar by replacing the original address bar with a picture of the legitimate URL or by replacing the original address bar with a new one .
Address bar manipulation attacks require the use of JavaScript commands .
Such attacks exploit that users can not easily distinguish different character encodings .
Attacks that involve manipulated URLs and address bars are even harder to detect in mobile browsers since the address bar is not visible during regular browsing .
Website phishing is one of the most frequent attacks .
Therefore , common countermeasures are anti-phishing training and public awareness campaigns [ 1301 ] that try to sensitise users and teach them how to spot phishing URLs .
Google Chrome shows URLs using an encoding that exposes deceptive characters in IDN attacks 7 .
Attackers need to ﬁngerprint victim clients and exploit vulnerable software components on the client ’ s computer to plant the malware .
Detecting such attacks is an active research area and includes approaches such as anomaly or signature based malware detection [ 814 ] .
Clickjacking is also known as a user interface redress attack and belongs to the class of confused deputy attacks [ 1303 ] .
Attackers fool their victims using transparent or opaque layers over original websites .
While victims believe they have clicked on the overlay element , the original website element is clicked on .
Attackers can thus make their victims trigger arbitrary actions on the original website .
The attack website uses an iFrame to load the target website and can make use of the absolute positioning features of iFrames for correct visual alignment .
Thus , it is hard for victims to detect the attack elements over the original website .
Clickjacking attacks are particularly dangerous when victims have already logged in to an online account and visit their account settings website .
In those cases , an attacker can trick the victim into performing actions on a trusted site when the victim is already logged in .
Web browser users can disable JavaScript and iFrames to prevent clickjacking attacks .
In order to contain the impact of clickjacking attacks , users should log out of online accounts when leaving a website , although this could be impractical .
Websites can include JavaScript code to detect whether a website has been put into an iFrame and break out of the iFrame .
However , since users might have disabled JavaScript , this method is not reliable .
The X-FRAME-OPTIONS header can be set to DENY , which will prevent a website being loaded inside an iFrame .
Clickjacking attacks affect both desktop and mobile web browsers .
Phishing and Clickjacking on Mobile Devices Phishing and Clickjacking are not limited to browsers and the web .
Mobile application users are susceptible to both attacks .
[ 1315 ] ﬁnd that it is possible to trick users into an end-to-end phishing attack that allows attackers to gain full UI control by abusing Android ’ s Instant App feature and password managers to steal login credentials .
The attack allows for advanced clickjacking , keylogging , stealthy ﬁshing and silent phone unlocking .
15.3.2 Client Side Storage Client-side storage refers to areas that a browser or operating system provides to websites or mobile applications to read and write information .
Storage is local to the client and does not require server-side resources or an active Internet connection .
At the same time , malicious users may manipulate stored information .
This section describes common client-side storage areas and their protection mechanisms .
However , due to their simple design and limited capacity , cookies can not be used to store large or complex amounts of information .
As mentioned , the primary security issue with client-side storage mechanisms is that malicious users can manipulate them .
To guarantee integrity for sensitive information ( e. g. , session information ) , developers are advised to cryptographically sign the data stored on the client and verify it upon retrieval .
In addition to information integrity , a second important aspect of WebStorage and IndexedDB storage is that stored information is not automatically cleared after users leave a website .
15.3.2.2 Client Side Storage in Mobile Applications In mobile applications , handling client-side storage security also depends on the type of information and storage mechanism , e. g. , private storage of an application or public storage such as an SD card .
It is recommended that developers sign and encrypt sensitive information and apply proper user input sanitisation .
This is particularly relevant for shared storage such as SD-cards that do not use secure access control mechanisms .
Instead , proper access administration mechanisms are provided for storage areas that are private to an application .
Sensitive Information Leaks in Android Applications Enck et al .
Amongst other things , they found that a signiﬁcant number of apps leaked sensitive user information to publicly readable storage locations such as log ﬁles and the SD card .
[ 1317 ] discovered that some sensitive information leaks are made intentionally to pass sensitive information to another , collaborating and malicious app .
KA Web & Mobile Security | October 2019 Page 506 The Cyber Security Body Of Knowledge www.cybok.org 15.3.3 Physical Attacks Instead of attacking web or mobile applications ’ code , physical attacks aim to exploit bugs and weak points that result from using a device .
We focus on two representative examples below .
The main problem with entering sensitive unlock information through a touchscreen is the oily smudges that users ’ ﬁngers leave behind when unlocking a device .
The attacker can mount a shoulder surﬁng attack either directly by looking over the victim ’ s shoulder or from a longer range by using dedicated tools such as cameras or telescopes .
Shoulder surﬁng attacks are particularly dangerous for mobile device users when authenticating to the device or online services in public spaces such as trains , railways , and airports .
It provides details for common aspects of server security , including well-known vulnerabilities and mitigations .
The aspects discussed below are central for the web and mobile environments and dominated many of the security discussions in this area in the past .
15.4.1 Injection Vulnerabilities Injection attacks occur whenever applications suffer from insufﬁcient user input validation so that attackers can insert code into the control ﬂow of the application ( cf .
Due to inadequate sanitisation of user input , requests to a database or shell commands can be manipulated by an attacker .
Such attacks can leak or modify information stored in the database or issue commands on a system in ways developers or operators have not intended .
The main goal of injection attacks is to circumvent authentication and expose sensitive information such as login credentials , personally identiﬁable information , or valuable intellectual property of enterprises .
Injection vulnerabilities can be addressed by adequately sanitising attacker-controlled information and deploying proper access control policies .
The goal of input sanitisation is to ﬁlter KA Web & Mobile Security | October 2019 Page 507 The Cyber Security Body Of Knowledge www.cybok.org invalid and dangerous input .
Many web and mobile applications allow users to enter information through forms or URL parameters .
SQL injection occurs if such user input is not ﬁltered correctly for escape characters and then used to build SQL statements .
Enabling attackers to modify SQL statements can result in malicious access or manipulation of information stored in the database .
Example : SQL Injection attack The statement below illustrates the vulnerability .
A potential web application with the above SQL injection vulnerability could leak sensitive credit card information for all users of the application .
The consequences of the above SQL injection vulnerability might be directly visible to the attacker if all credit card details are listed on a results page .
However , the impact of an SQL injection can also be hidden and not visible to the attacker .
However , the impact of an attack might still be visible through observing information as part of a true-false response of the database .
Attackers might be able to determine the true-false response based on the web application response and the way the web site is displayed .
second order In contrast to the previous types of SQL injection attacks , second order attacks occur whenever user submitted input is stored in the database for later use .
Other parts of the application then rely on the stored user input without escaping or ﬁltering it properly .
Instead of embedding user input into raw SQL statements ( see above ) , prepared statements use placeholder 8 variables to process user input .
Placeholder variables are limited to store values of a given type and prohibit the input of arbitrary SQL code fragments .
SQL injections attacks would result in invalid parameter values in most cases and not work as intended by an attacker .
Also , prepared statements are supported by many web application development frameworks at the coding level using Object Relational Mapping ( ORM ) interfaces .
KA Web & Mobile Security | October 2019 Page 508 The Cyber Security Body Of Knowledge www.cybok.org ORMs do not require developers to write SQL queries themselves but generate database statements from code .
While prepared statements are an effective mitigation mechanism , a further straightforward way is to escape characters in user input that have a special meaning in SQL statements .
However , this approach is error-prone , and many applications that apply some form of SQL escaping are still vulnerable to SQL injection attacks .
The reasons for the mistakes are often incomplete lists of characters that require escaping .
15.4.1.2 Command Injections This type of injection attack affects vulnerable applications that can be exploited to execute arbitrary commands on the host operating system of a web application [ 1328 ] .
Similar to SQL injection attacks , command injections are mostly possible due to insufﬁcient user input validation .
Vulnerable commands usually run with the same privileges as the host application .
An example of a command injection attack is a web application that converts user-provided images using a vulnerable image command line program .
Providing malicious input ( e. g. , a ﬁlename or a specially crafted support graphic that includes malicious code ) might allow attackers to exploit insufﬁcient input validation and extend the original command or run additional system commands .
A mitigation for command injection attacks is to construct the command strings , including all parameters in a safe way that does not allow attackers to exploit malicious string input .
In addition to proper input validation due to escaping , following the principle of least-privilege and restricting the privileges of system commands and the calling application is recommended .
The number of callable system commands should be limited by using string literals instead of raw user-supplied strings .
Instead , the use of API calls in the respective development framework is recommended .
15.4.1.3 User Uploaded Files Files provided by users such as images or PDFs have to be handled with care .
Example : Online Social Network An example application could be an online social network that allows users to upload their avatar picture .
Without proper mitigation techniques in place , the web application itself might be vulnerable .
Accessing that ﬁle might prompt the server to process it as an executable PHP ﬁle .
This vulnerability would allow attackers to both execute code on the server with the permissions of the PHP process and also control the content served to other users of the application .
looking for malware in uploaded ﬁles .
Filenames and paths should be constructed using string literals instead of raw strings and proper mime-types for HTTP responses used whenever possible .
Another successful mitigation for the above issue is to serve ﬁles from a different domain .
If the domain is not a subdomain of the original domain , the SOP 15.2.4.2 prevents cookies and other critical information from being accessible to the malicious ﬁle .
Additionally , JavaScript and HTML ﬁles are protected by the SOP as well .
A vulnerable web application might then access the maliciously crafted ﬁle path and instead of loading a benign ﬁle , read and send the content of the attacker-chosen ﬁle and e. g. leak login credentials in the /etc/shadow ﬁle .
In addition to sanitisation of ﬁle path parameters such as leading / and .. in user input , the application of the least privilege principle is recommended .
A web application should be executed with minimal privileges and so that it can not access sensitive ﬁles .
They can occur whenever malicious website users are able to submit client scripts to web applications that redistribute the malicious code to other end-users .
Common examples of websites that are vulnerable to XSS attacks are message forums that receive user content and show it to other users .
The primary root cause for XSS vulnerabilities is web applications that do not deploy effective input validation mechanisms .
Without proper user input validation , a malicious JavaScript previously provided by one user , might be distributed to other users and manipulate the website they are visiting or steal sensitive information .
In an XSS attack , the client browser can not detect the malicious code , since it is sent from the original remote host , i. e. same-origin-policy based security measures are ineffective .
We distinguish two types of XSS attacks : stored In a stored XSS attack the malicious script is permanently stored on the target server ( e. g. in a database ) and distributed to the victims whenever they request the stored script for example as part of a comment in a message forum .
Stored XSS attacks are also called permanent or Type-I XSS .
reﬂected In a reﬂected XSS attack , the malicious script is not permanently stored on the target server , but reﬂected by the server to the victims .
Malicious scripts in reﬂected attacks are distributed through different channels .
The link contains the script and clicking the link executes the malicious script in the website ’ s script execution context .
Preventing both types of XSS attacks requires rigorous user input validation and escaping by the server .
The most effective means of input validation is a whitelist approach , which denies any input that is not explicitly allowed .
For proper and secure entity encoding , the use of a KA Web & Mobile Security | October 2019 Page 510 The Cyber Security Body Of Knowledge www.cybok.org security encoding library is recommended , since writing encoders is very difﬁcult and code review in combination with the use of static code analysis tools is also valuable .
Since eliminating XSS vulnerabilities entirely due to user input sanitization is hard , different approaches are discussed in the literature .
A promising approach is the randomisation of HTML tags and attributes .
Web applications randomise their order so clients can distinguish between benign and trusted content and potentially untrusted malicious content .
As long as an attacker does not know the randomisation mapping , clients can successfully distinguish trusted from untrusted scripts [ 1329 ] .
The malicious request is executed on behalf of the user and inherits their identity and permissions .
CSRF attacks are so dangerous because most requests to remote servers include credentials and session information associated with a user ’ s identity , including session cookies .
Authenticated users are particularly attractive victims for attackers since it can be hard for remote servers to distinguish between benign and malicious requests as long as they are submitted from the victim ’ s machine .
CSRF attacks do not easily allow attackers to access the server response for the malicious request .
Therefore , the main goal of a CSRF attack is to trick victims into submitting state-changing requests to remote servers .
Attractive targets are requests that change the victim ’ s credentials or purchase something .
Example : Online Banking In the following online banking scenario Alice wishes to transfer 50 EUR to Bob using an online banking website that is vulnerable to a CSRF attack .
The second step for successful CSRF attack requires the attacker to trick Alice into sending the malicious request with her web browser , e. g. by sending a SPAM email containing the request which Alice subsequently clicks on .
Many misconceptions lead to ineffective countermeasures .
CSRF attacks can not be prevented by using secret cookies because all cookies are sent from a victim to the remote server .
Also , the use of HTTPS is ineffective as long as the malicious request is sent from the victim , because the protocol does not matter and the use of POST requests for sensitive information is insufﬁcient since attackers can craft malicious HTML forms with hidden ﬁelds .
To effectively prevent CSRF attacks , it is recommended to include randomised tokens in sensitive requests , e. g. , by adding them to the request headers .
The tokens must be unique per session and generated with a secure random number generator to prevent attackers from predicting them .
Servers must not accept requests from authenticated clients that do not include a valid token .
Overall , web application security highly depends on the security of each of the involved components .
A single insecure component is often enough to allow an attacker access to the web application and further escalate their attack from the inside .
This is why deploying and maintaining a secure web application requires more than focusing on the code of the app itself .
Every component of the web application stack needs to be conﬁgured securely and kept up to date ( see Section 15.2.10 ) .
Heartbleed was a vulnerability in the widely used OpenSSL library and caused web servers to leak information stored in the webservers ’ memory .
To ﬁx affected systems , administrators had to update their OpenSSL libraries as quickly as possible and ideally also revoke certiﬁcates and prompt users to change their passwords .
Proper ﬁrewall and load balancer conﬁgurations serve as examples : 15.4.2.1 Firewall To protect a webserver , a ﬁrewall should be conﬁgured to only allow access from outside where access is needed .
Access should be limited to ports like 80 and 443 for HTTP requests via the Internet and restricting system conﬁguration ports for SSH and alike to the internal network ( cf .
Load balancers control HTTP trafﬁc between servers and clients and provide additional access control for web application resources .
They can be used to direct requests and responses to different web servers or ports , balance trafﬁc load between multiple web servers and protect areas of a website with additional access control mechanisms .
The most common approach for controlling access is the use of .htaccess ﬁles .
They can restrict access to content on the original web server and instruct load balancers to require additional authentication .
Load balancers can also serve for rate limiting purposes .
They can limit request size , allowed request methods and paths or deﬁne timeouts .
The main use of rate-limiting is to reduce the potentially negative impact of denial of service attacks on a web server and prevent users from spamming systems , as well as restrict and prevent unexpected behavior .
Additionally , load balancers can be used to provide secure TLS connections for web applications .
When managing TLS , load balancers serve as a network connection endpoint for the TLS encryption and either establish new TLS connections to the application service or connect to the web application server using plain HTTP .
If the web application server is not hosted on the same machine , using plain network connections might leak information to the KA Web & Mobile Security | October 2019 Page 512 The Cyber Security Body Of Knowledge www.cybok.org internal network .
However , if the web application server does not provide HTTPS itself , using a load balancer as a TLS endpoint increases security .
HTTPS Misconﬁgurations One cornerstone of web and mobile security is the correct and secure conﬁguration of HTTPS on web servers .
[ 1330 ] found that a signiﬁcant number of popular websites deploy invalid certiﬁcates with incomplete certiﬁcate chains , issued for the wrong hostname or expired lifetime .
[ 1331 ] conﬁrmed these ﬁndings and also asked website operators for the reasons for deploying invalid certiﬁcates .
Most operators were not aware of using an invalid certiﬁcate or used one on purpose because they did not trust the web PKI .
15.4.2.3 Databases Similar to load balancers and ﬁrewalls , many web applications include databases to store user information permanently .
Often , databases are operated as an additional service that is hosted on another server .
The application server interacts with the database through libraries and APIs .
It is important to prevent injection vulnerabilities on the server .
Additionally , errors in the implementation of database libraries or coarse permissions required by the application can lead to vulnerabilities .
To reduce the attack vector , most database systems provide user management , to limit user privileges to create , read , delete or modify entries in tables and across databases .
In this way one database per application can be created and particular users with read-only permissions can be used by the application server .
An important aspect of increasing database security is the decision on how to store data .
Encrypting data before storage in the database can help .
However , especially for passwords or other information that only needs to be compared for equality , hashing before storage can tremendously increase security .
Password Leaks Developers tend to store plain passwords , credit card information or other sensitive information in databases instead of encrypting or hashing them ( cf .
This Knowledge Area emphasised an intersectional approach by exploring security concepts and mechanisms that can be found in both the web and the mobile worlds .
We showed that due to the ubiquitous availability and use of web and mobile applications and devices , paying attention to their security issues is crucial for overall information security .
We discussed web technologies that build the core of both web and mobile security , outlined their characteristics and illustrated how they are different from other ecosystems .
In particular , this Knowledge Area has focused on attacks and defences that were prevalent in web and mobile clients and servers and that dominated discussions in recent years .
KA Web & Mobile Security | October 2019 Page 514 The Cyber Security Body Of Knowledge www.cybok.org The OWASP Project & Wiki The Open Web Application Security Project ( OWASP ) is an international not-for-proﬁt charitable organisation providing practical information about application and web security .
It funds many projects including surveys like the OWASP TOP 10 , books , CTFs and a wiki containing in-depth descriptions , recommendations and checklists for vulnerabilities and security measurements .
Mozilla Developer Network An all-encompassing resource provided by Mozilla covering open web standards , including security advice and cross platform behaviour for Javascript APIs , as well as a HTML and CSS speciﬁcations .
It can be found at https : //developer.mozilla.org Android Developers The ofﬁcial documentation for the Android development ecosystem , including security advice for client side storage , webviews , permissions , Android databases and network connections .
It also includes information for outdated operating system versions and the Google Play Update process .
Available at https : //developer.android.com KA Web & Mobile Security | October 2019 Page 515 The Cyber Security Body Of Knowledge www.cybok.org KA Web & Mobile Security | October 2019 Page 516 Chapter 16 Secure Software Lifecycle Laurie Williams North Carolina State University 517 The Cyber Security Body Of Knowledge www.cybok.org INTRODUCTION The purpose of this Secure Software Lifecycle knowledge area is to provide an overview of software development processes for implementing secure software from the design of the software to the operational use of the software .
This implementation may involve new coding as well as the incorporation of third party libraries and components .
The goal of this overview is for use in academic courses in the area of software security ; and to guide industry professionals who would like to use a secure software lifecycle .
The Software Security Knowledge Area ( Chapter 14 ) provides a structured overview of secure software development and coding and the known categories of software implementation vulnerabilities and of techniques that can be used to prevent or detect such vulnerabilities or to mitigate their exploitation .
By contrast , this Secure Software Lifecycle Knowledge Area focuses on the components of a comprehensive software development process to prevent and detect security defects and to respond in the event of an exploit .
This Knowledge Area will begin with a history of secure software lifecycle models .
Section 2 provides examples of three prescriptive secure software lifecycle processes ; the Microsoft Secure Development Lifecycle , Touchpoints , and SAFECode .
[ 1342 ] With this approach , security is assessed when the product is complete via penetration testing by attempting known attacks ; or vulnerabilities are discovered post release when organisations are victims of an attack on deployed software .
In either case , organisations then react by ﬁnding and ﬁxing the vulnerability via a security patch .
The following shortcomings are likely to be more prevalent with a predominantly reactive approach to cyber security : • Breaches are costly .
Breaches were the least expensive in India and Brazil , but these countries still spent an average of 1.8 million and 1.2 million US dollars per breach , respectively .
Loss of reputation caused by a breach is difﬁcult to quantify .
• Attackers can ﬁnd and exploit vulnerabilities without being noticed .
Vulnerability patches are considered urgent and can be rushed out , potentially introducing new problems to a system .
The new vulnerability allowed attackers to read kernel memory much faster and to write their own memory , and could allow an attacker to access every user-level computing process running on a machine .
Users and system administrators may be reluctant to apply security patches .
Once a vulnerability is publicly reported , attackers formulate a new mechanism to exploit the vulnerability with the knowledge that many organisations will not adopt the ﬁx .
In 1998 , McGraw [ 1342 ] advocated moving beyond the penetrate and patch approach based upon his work on a DARPA-funded research effort investigating the application of software engineering to the assessment of software vulnerabilities .
He contended that proactive rigorous software analysis should play an increasingly important role in assessing and preventing vulnerabilities in applications based upon the well-known fact that security violations occur because of errors in software design and coding .
In 2002 , Viega and McGraw published the ﬁrst book on developing secure programs , Building Secure Software [ 1238 ] , with a focus on preventing the injection of vulnerabilities and reducing security risk through an integration of security into a software development process .
In the early 2000s , attackers became more aggressive , and Microsoft was a focus of this aggression with exposure of security weaknesses in their products , particularly the Internet Information Services ( IIS ) .
Gartner , a leading research and advisory company who seldom advises its clients to steer clear of speciﬁc software , advised companies to stop using IIS .
The memo was also widely circulated on the Internet .
An excerpt of the memo deﬁnes Trustworthy Computing : ‘ Trustworthy Computing is the highest priority for all the work we are doing .
We must lead the industry to a whole new level of Trustworthiness in computing ... Trustworthy Computing is computing that is as available , reliable and secure as electricity , water services and telephony ’ .
The Trustworthy Computing memo caused a shift in the company .
In 2003 , Microsoft employees Howard and Le Blanc [ 1345 ] publicly published a second edition of a book on writing secure code to prevent vulnerabilities , to detect design ﬂaws and implementation bugs , and to improve test code and documentation .
The ﬁrst edition had been required reading for all members of the Windows team during the Push .
True to Gates ’ original intent , the Microsoft SDL provided the foundation for the information technology industry by providing the ﬁrst documented comprehensive and prescriptive lifecycle .
As discussed in the rest of this knowledge area , organisations have built upon the foundation set forth by Microsoft and by Viega and McGraw [ 1238 , 1342 ] .
These processes work software security deeply into the full product development process and incorporate people and technology to tackle and prevent software security issues .
This section will provide information on three prominent secure software lifecycle processes and then reﬂect on the commonalities between them in Table 16.1 .
16.2.1 Secure Software Lifecycle Processes Three exemplar prescriptive secure software lifecycle processes are summarised in this section .
The processes are prescriptive in that they explicitly recommend software practices .
The three processes were chosen because the practices of these processes are integrated and cover a broad spectrum of the lifecycle phases , from software requirements to release/deployment and software maintenance .
As such , the practices span the prevention of security defects , the detection of security defects , and the mitigation of security defects once a product is in the ﬁeld .
The three were also chosen due to their maturity in terms of the number of years they have existed and in terms of their widespread acceptance in the industry .
Practitioners should consider incorporating practices from each of these processes into their own secure software process .
Since that time , Microsoft has continued to evolve their SDL and to provide up-to-date resources to the community [ 1347 ] , including an increased focus on compliance requirements that are being imposed on the industry .
For each of the practices , techniques for implementing the practice may be mentioned though the SDL does not prescribe the speciﬁc technique .
A range of professionals , such as developers , service engineers , program managers , product managers , and project managers , participate in the development of secure products while still addressing business needs and delivering user value .
Software developers and architects must understand technical approaches for preventing and detecting vulnerabilities .
The entire development organisation should be cognisant of the attacker ’ s perspective , goals , and techniques ; and of the business implications of not building secure products .
Often , the formal education of these professionals does not include cyber security .
Additionally , attack vectors , security tools , secure programming languages , and experiences are constantly evolving , so knowledge and course material must be refreshed .
Ongoing cyber security training is essential for software organisations .
Security requirements should be deﬁned during the initial design and planning phases .
Factors that inﬂuence these requirements include the speciﬁc functional requirements of the system , the legal and industry compliance requirements , internal and external standards , previous security incidents , and known threats .
Techniques have been developed for systematically developing security requirements .
An obstacle negates existing goals of the system .
Security requirements must be continually updated to reﬂect changes in required functionality , standards , and the threat landscape .
The management team should understand and be held accountable for minimum acceptable levels of security using security metrics [ 1349 ] .
A subset of these metrics may be set as Key Performance Indicators ( KPIs ) for management reporting .
Defect tracking should clearly label security defects and security work items as such to allow for accurate prioritisation , risk management , tracking , and reporting of security work .
Teams should consider the motivations of their adversaries and the strengths and weaknesses of systems to defend against the associated threat scenarios .
Spooﬁng threats allow an attacker to pose as another user or allow a rogue server to pose as a valid server .
Data tampering threats involves malicious modiﬁcation of data .
Repudiation threats are associated with users who deny performing an action without other parties having any way to prove otherwise .
Information disclosure threats involve the exposure of information to individuals who are not supposed to have access to it .
A Denial of Service ( DoS ) attack denies service to valid users by making the system unavailable or unusable .
An unprivileged user gains privileged access and thereby has sufﬁcient access to compromise or destroy the system .
Threat modelling aids the team in enumerating threats , so that the system design can be fortiﬁed and security features can be selected .
In addition to STRIDE , other models exist to formulate threat models , such as 12 methods6 , including attack trees [ 1363 ] which are conceptual diagrams of threats on systems and possible attacks to reach those threats .
Additionally , the architecture and design must be resistant to known threats in the intended operational environment .
Keep the design of the system as simple and small as possible .
Base access decisions on permissions rather than exclusion ; the default condition is lack of access and the protection scheme identiﬁes conditions under which access is permitted .
Design a security mechanism so that a failure will follow the same execution path as disallowing the operation .
Every access to every object must be checked for authorisation .
The design should not depend upon the ignorance of attackers but rather on the possession of keys or passwords .
A protection mechanism that requires two keys to unlock is more robust than one that requires a single key when two or more decisions must be made before access should be granted .
Every program and every user should operate using the least set of privileges necessary to complete the job .
Minimise the amount of mechanisms common to more than one user and depended on by all users .
The human interface should be designed for ease of use so that users routinely and automatically apply the mechanisms correctly and securely .
Two other important secure design principles include the following : • Defense in depth .
Provide multiple layers of security controls to provide redundancy in the event a security breach .
The software security must be designed for change , such as for security patches and security property changes .
Design requirements also involve the selection of security features , such as cryptography , authentication and logging to reduce the risks identiﬁed through threat modelling .
Teams also take actions to reduce the attack surface of their system design .
In 2014 , the IEEE Center for Secure Design [ 1351 ] enumerated the top ten security design ﬂaws and provided guidelines on techniques for avoiding them .
The use of cryptography is an important design feature for a system to ensure security- and privacy-sensitive data is protected from unintended disclosure or alteration when it is transmitted or stored .
However , an incorrect choice in the use of cryptography can render the intended protection weak or ineffective .
Experts should be consulted in the use of clear encryption standards that provide speciﬁcs on every element of the encryption implementation and on the use of only properly vetted encryption libraries .
Systems should be designed to allow the encryption libraries to be easily replaced , if needed , in the event the library is broken by an attacker , such as was done to the Data Encryption Standard ( DES ) through ’ Deep Crack ’ 9 , a brute force search of every possible key as designed by Paul Kocher , president of Cryptography Research .
The vast majority of software projects are built using proprietary and open-source third-party components .
Each of these components can have vulnerabilities upon adoption or in the future .
Freely available and proprietary tools can be used to identify project component dependencies and to check if there are any known , publicly disclosed , vulnerabilities in these components .
An organisation should publish a list of approved tools and their associated security checks and settings such as compiler/linker options and warnings .
Engineers should use the latest version of these tools , such as compiler versions , and take advantage of new security analysis functionality and protections .
Often , the resultant software must be backward compatible with previous versions .
SAST tools can be used for an automated security code review to ﬁnd instances of insecure coding patterns and to help ensure that secure coding policies are being followed .
SAST can be integrated into the commit and deployment pipeline as a check-in gate to identify vulnerabilities each time the software is built or packaged .
For increased efﬁciency , SAST tools can integrate into 9 https : //w2.eff.org/Privacy/Crypto/Crypto_misc/DESCracker/HTML/19980716_eff_des_faq.html KA Secure Software Lifecycle | October 2019 Page 524 The Cyber Security Body Of Knowledge www.cybok.org the developer environment and be run by the developer during coding .
Some SAST tools spot certain implementation bugs , such as the existence of unsafe or other banned functions and automatically replace with ( or suggest ) safer alternatives as the developer is actively coding .
DAST performs run-time veriﬁcation of compiled or packaged software to check functionality that is only apparent when all components are integrated and running .
DAST often involves the use of a suite of prebuilt attacks and malformed strings that can detect memory corruption , user privilege issues , injection attacks , and other critical security problems .
DAST tools may employ fuzzing , an automated technique of inputting known invalid and unexpected test cases at an application , often in large volume .
Similar to SAST , DAST can be run by the developer and/or integrated into the build and deployment pipeline as a check-in gate .
DAST can be considered to be automated penetration testing .
Manual penetration testing is black box testing of a running system to simulate the actions of an attacker .
Penetration testing is often performed by skilled security professionals , who can be internal to an organisation or consultants , opportunistically simulating the actions of a hacker .
The objective of a penetration test is to uncover any form of vulnerability - from small implementation bugs to major design ﬂaws resulting from coding errors , system conﬁguration faults , design ﬂaws or other operational deployment weaknesses .
Tests should attempt both unauthorised misuse of and access to target assets and violations of the assumptions .
Penetration testers can be referred to as white hat hackers or ethical hackers .
In the penetration and patch model , penetration testing was the only line of security analysis prior to deploying a system .
The plan should include who to contact in case of a security emergency , establish the protocol for efﬁcient vulnerability mitigation , for customer response and communication , and for the rapid deployment of a ﬁx .
The IRP should include plans for code inherited from other groups within the organisation and for third-party code .
The IRP should be tested before it is needed .
Lessons learned through responses to actual attack should be factored back into the SDL .
McGraw uses the term touchpoint to refer to software security best practices which can be incorporated into a secure software lifecycle .
Implementation bugs are localized errors , such as buffer overﬂow and input validation errors , in a single piece of code , making spotting and comprehension easier .
Design ﬂaws are systemic problems at the design level of the code , such as error-handling and recovery systems that fail in an insecure fashion or object-sharing systems that mistakenly include transitive trust issues [ 1346 ] .
The seven touchpoints help to prevent and detect both bugs and ﬂaws .
These seven touchpoints are described below and are provided in order of effectiveness based upon McGraw ’ s experience with the utility of each practice over many years , hence prescriptive : 1 .
Code review is used to detect implementation bugs .
Manual code review may be used , but requires that the auditors are knowledgeable about security vulnerabilities before they can rigorously examine the code .
the use of static analysis tools or SAST ) has been shown to be effective and can be used by engineers that do not have expert security knowledge .
Designers and architects provide a high-level view of the target system and documentation for assumptions , and identify possible attacks .
Through architectural risk analysis , security analysts uncover and rank architectural and design ﬂaws so mitigation can begin .
For example , risk analysis may identify a possible attack type , such as the ability for data to be intercepted and read .
This identiﬁcation would prompt the designers to look at all their code ’ s trafﬁcs ﬂows to see if interception was a worry , and whether adequate protection ( i.e .
That review that the analysis prompted is what uncovers design ﬂaws , such as sensitive data is transported in the clear .
No system can be perfectly secure , so risk analysis must be used to prioritise security efforts and to link system-level concerns to probability and impact measures that matter to the business building the software .
Risk exposure is computed by multiplying the probability of occurrence of an adverse event by the cost associated with that event [ 1367 ] .
McGraw proposes three basic steps for architectural risk analysis : • Attack resistance analysis .
Attack resistance analysis uses a checklist/systematic approach of considering each system component relative to known threats , as is done in Microsoft threat modelling discussed in Section 2.1.1 bullet 4 .
Information 11 http : //nvd.nist.gov KA Secure Software Lifecycle | October 2019 Page 526 The Cyber Security Body Of Knowledge www.cybok.org about known attacks and attack patterns are used during the analysis , identifying risks in the architecture and understanding the viability of known attacks .
Threat modelling with the incorporation of STRIDE-based attacks , as discussed in Section 2.1.1 bullet 4 , is an example process for performing attack resistance analysis .
Ambiguity analysis is used to capture the creative activity required to discover new risks .
Ambiguity analysis requires two or more experienced analysts who carry out separate analysis activities in parallel on the same system .
Through unifying the understanding of multiple analysis , disagreements between the analysts can uncover ambiguity , inconsistency and new ﬂaws .
The idea is to understand the assumptions being made about third-party software and what will happen when those assumptions fail .
For web applications , testing of security functionality can be guided by the OWASP Application Security Verﬁcation Standard ( ASVS ) Project12 open standard for testing application technical security controls .
ASVS also provides developers with a list of requirements for secure development .
Guiding tests with knowledge of the software architecture and construction , common attacks , and the attacker ’ s mindset is extremely important .
Using the results of architectural risk analysis , the tester can properly focus on areas of code where an attack is likely to succeed .
The difference between risk-based testing and penetration testing is the level of the approach and the timing of the testing .
Penetration testing is done when the software is complete and installed in an operational environment .
Risk-based security testing can begin before the software is complete and even pre-integration , including the use of white box unit tests and stubs .
The two are similar in that they both should be guided by risk analysis , abuse cases and functional security requirements .
For each bad actor , the analyst creates one or more abuse case ( s ) for the functionality the bad actor desires from the system .
The analyst then considers the interaction between the use cases and the abuse cases to fortify the system .
This abuse case threatens the use case .
To prevent the theft , a new use case ’ lock the car ’ can be added to mitigate the abuse case and fortify the system .
Human error is responsible for a large number of breaches .
System analysts should also consider actions by benevolent users , such as being the victim of a phishing attack , that result in a security breach .
These actions can be considered misuse cases [ 1355 ] and should be analysed similarly to abuse cases , considering what use case the misuse case threatens and the fortiﬁcation to the system to mitigate the misuse case .
The attacks and mitigations identiﬁed by the abuse and misuse case analysis can be used as input into the security requirements ( Section 2.1.1 bullet 2 .
Network security can integrate with software security to enhance the security posture .
Inevitably , attacks will happen , regardless of the applications of the other touchpoints .
Understanding attacker behaviour and the software that enabled a successful attack is an essential defensive technique .
Knowledge gained by understanding attacks can be fed back into the six other touchpoints .
The seven touchpoints are intended to be cycled through multiple times as the software product evolves .
The touchpoints are also process agnostic , meaning that the practices can be included in any software development process .
16.2.1.3 SAFECode The Software Assurance Forum for Excellence in Code ( SAFECode ) 13 is a non-proﬁt , global , industry-led organisation dedicated to increasing trust in information and communications technology products and services through the advancement of effective software assurance methods .
The SAFECode mission is to promote best practices for developing and delivering more secure and reliable software , hardware and services .
The fundamental practices deal with assurance – the ability of the software to withstand attacks that attempt to exploit design or implementation errors .
The development of ASC begins before the design phase and continues throughout the lifecycle to provide clear and actionable controls and to be responsive to changing business requirements and the ever-evolving threat environment .
Software must incorporate security features to comply with internal security practices and external laws or regulations .
Additionally , the software must resist known threats based upon the operational environment .
Threat modelling ( see Section 2.1.1 bullet 4 ) , architectural reviews , and design reviews can be used to identify and address design ﬂaws before their implementation into source code .
The system design should incorporate an encryption strategy ( see Section 2.1.1 bullet 6 ) to protect sensitive data from unintended disclosure or alteration while the data are at rest or in transit .
The system design should use a standardised approach to identity and access management to perform authentication and authorisation .
The standardisation provides consistency between components and clear guidance on how to verify the presence of the proper controls .
Authenticating the identity of a principal ( be it a human user , other service or logical component ) and verifying the authorisation to perform an action are foundational controls of the system .
Each of these has beneﬁts and drawbacks and should be chosen based upon project characteristics .
Log ﬁles provide the evidence needed in forensic analysis when a breach occurs to mitigate repudiation threats .
In a well-designed application , system and security log ﬁles provide the ability to understand an application ’ s behaviour and how it is used at any moment , and to distinguish benevolent user behaviour from malicious user behaviour .
Because logging affects the available system resources , the logging system should be designed to capture the critical information while not capturing excess data .
Policies and controls need to be established around storing , tamper prevention and monitoring log ﬁles .
If the generic handlers are invoked , the application should be considered to be in an unsafe state such that further execution is no longer considered trusted .
Manage Security Risk Inherent in the Use of Third-Party Components .
The ﬁrst ﬁve practices produce artifacts that contain or generate ﬁndings related to the security of the product ( or lack thereof ) .
The ﬁndings in these artifacts should be tracked and actions should be taken to remediate vulnerabilities , such as is laid out in the Common Criteria ( see Section 4.3 ) ﬂaw remediation procedure [ 1369 ] .
Alternatively , the team may consciously accept the security risk when the risk is determined to be acceptable .
Clear deﬁnitions of severity are important to ensure that all participants have and communicate with a consistent understanding of a security issue and its potential impact .
The severity levels are used to prioritise mitigations based upon their complexity of exploitation and impact on the properties of a system .
Even with following a secure software lifecycle , no product can be ’ perfectly secure ’ because of the constantly changing threat landscapes .
Vulnerabilities will be exploited and the software will eventually be compromised .
An organisation must develop a vulnerability response and disclosure process to help drive the resolution of externally discovered vulnerabilities and to keep all stakeholders informed of progress .
To prevent vulnerabilities from re-occurring in new or updated products , the team should perform a root cause analysis and feed the lessons learned into the secure software lifecycle practices .
Planning the Implementation and Deployment of Secure Development .
A healthy and mature secure development lifecycle includes the above seven practices but also an integration of these practices into the business process and the entire organisation , including program management , stakeholder management , deployment planning , metrics and indicators , and a plan for continuous improvement .
The speciﬁcation of the organisation ’ s secure software lifecycle including the roles and responsibilities should be documented .
The authors mapped the 153 possible activities of each lifecycle model into six software development phases : education and awareness ; project inception ; analysis and requirements ; architectural and detailed design ; implementation and testing ; and release , deployment and support .
The activities took the practices in Sections 2.1.1–2.1.3 into much ﬁner granularity .
The authors indicated whether each model includes each of the 153 activities and provides guidance on the strengths and weaknesses of each model .
The authors found no clear comprehensive ’ winner ’ among the models , so practitioners could consider using guidelines for the desired ﬁne-grained practices from all the models .
Table 16.1 places the the practices of Sections 2.1.1–2.1.3 into the six software development phases used by De Win et al .
Similar to prior work [ 1370 ] , the models demonstrate strengths and weaknesses in terms of guidance for the six software development phases .
No model can be considered perfect for all contexts .
Security experts can customize a model for their organizations considering the spread of practices for the six software development phases .
In this section , information on six adaptations to secure software lifecycle is provided .
16.3.1 Agile Software Development and DevOps Agile and continuous software development methodologies are highly iterative , with new functionality being provided to customers frequently - potentially as quickly as multiple times per day or as ’ slowly ’ as every two to four weeks .
Agile software development methodologies can be functional requirement-centric , with the functionality being expressed as user stories .
These stories are based upon common security issues such as those listed in the OWASP Top 1021 Most Critical Web Application Security Risks .
For example , a security-focused story using this format is provided : As Quality Assurance , I want to verify that all users have access to the speciﬁc resources they require which they are authorised to use , that is mapped to CWE-862 and CWE863 .
The security-focused stories are further broken down into manageable and concrete tasks that are owned by team roles , including architects , developers , testers and security experts , and are mapped to SAFECode Fundamental Practices [ 1368 ] .
These tasks are not directly tied to stories but are handled as continuous maintenance work ( such as , Continuously verify coverage of static code analysis tools ) or as an item requiring special attention ( such as , Conﬁgure bug tracking to track security vulnerabilities ) .
With a DevOps approach to developing software , development and operations are tightly integrated to enable fast and continuous delivery of value to end users .
Microsoft has published a DevOps secure software lifecycle model [ 1372 ] that includes activities for operations engineers to provide fast and early feedback to the team to build security into DevOps processes .
The Secure DevOps model contains eight practices , including eight of the 12 practices in the Microsoft Security Development Lifecycle discussed in Section 2.1.1 : 1 .
The training should encompass attack vectors made available through the deployment pipeline .
When selecting both commercial and open-source third-party components , the team should understand the impact that a vulnerability in the component could have on the overall security of the system and consider performing a more thorough evaluation before using them .
Software Composition Analysis ( SCA ) tools , such as WhiteSource23 can assist with licensing exposure , provide an accurate inventory of components , and report any vulnerabilities with referenced components .
Threat modelling may be perceived as slowing down the rapid DevOps pace .
However , products that are deployed rapidly under a DevOps deployment process should have a deﬁned overall architecture within which the DevOps process makes changes and adds features .
That architecture should be threat modeled , and when the team needs to change the architecture the threat model should also be updated .
New features that do not have an architectural impact represent a null change to the threat model .
The team should carefully select tools that can be integrated into the engineer ’ s Integrated Development Environment ( IDE ) and workﬂow such that they cause minimal disruption .
The goal of using these tools is to detect defects and vulnerabilities and not to overload engineers with too many tools or alien processes outside of their everyday engineering experience .
Scanning for credentials and other sensitive content in source ﬁles is necessary during pre-commit to reduce the risk of propagating the sensitive information through the CI/CD process , such as through Infrastructure as Code or other deployment scripts .
Some commonly found types of credentials include default passwords , hard-coded passwords , SQL connection strings and Certiﬁcates with private keys .
Rapidly-deployed systems often monitor the health of applications , infrastructure and networks through instrumentation to ensure the systems are behaving ’ normally ’ .
This monitoring can also help uncover security and performance issues which are departures from normal behaviour .
Four resources are provided to aid in the secure software lifecycle of mobile applications : 1 .
The MASVS deﬁnes a mobile app security model and lists generic security requirements for mobile apps .
The MASVS can be used by architects , developers , testers , security professionals , and consumers to deﬁne and understand the qualities of a secure mobile app .
The guide25 is a comprehensive manual for mobile application security testing and reverse engineering for iOS and Android mobile security testers .
The guide provides the following content : ( a ) A general mobile application testing guide that contains a mobile app security testing methodology and general vulnerability analysis techniques as they apply to mobile app security .
The guide also contains additional technical test cases that are operating system independent , such as authentication and session management , network communications , and cryptography .
The checklist26 is used for security assessments and contains links to the MSTG test case for each requirement .
The mobile application architecture describes device-speciﬁc features used by the application , wireless transmission protocols , data transmission medium , interaction with hardware components and other applications .
The attack surface can be assessed through a mapping to the architecture .
This section of the threat model deﬁnes the data the application stores , transmits and receives .
The data ﬂow diagrams should be reviewed to determine exactly how data are handled and managed by the application .
The threat agents are enumerated , including humans and automated programs .
The most common attacks utilised by threat agents are deﬁned so that controls can be developed to mitigate attacks .
The controls to mitigate attacks are deﬁned .
16.3.3 Cloud Computing The emergence of cloud computing bring unique security risks and challenges .
The Cloud guideline provides additional secure development recommendations to address six threats unique to cloud computing and to identify speciﬁc security design and implementation practices in the context of these threats .
Multitenancy allows multiple consumers or tenants to maintain a presence in a cloud service provider ’ s environment , but in a manner where the computations , processes , and data ( both at rest and in transit ) of one tenant are isolated from and inaccessible to another tenant .
Ensure that the multitenancy threats , such as information disclosure and privilege elevation are modeled for each of these interfaces , and ensure that these threats are mitigated in the application code and/or conﬁguration settings .
An organisation may not wish to generate and store intellectual property in a cloud environment not under its control .
Tokenisation is a method of removing sensitive data from systems where they do not need to exist or disassociating the data from the context or the identity that makes them sensitive .
The sensitive data are replaced with a token for those data .
The token is later used to rejoin the sensitive data with other data in the cloud system .
The sensitive data are encrypted and secured within an organisation ’ s central system which can be protected with multiple layers of protection and appropriate redundancy for disaster recovery and business continuity .
Practices : ( a ) When designing a cloud application , determine if the application needs to process sensitive data and if so , identify any organisational , government , or industry regulations that pertain to that type of sensitive data and assess their impact on the application design .
( b ) Consider implementing tokenisation to reduce or eliminate the amount of sensitive data that need to be processed and or stored in cloud environments .
This approach allows the test and debug systems to be exempt from sensitive data protection requirements .
Trusted Compute Pools are either physical or logical groupings of compute resources/systems in a data centre that share a security posture .
These systems provide measured veriﬁcation of the boot and runtime infrastructure for measured launch and trust veriﬁcation .
The measurements are stored in a trusted location on the system ( referred to as a Trusted Platform Module ( TPM ) ) and veriﬁcation occurs when an agent , service or application requests the trust quote from the TPM .
Practices : ( a ) Ensure the platform for developing cloud applications provides trust measurement capabilities and the APIs and services necessary for your applications to both request and verify the measurements of the infrastructure they are running on .
( b ) Verify the trust measurements as either part of the initialisation of your application or as a separate function prior to launching the application .
( c ) Audit the trust of the environments your applications run on using attestation services or native attestation features from your infrastructure provider .
Encryption is the most pervasive means of protecting sensitive data both at rest and in transit .
When encryption is used , both providers and tenants must ensure that the associated cryptographic key materials are properly generated , managed and stored .
Practices : ( a ) When developing an application for the cloud , determine if cryptographic and key management capabilities need to be directly implemented in the application or if the application can leverage cryptographic and key management capabilities provided by the PaaS environment .
( b ) Make sure that appropriate key management capabilities are integrated into the application to ensure continued access to data encryption keys , particularly as the data move across cloud boundaries , such as enterprise to cloud or public to private cloud .
As an authentication consumer , the application may need to authenticate itself to the PaaS to access interfaces and services provided by the PaaS .
As an authentication provider , the application may need to authenticate the users of the application itself .
Practices : ( a ) Cloud application developers should implement the authentication methods and credentials required for accessing PaaS interfaces and services .
Several cloud providers offer domains that developers can use to store user content , or for staging and testing their cloud applications .
The European Union Agency for Cybersecurity ( ENISA ) [ 1377 ] conducted an in-depth and independent analysis of the information security beneﬁts and key security risks of cloud computing .
The analysis reports that the massive concentrations of resources and data in the cloud present a more attractive target to attackers , but cloud-based defences can be more robust , scalable and cost-effective .
IoT and IIoT constitute an area of rapid growth that presents unique security challenges .
Devices must be securely provisioned , connectivity between these devices and the cloud must be secure , and data in storage and in transit must be protected .
Building security into each device may not be considered to be cost effective by its manufacturer , depending upon the value of the device and the importance of the data it collects .
As a result of these technical challenges , trust concerns exist with the IoT , most of which currently have no resolution and are in need of research .
Readers activate a tag , causing the device to broadcast radio waves within a bandwidth reserved for RFID usage by governments internationally .
The radio waves transmit identiﬁers or codes that reference unique information associated with the device .
Not using or allowing the use of default passwords or credentials .
IoT devices are often not developed to require users and administrators to change default passwords during system set up .
Additionally , devices often lack intuitive user interfaces for changing credentials .
Recommended practices are to require passwords to be changed or to design in intuitive interfaces .
Alternatively , manufacturers can randomise passwords per device rather than having a small number of default passwords .
The Manufacturer Usage Description ( MUD ) 28 speciﬁcation allows manufacturers to specify authorised and expected user trafﬁc patterns to reduce the threat surface of an IoT device by restricting communications to/from the device to sources and destinations intended by the manufacturer .
In non-IoT systems , updates are usually delivered via a secure process in which the computer can authenticate the source pushing the patches and feature and conﬁguration updates .
IoT manufacturers have , generally , not established such a secure upgrade process , which enables attackers to conduct a man-in-the-middle push of their own malicious updates to the devices .
The IoT Firmware Update Architecture 29 provides guidance on implementing a secure ﬁrmware update architecture including hard rules deﬁning how device manufacturers should operate .
Included in the code of practice are 13 guidelines for improving the security of consumer IoT products and associated services .
Finally , Microsoft has provided an Internet of Things security architecture.31 16.3.5 Road Vehicles A hacker that compromises a connected road vehicle ‘ s braking or steering system could cause a passenger or driver to lose their lives .
Attacks such as these have been demonstrated , beginning with the takeover of a Ford Escape and a Toyota Prius by white-hat hackers Charlie Miller and Chris Valasek in 201332 .
Connected commercial vehicles are part of the critical infrastructure in complex global supply chains .
In 2018 , the number of reported attacks on connected vehicles shot up six times more than the number just three years earlier [ 1378 ] , due to both the increase in connected vehicles and their increased attractiveness as a target of attackers [ 1379 ] .
The US National Highway Trafﬁc Safety Administration ( HTSA ) deﬁnes road vehicle cyber security as the protection of automotive electronic systems , communication networks , control algorithms , software , users and underlying data from malicious attacks , damage , unauthorised access or manipulation33 .
The HTSA provides four guidelines for the automotive industry for consideration in their secure software development lifecycle : 1 .
The team should follow a secure product development process based on a systemsengineering approach with the goal of designing systems free of unreasonable safety risks including those from potential cyber security threats and vulnerabilities .
The automotive industry should have a documented process for responding to incidents , vulnerabilities and exploits .
The industry should also establish metrics to periodically assess the effectiveness of their response process .
The automotive industry should document the details related to their cyber security process , including the results of risk assessment , penetration testing and organisations decisions related to cyber security .
Keys should not provide access to multiple vehicles .
( c ) Diagnostic features should be limited to a speciﬁc mode of vehicle operation which accomplishes the intended purpose of the associated feature .
For example , a diagnostic operation which may disable a vehicle ’ s individual brakes could be restricted to operating only at low speeds or not disabling all the brakes at the same time .
( e ) Limit the ability to modify ﬁrmware and/or employ signing techniques to make it more challenging for malware to be installed on vehicles .
( f ) The use of network servers on vehicle ECUs should be limited to essential functionality , and services over these ports should be protected to prevent use by unauthorised parties .
( g ) Logical and physical isolation techniques should be used to separate processors , vehicle networks , and external connections as appropriate to limit and control pathways from external threat vectors to cyber-physical features of vehicles .
( h ) Sending safety signals as messages on common data buses should be avoided , but when used should employ a message authentication scheme to limit the possibility of message spooﬁng .
( i ) An immutable log of events sufﬁcient to enable forensic analysis should be maintained and periodically scrutinised by qualiﬁed maintenance personnel to detect trends of cyber-attack .
( j ) Encryption methods should be employed in any IP-based operational communication between external servers and the vehicle , and should not accept invalid certiﬁcates .
The standard will specify minimum requirements on security engineering processes and activities , and will deﬁne criteria for assessment .
Explicitly , the goal is to provide a structured process to ensure cyber security is designed in upfront and integrated throughout the lifecycle process for both hardware and software .
The adoption of a secure software lifecycle in the automotive industry may be driven by legislation , such as through the US SPY Car Act37 or China and Germany ’ s Intelligent and Connected Vehicles ( ICVs ) initiative38 .
16.3.6 ECommerce/Payment Card Industry The ability to steal large quantities of money makes the Payment Card Industry ( PCI ) an especially attractive target for attackers .
In response , the PCI created the Security Standards Council , a global forum for the ongoing development , enhancement , storage , dissemination , and implementation of security standards for account data protection .
The Security Standards Council established the Data Security Standard ( PCI DSS ) , which must be upheld by any organisations that handle payment cards , including debit and credit cards .
PCI DSS contains 12 requirements39 that are a set of security controls that businesses are required to implement to protect credit card data .
Install and maintain a ﬁrewall conﬁguration to protect cardholder data .
Do not use vendor-supplied defaults for system passwords and other security parameters .
Encrypt transmission of cardholder data across open , public networks .
Use and regularly update antivirus software .
Develop and maintain secure systems and applications , including detecting and mitigating vulnerabilities and applying mitigating controls .
Assign a unique ID to each person with computer access .
Restrict physical access to cardholder data .
Track and monitor all access to network resources and cardholder data .
Regularly test security systems and processes .
Four assessment approaches are described in this section .
16.4.1 SAMM The Software Assurance Maturity Model ( SAMM ) 40 is an open framework to help organisations formulate and implement a strategy for software security that is tailored to the speciﬁc risks facing the organisation .
Resources are provided for the SAMM to enable an organisation to do the following : 1 .
Evaluate their existing software security practices .
The SAMM designers enumerated activities executed by organisations in support of their software security efforts .
Some example activities include : build and maintain abuse case models per project ; specify security requirements based upon known risks ; and identify the software attack surface .
These activities are categorised into one of 12 security practices .
The 12 security practices are further grouped into one of four business functions .
Spreadsheets are provide by SAMM for scoring the assessment , providing information for the organisation on their current maturity level : • 0 : Implicit starting point representing the activities in the Practice being unfulﬁlled .
Assessments may be conducted periodically to measure improvements in an organisation ’ s security assurance program .
Since that time , the BSIMM has been used to structure a multi-year empirical study of the current state of software security initiatives in industry .
Based upon their observations , the BSIMM designers enumerated 113 activities executed by organisations in support of their software security efforts .
Some example activities include : build and publish security features ; use automated tools along with a manual review ; and integrate black-box security tools into the quality assurance process .
Each activity is associated with a maturity level and is categorised into one of 12 practices .
The 12 practices are further grouped into one of four domains .
Via the interviews , the ﬁrm obtains a scorecard on which of the 113 software security activities the ﬁrm uses .
After the ﬁrm completes the interviews , they are provided information comparing themselves with the other organisations that have been assessed .
To ensure the continued relevance of the data reported , the BSIMM9 report excluded measurements older than 42 months and reported on 320 distinct measurements collected from 120 ﬁrms .
The objective of the CC is for IT products that have earned a CC certiﬁcate from an authorised Certiﬁcation/Validation Body ( CB ) to be procured or used with no need for further evaluation .
The Common Criteria seek to provide grounds for conﬁdence in the reliability of the judgments on which the original certiﬁcate was based by requiring that a CB issuing Common Criteria certiﬁcates should meet high and consistent standards .
A developer of a new product range may provide guidelines for the secure development and conﬁguration of that product .
This guideline can be submitted as a Protection Proﬁle ( the pattern for similar products that follow on ) .
Any other developer can add to or change this guideline .
Products that earn certiﬁcation in this product range use the protection proﬁle as the delta against which they build .
A product or system must meet speciﬁc assurance requirements to achieve a particular EAL .
Requirements involve design documentation , analysis and functional or penetration testing .
The highest level provides the highest guarantee that the system ’ s principal security features are reliably applied .
Applies when security threats are not viewed as serious .
The evaluation provides evidence that the system functions in a manner consistent with its documentation and that it provides useful protection against identiﬁed threats .
Applies when stakeholders require moderate-to-high independently-assured security in commodity products and are prepared to incur additional security-speciﬁc engineering costs .
Applies when stakeholders require high , independently-assured security in a planned development and require a rigorous development approach that does not incur unreasonable costs from specialist security engineering techniques .
Applies when developing systems in high-risk situations where the value of the protected assets justiﬁes additional costs .
Applies when developing systems in extremely high-risk situations and when the high value of the assets justiﬁes the higher costs .
The CC provides a set of security functional and security assurance requirements .
Some of these practices , such as those discussed in Section 2 , potentially apply to any product .
Organisations adopting new practices often like to learn from and adopt practices that are used by organisations similar to themselves [ 1382 ] .
When choosing which security practices to include in a secure software lifecycle , organisations can consider looking at the latest BSIMM [ 1380 , 1381 ] results which provide updated information on the adoption of practices in the industry .
DISCUSSION [ 1383 ] This chapter has provided an overview of of three prominent and prescriptive secure software lifecycle processes and six adaptations of these processes that can be applied in a speciﬁed domain .
For example , a practice has has not be been mentioned in any of these nine processes is the use of a bug bounty program for the identiﬁcation and resolution of vulnerabilities .
These individuals are external to the KA Secure Software Lifecycle | October 2019 Page 545 The Cyber Security Body Of Knowledge www.cybok.org organisation producing the software and may work independently or through a bug bounty organisation , such as HackerOne42 .
While the majority of this knowledge area focuses on technical practices , the successful adoption of these practices involves organisational and cultural changes in an organisation .
Additionally , every developer must uphold his or her responsibility to take part in such a process .
A team and an organisation need to choose the appropriate software security practices to develop a customised secure software lifecycle based upon team and technology characteristics and upon the security risk of the product .
While this chapter has provided practices for developing secure products , information insecurity is often due to economic disincentives [ 1383 ] which drives software organizations to choose the rapid deployment and release of functionality over the production of secure products .
As a result , increasingly governments and industry groups are imposing cyber security standards on organisations as a matter of legal compliance or as a condition for being considered as a vendor .
Compliance requirements may lead to faster adoption of a secure development lifecycle .
However , this compliance-driven adoption may divert efforts away from the real security issues by driving an over-focus on compliance requirements rather than on the pragmatic prevention and detection of the most risky security concerns .
This book provides essential lessons and expert techniques for security professionals who understand the role of software in security problems and for software developers who want to build secure code .
The book also discusses risk assessment , developing security tests , and plugging security holes before software is shipped .
[ 1345 ] The ﬁrst edition of this book was internally published in Microsoft and was required reading for all members of the Windows team during the Windows Security Push .
The second edition was made publicly available in the 2003 book and provides secure coding techniques to prevent vulnerabilities , to detect design ﬂaws and implementation bugs , and to improve test code and documentation .
It also provides information on software security fundamentals and contexts for a software security program in an enterprise .
The Security Development Lifecycle ( Original Book ) [ 1340 ] This seminal book provides the foundation for the other processes laid out in this knowledge area , and was customised over the years by other organisations , such as Cisco 43 .
The book lays out 13 stages for integrating practices into a software development lifecycle such that the product is more secure .
The Security Development Lifecycle ( Current Microsoft Resources ) [ 1347 ] The Microsoft SDL are practices that are used internally to build secure products and services , and address security compliance requirements by introducing security practices throughout every phase of the development process .
Additionally , this book discusses governance and the need for a dynamic risk management approach for identifying priorities throughout the product lifecycle .
Cyber Security Engineering : A Practical Approach for Systems and Software Assurance [ 1384 ] This book provides a tutorial on the best practices for building software systems that exhibit superior operational security , and for considering security throughout your full system development and acquisition lifecycles .
This book provides seven core principles of software assurance , and shows how to apply them coherently and systematically .
This book addresses important topics , including the use of standards , engineering security requirements for acquiring COTS software , applying DevOps , analysing malware to anticipate future vulnerabilities , and planning ongoing improvements .
SAFECode ’ s Fundamental Practices for Secure Software Development : Essential Elements of a Secure Development Lifecycle Program , Third Edition [ 1368 ] Eight practices for secure development are provided based upon the experiences of member companies of the SAFECode organisation .
The committee of industry participants are members of the Open Web Application Security Project ( OWASP ) 45 , an international not-for-proﬁt organisation focused on improving the security of web application software .
The earliest secure software lifecycle contributions from OWASP were referred to as the Comprehensive , Lightweight Application Security Process ( CLASP ) .
The purpose of the TSFr is to provide a minimum set of controls such that , when applied , all software ( irrespective of implementation constraints ) can be speciﬁed , realised and used in a trustworthy manner .
This Framework provides resources on cybersecurity Knowledge , Skills and Abilitiess ( KSAs ) , and tasks for a number of work roles for achieving the identiﬁed cyber resiliency outcomes based on a systems engineering perspective on system life cycle processes .
The Software Engineering Institute ( SEI ) has collaborated with professional organisations , industry partners and institutions of higher learning to develop freely-available curricula and educational materials .
Included in these materials are resources for a software assurance program48 to train professionals to build security and correct functionality into software and systems .
The Trustworthy Software Foundation provides a resource library 53 of awareness materials and guidance targeted for those who teach trustworthy software principles , those who seek to learn about Trustworthy Software and those who want to ensure that the software they use is trustworthy .
The Software Engineering Institute ( SEI ) has collaborated with professional organisations , industry partners and institutions of higher learning to develop freely-available curricula and educational materials .
Included in these materials are resources for a software assurance program54 to train professionals to build security and correct functionality into software and systems .
However , our heavy reliance on networking technology also makes it an attractive target for malicious users who are willing to compromise the security of our communications and/or cause disruption to services that are critical for our day-to-day survival in a connected world .
In this chapter , we will explain the challenges associated with securing a network under a variety of attacks for a number of networking technologies and widely used security protocols , along with emerging security challenges and solutions .
This chapter aims to provide the necessary background in order to understand other knowledge areas , in particular the Security Operations & Incident Management Knowledge Area ( Chapter 8 ) which takes a more holistic view of security and deals with operational aspects .
An understanding of basic networking protocol stack and TCP/IP suite is assumed .
When considering the security of the Internet and Wireless LAN ( WLAN ) technologies , it can sometimes be instructive to consider how certain original protocols are either designed without bearing security in mind , or with poor security design decisions .
This is not merely of historical interest : contemporary designs are often constrained by their predecessors for pragmatic reasons .
CONTENT 17.1 INTERNET ARCHITECTURE A complex system such as distributed applications running over a range of networking technologies is best understood when viewed as layered architecture .
Figure 17.1 shows the 7layer protocol ISO OSI stack and the interaction between the various layers .
The model also allows us to understand the security issues on each layer and the interplay between them .
The Internet is the predominant architecture today .
The Presentation and Session layers shown in the dotted box are optional in the IP protocol stack and some or all of the functions can be custom built on application requirements .
Network security requires cryptographic techniques such as public and symmetric keys for encryption and signing , block and stream ciphers , hashing , and digital signature , as described in the Cryptography Knowledge Area ( Chapter 10 ) .
We will take an applied approach to understand how these techniques help build a secure network .
The Dolev-Yao model assumes that an adversary has complete control over the entire network , and concurrent executions of the protocol between the same set of 2-or-more parties can take place .
The Dolev-Yao model describes the worst possible adversary : depending on the context , real adversaries may have limited capabilities .
This model is summarised as allowing the adversary to read any message , prevent delivery of any message , duplicate any message , or otherwise synthesise any message for which the adversary has the relevant cryptographic keys ( if any ) .
Physical Physical path traversed by data Logical path traversed by data Network Devices Figure 17.1 : 7 Layer Protocol Stack We examine a few common network security attacks to highlight the importance of understanding network security issues .
The popular characters called Alice and Bob from the security literature want to exchange messages securely .
In terms of information and communication infrastructure context , we can replace Alice and Bob with Web servers and clients , two email clients , two people using video-conferencing and so on .
The hackers , an eavesdropper called Eve , and a malicious attacker called Mallory are waiting to compromise their communications .
Messages sent by Alice and Bob over a network can be captured by Eve using packet snifﬁng tools .
This allows Eve to inspect each packet and possibly extract conﬁdential information such as passwords , credit card details and many other types of sensitive information .
Broadcast networking technologies such as WLAN or cable modem make it relatively easy to sniff packets .
The man in the middle attack ( MITM ) is another common security threat where Mallory , an attacker , places himself between Alice and Bob .
For example , a compromised gateway/router/access-point , malware present in the user ’ s device or server can potentially capture all of the packets being exchanged between the two parties , add/modify/delete information and carry out other malicious activities .
The Denial of Service ( DoS ) attack is a technique where an attacker sends an avalanche of bogus packets to a server .
This would either keep the server constantly busy or clog up the access link , resulting in disruption of service for legitimate users .
The IoT devices were turned into bots by exploiting weak authentication conﬁgurations including use of default passwords .
The bots were then used from a command and control centre to attack several high-proﬁle websites .
The use of IoT devices allowed the attackers to circumnavigate traditional security measures .
KA Network Security | October 2019 Page 555 The Cyber Security Body Of Knowledge www.cybok.org In an IP spooﬁng attack , an attacker tries to impersonate as an authorised user by crafting a packet with a forged IP address and adjusting certain other ﬁelds to make it look legitimate .
Having looked at examples of network attacks , we will now examine the security on each layer of the protocol stack .
In a simplistic scenario , Alice and Bob would decide to use an encryption algorithm such as AES with a 128 or 256-bit key to encrypt their messages .
This meets their conﬁdentiality requirement as the message can not be decrypted by anyone other than Alice and Bob .
However , this would require Alice and Bob to agree on a shared key .
Distributing this key over the network makes the secret key an easy target for Eve or Mallory .
Also , the above scenario fails to provide integrity and origin authentication .
The message can be altered as it traverses the network .
Alice and Bob ( in this instance , their email clients ) must use additional measures to provide message integrity and origin authentication .
In a variant of this setting , it is also likely that Alice and Bob do not care about the conﬁdentiality of their messages , but they want assurance that their messages will not be tampered with in transit .
Alice could calculate the hash of her message using the SHA-3 algorithm and send it to Bob .
On receiving this message , Bob would recalculate the hash and verify whether there is a match .
Bob can not tell whether the message sent by Alice has been altered since the hash matches .
One possible solution for Alice is to use a pre-negotiated symmetric key to encrypt the hash .
Bob now decrypts this hash using the pre-negotiated symmetric key and veriﬁes the integrity of the message received .
This also authenticates that the message was sent by someone who shares a key with Bob , in this instance Alice .
We highlighted the challenges of key distribution over the network .
We will ignore the conﬁdentiality requirement for the moment .
Alice signs the hash of her message using her private key .
This allows for an integrity check and authentication at the same time , as no one other than Alice knows her private key .
So , how does Bob get Alice ’ s public key and trust that Eve or Mallory are not using a forged public/private key to perform MITM ?
We provide a brief introduction to key management in the context of public key cryptography in the next section , as it is used by a number of network security protocols .
The above example also achieves non-repudiation , as it can be proved that the hash ( or in other cases , the whole message ) was signed by Alice ’ s private key and she could not deny this fact .
Government agencies or standard organisations appoint or recognise registrars who issue keys , and keep track of the public certiﬁcates of entities ( individuals , servers , routers etc ) .
The registrars , a large number of which are private companies , themselves have a registered public/private key pair with stakeholders relevant to the application domain .
The idea is similar to registering your motor number plate with an authority .
She then presents her proof of identity to one of the registrars .
This certiﬁcate is KA Network Security | October 2019 Page 556 The Cyber Security Body Of Knowledge www.cybok.org signed by the registrar ’ s private key and can be veriﬁed by anyone using the registrar ’ s public key .
The ﬁelds on the certiﬁcate include a unique identiﬁer/serial number , a signature algorithm used by the CA and the period of validity .
Organisations can also manage their own private PKI .
CAs also publish a list of revoked certiﬁcates which have either expired or been revoked .
The web of trust is an alternative scheme where users can create a community of trusted parties by mutually signing certiﬁcates without needing a registrar .
Continuing with our email example , Alice could send her certiﬁcate to Bob along with her email message .
Bob is now able to check the validity of the certiﬁcate presented by Alice .
In our simple example , Alice and Bob could use these techniques to build a secure email system .
Pretty Good Privacy ( PGP ) was one of the earliest email systems to propose the security approach described above , albeit using the web of trust for certiﬁcates .
Generally , in order for systems to be compatible across platforms and between vendors , application developers make use of the standard application layer protocol , the Simple Mail Transfer Protocol ( SMTP ) for exchanging messages between mail servers .
The content itself is formatted based on a set of standards called Multipurpose Internet Mail Extensions ( MIME ) .
As the original Internet protocols lacked security features , a secure version SMIME was developed in order to add an integrity check and certiﬁcates to the email header .
The functions of the certiﬁcate veriﬁcation and checking revocation list are automatically performed by Alice and Bob ’ s mail agents .
The existing PKI model has faced several challenges , as evidenced by a number of documented cases where Certiﬁcate Authorities have issued certiﬁcates in error , or under coercion , or through their own infrastructure being attacked .
Recent years have seen many partial solutions such as certiﬁcate pinning and public immutable logs of issued certiﬁcates being implemented to prevent the PKI trust model from being undermined .
17.3.2 DNS Security Extensions Internet design philosophy mandates keeping the Internet core functions implemented in the backbone routers to be simple along with other supporting functions to be deployed at the edge .
This mapping is performed and maintained by a hierarchy of name servers .
We provide an overiew of attacks on DNS .
In an MITM , Mallory can impersonate a DNS server , return a bogus address and divert trafﬁc to a malicious server , thus allowing it to collect user passwords and other credentials .
However , the robust distributed design of the DNS has fortunately saved us from a total collapse of the Internet .
DNSSEC uses techniques similar to our secure email example above by sending a response signed by the private key of a DNS server .
The authenticity of the DNS records is proven by the fact that a responding server signs the record using its private key , which a requester can verify using the corresponding public key .
In addition , a digital signature also provides the integrity of the response data .
An astute reader may note KA Network Security | October 2019 Page 557 The Cyber Security Body Of Knowledge www.cybok.org that conﬁdentiality is not a signiﬁcant issue for this transaction .
Very few registrars support DNSSEC and other mechanisms , as communicating DNSSEC information has several security vulnerabilities .
DDoS defence is not part of DNSSEC .
The popularity of HTTP and its wide adoption for e-commerce imposed strict security requirements on this protocol .
A secure version called HTTPS was introduced by using security services from the transport layer , which allows the URL , content , forms and cookies to be encrypted during communication .
We discuss the secure transport layer protocols in the next section .
Although not mandated , most browsers support conﬁdentiality by encrypting data .
New features such as header compression and ﬂow control require servers to maintain additional state information .
An attacker could send a large number of empty or tiny frames and keep the server busy processing frame headers .
Servers must employ a threshold on the number of connections being processed to limit such attacks .
In a DoS ampliﬁcation attack , an attacker can send a few bytes of the MONLIST command and get the server to send a list of the last 600 clients that made an NTP request .
A possible countermeaure would require restricting access to this command from internal hosts only .
The most recent implementation of the NTP daemon ntpd ) uses a hierarchical security model implementing several PKIs , digital signatures and other standard application-layer security mechanisms .
17.4 TRANSPORT-LAYER SECURITY In the previous section , we discussed ways in which applications could build security features by using cryptographic primitives .
Data sent over the TCP/IP protocol were not safe and hence each application had to take care of security itself .
Ideally , if the transport-layer could provide conﬁdentiality , integrity and authentication mechanisms , the application-layer could be relieved from the burden of security and use the transport layer services instead .
These capabilities are provided by a shim layer between the application and transport layers called the Secure Sockets Layer ( SSL ) .
IETF started to develop the Transport Layer Security ( TLS ) borrowing most of its ideas from the SSL 3.0 protocol .
The most prominent web browsers have started to support the latest TLS KA Network Security | October 2019 Page 558 The Cyber Security Body Of Knowledge www.cybok.org Alice ( Receiver ) Bob ( Sender ) Internet TCP 3-way Handshake Start of TLS Handshake Client Hello Server Hello Cer @ ﬁcate ne Server Hello Do ClientKeyExchang e ChangeCipherSp ec Finished ChangeCipherSp Finished Encrypted Traﬃc ec Applica @ on Data Figure 17.2 : TLS Handshake 1.3 standardised in 2018 .
In this section , our discussions will relate to a simpliﬁed version of the security features in order to understand the basics of the TLS protocol .
The exact syntax and semantics of the protocols and a rich set of conﬁgurations are described in hundreds of pages of RFCs .
It is worth emphasising that some of these basic techniques are also used in security protocols on other layers , which we will discuss in this chapter .
First Bob and Alice exchange the three-way TCP SYN , SYNACK and ACK messages .
It should be noted that this step is not part of TLS/SSL .
Bob then sends a ClientHello message to Alice along with the cipher suites ( ciphers and the hash functions it supports ) and a nonce , a large , random number , chosen speciﬁcally for this run of the protocol .
Bob checks validity of the certiﬁcate and is assured that it belongs to Alice .
Bob sends a ClientCipherSpec and a Finished Message suggesting that the key generation and authentication are complete .
Alice also has the shared key at this point .
Bob decrypts the message with the negotiated symmetric key and performs a message integrity check .
After successfully completing the above steps , a secure tunnel is established and the encrypted application data can now be sent , as shown at the bottom of ﬁgure 17.2 .
All the other key data for this connection are derived from this master secret in conjunction with the additional parameters .
Session encryption key for data sent from Bob to Alice ( client encryption key ) .
Session encryption key for data sent from Alice to Bob ( server encryption key ) .
Session MAC key for data sent from Bob to Alice ( client MAC key ) .
Session MAC key for data sent from Alice to Bob ( server MAC key ) .
Bob and Alice derive separate keys for encryption and integrity in each direction for enhanced security .
Generating these ephemeral keys allows for perfect forward secrecy , as these keys can not be reused in future sessions .
For example , Eve could capture every communication between Alice and Bob .
She could pretend to be Bob and repeat the sequence of commands sent by Bob later in the day .
The PMS generation algorithm uses a nonce in the mix .
The connection replay attack will fail , as Alice would have a different set of keys from Eve for the new session due to this new nonce .
Integrity check algorithms require ﬁxed length data for a MAC calculation .
If applications have to collect and pass ﬁxed length data to these algorithms , further delay will be incurred .
Hence , TLS deﬁnes a record format , as shown in ﬁgure 17.3 , where the length of the data sent in each record can be indicated along with the type of record ( data or control ) .
A MAC is also appended at the end of each record .
For example , if data are sent from Bob to Alice , the session MAC key for the data sent from Bob to Alice are used to generate this MAC .
Further , the data plus the MAC are encrypted using the session encryption key for data sent from Bob to Alice .
A receiver would not be able to detect this attack as the integrity of the TLS records remains unchanged .
The TLS provides a separate mechanism where the sender and receiver keep track of the record sequence number without explicitly exchanging it .
However , the MAC calculations at both ends use this sequence number in the mix .
Any MITM rearrangement of records will fail an integrity check .
Having discussed the technical details of the TLS , we now consider how it performs in the presence of certain attacks .
In a Password Snifﬁng attack , Eve captures a few packets and wants to get passwords in HTTPS or other application trafﬁc .
As the user data are encrypted , the password can not be sniffed .
In an IP Spooﬁng attack , Mallory uses a forged IP addresses to fool Bob into accepting bogus data .
Mallory must be in possession of the secret key as well as the forged IP address to succeed .
An MITM attack is prevented by using public key certiﬁcates to authenticate the correspondents .
We note that in a related transport-layer attack called a SYN Flooding DDoS attack , a group of attacking machines keep sending TCP SYN messages to request a connection and let the server allocate resources .
However , this type of attack can be handled by the TCP and hence is not duplicated in the TLS .
The server does not half open a connection right away on receiving a TCP connection request .
It selects an Initial Sequence Number ( ISN ) using a hash function over source and destination IP addresses , port numbers of the SYN segment , as well as a secret number only known to the server .
The server then sends the client this ISN , otherwise known as a Cookie , in the SYNACK message .
If the request is from a legitimate sender , the server receives an ACK message with a new sequence number which is ISN plus 1 .
A DDoS sender would KA Network Security | October 2019 Page 561 The Cyber Security Body Of Knowledge www.cybok.org either not respond with ACK or would not have the correct ISN in its response .
The current version of SSL ( and TLS ) has evolved through experiencing several attacks and vulnerabilities found in earlier versions .
SSL Stripping attacks remove the use of SSL/TLS altogether by modifying unencrypted protocols which request the use of the TLS .
The BEAST attack exploits the predictable initialisation vector of TLS 1.0 implementation due to use of the Cipher Block Chaining ( CBC ) .
Many of these vulnerabilities are also attributed to either an improper implementation or poor understanding of the protocol suite rather than a lack of proper speciﬁcations .
For example , the TLS design problem of calculating MAC before encryption results in a timing side-channel attack called the Lucky Thirteen attack , which allows attackers to decrypt arbitrary ciphertext .
17.4.4 Quick UDP Internet Connections ( QUIC ) QUIC is a new transport protocol designed by Google for faster web-browsing using UDP instead of HTTP over TCP .
The protocol currently uses proprietary encryption and authentication .
Firewalls and IDS systems typically detect HTTP trafﬁc , and perform deep packet inspection , virus scanning and other security measures .
Although QUIC uses the standard HTTP ports , security devices do not track this application layer protocol at present .
It is treated as regular UDP trafﬁc .
Since the standardisation work is already in progress , it is likely to use TLS1.3 for secure transport .
In this section , we looked at various mechanisms for securing the end-to-end communication channel via transport protocols .
However , if the content being transferred becomes accessible to an attacker outside the communication channel , they could compare the volume of the encrypted material and make inferences .
17.5 NETWORK LAYER SECURITY Although application-layer and transport-layer security help to provide end-to-end security , there is also merit in adding security mechanisms onto the network layer .
If and when malicious trafﬁc is detected at the end-hosts , it is too late , as the bandwidth has already been consumed .
This makes the IP addresses of the communicating end-hosts visible to eavesdroppers .
Additionally , many organisations prefer their trafﬁc to be fully encrypted as it leaves their network .
In the early days of networking , several private networks were in use .
An alternative solution is to make use of the Internet to connect several islands of private networks owned by an organisation .
Also , employers and employees want a ﬂexible work environment where people can work from home , or connect from a hotel room or an airport lounge without compromising their security .
We have already determined that the Internet is unsafe .
The concept of a Virtual Private Network ( VPN ) over the public Internet requires a set of network layer security mechanisms KA Network Security | October 2019 Page 562 The Cyber Security Body Of Knowledge www.cybok.org that we will explore in this section .
We start our discussion with security additions to the network layer IP protocol called IPsec .
Figure 17.4 shows that an employee working from home accesses a server at work , the VPN client in their host encapsulates IPv4 datagrams into IPsec and encrpyts IPv4 payload containing TCP or UDP segments , or other control messages .
The corporate gateway detects the IPSec datagram , decrypts it and decapsulates it back to the IPv4 datagram before forwarding it to the server .
Every response from the server is also encrypted by the gateway .
We note that encryption is not mandatory in IPsec .
Figure 17.4 is one of several modes of operation for IPsec .
For example , there could be two corporate networks , each with their own IPsec gateway communicating over the open Internet .
IP Header Public Internet IPSec IP Header Header TCP/UDP Header TCP/UDP Header Data Payload Data Payload Encrypted IPSec compliant Gateway Router Enterprise Network IPSec IP Header Header TCP/UDP Header Data Payload Encrypted IPSec Compliant Host Home Network Figure 17.4 : Example IPsec Client Server Interaction We started off with a simple example showing data conﬁdentiality using encryption .
However , IPsec also provides data integrity , origin authentication and replay attack prevention .
Again , the set of modes/conﬁgurations/standards provided by IPsec is extensive ; interested readers should access the relevant IETF RFCs for formats and protocol details .
IPsec supports Tunneling and Transport modes of operation .
In Transport mode , as shown in ﬁgure 17.5 , the original IP header is used but the rest of the payload gets encrypted .
This can be achieved if the endpoint is behind a NAT .
In the rest of this section , we will discuss the widely used alternate Tunneling mode in detail .
The edge devices perform the encapsulation of every IP including the header .
This virtually creates a secure tunnel between the two edge devices .
The receiving edge device then decapsulates the IPv4 datagram and forwards within its network using standard IP forwarding .
Other possible conﬁgurations for a tunnel could involve one IPsec aware host and an IPsec aware gateway ( as in ﬁgure 17.4 ) .
A tunnel between KA Network Security | October 2019 Page 563 The Cyber Security Body Of Knowledge www.cybok.org two IPsec aware hosts is also possible without involving edge routers .
The Tunneling mode remains in widespread use due to its simplicity , as it does not require IPsec protocol support in the end hosts .
Also , key negotiation is simpliﬁed , as two edge devices can handle connections on behalf of multiple hosts in their respective networks .
The ESPv3 allows to use the Trafﬁc Flow Conﬁdentiality ( TFC ) mechanisms which adds arbitrary length padding to obfuscate the trafﬁc pattern and prevent avoid statistical trafﬁc analysis attacks .
[ 1392 ] reported experimental results exploring padding and several other techniques such as packet framgmentation , introduction of artiﬁcial inter-packet delay , inserting of dummy packets to avoid trafﬁc analysis .
Transport Mode : Original IP Header Tunnel Mode : New IP Header Data orig IP hdr TCP hdr Data orig IP hdr TCP hdr Data ESP hdr TCP hdr Data Data ESP trlr ESP Auth new IP hdr TCP hdr Data orig IP hdr TCP hdr Data ESP hdr orig IP hdr TCP hdr Data ESP trlr ESP Auth ESP hdr orig IP hdr TCP hdr Data ESP trlr ESP Auth Figure 17.5 : Transport and Tunnel Mode Encapsulation IPsec supports a set of formats to implement security .
The Encapsulation Security Payload ( ESP ) format supports conﬁdentiality using encrypted IP packets , data integrity using hash functions , and source authentication .
If an application does not require conﬁdentiality , it may simply use the Authentication Header ( AH ) format , which supports data integrity and source authentication .
The IETF RFC2410 deﬁnes the NULL Encryption algorithm with ESP to achieve the same outcome .
In total , we get four different options for communication : Transport mode with ESP , Transport mode with AH , Tunnel mode with ESP and Tunnel Mode with AH .
Since VPN tunnels are fully encrypted , the Tunnel mode with ESP remains the protocol of choice .
Two entities participating in IPsec communication establish Security Association ( SA ) for each direction of the link .
Essentially , a number of variables are recorded in a database called the Security Association Database ( SAD ) for lookup during IPsec protocol processing , somewhat similar to the TCP connection state .
An Anti-Replay Window is also used to determine whether an inbound AH or ESP packet is a replay .
Readers will observe a similarity between TLS 17.4 and IKE , in that IKE also requires an initial handshake process to negotiate cryptographic algorithms and other values such as nonces and exhange identities and certiﬁcates .
We will skip the details of a complex two-phase protocol exchange which results in the establishment of a quantity called SKEYSEED .
These SKEYSEEDs are used to generate the keys used during a session , as we recall IPsec SAs .
The ISAKMP is a framework that deﬁnes the procedures for authenticating the communicating peer , creation and management of Security Associations , and the key generation techniques .
It can also provide threat mitigation against DoS and replay attack .
17.5.1 IP Masquerading Due to the shortage of IPv4 address space , Network Address Translation ( NAT ) was designed so that private IP addresses could be mapped onto an externally routable IP address by the NAT device [ 1387 ] .
For an outgoing IP packet , The NAT device changes the private source IP address to a public IP address of the outgoing link .
As a consequence , it obfuscates the internal IP address from the outside world .
To a potential attacker , the packets appear to be coming from the NAT device , not the real host/server behind the NAT device .
The shortage of IPv4 addresses resulted in the development of new IPv6 protocol , as the NAT mechanism had several ﬂaws .
As IPv6 adoption is gradually increasing , we should highlight the security beneﬁts and challenges associated with the deployment of IPv6 .
For example , the use of 128-bit address space means attackers need a lot more time to scan the ports , as opposed to IPv4 , where the entire address space can be scanned in a few hours .
Several security problems associated with ARP , which can be discussed later in this chapter , disappear as IPv6 layer-3 addresses are derived directly from layer-2 addresses without any need for address resolution .
However , this allows attackers to infer information about the host/servers which can be handy when launching attacks .
Using hash function for address generation is recommended as a mitigation technique .
This helps when authenticating between routers for secure message exchange .
KA Network Security | October 2019 Page 565 The Cyber Security Body Of Knowledge www.cybok.org 17.5.3 Routing Protocol Security So far , we have primarily focussed on the security of data being sent using the TCP/IP protocol suite .
However , a network can easily be disrupted if either the routers themselves are compromised or they accept spurious routing exchange messages from malicious actors .
These protocols support no security by default but can be conﬁgured to support either plain text-based authentication or MD5-based authentication .
Plain text authentication sends a secret key in clear text along with routing updates , thus making it easy to be sniffed by a packet analyser .
Authentication can avoid several kinds of attacks such as bogus route insertion or modifying and adding a rogue neighbour .
Additionally , routers may employ route ﬁltering to avoid propagating the only legitimate route .
17.5.3.1 Border Gateway Protocol ( BGP ) Security The Internet uses a hierarchical system where each AS managed by an ISP , exchanges routing information with other ASs using the Border Gateway Protocol ( BGP ) .
After receiving an IP preﬁx [ 1387 ] , the reachability information , from its neighbour , the router checks the newly received information against its stored knowledge to see if there is a better path to reach a destination network .
This information is updated locally and propagated to its immediate neighbours .
The distributed system allows networks to reach each other globally .
In recent years , attacks on the BGP have been seen with the apparent intention of disrupting YouTube services globally .
The entire Internet experienced an outage in another country due to either mis-conﬁguration or the malicious advertising of bogus BGP updates .
Either way , this highlights the security weakness in the BGP protocol .
This vulnerability arises because of a lack of integrity and authentication for BGP messages .
We will describe some well-known attacks on the BGP protocol .
In what is known as a BGP route hijacking attack , a malicious router could advertise an IP Preﬁx , saying that the best route to a service is through its network .
Once the trafﬁc starts to ﬂow through its network , it will then choose to drop all the packets to this service for a variety of reasons , including censorship .
the attacker could divert trafﬁc through an unsuspecting AS , thus suddenly increasing their load .
In a BGP denial-of-service ( DoS ) attack , a malicious router would send an avalanche of BGP trafﬁc to a victim AS , while keeping its border router busy so that it could not process any valid updates .
The attacker could also propagate spurious BGP updates and corrupt routing tables so as to prevent trafﬁc from reaching its intended destination .
IETF is currently working on a standard called BGPSec to address these security concerns .
The core of the scheme lies in the use of PKI to verify the signatures of the neighbours sending the updates .
Two neighbouring routers could use IPsec mechanisms for point-point security to exchange updates .
We will now look at a simple example where a BGP router receives a path ZZZ YYY XXX .
The BGP router veriﬁes the signature of AS XXX using PKI mechanisms that we learnt about earlier .
It KA Network Security | October 2019 Page 566 The Cyber Security Body Of Knowledge www.cybok.org then veriﬁes the signature generated by YYY and subsequently by ZZZ .
This allows us to verify the origin and authenticity of the whole chain of updates .
Signature veriﬁcation comes at a cost , implementing BGPSec would require the border routers to verify a larger number of signatures on booting .
Additional crypto hardware and memory would certainly help keep the performance on track .
Despite these BGPSec and other standardisation efforts , not many routers deploy these mechanisms due to additional costs and a lack of short-term beneﬁts unless there is a consensus to mandate it globally [ 1394 ] .
Mechanism costs are an additional but smaller barrier to widespread deployment .
The existing BGP security proposals suffer from a classic economic problem .
17.6 LINK LAYER SECURITY In this section , we are conﬁning our attention to the security of link layer technologies which are relevant to end-user/PC deployments .
Other link layer technologies are addressed in other knowledge areas .
We will start our discussion with the prominent 802.1X Port-based Authentication followed by link layer security issues in Ethernet Switched LAN and WLAN environments .
Before a user can access a network at the link layer , it must authenticate the switch or access point ( AP ) they are attempting to connect to , either physically or via a wireless channel .
As with most standards bodies , this group has its own jargon .
The AS function can also be co-located with the authenticator .
We will now consider RADIUS as our example AS .
Using the RADIUS protocol as an example , once a supplicant request is received , the authenticator sends a RADIUS Access Request message to the RADIUS server , requesting authorisation to be granted to access the resources .
Supplicant software is typically available on various OS platforms or it can also be provided by chip-set vendors .
There is no need for higher layer protocols .
As the authenticator is connected to the AS using a trusted link with a shared secret , a higher layer protocol such as RADIUS/DIAMETER over UDP can be used on this side of the link .
The authenticator sends out the EAP-Request identity to the supplicant .
The supplicant responds with the EAP-response packet , which is forwarded to the AS .
Upon veriﬁcation , the AS returns one of the following responses : Access Accept , Access Reject , Access Challenge for extra credentials .
If the result is Access Accept , the authenticator unblocks the port to let higher layer trafﬁc through .
When the supplicant logs off , the EAP-logoff to the authenticator sets the port to block all non-EAP trafﬁc .
To safeguard against any eavesdropping , the EAP uses a Tunnel for authentication and authorisation .
Essentially , all of these protocols establish a TLS tunnel but differ in choice of hash algorithms , the type of credentials used , whether a client-side certiﬁcate is used etc .
As we have already discussed , the authenticator has been playing the role of a relay up to this point .
The AS also derives the same PMK and sends this to the authenticator .
From this point on , the supplicant and authenticator use the PMK to derive the Temporal Key ( TK ) used for the message encryption and integrity .
The key derivation process is similar to what we learnt in the TLS earlier .
We will revisit key generation and the relationship between the various keys in detail later in the Robust Secure Networking ( RSN ) section .
17.6.2 Attack On Ethernet Switch Although the research literature has primarily focused on higher layer security , the Stuxnet [ 796 ] attack has demonstrated that an innocuous looking USB drive could easily wreak havoc in a Local Area Network ( LAN ) environment without any need for an Internet connection .
Widely deployed Ethernet technology is built around self-learning and conﬁguring protocols .
We provide a brief review of some of the possible attacks here .
Media Access Control Attack : Switch Poisoning Attack Ethernet switches keep forwarding table entries in a Content Addressable Memory ( CAM ) .
As a switch learns about a new destination host , it updates the table and for all future communications , this table entry is looked up to forward a frame .
Unlike broadcast Ethernet or WLAN , these frames are not accessible to hosts attached to other ports .
An attacker could craft several frames with random addresses to populate an entire CAM .
This would result in the switch ﬂooding all the incoming data frames to all the outgoing ports , as there KA Network Security | October 2019 Page 569 The Cyber Security Body Of Knowledge www.cybok.org is no space available to enter a new mapping .
This makes the frame available to the attacker attached to one of these ports .
However , this kind of attack requires an attacker to control a device that is directly connected to an Ethernet switch or possibly to some used but unattended Ethernet wall sockets which are still connected to a port .
Mitigating this kind of attack would require authenticating and verifying the MAC addresses from some local database of legitimate addresses before populating the forwarding table entry .
MAC Spooﬁng : attacks occur when an attacker eavesdrops on a link and detects the MAC address of a target host .
It then masquerades as a legitimate host by altering its host ’ s MAC address to match the newly detected MAC address .
The attacker ﬂoods the network with the newly conﬁgured MAC address while directing the trafﬁc to itself by altering the switch forwarding table entry .
The switch is now tricked into forwarding the frames destined for the target host to the attacking host .
The MAC address is not not designed or intended to be used for security .
As a side issue , a user may choose to spoof his or her MAC address in order to protect his or her privacy .
Most popular operating systems support MAC address randomisation to avoid devices being tracked based on a MAC address .
Once it manages to compromise the ARP table , it will start receiving any data that were intended for the target ’ s IP address .
ARP spooﬁng can also be used for DoS attacks by populating the ARP table with multiple IP addresses corresponding to a single MAC address of a target server , for example .
This would then redirect unnecessary trafﬁc to the target , keeping it busy processing these messages .
ARP Spooﬁng is also helpful in session hijacking and MITM attacks .
In fact , a mitigation scheme would set limits on the number of addresses that can be learnt per-port on a switch .
Some vendors use a veriﬁcation process where they inspect the MAC address and IP address information in ARP packets against the MAC-IP bindings contained in a trusted binding table .
This allows for any ARP packets that do not have an entry in the binding table to be discarded .
The binding table must be updated frequently to avoid blocking legitimate updates .
VLAN hopping : VLAN hopping attacks allow an attacking host on a VLAN to gain access to resources on other VLANs that would normally be restricted .
There are two primary methods of VLAN hopping : switch spooﬁng and double tagging .
The attacker now succeeds in accessing trafﬁc for multiple VLANs .
Vendors mitigate these attacks by proper switch conﬁguration .
For example , the ports are assigned a trunking role explicitly and the others are conﬁgured as access ports only .
Also , any automatic trunk negotiation protocol can be disabled .
In a double tagging attack , an attacker succeeds in sending its frame to more than one VLAN by inserting two VLAN tags to a frame it transmits .
Again , vendors provide recommended conﬁguration methods to deal with these possible attacks .
KA Network Security | October 2019 Page 570 The Cyber Security Body Of Knowledge www.cybok.org 17.7 WIRELESS LAN SECURITY Wireless LAN are more vulnerable to security risks due to the broadcast nature of media , which simpliﬁes eavesdropping .
The Wired Equivalent Privacy ( WEP ) protocol , despite being obsolete due to its design ﬂaws , provides several important lessons about how not to design a security protocol .
The WEP protocol was designed to provide integrity , conﬁdentiality and authentication .
It uses a symmetric key encryption method where the host shares a key with an access point using out of band methods , mostly pre-installation by an administrator or a home network user .
The plaintext payload and the CRC of the frame are then combined with the key sequence generated by the RC4 using bit-wise exclusive-or operation to encrypt the frame .
For authentication , the Access Points ( APs ) advertise via beacon frames whether authentication is necessary or not .
It would encrypt the nonce with the shared key and send it back to the AP .
The AP would decrypt this response with the shared key and verify whether it matched the nonce it sent originally .
The receiver would extract the IV received in plaintext , input IV and shared secret key into PRNG , get a keystream , XOR the keystream with the encrypted data to decrypt data + ICV and ﬁnally verify the integrity of the data with the ICV .
Given that IVs are sent in plaintext , an eavesdropper can easily detect this reuse and mount a known plaintext attack .
The linear CRC algorithm is good for detecting random link errors but is a poor choice for maliciously modifying the message .
Strong cryptographic techniques such as message authentication codes and signatures , as discussed in higher layer protocols , are better suited for this task .
Given the poor security design of WEP , the Wi-Fi Alliance took on the job of securing wireless networks .
It would take 100 years to replay the same IV .
A packet received out of order , would be dropped by the receiving station .
It also provides an improved 4-way handshake and temporary key generation method .
The PSK is replaced with a new key distribution called the Simultaneous Authentication of Equals ( SAE ) based on the IETF Dragonﬂy key exchange .
However , the IEEE 802.11i working group came up with the RSN framework to provide the strongest form of security .
It continues to use the TKIP and CCMP for various cryptographic functions such as encryption/decryption , integrity check , as well as origin authentication and replay attack detection .
The RSN Key derivation mechanisms are involved to a degree , as can be seen in ﬁgure 17.8 .
We will provide a summary of this , as many other protocols ( including Cellular GSM ) following a similar scheme to the pairwise key scheme provide a mechanism for generating dynamic session keys each time a user starts a new session .
With these two options available , a Pairwise Master Key ( PMK ) can be generated in the following two ways : using the PSK as the PMK or deriving the PMK from the MSK using the Pseudo-Random Function ( PRF ) .
The PSK also uses the host and AP addresses when generating the PTK , thus providing additional defence against session hijacking and impersonation .
Further , a nonce is used in the mix to achieve good random keying material .
The PTK is now split three ways , thus generating separate keys for each function .
This key is generated by the AP and distributed securely to the hosts associated using the secure pairwise keys derived above .
This group key can be changed periodically based on a variety of network policies .
The Group Temporal Key generation method is not deﬁned in the standards .
We will discuss a number of approaches that can be implemented on various layers of the protocol stack .
The effective deployment of these tools is covered in detail in the Security Operations & Incident Management Knowledge Area ( Chapter 8 ) .
This was typical of the early packet ﬁlters , which worked on inspecting header ﬁelds .
These ﬁlters did not retain any state information about the packets/ﬂows/sessions they belonged to .
As more computing power and cheaper memory became available , the next generation of packet ﬁlters started to track transport layer ﬂow , a chain of packets belonging to a session , known as stateful ﬁlters .
The packet ﬁlters , aka , Firewall system can be co-located with routers or implemented as specialised servers .
The ﬁlters are set based on a network ’ s security policy and the packets are treated accordingly .
Although ﬁrewalls play a key role in securing a network , taking down a ﬁrewall can potentially wreak havoc for organisations which are dependent on networking technology .
However , many organisations use application level gateways , aka application proxy , to perform access control , as they facilitate any additional requirements of user authentication before a session is admitted .
Both the AG and ﬁrewall are also co-located in many deployments .
A client wanting to access an external service would connect to the AG ﬁrst .
The AG would prompt him or her for authentication before initiating a session to the external server .
The AG would now establish the connection with the destination acting as a relay on behalf of the client , essentially creating two sessions : one between the client and the AG , and one between the AG and the destination .
Another interesting application of an AG is SSL termination .
An incoming webserver SSL connection could be terminated at the AG , so that it could do the resource intensive encryption/decryption and pass the un-encrypted trafﬁc to the back-end servers .
This allows the workload on these busy servers to be reduced in addition to implementing security measures .
In practice , the AGs are also conﬁgured to inspect encrypted outbound trafﬁc where the clients are conﬁgured with corresponding certiﬁcates installed at the AG .
Higher level security provided by an AG comes at the expense of additional hardware/software resources .
Further , an AG can slow down the connection , as authentication , policy checks and state maintenance are performed to keep track of every session going through the AG .
Another complexity involved with an AG is the need to conﬁgure it for each application , or possibly be implemented as multiple application speciﬁc servers .
The most widely used CG today is SOCKS .
For end user applications , it runs transparently as long as the hosts are conﬁgured to use SOCKS in place of a standard socket interface .
A CG is simple to implement compared to an AG , as it does not need to understand application layer protocols .
However , other complementary techniques are also required if all trafﬁc is encrypted .
Similar to AGs , they inspect higher layer information and many more attributes of sessions beyond what a packetﬁlter or ﬁrewall can do .
An IDS would monitor network trafﬁc with the help of agents/sensors/monitors on the network and sets off alarms when it detects ( or thinks it has ) suspicious activity .
Essentially , the IDS would compare the trafﬁc against what it considers normal trafﬁc and , using a range of techniques , would generate an alert .
For example , false positives may be generated by the IDS for legitimate hosts carrying out identical legitimate behaviour that may appear malicious .
We will now consider a situation where a legitimate domain accessed frequently by hosts in a network becomes temporarily unreachable .
The failed DNS queries to the same domain in this instance would be generated for many hosts and may appear suspicious , but should not be considered malicious activity .
The following are the two main IDS categories : • Signature-based intrusion detection systems compare monitored trafﬁc against a database containing known threat signatures similar to virus scan software .
The database has to be continually updated , however , or it will not detect new types of attacks .
Signatures can be as simple as a source/destination IP address or contain many other protocol headers including certain patterns in the payload .
We provide a simple example from an open source IDS Snort below .
The source is deﬁned for any TCP ﬂow with any address .
The rule is deﬁned to check whether the packet contains a ‘ GET ’ string and then generate an alert .
Snort provides a long set of rules but allows users to deﬁne their own .
IDS generates a heavy workload , as it has to compare huge numbers of signatures .
Speed of detection plays a key role in preventing these attacks .
Several systems deploy parallel and distributed detection systems that can cope with high trafﬁc rates on large networks and allow online detection ; others exploit parallelism at the hardware level in order to overcome processing delays so that packets and ﬂows can be processed at high speeds , thus providing faster results .
A lot of research has also focused on faster patterns or rule matching with the aim of reducing packet processing delays .
KA Network Security | October 2019 Page 575 The Cyber Security Body Of Knowledge www.cybok.org • Anomaly-based intrusion detection systems use statistical features of normal trafﬁc to compare with the monitored trafﬁc .
Attacks can be detected by monitoring hosts or networks for behaviour typical of different attacks .
A target link ﬂooding attack aims to overwhelm a particular link in the network , thus disconnecting a selected network region or server from the network .
Observing an increase in traceroute packets in the network could indicate an upcoming target link ﬂooding DDoS attack .
Despite using machine learning techniques such as Linear Regression , Neural Networks , Deep Learning etc .
Another way of classifying IDSes is the point of monitoring for malicious behaviour .
Most virus scan software would have this feature where they also monitor inbound and outbound trafﬁc in addition to the usual virus scanning .
This can be particularly helpful if the hosts have been compromised and form part of a bot to attack other servers/networks .
In contrast , a network intrusion detection system is deployed at strategic locations within the network to monitor inbound and outbound trafﬁc to and from the devices in various segments of the network .
17.8.5 An Intrusion Prevention System ( IPS ) An IPS distinguishes itself from an IDS in that it can be conﬁgured to block potential threats by setting ﬁltering criteria on routers/switches at various locations in the network .
IPS systems monitor trafﬁc in real time dropping any suspected malicious packets , blocking trafﬁc from malicious source addresses or resetting suspect connections .
In most cases , an IPS would also have IDS capabilities .
Several IDS/IPS tools generate an alert for a spam preparation stage , which is indicated by a rise in DNS MX queries that spam bots generate to discover a mail server before sending spam emails .
For example , on inspecting the headers , if an IPS system suspects an email to be unsafe , it could prevent it from being forwarded to an end user .
However , the risk of blocking legitimate trafﬁc is a huge problem due to false positives or the mis-conﬁguration of these systems .
In practice , however , IPS systems are mostly set to detect modes and start blocking trafﬁc only when the conﬁdence in the incidence being true positive becomes high .
IDS/IPS vendors provide regular signature updates and security teams will have to determine which ones to deploy , depending on the network environment that it is deployed .
IDS/IPS can also be software , deployed on the application layer on strategic endpoints .
These do not have their own OS , relying instead on the host , but can be ﬁne-tuned to support and protect the speciﬁc device it is deployed to .
There are several other mechanisms for network defence .
In highly secured environments such as defence or critical infrastructure , a device known as a Data Diode can be conﬁgured to allow a secure ﬂow of data in one direction only .
For example , a water dam could provide information on water levels to people living in the neighbourhood , but may restrict sending KA Network Security | October 2019 Page 576 The Cyber Security Body Of Knowledge www.cybok.org any information back to the dam control network .
17.8.6 Network Architecture Design These network protection tools are most effective when deployed in combination , where different local networks have distinct and focussed purposes .
Network design must balance the concerns of cost and performance against the beneﬁts of segmenting trafﬁc as much as possible .
An early example was Network Perimeter Protection .
The network perimeter protection idea comes from the ancient technique of using walls such as Hadrian ’ s Wall or the Great Wall for protecting a city .
All external untrusted users are restricted from using the services available in this zone .
The rest of the network is partitioned into several security zones by a security architect .
Each zone is managed by one or more of the IDS , IPS or AG systems based on the signiﬁcance of the information/infrastructure to be protected .
Although without any tight control of the endpoints on the network , this has proven to achieve less separation than expected .
17.9 ADVANCED NETWORK SECURITY TOPICS 17.9.1 Software Deﬁned Network , Virtualisation Software Deﬁned Networking ( SDN ) has become commonplace in data centres and other contexts for managing and controlling the network operation .
In conventional IP network , routers perform both routing and forwarding functions .
the data plane from the control plane .
The routing function and other intelligence is implemented in a centralised controller .
On receiving of a new packet , the SDN switch requests for a forwarding rule from the controller .
The switch then forwards all subsequent packets from the ﬂow using this rule .
The SDN architecture provides many new features to improve security for threat detection and attack prevention and provides innovative security services [ 1399 , 1400 ] .
For example , a DDoS attack can be inferred by the central controller more accurately , and a threat mitigation application may dynamically reprogram switches at the network perimeter to drop malicious trafﬁc ﬂows .
Another group of researchers has focussed on securing the SDN platform itself .
In a DoS attack , an adversary could advertise a fake link and force the SPTA to block legitimate ports .
SDN switches are prone to a timing side channel attack .
An attacker can send a packet and measure the time it takes the switch to process this packet .
As discussed above , for a new packet , the switch will need to fetch a new rule from the controller , thus resulting in additional delay over the ﬂows that already have rules installed at the switch .
As an example , the attacker can determine whether an exchange between an IDS and a database server has taken place , or whether a host has visited KA Network Security | October 2019 Page 577 The Cyber Security Body Of Knowledge www.cybok.org a particular website .
SDN switches store rules in the cache memory for fast lookups .
The rules are typically purged from the memory after a speciﬁed timeout period or removed due to certain other policy decisions .
The goal is to reduce capex and allow for the rapid introduction of new services to the market .
NFV researchers have proposed the deployment of these middleboxes entirely as virtualised software modules and managed via standardised and open APIs .
A large number of possible attacks concern the Virtual Machine ( Hypervisor ) as well as conﬁguring virtual functions .
For example , an attacker can compromise a VNF and spawn other new VNFs to change the conﬁguration of a network by blocking certain legitimate ports .
Authors suggest hypervisor introspection and security zoning as mitigation techniques .
17.9.2 Internet of Things ( IoT ) Security As discussed earlier , the Mirai malware shows how IoT devices such as IP cameras can be used to launch serious DDoS attacks .
As it is an application driven ﬁeld , vendors prefer ’ ﬁrst to market ’ with the resulting security being low priority .
The other reason is that IoT devices are typically low-end and have limited capability for participating in advanced security protocols , especially when they are resource-constrained through battery power etc .
Prominent IoT application layer protocols adopt either TLS or DTLS as their security protocol in combination with Public Key Crytography ( PKC ) or a Pre-Shared Key ( PSK ) suite .
These IoT application frameworks fulﬁll standard security requirements similar to traditional Internet applications .
Since TLS requires a TCP connection , DTLS is widely used for limited bandwidth and lower reliability , as it is connectionless and UDP-based .
Given the emerging characteristics of heterogeneity , energy and performance , scalability , mobility and management , it is obvious that the current PKC with an E2E infrastructure will almost certainly not scale to accommodate future IoT applications [ 1408 ] .
To classify these topics we follow the different hardware abstraction layers as introduced by the Y-chart of Gajski & Kuhn .
The different layers of the hardware design process will be introduced in section 18.1 .
It is linked with the important concept of a root of trust and associated threat models in the context of hardware security .
Next follows section 18.2 on measuring and evaluating hardware security .
The next sections gradually reduce the abstraction level .
Next section 18.4 covers hardware support for software security : what features should a programmable processor include to support software security .
Register transfer level is the next abstraction level down , covered in section 18.5 .
Focus at this level is typically the efﬁcient and secure implementation of cryptographic algorithms so that they can be mapped on ASIC or FPGA .
All implementations also need protection against physical attacks , most importantly against side-channel and fault attacks .
Section 18.7 describes entropy sources at the lowest abstraction level , close to CMOS technology .
It includes the design of random numbers generators and physically unclonable functions .
The last technical section describes aspects related to the hardware design process itself .
This chapter ends with the conclusion and an outlook on hardware security .
18.1 HARDWARE DESIGN CYCLE AND ITS LINK TO HARDWARE SECURITY Hardware security is a very broad topic and many topics fall under its umbrella .
In this section , these seemingly unrelated topics are grouped and ordered according to the design levels of abstraction as introduced by the Y-chart of Gajski & Kuhn [ 1409 ] .
While Gajski & Kuhn propose a general approach to hardware design , in this chapter it is applied to the security aspects of hardware design and it is linked to threat models and the associated root of trust .
18.1.1 Short background on the hardware design process Design abstraction layers are introduced in hardware design to reduce the complexity of the design .
As indicated in 18.1 , the lowest abstraction level a designer considers are individual transistors at the center of the ﬁgure .
These transistors are composed together to form basic logic gates , such as NAND , NOR gates or ﬂip-ﬂops , called the logic level .
These modules are then composed to form processors , speciﬁed by instruction sets , upon which applications and algorithms can be implemented .
By going up in the abstraction layers , details of underlying layers are hidden .
This reduces design complexity at higher abstraction layers .
The abstraction layers are represented by concentric circles in ﬁgure 18.1 .
Typically one starts with the speciﬁcations at the top of the behavioral domain .
A structural component at one abstraction level becomes a behavioral component at one level down .
The crypto-algorithms are provided as a behavioral speciﬁcation to the hardware designer , who has the choice of implementing it as a dedicated co-processor , as an assembly program , or support it with a set of custom instructions .
Depending on costs and volumes , a choice of a target CMOS technology or an FPGA platform is made .
Essential for the division in design abstraction layers , is the creation of models on how components behave .
to simulate the throughput or energy consumption of a arithmetic unit , quality models of the underlying gates need to be available .
KA Hardware Security | October 2019 Page 583 The Cyber Security Body Of Knowledge www.cybok.org 18.1.2 Root of trust In the context of security , a root of trust is a model of an underlying component for the purpose of security evaluation .
The designer uses one or multiple components to construct a security function , which then deﬁnes the trusted computing base .
For the TPM designer , the TPM is composition of smaller components which are composed together to provide security functionality .
At the lowest hardware abstraction layers , basic roots of trust are the secure storage of the key in memory or the quality of the True Random Number Generator .
Hardware security is used as an enabler for software and system security .
For this reason , hardware provides basic security services such as secure storage , isolation or attestation .
The software or system considers the hardware as the trusted computing base .
And thus from a systems or application view point , hardware has to behave as a trusted component .
However , the hardware implementation can violate the trust assumption .
Trojan circuits or side-channel attacks could leak the key or other sensitive data to an attacker .
Moreover hardware needs security at all abstraction layers .
Therefore , at every abstraction layer , a threat model and associated trust assumptions need to be made .
An alternative deﬁnition for a root of trust in the context of design abstraction layers is therefore : “ A root of trust is a component at a lower abstraction layer , upon which the system relies for its security .
Its trustworthiness can either not be veriﬁed , or it is veriﬁed at a lower hardware design abstraction layer .
When using a root of trust , it is assumed that the threat model is not violated .
This means that the threat model is also linked to the hardware abstraction layers .
If we consider a root of trust at a particular abstraction layer , then all components that constitute this root of trust , are also considered trusted .
Example 1 : security protocols assume that the secret key is securely stored and not accessible to the attacker .
The root of trust , upon which the protocol relies , is the availability of secure memory to guard this key .
The hardware designer has to decompose this requirement for a secure memory into a set of requirements at a lower abstraction layer .
What type of memory will be used ?
On which busses will the key travel ?
Which other hardware components or software have access to the storage ?
Example 2 : It is during this translation of higher abstraction layer requirements from protocol or security application developers into lower abstraction layers for the hardware designers that many security vulnerabilities occur .
Implementations of cryptographic algorithms used to be considered black boxes to the attacker : only inputs/outputs at the algorithm level are available to mount mostly mathematical cryptanalysis attacks .
Taking side-channel leakage into account the attacker has the algorithm level information as KA Hardware Security | October 2019 Page 584 The Cyber Security Body Of Knowledge www.cybok.org well as the extra timing , power , electro-magnetic information as observable from the outside of the chip .
Thus the attacker model moves from black box to gray box .
It is still assumed that the attacker does not know the details of the internals , e.g .
the contents of the key registers .
The ISA is what is visible to the software programmer and the implementation of the ISA is left to the hardware designer .
The ISA used to be considered the trust boundary for the software designer .
18.1.4 Root of trust , threat model and hardware design abstraction layers The decomposition in abstraction layers , in combination with Electronic Design Automation ( EDA ) tools , is one of the main reasons that the exponential growth of Moore ’ s law was sustainable in the past decades and it still is .
This approach works well when optimizing for performance , area , energy or power consumption .
Yet for hardware security , no such general decomposition exists .
In this chapter , we propose to organise the different hardware security topics , their associated threat models and root of trust according to the hardware design abstraction layers , as there is no known other general body of knowledge available to organize the topics .
This organization has the advantage that it can be used to identify the state of the art on different subtopics of hardware security .
As an example , in the speciﬁc context of hardware implementations of cryptographic algorithms , the state of the art is well advanced and robust countermeasures exist to protect cryptographic implementations against a wide range of side-channel attacks , as shown in detail in section 18.5 .
to isolate process related data or to provide secure execution , new security hazards continue to be discovered on a regular basis .
The highest level ( system and software ) sits on top of the hardware platform .
Thus the secure platform is the root of trust , providing security functionality .
The second column describes the functionality provided by the root of trust .
The third column describes how this functionality might be implemented .
at the highest abstraction layer this might be by providing a Trusted Execution Module or a secure element , etc .
The fourth column describes the threat models and attack categories at that abstraction layer .
The last column describes typical design activities at this particular design abstraction layer .
This exercise is repeated for each abstraction layer and described in detail in each of the following sections .
At the processor level , one can distinguish general purpose programmable processors and domain speciﬁc processors .
General purpose processors should support a wide range of applications , which unfortunately typically include software vulnerabilities .
Hardware features are added to address these software vulnerabilities , such as a shadow stack or measures to support hardware control ﬂow integrity .
Domain speciﬁc processors typically focus on KA Hardware Security | October 2019 Page 585 The Cyber Security Body Of Knowledge www.cybok.org Abstraction level Root of trust functionality Structural ( how ) examples Example Threats Typical HW design activities System and application Secure platforms e.g .
shadow stack SW vulnerabilities ISA , HW/SW co-design Processor domain speciﬁc Crypto speciﬁc RTL Timing attacks Constant number of clock cycles Register Transfer Crypto speciﬁc Building blocks , Side Channel Attack , Logic synthesis Logic Resistance to SCA , Power , EM , fault Masking , Circuit styles Side Channel attack , fault FPGA tools , standard cell design Circuit and technology Source of entropy TRNG , PUF , Secure SRAM Temperature , glitches SPICE simulations Physical Tamper Resistance Shields , sensors Probing , heating Layout activities Table 18.1 : Design abstraction layers linked to threat models , root of trust and design activities a limited functionality .
Typical examples are co-processors to support public key or secret key cryptographic algorithms .
Time at the processor level is typically measured in instruction cycles .
Both general purpose and domain speciﬁc processors are composed together from computational units , multipliers and ALU ’ s , memory and interconnect .
These modules are typically described at the register transfer level : constant-time and resistance against side-channel attacks become the focus .
Time at this level is typically measured in clock cycles .
Time is typically measured in absolute time ( nsec ) based on the available standard cell libraries or FPGA platforms .
The design of entropy sources requires knowledge and insights into the behavior of transistors and the underlying Complementary Metal-Oxide-Semiconductor ( CMOS ) technology.The design of these hardware security primitives is therefore positioned at the circuit and transistor level .
Similarly the design of sensors and shields against physical tampering require insight into the technology .
At the circuit and technology level it is measured in absolute time , e.g .
nsec delay or GHz clock frequency .
The idea is to illustrate each abstraction layer with an example .
In the next sections , the hardware security goals and their associated threat models will be discussed in detail in relation to and relevance for each abstraction layer .
KA Hardware Security | October 2019 Page 586 The Cyber Security Body Of Knowledge www.cybok.org 18.2 MEASURING HARDWARE SECURITY Depending on the commercial application domain , several industrial and government organizations have issued standards or evaluation procedures .
FIPS 140-2 mostly focuses on the implementation security of cryptographic algorithms .
Common Criteria are applicable to IT security in general .
The following gives a description of the four levels from a physical hardware security point of view .
Level 3 also requires the tamper evidence , but on top requires tamper resistance .
Tamper evidence means that there is a proof or testimony that tampering with a hardware module has happened .
A light sensor might observe that the lid of a chip package was lifted .
Tamper resistance means that on top of tamper evidence , protection mechanisms are added to the device .
by extra coating or dense metal layers , it is difﬁcult to probe the key registers .
Level 4 increases the requirements such that the cryptographic module can operate in physically unprotected environments .
If any of these physical components depend on sensitive data being processed , information is leaked .
Since the device is under normal operation , a classic tamper evidence mechanism will not realize that the device is under attack .
CC is a very generic procedure applicable to the security evaluation of IT products .
Several parties are involved in this procedure .
The customer will deﬁne a set of security speciﬁcations for its product .
The manufacturer will design a product according to these speciﬁcations .
An independent evaluation lab will verify if the product fulﬁlls the claims made in the security requirements .
Certiﬁcation bodies will issue a certiﬁcation that the procedure was correctly followed and that the evaluation lab indeed conﬁrmed the claims made .
Depending on the amount of effort put into the security evaluation , the CC deﬁnes different Evaluation Assurance Levels ( EALs ) .
CC further subdivides the process of evaluation into several classes , where most of the classes verify the conformity of the device under test .
It is the most important class from a hardware security viewpoint as it searches for vulnerabilities and associated tests .
It will assign a rating on the difﬁculty to execute the test , called the identiﬁcation , and the possible beneﬁt an attacker can gain from the penetration , called the exploitation .
The difﬁculty is a function of the time required to perform the attack , the expertise of the attacker from layman to multiple experts , how much knowledge of the device is required from simple public information to detailed hardware source code , the number of samples required , and the cost and availability of equipment to perform the attack , etc .
A high difﬁculty level will result in a high score and a high level of the AVA class .
The highest score one can obtain is an AVA level of 5 , which is required to obtain a top EAL score .
Its usage is well established in the ﬁeld of smartcards and secure elements as they are used in telecom , ﬁnancial , government ID ’ s applications .
For certain classes of applications minimum sets of requirements are deﬁned into protection proﬁles .
Since certiﬁcation comes from one body , there exist agreements between countries so that the certiﬁcations in one country are recognized in other countries .
As an exception EMVCo is a private organization to set the speciﬁcations for worldwide interoperability of payment transactions .
It has its own certiﬁcation procedure similar to CC .
Please note that the main purpose of a common criteria evaluation is to verify that an IT product delivers the claims promised in the proﬁle .
It does not mean that there are no vulnerabilities left .
Several levels of threat model for IoT are possible : from only remote internet access , over various remote software attack options , to also physical attack resistance .
A comprehensive set of security functional requirements are deﬁned : identiﬁcation and attestation , product lifecycle , secure communication , software and physical attack resistance , cryptographic functionality including random number generation , and some compliance functionality to e.g .
provide secure encrypted storage or provide reliable time .
Similar to Common Criteria , SESIP provides several levels of assurance .
The highest level of SESIP consists of a full CC evaluation similar to smart cards or secure elements .
The levels in between cover from a black box penetration testing over white box penetration testing with or without time limitations .
At this high level of abstraction the system designer receives a complete chip or board as trusted computing base .
The system designers assume that the trusted root delivers a set of cryptographic functions , protected by the hardware and software inside the physical enclosure .
Common to these platforms is that they are stand-alone pieces of silicon with a strict access policy .
Depending on the provided functionality , the hardware tamper resistance and protection levels , and the communication interface , these secure platforms are used in different application ﬁelds ( automotive , ﬁnancial , telecom ) .
Three important platforms are the Hardware Security Module ( HSM ) , the Subscriber Identiﬁcation Module or SIM and the Trusted Platform Module ( TPM ) .
a set of public key and secret key algorithms , together with secure key management including secure generation , storage and deletion of keys .
In previous generations , inside the casing multiple components reside on one board .
What exactly is covered under HSM functionality depends on the application domain .
Therefore , compliance with security levels is also evaluated by specialized independent evaluation labs according to speciﬁc protection proﬁles .
The main difference with an HSM are cost , size , and form factor .
The main difference between a smart card and a secure element sits in the form factor and the different markets they address .
Secure elements are a more generic term , while smart cards have the very speciﬁc form factor of a banking card .
They are produced in large volumes and need to be very cheap as they are used for SIM cards in cell phones and smart phones .
They are also used in banking cards , pay-TV systems access cards , national identity cards and passports , and recently in IOT devices , vehicular systems and so on .
Tamper resistance and physical protection are essential to secure elements .
A typical embedded secure element is one integrated circuit with no external components .
Building a secure element is a challenge for a hardware designer , as one needs to combine security with non-security requirements of embedded circuits : small form factor ( no external memory ) , low power and/or low energy consumption in combination with tamper resistance and resistance against physical attacks , such as sidechannel and fault attacks ( see section 18.6 ) .
Besides these three basic functions , other functionality of TPMs is being used : access to speciﬁc cryptographic functions , secure key storage , support for secure login , etc .
Its architecture at minimum consists of an embedded micro-controller , several crypto coprocessors , secure volatile and non-volatile storage for root keys and a high quality true random number generator .
Next to its main scope of integrity protection , TPM also has applications in disk encryption , digital rights management , etc .
The most recent TPM2.0 version broadens the application scope from PC oriented to also supporting networking , embedded , automotive , IoT , and so on .
It also provides a more ﬂexible approach in the functionality included .
Four types of TPM are identiﬁed : the dedicated integrated circuit ‘ discrete element ’ TPM provides the highest security level .
One step lower in protection level is the ‘ integrated TPM ’ as an IP module in a larger SoC .
The lowest levels of protection are provided by the ﬁrmware and software TPM .
The adoption of TPMs has evolved differently from what was originally the focus of the TCG .
Originally , the main focus was the support of a secure boot and the associated software stack , so that a complete measurement of the software installed could be made .
The problem is that the complexity of this complete software base grows too quickly , making it too difﬁcult to measure completely all variations in valid conﬁgurations .
Thus TPMs are less used to protect a complete software stack up to the higher layers of software .
Still most new PCs now have TPMs but they are used to protect the encryption keys , avoid ﬁrmware roll-back , and assist the boot process in general .
hardware and its enclosed embedded software , are part of the trusted computing base .
One level down on the abstraction layers , we make the assumption that all hardware is trusted , while software is no longer trusted .
To prevent the exploitation or to mitigate the effects of software vulnerabilities , a large variety of hardware modiﬁcations/additions to the processor architecture have been proposed in literature and have been included in commercial processors .
We call this abstraction layer the hardware/software boundary : hardware forms the trust boundary , while software is no longer trusted .
These security additions to the hardware typically have a cost in extra area and loss in performance .
In a traditional computer architecture , usually the OS kernel is part of the Trusted Computing Base ( TCB ) , but the rest of the software is not .
• With isolation , a hardware mechanism is added that controls access to pieces of software and associated data .
Isolation separates two parties : a software module might need protection from the surrounding software is one case .
The opposite case , if we want to limit the effects of possibly tainted software to its environment , it will be sandboxed or be put into a ‘ compartment .
’ Protected Module Architectures are a hardware only solution : the OS is not part of the TCB .
Attestation can be local or remote .
Local attestation means that one software module can attest its state to another one on the same compute platform .
Remote attestation means that a third party , outside the compute platform can get some guarantee about the state of a processor .
In the context of general purpose computing , Virtual Machines ( VMs ) and Hypervisors have been introduced to support multiple operating systems on one physical processor .
This sharing of resources improves efﬁciency and reuse .
It can however only be realized by a secure and efﬁcient sharing of physical memory : virtual machines should only be allowed to use the portions of physical memory assigned to it .
The organization and details of virtual memory are out of scope of hardware security and part of the Operating Systems & Virtualisation Knowledge Area ( Chapter 11 ) .
The hardware supports protection by providing privileged instructions , control and status registers and sometimes support for multiple parallel threads .
In the context of embedded micro-controllers , with no operating system , and only one applica- KA Hardware Security | October 2019 Page 591 The Cyber Security Body Of Knowledge www.cybok.org tion , the hardware support could be limited to only machine level support .
Memory protection could be added as an optional hardware module to the processor .
Other more advanced security objectives to support software security might include : • Sealed storage is the process of wrapping code and/or data with certain conﬁguration , process or status values .
Dynamic root of trust in combination with a late launch guarantees that even if the processor starts from an unknown state , it can enter a ﬁxed known piece of code and known state .
This typically requires special instructions to enter and exit the protected partition .
• Memory protection refers to the protection of data when it travels between the processor unit and the on-chip or off-chip memory .
It protects against bus snooping or sidechannel attacks or more active fault injection attacks .
• Control ﬂow integrity is a security mechanism to prevent malware attacks from redirecting the ﬂow of execution of a program .
In hardware , the control ﬂow of the program is compared on-the-ﬂy at runtime with the expected control ﬂow of the program .
• Information ﬂow analysis is a security mechanism to follow the ﬂow of sensitive data while it travels through the different processor components , from memory to cache over multiple busses into register ﬁles and processing units and back .
In the next subsections a representative set of hardware approaches to address the above software security challenges are presented .
Some hardware techniques address multiple security objectives .
Some are large complex approaches , others are simple dedicated hardware features .
Mostly , they offer a weaker level of security as they are not rooted in a hardware root of trust .
for control ﬂow integrity , software-only approaches might instruct the software code to check branches or jumps , while hardware support might calculate MACs on the ﬂy and compare these to stored associated MACs .
TEE has since evolved and covers in general the hardware modiﬁcations made to processors to provide isolation and attestation to software applications .
There is a large body of knowledge both from the industrial side as well as from the academic side .
It is important that the TEE is isolated from the so-called Rich Execution Environment ( REE ) , which includes the untrusted OS .
The reasoning behind this split is that it is impossible to guarantee secure execution and to avoid malware in the normal world due to the complexity of the OS and all other applications running there .
The rich resources are accessible from the TEE , while the opposite is not possible .
Global Platform does not specify the speciﬁcs on how these security properties should be implemented .
Three main hardware options are suggested .
It assumes that the package of the integrated circuit is a black box [ 1421 ] and thus secure storage is assumed by the fact that the secure asset remains inside the SoC .
It follows the procedures of common criteria assurance package EAL2 with some extra features .
It pays extra attention to the evaluation of the random number generator and the concept of monotonic increasing time .
18.4.2 IBM 4758 Secure coprocessor An early example , even before the appearance of the TEE of Global Platform is the IBM 4758 secure processor .
All of these components were enclosed in a box with tamper resistant and tamper evidence measures .
It is part of a system of ARM processors integrated into System on a Chips ( SoCs ) mostly used for smartphones .
The TEE is the secure part of the processor and it runs a smaller trusted OS .
It is isolated from the non-secure world , called the Rich Execution Environment , which runs the untrusted rich OS .
The AXI bus transactions are enhanced with a NS bit so that it can block the access of secure world resources by non-secure resources .
Each AXI transaction comes with this bit set or reset .
When the processor runs in the secure mode , then the transaction comes with the NS bit set to zero , which gives it access to both secure and non-secure resources .
When the processor runs in normal mode , it can only access resources from the normal world .
These caches store an extra information bit to indicate if the code can be accessed by a secure or non-secure master .
This is supported by a special monitor mode which exists in the secure world .
The split applied by ARM Trustzone is however a binary split .
Applications from different vendors could co-exist together in the secure world and so if one trusted component violates the system ’ s security , the security can no longer be guaranteed .
To address this issue , protected module architectures are introduced .
Trusted Execution Environments are also being created in open-source context , more specifically in the context of the RISC-V architecture .
KA Hardware Security | October 2019 Page 593 The Cyber Security Body Of Knowledge www.cybok.org 18.4.4 Protected Module Architectures and HWSW co-design solutions If multiple software applications want to run on the same platform isolated from each other , then hardware needs to isolate them from each other at a more ﬁne granularity .
The basic idea is that small software modules can run protected from all other software running on the processor .
And because they are small , their properties and behavior can be veriﬁed more thoroughly .
The protection is provided by extra features added to the hardware in combination with an extremely small trusted software base if needed .
for TPM usage , to CPU package only for SGX and other projects .
The software TCB varies from a complete secure world as is the case for TrustZone to privileged containers in the case of SGX or a trusted hypervisor , OS or security monitor .
Even more advanced are solutions with a zero trusted software base : only the hardware is trusted .
It implements a program counter based memory access control system .
Extra hardware is provided to compare the current program counter with stored boundaries of the protected module .
Access to data is only possible if the program counter is in the correct range of the code section .
Progress of the program in the code section is also controlled by the hardware so that correct entry , progress and exit of the module can be guaranteed .
Software modules of an application are placed in memory enclaves .
Enclaves are deﬁned in the address space of a process , but access to enclaves is restricted .
Enclaves are created , initialized , and cleared by possibly untrusted system software , but operating in the enclave can only be done by the application software .
Minimizing the extra hardware to support SGX , and especially avoiding performance degradation is an important goal .
The details of the hardware micro-architecture have not been disclosed : yet its most important parts are a memory encryption unit , a series of hardware enforced memory access checks and secure memory range registers [ 1422 ] .
for platforms on which a complex software stack will run .
In literature , more solutions are proposed to provide extremely light weight solutions to support speciﬁc security requests .
To protect against speciﬁc software attacks , more individual hardware countermeasures have been introduced .
One example is a hardware shadow stack : to avoid buffer overﬂow attacks and to protect control ﬂow integrity , return addresses are put on both the stack and the shadow stack .
When a function loads a return address , the hardware will compare the return address of the stack to that of the shadow stack .
Another example is the protection of jump and return addresses to avoid buffer overﬂow attacks and other abuses of pointers .
A novel recent technique is the use of pointer authentication .
A challenge for these algorithms is that they should create the authentication tag with very low latency to ﬁt into the critical path of a microprocessor .
These tags are calculated and veriﬁed on the ﬂy .
Address Space Layout Randomization or Stack canaries area general software technique : its aim is to make it hard to predict the destination address of the jump .
18.5 HARDWARE DESIGN FOR CRYPTOGRAPHIC ALGORITHMS AT RTL LEVEL The hardware features discussed so far are added to general purpose compute platforms , i.e .
General purpose means that a platform is created of which the hardware designer does not know the future applications that will run on it .
A second class of processors are domain-speciﬁc processors : they have limited or no programmability and designed for one or a small class of applications .
18.5.1 Design process from RTL to ASIC or FPGA When a dedicated processor is built for one or a class of cryptographic algorithms , this gives a lot of freedom to the hardware designer .
Typically , the hardware designer will , starting from the cryptographic algorithm description , come up with hardware architectures at the Register Transfer Level ( RTL ) taking into account a set of constraints .
Area is measured by gate count at RTL level .
Power consumption is important for cooling purposes and measured in Watt .
It is often expressed in the amount of operations or amount of bits that can be processed per unit energy .
The resistance to side channel attacks is measured by the number of measurements or samples required to disclose the key or other sensitive material .
Flexibility and programmability are difﬁcult to measure and are typically imposed by the application or class of applications that need to be supported : will the hardware support only one or a few algorithms , encryption and/or decryption , modes of operation , initialization , requirements for key storage , and so on .
A hardware architecture is typically described in a Hardware Description Language such as Verilog of VHDL .
Starting from this description the two most important hardware platforms available to a hardware designer are ASIC and FPGA .
By changing the bit-stream the functionality of the FPGA changes .
From the viewpoint of the Register Transfer Level ( RTL ) the actual design process for either FPGA or ASIC doesn ’ t differ that much .
Similar design options are available : the designer can decide to go for serial or parallel architectures , making use of mul- KA Hardware Security | October 2019 Page 595 The Cyber Security Body Of Knowledge www.cybok.org tiple design tricks to match the design with the requirements .
The most well-known tricks are to use pipelining to increase throughput , or unrolling to reduce latency , time multiplexing to reduce area , etc .
Implementation results should be compared not only on the number of operations , but also on memory requirements ( program memory and data memory ) , throughput and latency requirements , energy and power requirements , bandwidth requirements and the ease with which side-channel and fault attack countermeasures can be added .
Please note that this large body of knowledge exists for implementations that focus on efﬁciency .
18.5.2 Cryptographic algorithms at RTL level Cryptographic implementations are subdivided in several categories , enumerated below .
The details of the cryptographic algorithms themselves are discussed in the Cryptography Knowledge Area ( Chapter 10 ) .
Here only remarks related to the RTL implementation are made .
In this section only notes speciﬁc to the hardware implementations are made .
• Secret key algorithms : both block ciphers and stream ciphers result usually in compact and fast implementations .
Feistel ciphers are chosen for very area constrained designs as the encryption and decryption hardware is the same .
not the case for the AES algorithm for which encryption and decryption require different units .
Focus in these cases is mostly on area cost .
Latency is deﬁned as the time difference between input clear text and corresponding encrypted output or MAC .
Having a short latency is important in realtime control systems , automotive , industrial IoT but also in memory encryption , control ﬂow integrity applications etc .
• Secret key : block ciphers by themselves are not directly applicable in security application .
They need to be combined with modes of operation to provide conﬁdentiality or integrity , etc .
In this context efﬁcient implementations of authenticated encryption schemes are required : this is the topic of the CAESAR competition [ 1428 ] .
From an implementation viewpoint , the sequential nature of the authenticated encryption schemes makes it very difﬁcult to obtain high throughputs as pipelining can not directly be applied .
• Hash algorithms require typically a much larger area compared to secret key algorithms .
Especially the SHA3 algorithm and its different versions are large in area and slow in execution .
To obtain the required high throughputs , massive parallelism and pipelining is applied .
This KA Hardware Security | October 2019 Page 596 The Cyber Security Body Of Knowledge www.cybok.org is however limited as hash algorithms are recursive algorithms and thus there is an upper bound on the amount of pipelining that can be applied [ 1429 ] .
Cryptocurrencies form part of the more general technology of distributed ledgers , which is discussed in the Distributed Systems Security Knowledge Area ( Chapter 12 ) .
• The computational complexity of public key algorithms is typically 2 or 3 orders of magnitude higher than secret key and thus its implementation 2 to 3 orders slower or larger .
• Algorithms resistant to attacks of quantum computers , aka post-quantum secure algorithms , are the next generation algorithms requiring implementation in existing CMOS ASIC and FPGA technology .
Computational bottle-necks are the large multiplier structures , with/without the Number Theoretic Transform , the large memory requirements and the requirements on random numbers that follow speciﬁc distributions .
Thus it is expected that after the algorithms are decided , implementations in hardware will follow .
• Currently , the most demanding implementations for cryptographic algorithms are those used in homomorphic encryption schemes : the computational complexity , the size of the multipliers and especially the large memory requirements are the challenges to address [ 1433 ] .
18.6 SIDE-CHANNEL ATTACKS , FAULT ATTACKS AND COUNTERMEASURES This section ﬁrst provides an overview of physical attacks on implementations of cryptographic algorithms .
The second part discusses a wide range of countermeasures and some open research problems .
Physical attacks , mostly side-channel and fault attacks , were originally of great concern to the developers of small devices that are in the hands of attackers , especially smart-cards and pay-TV systems .
The importance of these attacks and countermeasures is growing as more electronic devices are easily accessible in the context of the IoT .
18.6.1 Attacks At the current state of knowledge , cryptographic algorithms have become very secure against mathematical and cryptanalytical attacks : this is certainly the case for algorithms that are standardized or that have received an extensive review in the open research literature .
Currently , the weak link is mostly the implementation of algorithms in hardware and software .
Information leaks from the hardware implementation through side-channel and fault attacks .
A distinction is made between passive or side-channel attacks versus active or fault attacks .
A second distinction can be made based on the distance of the attacker to the device : attacks can occur remotely , close to the device still non-invasive to actual invasive attacks .
More details on several classes of attacks are below .
Passive Side Channel Attacks General side-channel attacks are passive observations of a compute platform .
Through data dependent variations of execution time , power consumption or electro-magnetic radiation of the device , the attacker can deduce information of secret internals .
Variations of execution time , power consumption or electro-magnetic radiations KA Hardware Security | October 2019 Page 597 The Cyber Security Body Of Knowledge www.cybok.org are typically picked up in close proximity of the device , while it is operated under normal conditions .
It is important to note that the normal operation of the device is not disturbed .
Side channel attacks based on variations on power consumption have been extensively studied .
They are performed close to the device with access to the power supply or the power pins .
In SPA , the idea is to ﬁrst study the target for features that depend on the key .
a typical target in timing and power attacks are if-thenelse branches that are dependent on key bits .
In public key algorithm implementations , such as RSA or ECC , the algorithm runs sequentially through all key bits .
When the if-branch takes more or less computation time than the else-branch this can be observed from outside the chip .
SPA attacks are not limited to public key algorithms , they have also been applied to secret key algorithms , or algorithms to generate prime numbers ( in case they need to remain secret ) .
So with knowledge of the internal operation of the device , SPA only requires to collect one or a few traces for analysis .
With DPA , the attacker collects multiple traces , ranging from a few tens for unprotected implementations to millions in case of protected hardware implementations .
In this situation , the attacker exploits the fact that the instantaneous power consumption depends on the data that is processed .
The same operation , depending on the same unknown sub-key , will result in different power consumption proﬁles if the data is different .
The attacker will also built a statistical model of the device to estimate the power consumption as a function of the data and the different values of the subkey .
Statistical analysis on these traces based on correlation analysis , mutual information and other statistical tests are applied to correlate the measured values to the statistical model .
Side channel attacks based on Electro-Magnetic radiations have been recognized early-on in the context of military communication and radio equipment .
It consists of speciﬁcations on the protection of equipment against unintentional electro-magnetic radiation but also against leakage of information through vibrations or sound .
Electro-Magnetic radiation attacks can be mounted from a distance , as explained above , but also at close proximity to the integrated circuit .
Electro-Magnetic probing on top of an integrated circuit can release very localized information of speciﬁc parts of an IC by using a 2D stepper and ﬁne electro-magnetic probers .
Thus electro-magnetic evaluation has the possibility to provide more ﬁne grained leakage information compared to power measurements .
When the execution time of a cryptographic calculation or a program handling sensitive data , varies as a function of the sensitive data , then this time difference can be picked up by the attacker .
A timing attack can be as simple as a key dependent different execution time of an if-branch versus an elsebranch in a ﬁnite state machine .
This template is used to study the behavior of the device for all or a large set of inputs and secret data values .
One or a few samples of the target device are then compared to the templates in the database to deduce secret information from the device .
Template attacks are typically used when the original device has countermeasures against multiple executions .
it might have an internal counter to log the number of failed attempts .
As machine learning and AI KA Hardware Security | October 2019 Page 598 The Cyber Security Body Of Knowledge www.cybok.org techniques become more powerful , so will the attack possibility with template attacks .
The problem of information leaks and the difﬁculty of conﬁnement between programs was already identiﬁed early on in [ 1438 ] .
Later timing variations in cache hits and misses became an important class of timing attacks [ 1439 ] .
The strength of the attacks sits in the fact that they can be mounted remotely from software .
Modern processors include multiple optimization techniques to boost performance not only with caches , but also speculative execution , out-of-order execution , branch predictors , etc .
When multiple processes run on the same hardware platform , virtualization and other software techniques isolates the data of the different parties in separate memory locations .
Yet , through the outof-order execution or speculative execution ( or many other variants ) the hardware of the processor will access memory locations not intended for the process by means of so-called transient instructions .
These instructions are executed but never committed .
They have however touched memory locations , which might create side channel effects , such as variations in access time , and thus leak information .
The result is that the computation itself or the program control ﬂow is disturbed .
Faulty or no outputs are released .
Even if no output is released or the device resets itself , this decision might leak sensitive information .
With one faulty and one correct result signature , and some simple mathematical calculations , the secret signing key can be derived .
These require close proximity to the device but are non-invasive .
By repeating reading speciﬁc locations in DRAM memory , neighboring locations will loose their values .
Thus by hammering certain locations , bit ﬂips will occur in nearby locations .
With more expensive equipment , and with opening the lid of the integrated circuit or etching the silicon down , even more detailed information of the circuit can be obtained .
The latter are typically equipment that has been designed for chip reliability and failure analysis .
This equipment can also be used or misused for reverse engineering .
18.6.2 Countermeasures There are no generic countermeasures that resist all classes of side-channel attacks .
what is and what is not included in the root of trust ) , countermeasures have been proposed at several levels of abstraction .
The most important categories are summarized below .
To resist timing attacks , the ﬁrst objective is to provide hardware that executes the application or program in constant time independent of secret inputs , keys and internal state .
Depending on the time granularity of the measurement equipment of the attacker , constant time KA Hardware Security | October 2019 Page 599 The Cyber Security Body Of Knowledge www.cybok.org countermeasures also need to be more ﬁne grained .
At the processor architecture level , constant time means a constant number of instructions .
At the RTL level , constant time means a constant number of clock cycles .
At logic and circuit level , constant time means a constant logic depth or critical path independent of the input data .
At instruction level , constant time can be obtained by balancing execution paths and adding dummy instructions .
through caches , make constant time implementations extremely difﬁcult to obtain .
At RTL level , we need to make sure that all instructions run in the same number of clock cycles .
dummy operations or dummy gates , depending on the granularity level .
Providing constant time RTL level and gate level descriptions is however a challenge as design tools , both hardware and software compilers , will for performance reasons synthesize away the dummy operations or logic which were added to balance the computations .
Randomisation is a technique that can be applied at algorithm level : it is especially popular for public key algorithms , which apply techniques such as scalar blinding , or message blinding [ 1445 ] .
Randomisation applied at register transfer and gate level is called masking .
Masking schemes randomise intermediate values in the calculations so that their power consumption can no longer be linked with the internal secrets .
A large set of papers on gate level masking schemes is available , ranging from simple Boolean masking to threshold implementations that are provable secure under certain leakage models [ 1446 ] .
Randomisation has been effective in practice especially as a public key implementation protection measure .
The protection of secret key algorithms by masking is more challenging .
Some masking schemes require a huge amount of random numbers , others assume leakage models that do not always correspond to reality .
Hiding is another major class of countermeasures .
The idea is to reduce the signal to noise ratio by reducing the signal strength .
Shielding in the context of TEMPEST is one such example .
Similarly , at gate level , reducing the power signature or electro-magnetic signature of standard cells or logic modules , will increase the resistance against power or electro-magnetic attacks .
Simple techniques such as using a jittery or drifting clock , and large decoupling capacitances will also reduce the signal to noise ratio .
Therefore , if there is a risk that an encryption key leaks from an embedded device , a cryptographic protocol that changes the key at a sufﬁciently high frequency , will also avoid side-channel information leakage .
Thus protecting against micro-architectural attacks after fabrication by means of software patches and updates is extremely difﬁcult and mostly at the cost of reduced performance [ 1411 ] .
The main difference is that the translation from instructions to micro-code is a company secret , and thus for the user it looks like a hardware update .
Providing generic solutions to programmable hardware is a challenge as it is unknown beforehand which application will run .
Solutions to this problem will be a combined effort between hardware and software techniques .
KA Hardware Security | October 2019 Page 600 The Cyber Security Body Of Knowledge www.cybok.org Protection against fault attacks are made at the register transfer level , as well as at the circuit level .
At RTL , protection agains fault attacks is mostly based on redundancy either in space or in time and by adding checks based on coding , such as parity checks .
The price is expensive as calculations are performed multiple times .
One problem with adding redundancy is that it increases the attack surface of side-channels .
At circuit level , monitors on the clock or power supply , might detect deviations from normal operations and raise an alarm .
Many type of circuit level sensors are added to integrated circuits .
Examples are light sensors that detect that a lid of a package has been opened .
Mesh metal sensors which are laid-out in top level metal layers can detect probing attacks .
Temperature sensors detect heating or cooling of the integrated circuit .
Antenna sensors to detect electro-magnetic probes close to the surface have been developed : these sensors measure a change in electro-magnetic ﬁelds .
And sensors that detect manipulation of the power supply or clock can be added to the device .
Note that adding sensors to detect active manipulation can again leak extra information to the side channel attacker .
Joint countermeasures against side-channel and fault attacks are challenging and an active area of research .
18.7 ENTROPY GENERATING BUILDING BLOCKS : RANDOM NUMBERS , PHYSICALLY UNCLONABLE FUNCTIONS Sources of entropy are essential for security and privacy protocols .
In this section two important sources of entropy related to silicon technology are discussed : random number generators and physically unclonable functions .
18.7.1 Random number generation Security and privacy rely on strong cryptographic algorithms and protocols .
Random numbers are also used to create masks in masking countermeasures , random shares in multi party computation , zero-knowledge proofs , etc .
In this section the focus is on cryptographically secure random numbers as used in security applications .
The design , properties and testing of random numbers is described in detail by important standards , issued in the US by NIST .
KA Hardware Security | October 2019 Page 601 The Cyber Security Body Of Knowledge www.cybok.org An ideal RNG should generate all numbers with equal probability .
Secondly , these numbers should be independent from previous or next numbers generated by the RNG , called forward and backward secrecy .
The probabilities are veriﬁed with statistical tests .
Each standard includes a large set of statistical tests aimed at ﬁnding statistical weaknesses .
Not being able to predict future values or derive previous values is important not only in many security applications , e.g .
when this is used for key generation , but also in many gaming and lottery applications .
Pseudo-random number generators are deterministic algorithms that generate a sequence of bits or numbers that look random but are generated by a deterministic process .
Since a PRNG is a deterministic process , when it starts with the same initial value , then the same sequence of numbers will be generated .
Therefore it is essential that PRNG starts with a different start-up value each time the PRNG is initiated .
A PRNG is called cryptographically secure if the attacker , who learns part of the sequence , is not able to compute any previous or future outputs .
Cryptographically secure PRNGs rely on cryptographic algorithms to guarantee this forward and backward secrecy .
Forward secrecy requires on top a regular reseeding to introduce new freshness into the generator .
Hybrid RNG have an additional non-deterministic input to the PRNG .
PRNGs provide conditional security based on the computational complexity of the underlying cryptographic algorithms .
In contrast , ideal true random number generators provide unconditional security as they are based on unpredictable physical phenomena .
Thus their security is guaranteed independent of progress in mathematics and cryptanalysis .
The core of a true random number generator consists of an entropy source , which is a physical phenomena with a random behavior .
In electronic circuits , noise or entropy sources are usually based on thermal noise , jitter and metastability .
These noise sources are never perfect : the bits they generate might show bias or correlation or other variations .
Therefore , they are typically followed by entropy extractors or conditioners .
These building blocks improve the entropy per bit of output .
But as the entropy extractor are deterministic processes , they can not increase the total entropy .
So the output length will be shorter than the input length .
due to temperature or voltage variations , the quality of the generated numbers might vary over time .
Therefore , the standards describe speciﬁc tests that should be applied at the start and continuously during the process of generating numbers .
One can distinguish three main categories of tests .
The ﬁrst one is the total failure test , applied at the source of entropy .
The second ones are online health tests to monitor the quality of the entropy extractors .
The requirements for these tests are well described in the different standards and specialized text books [ 1455 ] .
The challenge in designing TRNGs is ﬁrst to provide a clear and convincing proof of the entropy source , second the design of online tests which at the same are compact and can detect a wide range of defects [ 1456 ] .
The topic of attacks , countermeasures and sensors for TRNGs , especially in the context of IoT and embedded devices , is an active research topic .
The manufacturing of silicon circuits results in unique process variations which can not be physically cloned .
The basic idea of PUFs is that these unique manufacturing features are magniﬁed and digitized so that they can be used in security applications similar to the use of ﬁngerprints or other biometrics .
Process and physical variations such as doping ﬂuctuations , line or edge widths of interconnect wires , result in variations of threshold voltages , transistor dimensions , capacitances , etc .
Thus circuits are created that are sensitive to and amplify these variations .
The major security application for PUFs is to derive unique device speciﬁc keys , e.g .
for usage in an IoT device or smart card .
Traditionally , this storage of device unique keys is done in non-volatile memory , as the key has to remain in the chip even when the power is turned-off .
Non-volatile memory requires however extra fabrication steps , which makes chips with nonvolatile memory more expense than regular standard CMOS chips .
Thus PUFs are promised as cheap alternative for secure non-volatile memory , because the unique silicon ﬁngerprint is available without the extra processing steps .
Indeed , each time the key is needed , it can be read from the post-processed PUF and directly used in security protocols .
They can also replace fuses , which are large and their state is relatively easy to detect under a microscope .
for access control or tracking of goods .
The ideal PUF has an exponential number of unique challenge response pairs , exponential in the number of circuit elements .
The uniqueness of PUFs is measured by the inter-distance between different PUFs seeing the same challenge .
there is no noise in the responses .
Moreover , PUF responses should be unpredictable and physically unclonable .
The ideal PUF unfortunately does not exist .
In literature , two main classes of PUFs are deﬁned , characterized by the number of challenge-response pairs they can generate .
The number of possible challenge-response pairs grows typically linear with the area of the integrated circuit .
Hence they are called weak PUFs .
These PUFs are typically used for key generation .
The raw PUF output material is not directly usable for key generation as the PUF responses are affected by noise .
Thus after the entropy extraction follows secure sketch ( similar to error correction ) circuits to eliminate the noise and compress the entropy to generate a full entropy key [ 1459 ] .
The challenge for the PUF designer is to come up with process variations and circuits that can be used as key material , but which are not sensitive to transient noise .
A second challenge is to keep all the post-processing modules compact so that the key-generation PUF can be included in embedded IoT devices .
In this case , the number of challengeresponse pairs grows large , ideally exponential , with the silicon area .
to create a chain of multiplexers or comparators , so that simple combinations of the elements create the large challenge-response space .
Also in this case , the effects of noise in the circuits needs to be taken into account .
Each time a challenge is applied to the PUF , a KA Hardware Security | October 2019 Page 603 The Cyber Security Body Of Knowledge www.cybok.org response unique to the chip will be sent .
The veriﬁer will accept the response if it can be uniquely tied to the prover .
This requires that the PUF responses are registered in a form of a database beforehand during an enrollment phase .
The problem with strong PUFs is that there is a strong correlation between different challengeresponse pairs of most circuits proposed in literature .
Hence all of these circuits are broken with machine learning techniques [ 1461 ] and can not be used for authentication purposes .
The fundamental problem is that very basic , mostly linear operations are used to combine PUF elements , which makes them easy targets for machine learning attacks .
Ideally , these should be cryptographic or other computationally hard operations resistant to machine learning : unfortunately these can not tolerate noise .
Light-weight PUF based security protocols are an active area of research .
18.8 HARDWARE DESIGN PROCESS In this section , several hardware security topics are described which are directly related to the lower design abstraction layers .
One is the trust in the hardware design process itself .
Directly related to this , is the problem of Trojan circuits .
Also part of the hardware design process are circuit level techniques for camouﬂaging , logic locking , etc .
18.8.1 Design and fabrication of silicon integrated circuits It is important to note that the hardware design process itself also needs to be trusted .
Because of its design complexity , design at each abstraction layer relies on Electronic Design Automation ( EDA ) tools .
The design , fabrication , packaging and test of silicon integrated circuits is an international engagement : silicon foundries are mostly located in Asia .
Silicon design tools are most developed in the US , and silicon testing and packaging usually occur all over the world .
For chips that end-up in critical infrastructure , such as telecommunication , military , aviation , trust and veriﬁcation of the complete design cycle is essential .
Since silicon foundries and mask making are extremely expensive , very few countries and companies can still afford it and a huge consolidation has and is taking place in the industry .
For critical infrastructure , governments demand more tools and techniques to increase the trustworthiness of this international design process .
On this topic , large research projects are deﬁned to come up with methods and tools to increase the trustworthiness of the design process and especially to assess the risk of Trojan insertions during the design process .
18.8.2 Trojan circuits Trojan circuits are logic or gates added to large integrated circuits .
As they are not part of the speciﬁed functionality , they are difﬁcult to detect .
They rely on the fact that they are extremely small in comparison with the large size of integrated circuits and SoCs .
how is the Trojan inserted into the circuit .
does it requires logic modiﬁcations or only layout modiﬁcations .
The second one is the activation characteristic : will the Trojan be turned on by an internal or external event , etc .
The third characteristic classiﬁes the type of action taken by the Trojan , e.g .
will it leak information or will it destroy functionality , etc .
These are standard cells or other modules that visually look the same , or they look camouﬂaged by random extra material .
This is done to avoid visual inspection and reverse engineering based on visual inspection .
Only when the correct key is applied to the secret gates , will the circuit perform the correct functionality .
This is an active research topic with logic locking schemes being proposed and attacked , with SAT solvers being a very useful tool in attacking the circuits .
Many of the attacks and countermeasures mentioned before for integrated circuits , can be repeated for PCBs albeit at a different scale .
While integrated circuits provide some level of protection because they are encapsulated in packages and use much smaller CMOS technologies , PCB ’ s are less complex and somewhat easier to access .
There have been some concerns that Trojan circuits could also be included at the board level .
18.8.5 Time The concept of time and the concept of sequence of events are essential in security protocols .
A monotonic counter always increases , but the wall clock time between two increments is unknown .
It only increases when the power is on .
Therefore the tick counter is linked with a nonce and methods are foreseen to link this with a real wall clock time .
Trusted time is the most secure .
It makes sure that there is a link between the tick counter and the real wall clock time .
The connection to a real wall clock will require synchronization and an actual communication channel .
In this chapter , a classiﬁcation is made based on the different design abstraction layers .
At each abstraction layer , the threat model , root of trust and security goals are identiﬁed .
Because of the growth of IoT , edge and cloud computing , the importance of hardware security is growing .
Yet , in many cases hardware security is in conﬂict with other performance optimisations , such as low power or limited battery operated conditions .
In these circumstances , performance optimization is the most important design task .
Yet it is also the most important cause of information leakage .
This is the case at all abstraction layers : instruction level , architecture level and logic and circuit level .
This is an important trend in processor architecture , where FPGA functionality is added to processor architectures .
The fundamental assumption that hardware is immutable is lost here .
A last big challenge for hardware security is the lack of EDA tools to support hardware security .
EDA tools are made for performance optimization and security is usually an afterthought .
An added challenge is that it is difﬁcult to measure security and thus difﬁcult to balance security versus area , throughput or power optimisations .
While automatic control systems like the steam governor have existed for several centuries , it is only in the past decades that the automation of physical infrastructures like the power grid , water systems , or chemical reactions have migrated from analogue controls to embedded computer-based control , often communicating through computer-based networks .
In addition , new advances in medical implantable devices , or autonomous self-driving vehicles are increasing the role of computers in controlling even more physical systems .
While computers give us new opportunities and functionalities for interacting with the physical world , they can also enable new forms of attacks .
The purpose of this Knowledge Area is to provide an overview of the emerging ﬁeld of CPS security .
In contrast with other Knowledge Areas within CyBOK that can trace the roots of their ﬁeld back to several decades , the work on CPS security is relatively new , and our community has not developed yet the same consensus on best security practices compared to cyber security ﬁelds described in other KAs .
Therefore , in this document , we focus on providing an overview of research trends and unique characteristics in this ﬁeld .
However , the security problems in the higher layers of this taxonomy are more related to classical security problems covered in other KAs .
Therefore , the scope of this document focuses on the aspects of CPSs more closely related to the sensing , control , and actuation of these systems ( e.g .
The rest of the Knowledge Area is organised as follows .
In Section 19.1 we provide an introduction to CPSs and their unique characteristics .
Finally , in Section 19.4 , we examine the unique challenges CPS security poses to regulators and governments .
In particular , we outline the role of governments in incentivising security protections for CPSs , and how CPS security relates to national security and the conduct of war .
CPSs are usually composed of a set of networked agents interacting with the physical world ; these agents include sensors , actuators , control processing units , and communication devices , as illustrated in Figure 19.1 .
In their program announcement , NSF outlined their goal for considering various industries ( such as water , transportation , and energy ) under a uniﬁed lens : by abstracting from the particulars of speciﬁc applications in these domains , the goal of the CPS program is to reveal crosscutting fundamental scientiﬁc and engineering principles that underpin the integration of cyber and physical elements across all application sectors .
Soon after the CPS term was coined , several research communities rallied to outline and understand how CPSs cyber security research is fundamentally different when compared to conventional IT cyber security .
While cyber security research had been previously considered in other physical domains—most notably in the Supervisory Control and Data Acquisition ( SCADA ) systems of the power grid [ 1478 ] —these previous efforts focused on applying well-known IT cyber security best practices to control systems .
What differentiates the early CPS security position papers was their crosscutting nature focusing on a multi-disciplinary perspective for CPS security ( going beyond classical IT security ) . ) .
, early CPSs papers bringing control theory elements [ 1469 ] suggested that intrusion detection systems for CPSs could also monitor the physical evolution of the system and then check it against a model of the expected dynamics as a way to improve attack detection .
It focuses instead on the fundamental intellectual problem of conjoining the engineering traditions of the cyber and physical worlds [ 1467 ] .
The rest of this section is organised as follows : in Section 19.1.1 , we introduce general properties of CPS , then in Section 19.1.2 , we discuss how physical systems have been traditionally protected from accidents and failures , and how these protections are not enough to protect the system against cyber-attacks .
We ﬁnalise this section by discussing the security and privacy risks in CPSs along with summarising some of the most important real-world attacks on control systems in Section 19.1.3 .
Embedded Systems : One of the most general characteristics of CPSs is that , because several of the computers interfacing directly with the physical world ( sensors , controllers , or actuators ) perform only a few speciﬁc actions , they do not need the general computing power of classical computers—or even mobile systems—and therefore they tend to have limited resources .
Some of these embedded systems do not even run operating systems , but rather run only on ﬁrmware , which is a speciﬁc class of software that provides low-level control of the device hardware ; devices without an operating systems are also known as bare metal systems .
Even when embedded systems have an operating system , they often run a strippeddown version to concentrate on the minimal tools necessary for the platform .
Network Protocols : Another characteristic of CPSs is that these embedded systems communicate with each other , increasingly over IP-compatible networks .
While many critical infrastructures such as power systems have used serial communications to monitor remote operations in their SCADA systems , it is only in the past two decades that the information exchange between different parts of the system has migrated from serial communications to IP-compatible networks .
For example , the serial communications protocol Modbus was released by Modicon in 1979 , and subsequent serial protocols with more capabilities included IEC 60870-5-101 and DNP3 in the 1990s .
Wireless : While most of the long-distance communications are done over wired networks , wireless networks are also a common characteristic of CPSs .
Wireless communications for embedded systems attracted signiﬁcant attention from the research community in the early 2000s in the form of sensor networks .
The challenge here is to build networks on top of low-powered and lossy wireless links , where traditional concepts for routing like the “ hop distance ” to a destination are no longer applicable , and other link quality metrics are more reliable , e.g .
These three communications technologies were developed on top of the IEEE 802.15.4 standard , whose original version deﬁned frames sizes so small , that they could not carry the header of IPv6 packets .
Since Internet-connected embedded systems are expected to grow to billions of devices in the next years , vendors and standard organisations see the need to create embedded devices compatible with IPv6 .
To be able to send IPv6 packets in wireless standards , several efforts tried to tailor IPv6 to embedded networks .
Most notably the Internet Engineering Task Force ( IETF ) launched the 6LoWPAN effort , originally to deﬁne a standard to send IPv6 packets on top of IEEE 802.15.4 networks , and later to serve as an adaptation layer for other embedded technologies .
Control : Finally , most CPSs observe and attempt to control variables in the physical world .
Feedback control systems have existed for over two centuries , including technologies like the steam governor , which was introduced in 1788 .
Most of the literature in control theory attempts to model a physical process with differential equations and then design a controller that satisﬁes a set of desired properties such as stability and efﬁciency .
Control systems were initially designed with analogue sensing and analogue control , meaning that the control logic was implemented in an electrical circuit , including a panel of relays , which usually encoded ladder logic controls .
Analogue systems also allowed the seamless integration of control signals into a continuous-time physical process .
The introduction of digital electronics and the microprocessor , led to work on discrete-time control [ 1488 ] , as microprocessors and computers can not control a system in continuous time because sensing and actuation signals have to be sampled at discrete-time intervals .
Hybrid systems played a fundamental role in the motivation towards creating a CPS research program , as they were an example of how combining models of computation and models of physical systems can generate new theories that enable us to reason about the properties of cyber- and physical-controlled systems .
Having discussed these general characteristics of CPSs , one caveat is that CPSs are diverse , and they include modern vehicles , medical devices , and industrial systems , all with different standards , requirements , communication technologies , and time constraints .
Therefore , the general characteristics we associate with CPSs might not hold true in all systems or implementations .
Before we discuss cyber security problems , we describe how physical systems operating under automatic control systems have been protected from accidents and natural failures , and how these protections against non-malicious adversaries are not enough against strategic attackers ( i.e .
, attackers that know that these protections are in place and try to either bypass them or abuse them ) .
KA Cyber-Physical Systems Security | October 2019 Page 611 The Cyber Security Body Of Knowledge www.cybok.org 19.1.2 Protections Against Natural Events and Accidents Failures in the control equipment of physical infrastructures can cause irreparable harm to people , the environment , and other physical infrastructures .
Safety : The basic principle recommended by the general safety standard for control systems ( IEC 61508 ) is to obtain requirements from a hazard and risk analysis including the likelihood of a given failure , and the consequence of the failure , and then design the system so that the safety requirements are met when all causes of failure are taken into account .
This generic standard has served as the basis for many other standards in speciﬁc industries , for example , the process industry ( reﬁneries , chemical systems , etc . ) .
Protection : A related concept to safety is that of protection in electric power grids .
These protection systems include , • Protection of Generators : when the frequency of the system is too low or too high , the generator will be automatically disconnected from the power grid to prevent permanent damage to the generator .
• Under Frequency Load Shedding ( UFLS ) : if the frequency of the power grid is too low , controlled load shedding will be activated .
This disconnection of portions of the electric distribution system is done in a controlled manner , while avoiding outages in safety- KA Cyber-Physical Systems Security | October 2019 Page 612 The Cyber Security Body Of Knowledge www.cybok.org critical loads like hospitals .
UFLS is activated in an effort to increase the frequency of the power grid , and prevent generators from being disconnected .
• Overcurrent Protection : if the current in a line is too high , a protection relay will be triggered , opening the line , and preventing damage to equipment on each side of the lines .
Reliability : While safety and protection systems try to prevent accidents , other approaches try to maintain operations even after failures in the system have occurred .
For example , the electric system is designed and operated to satisfy the so-called N-1 security criterion , which means that the system could lose any one of its N components ( such as one generator , substation , or transmission line ) and continue operating with the resulting transients dying out to result in a satisfactory new steady-state operating condition , meaning that the reliable delivery of electric power will continue .
Isolation is the process of identifying which device is the source of the anomaly , and reconﬁguration is the process of recovering from the fault , usually by removing the faulty sensor ( if there is enough sensor redundancy in the system ) .
Robust control deals with the problem of uncertainty in the operation of a control system .
, gusts of wind in the operation of planes ) , sensor noise , dynamics of the system not modelled by the engineers , or degradation of system components with time .
Robust control systems usually take the envelope of least favourable operating conditions , and then design control algorithms so that the system operates safely , even in the worst-case uncertainty .
Since then , there have been several examples that show why these mechanisms do not provide security .
[ 1494 ] showed how faultdetection ( bad data detection ) algorithms in the power grid can be bypassed by an adversary that sends incorrect data that is consistent with plausible power grid conﬁgurations , but at the same time is erroneous enough from the real values to cause problems to the system .
These are attacks that inject small false data in sensors so that the faultdetection system does not identify them as anomalies but , over a long-period of time , these attacks can drive the system to dangerous operating conditions .
Similarly , the N-1 security criterion in the electric power grid assumes that if there is a failure , all protection equipment will react as conﬁgured , but an attacker can change the conﬁguration of protection equipment in the power grid .
In such a case , the outcome of an N-1 failure in the power grid will be completely unexpected , as equipment will react in ways that were unanticipated by the operators of the power grid , leading to potential cascading failures in the bulk power system .
KA Cyber-Physical Systems Security | October 2019 Page 613 The Cyber Security Body Of Knowledge www.cybok.org Finally , in Section 19.1.3.1 , we will describe how real-world attacks are starting to target some of these protections against accidents ; for example , the Triton malware speciﬁcally targeted safety systems in a process control system .
Software updates and patching might violate safety certiﬁcations , and preventing unauthorised users from accessing a CPS might also prevent ﬁrst responders from access to the system in the case of an emergency ( e.g .
Security solutions should take these CPS safety concerns into account when designing and deploying new security mechanisms .
Industrial Control Systems systems , in particular , perform vital functions in critical national infrastructures , such as electric power distribution , oil and natural gas distribution , water and waste-water treatment , and intelligent transportation systems .
The disruption of these CPSs could have a signiﬁcant impact on public health , safety and lead to large economic losses .
For example , attacks on the power grid can cause blackouts , leading to interdependent cascading effects in other vital critical infrastructures such as computer networks , medical systems , or water systems creating potential catastrophic economic and safety effects in our society [ 1497 ] .
Attacks on ground vehicles can create highway accidents [ 1498 ] , attacks on GPS systems can mislead navigation systems and make drivers reach a destination desired by the attacker [ 1499 ] , and attacks on consumer drones can let attackers steal , cause accidents or surreptitiously turn on cameras and microphones to monitor victims [ 1500 ] .
Attacks on CPSs can happen at any point in the general architecture , as illustrated in Figure 19.4 , which considers eight attack points .
, if the sensor data is unauthenticated or if the attacker has the key material for the sensors ) and injects false sensor signals , causing the control logic of the system to act on malicious data .
An example of this type of attack is considered by Huang et al .
Attack 2 represents an attacker in the communication path between the sensor and the controller , who can delay or even completely block the information from the sensors to the controller , so the controller loses observability of the system ( loss of view ) , thus causing it to operate with stale data .
Attack 3 represents an attacker who has compromised the controller and sends incorrect control signals to the actuators .
Attack 4 represents an attacker who can delay or block any control command , thus causing a denial of control to the system .
Attack 5 represents an attacker who can compromise the actuators and execute a control action that is different to what the controller intended .
Notice that this attack is different to an attack that directly attacks the controller , as this can lead to zero dynamics attacks .
These types of attacks are considered by Teixeira et al .
This type of joint cyber and physical attack has been considered by Amin et al .
Attack 7 represents an attacker who can delay or block communications to and from the supervisory control system or conﬁguration devices .
Attack 8 represents an attacker who can compromise or impersonate the SCADA system or the conﬁguration devices , and send malicious control or conﬁguration changes to the controller .
These types of attacks have been illustrated by the attacks on the power grid in Ukraine where the attackers compromised computers in the control room of the SCADA system [ 1508 ] and attacks where the conﬁguration device of medical devices has been compromised [ 1509 ] .
While traditionally most of the considered attacks on CPSs have been software-based , another property of CPSs is that the integrity of these systems can be compromised even without a computer-based exploit in what has been referred to as transduction attacks [ 1510 ] ( these attacks represent a physical way to inject false signals , as covered by Attack 1 in Figure 19.4 ) .
In addition to security and safety-related problems , CPSs can also have profound privacy implications unanticipated by designers of new systems .
Warren and Brandeis stated in their seminal 1890 essay The right to privacy [ 149 ] that they saw a growing threat from recent inventions , like “ instantaneous photographs ” that allowed people to be unknowingly photographed , and new media industries , such as newspapers , that would publish photographs without their subjects ’ consent .
The rise of CPS technologies in general , and consumer IoT in particular , are similarly challenging cultural assumptions about privacy .
CPS devices can collect physical data of diverse human activities such as electricity consumption , location information , driving habits , and biosensor data at unprecedented levels of granularity .
In addition , the passive manner of collection leaves people generally unaware of how much information about them is being gathered .
Furthermore , people are largely unaware that such collection exposes them to possible surveillance or criminal targeting , as the data collected by corporations can be obtained by other actors through a variety of legal or illegal means .
For example , automobile manufacturers are remotely collecting a wide variety of driving history data from cars in an effort to increase the reliability of their products .
Having presented the general risks and potential attacks to CPSs we ﬁnalise our ﬁrst section by describing some of the most important real-world attacks against CPSs launched by malicious attackers .
KA Cyber-Physical Systems Security | October 2019 Page 616 The Cyber Security Body Of Knowledge www.cybok.org 19.1.3.2 High-Proﬁle , Real-World Attacks Against CPSs Control systems have been at the core of critical infrastructures , manufacturing and industrial plants for decades , and yet , there have been few conﬁrmed cases of cyber-attacks ( here we focus on attacks from malicious adversaries as opposed to attacks created by researchers for illustration purposes ) .
Non-targeted attacks are incidents caused by the same attacks that classical IT computers may suffer , such as the Slammer worm , which was indiscriminately targeting Windows servers but that inadvertently infected the Davis-Besse nuclear power plant [ 1515 ] affecting the ability of engineers to monitor the state of the system .
Targeted attacks are those where adversaries know that they are targeting a CPS , and therefore , tailor their attack strategy with the aim of leveraging a speciﬁc CPS property .
We look in particular at attacks that had an effect in the physical world , and do not focus on attacks used to do reconnaissance of CPSs ( such as Havex or BlackEnergy [ 1517 ] ) .
The ﬁrst publicly reported attack on an SCADA system was the 2000 attack on Maroochy Shire Council ’ s sewage control system1 in Queensland , Australia [ 1519 ] , where a contractor who wanted to be hired for a permanent position maintaining the system used commercially available radios and stolen SCADA software to make his laptop appear as a pumping station .
During a 3-month period the attacker caused more than 750,000 gallons of untreated sewage water to be released into parks , rivers , and hotel grounds causing loss of marine life , and jeopardising public health .
By intercepting these requests , Stuxnet was able to modify the data sent to , and returned from , the PLC , without the knowledge of the PLC operator .
The more popular attack variant of Stuxnet consisted in sending incorrect rotation speeds to motors powering centrifuges enriching Uranium , causing the centrifuges to break down so that they needed to be replaced .
As a result , centrifuge equipment had to be replaced regularly , slowing down the amount of enriched Uranium the Natanz plant was able to produce .
These attacks caused power outages and clearly illustrate the evolution of attack vectors .
While the attacks in 2015 leveraged a remote access program that attackers had on computers in the SCADA systems of the distribution power companies , and as such a human was involved trying to send malicious commands , the attacks in 2016 were more automated thanks to the Industroyer malware [ 1532 ] which had knowledge of the industrial control protocols these machines use to communicate and could automatically craft malicious packets .
The most recent example in the arms race of malware creation targeting control systems 1 There are prior reported attacks on control systems [ 1518 ] but there is no public information corroborating these incidents and the veracity of some earlier attacks has been questioned .
It was responsible for at least one process shutting down .
Stuxnet , Industroyer , and Triton demonstrate a clear arms race in CPS attacks believed to be state sponsored .
These attacks will have a profound impact on the way cyber-conﬂicts evolve in the future and will play an essential part in how wars may be waged , as we discuss in the last section of this chapter .
Penetration testing is perhaps the most common way to understand the level of risk of the system and can be used to design a vulnerability management and patching strategy .
In this section we look at crosscutting security efforts to prevent , detect , and mitigate attacks , and the next section will look at speciﬁc CPS domains such as the power grid and intelligent transportation systems .
19.2.1 Preventing Attacks The classical way to protect the ﬁrst computer-based control systems was to have them isolated from the Internet , and from the corporate networks of the asset owners .
As business practices changed , and efﬁciency reasons created more interconnections of control systems with other information technology networks , the concept of sub-network zone isolation was adopted by several CPS industries , most notably in the nuclear energy sector .
On the other hand , there are several ways to break the air gap , including insider attacks , or adding new connectivity to the network via mobile devices .
Therefore , to prevent attacks in modern CPSs , designers and developers have to follow the same best security practices as classical IT systems ; i.e .
While the best security practices of classical IT systems can give the necessary mechanisms for the security of control systems , these mechanisms alone are not sufﬁcient for the defencein-depth of CPSs .
In this section we will discuss how , by understanding the interactions of the CPS system with the physical world , we should be able to KA Cyber-Physical Systems Security | October 2019 Page 618 The Cyber Security Body Of Knowledge www.cybok.org 1. better understand the consequences of an attack .
In the rest of this subsection we will focus on illustrating the challenges for implementing classical IT security best practices in CPSs , including the fact that several CPSs are composed of legacy systems , are operated by embedded devices with limited resources , and face new vulnerabilities such as analogue attacks .
Securing Legacy Systems : The life cycle of CPS devices can be an order of magnitude larger than regular computing servers , desktops , or mobile systems .
Consumers expect that their cars last longer than their laptops , hospitals expect medical equipment to last over a decade , the assets of most industrial control systems last for at least 25 years [ 1548 ] , and most of these devices will not be replaced until they are fully depreciated .
Some of these devices were designed and deployed assuming a trusted environment that no longer exists .
In addition , even if these devices were deployed with security mechanisms at the time , new vulnerabilities will eventually emerge and if the devices are no longer supported by the manufacturer , then they will not be patched .
For example , after the Heartbleed vulnerability was discovered , major manufacturers pushed updates to mitigate this problem ; however most embedded devices monitoring or controlling the physical world will not be patched ( patching some safety-critical systems might even violate their safety certiﬁcation ) .
So even if a vendor used OpenSSL to create a secure communication channel between CPS devices originally , they also need to consider supporting the device over a long-time frame .
The legacy device thus sends unencrypted and unauthenticated packets and the network appliance will tunnel them over a secure channel to another bump-in-the-wire system at the other end of the communication channel that then removes the security protections and gives the insecure packet to the ﬁnal destination .
A similar concept has been proposed for wireless devices like implantable medical devices .
Because some of these wireless devices communicate over insecure channels , attackers can listen or inject malicious packets .
The wireless shield will jam any communication attempt to the vulnerable devices except the ones from devices authorised by the owner of the shield .
Wireless shields have also been proposed for other areas , such as protecting the privacy of consumers using BLE devices [ 1552 ] .
Because of their disruptive nature , it is not clear if wireless shields will ﬁnd practical applications in consumer applications .
Lightweight Security : While several embedded devices support classical cryptography , for some devices the performance of cryptographic algorithms in terms of energy consumption , or latency , may not be acceptable [ 1553 ] .
For public-key algorithms , Elliptic Curve Cryptography generally offers the best balance of performance and security guarantees , but other lightweight public-key algorithms might be more appropriate depending on the requirements of the system [ 1556 ] .
When it comes to exploit mitigation , the solutions are less clear .
Most deeply embedded devices do not have support for data execution prevention , address space layout randomisation , stack canaries , virtual memory support , or cryptographically secure random number generators .
In addition system-on-chip devices have no way to expand their memory , and real-time requirements might pose limitations on the use of virtual memory .
Secure Microkernels : Another OS security approach is to try to formally prove the security of the kernel .
The design of secure operating systems with formal proofs of security is an effort dating back to the Orange Book [ 1031 ] .
Because the increasing complexity of code in monolithic kernels makes it hard to prove that operating systems are free of vulnerabilities , microkernel architectures that provide a minimal core of the functionality of an operating system have been on the rise .
Preventing Transduction Attacks : As introduced in the previous section , transduction attacks represent one of the novel ways in which CPS security is different from classical IT security .
Sensors are transducers that translate a physical signal into an electrical one , but these sensors sometimes have a coupling between the property they want to measure , and another analogue signal that can be manipulated by the attacker .
Security countermeasures to prevent these attacks include the addition of better ﬁlters in sensors , improved shielding from external signals , anomaly detection , and sensor fusion [ 1511 ] .
Some speciﬁc proposals include : drilling holes differently in a circuit board to shift the resonant frequency out of the range of the sensor , adding physical trenches around boards containing speakers to reduce mechanical coupling , using microﬁber cloths for acoustic isolation , implementing low-pass ﬁlters that cut-off coupled signals , and secure ampliﬁers that prevent signal clipping [ 1510 , 1559 ] .
19.2.2 Detecting Attacks Detecting attacks can be done by observing the internal state of a CPS device , by monitoring the interaction among devices to spot anomalous activities , or even using out-of-band channels .
Software-based attestation does not rely on any special security hardware in the device , but it has weak security guarantees and usually requires wireless KA Cyber-Physical Systems Security | October 2019 Page 620 The Cyber Security Body Of Knowledge www.cybok.org range between the veriﬁer and the device being checked .
The minimal secure hardware requirements include a secure place to store the secret key , and safe code that has exclusive access to that key .
In addition to academic work , industry is also developing standards to enhance the security of embedded systems with minimal silicon requirements .
For example , the Trusted Computing Group ( TCG ) Device Identiﬁer Composition Engine ( DICE ) is working on combining simple hardware capabilities to establish strong identity , attest software , and security policy , and assist in deploying software updates .
We ﬁnalise our description of attestation by pointing out that most of the practical proposals for attestation work for initialisation , but building practical run-time attestation solutions remains a difﬁcult challenge .
Network Intrusion Detection : The second category of solutions for detecting attacks relies on monitoring the interactions of CPS devices .
In contrast with classical IT systems , where simple Finite-State models of network communications will fail , CPSs exhibit comparatively simpler network behaviour : servers change less frequently , there is a more stable network topology , a smaller user population , regular communication patterns , and networks host a smaller number of protocols .
While network speciﬁcation is in general easier in CPS environments when compared to IT , it is still notoriously difﬁcult to maintain .
Physics-Based Attack Detection : The major distinction of control systems with respect to other IT systems is the interaction of the control system with the physical world .
In contrast to work in CPS intrusion detection that focuses on monitoring “ cyber ” patterns , another line of work studies how monitoring sensor ( and actuation ) values from physical observations , and control signals sent to actuators , can be used to detect attacks ; this approach is usually called physics-based attack detection [ 1535 ] .
There are two main classes of physical anomalies : historical anomalies and physical-law anomalies .
Historical Anomalies : identify physical conﬁguration we have not seen before .
For example if during the learning phase , a water level in a tank is always between 1m and 2m , then if the water level ever goes above or below these values we can raise an alert .
Machine learning models of the historical behaviour of the variables can also capture historical correlations of these variables .
One problem with historical anomalies is that they might generate a large number of false alarms .
Physical-Law Anomalies : A complementary approach to historical observations that may have fewer false alarms , is to create models of the physical evolution of the system .
For example we have a sensor that monitors the height of a bouncing ball , then we know that this height follows the differential equations from Newton ’ s laws of mechanics .
Thus , if a sensor reports a trajectory that is not plausible given the laws of physics , we can immediately identify that something is not right with the sensor ( a fault or an attack ) .
Similarly , the physical properties of water systems ( ﬂuid dynamics ) or the power grid ( electromagnetic laws ) can be used to create time series models that we can then use to conﬁrm that the control commands sent to the ﬁeld were executed correctly and that the information coming from sensors is consistent with the expected behaviour of the system .
For example , if we open an intake valve we should expect that the water level in the tank should rise , otherwise we may have a problem with the control , actuator , or the sensor .
Models of the physical evolution of the system have been shown to be better at limiting the short-term impact of stealthy attacks ( i.e .
However , if the attack persists for a long time and drives the system to an unsafe region by carefully selecting a physically plausible trajectory , then historical models can help in detecting this previously unseen state [ 1576 ] .
In addition to the physics of the system being controlled , devices ( such as actuators ) have dynamics as well , and these physical properties can also be used to monitor the proper behaviour of devices [ 1577 ] .
For example , Radio Frequency-based Distributed Intrusion Detection [ 1579 ] monitors radio frequency emissions from a power grid substation in order to check if there are malicious circuit breaker switching , transformer tap changes , or any activation of protecting relays without the direct request sent from the SCADA server .
The basic idea is to correlate control commands sent by the SCADA server , with the radio frequency emissions observed in the substation .
A potential drawback with this approach is that attackers can launch RF attacks mimicking the activation of a variety of electric systems , which can lead to security analysts losing conﬁdence in the veracity of the alerts .
Active Detection : In addition to passively monitoring a CPS , an intrusion detection system can actively query devices to detect anomalies in how devices respond to these requests [ 1580 ] .
However , both active detection and moving target defence might impose unnecessary perturbations in a system by their change of the physical world for security purposes .
Therefore , these techniques might be too invasive and costly .
Consequently , the practicality of some of these approaches is uncertain .
KA Cyber-Physical Systems Security | October 2019 Page 622 The Cyber Security Body Of Knowledge www.cybok.org 19.2.3 Mitigating Attacks Most of the efforts for mitigating faults in CPSs have focused on safety and reliability ( the protection of the system against random and/or independent faults ) .
Attack mitigation is an extension of safety and reliability protections for when the faults in the systems are not created at random by nature , but by an adversary .
Attack mitigation is related to the concept of resilient control systems , deﬁned as those that maintain state awareness and an accepted level of operational normalcy in response to disturbances , including threats of an unexpected and malicious nature [ 1590 ] .
Proactive mitigation considers design choices deployed in the CPS prior to any attack .
On the other hand , reactive responses only take effect once an attack has been detected , and they reconﬁgure the system online in order to minimise the impact of the attack .
Conservative Control : One of the ﬁrst ideas for mitigating the impact of attacks was to operate the system with enough safety margins so that if an attack ever occurred , it would be harder for the attacker to reach an unsafe region .
One intuitive idea for this type of control algorithm is to use Multi-Party Computation ( MPC ) to design a control strategy that predicts that an attack will happen starting at the next time step [ 1502 ] , and therefore plans an optimal control action that will attempt to keep the system safe if the attack happens .
Operating a CPS conservatively usually comes at the cost of suboptimal operation and extra costs when the system is not under attack .
The basic idea is to use the knowledge of a CPS and the correlations of all sensor values .
With enough redundancy in sensor measurements , a resilient estimation algorithm can reject attempted attacks and still obtain an accurate state estimate .
This idea is similar to error correcting codes in information theory , where a subset of the bits transmitted can be corrupted , but the error correcting code reconstructs the original message .
The drawback , however , is that not all CPSs will have a variety of correlated sensors to check the consistency of others , so this approach depends on the properties of the system .
Sensor Fusion : Resilient estimation algorithms usually assume a variety of multi-modal sensors to achieve their security guarantees .
A basic example of sensor fusion in automotive systems is to verify that both the LiDAR readings and the camera measurements report consistent observations .
Therefore , one way to mitigate attacks on the sensors of a CPS is to use a physical model of the system to come up with the expected sensor values that can then be provided to the control algorithm [ 1495 , 1576 , 1596 ] .
By removing a sensor value with its expected value obtained from the system model , we are effectively controlling a system using open-loop control , which might work in the short-term , but may be risky as a long-term solution , as all physical models are not perfect , and the error between the real-world and the model simulation can increase over time .
Another important consideration when designing virtual sensors as an attack-response mechanism , is to evaluate the safety of the system whenever the system is activated due to a false alarm [ 1495 ] .
KA Cyber-Physical Systems Security | October 2019 Page 623 The Cyber Security Body Of Knowledge www.cybok.org Constraining Actuation : A similar principle of operating conservatively is to physically constrain the actuators of a CPS so that if the attacker ever succeeds in gaining access to the system , it is restricted in how fast it can change the operation of the system .
This approach can guarantee , for example , the safety of vehicle platooning systems , even when the attacker has complete control of one of the vehicles [ 1597 ] .
Inertial Resets : Another idea to mitigate attacks is to reset and diversify the system as frequently as possible so that attackers are unable to gain persistent control of the system [ 1598 , 1599 ] .
The basic idea is that a full software reset of the system will make the system boot again in a trusted state , eliminating the presence of an attacker .
This requires the system to have a trusted computing base that can boot the system in a secure state where the malware is not loaded yet .
However , turning off a system that is in operation is a potentially dangerous action , and it is not clear if this proposal will be practical .
Reactive Control Compensation : When sensors or controllers are under attack , new actions are generated in order to maintain the safety of the system .
Inspired by the literature on faulttolerant control , one idea is to attempt to estimate the attack signal , and then generate a compensating action to eliminate it [ 1600 ] .
The problem with this approach is that it does not consider strategic adversaries ; however game-theoretic approaches can address that limitation .
In game-theoretic models , an attacker compromises a set of control signals uak ∈ Rma and the defender uses the remaining controllers udk ∈ Rmd to deploy a defence action .
One of the challenges with game theory is that , in order to model and prove results , the formulation needs to be simpliﬁed , and in addition , models need to add a number of extra assumptions that might not hold in practice .
Safe Control Actions : Another reactive approach is to change or even prevent a potentially malicious control action from acting on the system .
A more recent and security-oriented approach is to use the concept of a reference monitor to check if the control action will result in any unsafe behaviour before it is allowed to go into the ﬁeld [ 1504 ] .
The proposed approach depends on a controller of controllers ( C2 ) , which mediates all control signals sent by the controller to the physical system .
All the security proposals for preventing , detecting , and responding to attacks presented in this section are generally applicable to CPSs .
However , there are unique properties of each CPS application that can make a difference in how these solutions are implemented .
In the next section we change focus from general and abstract CPS descriptions , to domain-speciﬁc problems and solutions .
Depending on the application , these control systems are also called Process Control Systems ( PCSs ) in the chemical industry , or Distributed Control Systems ( DCSs ) if the devices used for supervision and control are procured using a monolithic architecture .
For example , the oil and gas industry uses integrated control systems to manage reﬁning operations at plant sites , remotely monitor the pressure and ﬂow of gas pipelines , and control the ﬂow and pathways of gas transmission .
Water utilities can remotely monitor well levels and control the wells ’ pumps ; monitor ﬂows , tank levels , or pressure in storage tanks ; monitor pH , turbidity , and chlorine residual ; and control the addition of chemicals to the water .
Figure 19.5 shows an illustration of the lower layers of this hierarchy .
The top layers operate using mostly traditional Information Technology : computers , operating systems , and related software .
The supervisory control layer is where the Supervisory Control and Data Acquisition ( SCADA ) systems and other servers communicate with remote control equipment like Programmable Logic Controllers ( PLCs ) and Remote Terminal Units ( RTUs ) .
, 4-20 milliamperes ) , the growing numbers of sensors and actuators as well as their increased intelligence and capabilities , has given rise to new Field Communication Networks ( FCNs ) where the PLCs and other types of controllers interface with remote Input/Output boxes or directly with sensors and actuators using new Ethernet-based industrial protocols like ENIP and PROFINET , and wireless networks like WirelessHART .
Several ring topologies have also been proposed to avoid a single point of failure for these networks , such as the use of Device Level Ring ( DLR ) over ENIP .
SCN and FCN networks represent Oblivious Transfer ( OT ) networks , and they have different communication requirements and different industrial network protocols .
While SCN can tolerate delays of up to the order of seconds , FCN typically require an order of magnitude of lower communication delays , typically enabling communications between devices with a period of 400 us .
The layer where we monitor the physics of the system can have a signiﬁcant impact on the types of attacks that can be detected [ 1621 ] .
Most of the work on network security monitoring for industrial control systems has deployed network intrusion detection systems at the SCN .
However , if an anomaly detection system is only deployed in the supervisory control network then a compromised PLC can send manipulated data to the ﬁeld network , while pretending to report that everything is normal back to the supervisory control network .
Upon reception of ua , the frequency converters periodically increased and decreased the rotor speeds well above and below their intended operation levels .
While the status of the frequency converters y was then relayed back to the PLC , the compromised PLC reported a manipulated value ya 6= y to the control centre ( claiming that devices were operating normally ) .
A similar attack was performed against the Siemens 417 controller [ 1623 ] , where attackers captured 21 seconds of valid sensor variables at the PLC , and then replayed them continuously for the duration of the attack , ensuring that the data sent through the SCN to the SCADA monitors would appear normal [ 1623 ] .
[ 1621 ] , and the ﬁnal recommendation is to deploy system monitors at the ﬁeld network , as well as at the supervisory network , and across different loops of the control system .
The basic idea is to identify that a control action can cause a problem in the system , and therefore a reference monitor will prevent this control signal from reaching the physical system .
A concise survey of research in ICS security was given by Krotoﬁl and Gollmann [ 1632 ] , and reviews of state-of-the-art practices in the ﬁeld of ICS security include the work of Knowles et al .
Therefore one of the big challenges in this space is the reproducibility of results and the generality of industrial control testbeds [ 1634 ] .
19.3.2 Electric Power Grids At the turn of the century , the US National Academy of Engineering selected the top 20 engineering achievements of the twentieth century ( the achievements that most improved people ’ s quality of life ) and at the top of this list , was the power grid [ 1635 ] .
In the approximately 140 years since their inception , electric grids have extended transmission lines to 5 billion people around the world , bringing light , refrigeration , and many other basic services to people across the globe .
Electric power is generated wherever it is convenient and economical , and then it is transmitted at high voltages ( 100kV-500kV ) in order to minimise energy losses—electrical power is equal to voltage times electrical current ( P = V I ) , ( and given a constant power , high voltage lines have less electrical current ) , and therefore there is less energy lost as heat as the current moves through the transmission lines .
is more important , therefore they are operated at lower voltages .
The transmission system is an interconnected , redundant network that spans large regions ( usually one country ) .
Large generation plants and the transmission network ( the ﬁrst two parts of the power grid ) are usually referred to as the Bulk Power System , and this bulk power system is responsible for the reliable delivery of electricity to large areas .
A disruption in the bulk power grid can cause a country-level blackout that would require several days of a blackstart period to restart the system .
This is the reason most government and industry efforts have prioritised the creation of standards for security in the bulk power system [ 1611 ] .
One of the most popular lines of work related to the security of power systems is the study of false data injection attacks in order to cause the algorithms in the power grid to misbehave .
The most popular of this type of attacks are the false data injection attacks against state estimation .
In the power grid , operators need to estimate the phase angles xk from the measured power ﬂow yk in the transmission grid .
As mentioned in the section about CPS safety , bad data detection algorithms were meant to detect random sensor faults , not strategic attacks , and as Liu et al .
There has been a signiﬁcant amount of follow up research focusing on false data injection for state estimation in the power grid , including the work of Dán and Sandberg [ 1638 ] , who study the problem of identifying the best k sensors to protect in order to minimise the impact of attacks , and Kosut et al .
19.3.2.1 Smart Grids While the current power grid architecture has served well for many years , there is a growing need to modernise the world ’ s electric grids to address new requirements and to take advantage of the new technologies .
This modernisation includes the integration of renewable sources of energy , the deployment of smart meters , the exchange of electricity between consumers and the grid , etc .
The rationale for modernising the power grid includes the following reasons : Bulk Generation Transmission Distribution Renewable Energy Integration Renewable Wide Area Monitoring Non Renewable Smart Relays Phasor Measurement Unit Large Capacity Batteries Customers Renewable Energy Smart Meter One-way electricity flow Two-way electricity flow Smart Meter Energy Management Systems Batteries Smart Appliances Plug-in Vehicles Figure 19.6 : Modernization of the power grid [ 1643 ] .
Efﬁciency : One of the main drivers of the smart grid programs is the need to make more efﬁcient use of the current assets .
The peak demand for electricity is growing every year and so utility companies need to spend more money each year in new power plants and their associated infrastructures .
However , the peak demand is only needed 16 % of the time and so the equipment required to satisfy this peak demand will remain idle for the rest of the time .
One of the goals for the smart grid is to change the grid from load following to load shaping by giving incentives to consumers for reducing electricity consumption at the times of peak demand .
Reducing peak demand – in addition to increasing the grid stability – can enable utilities to postpone or avoid the construction of new power stations .
The control or incentive actions used to shape the load is usually called Demand Response .
KA Cyber-Physical Systems Security | October 2019 Page 628 The Cyber Security Body Of Knowledge www.cybok.org Efﬁciency also deals with the integration of the new and renewable generation sources , such as wind and solar power with the aim of reducing the carbon footprint .
Reliability : The second main objective of modernising the power grid is reliability , especially at the distribution layer ( the transmission layer is more reliable ) .
By deploying new sensors and actuators throughout the power grid , operators can receive real-time , ﬁne-grained data about the status of the power grid , that enables better situational awareness , faster detection of faults ( or attacks ) , and better control of the system , resulting in fewer outages .
For example , the deployment of smart meters is allowing distribution utilities to automatically identify the location and source of an outage .
Consumer choice : The third objective is to address the lack of transparency the current power grid provides to consumers .
Currently , most consumers receive only monthly updates about their energy usage .
In general , consumers do not know their electricity consumption and prices that they are paying at different times of the day .
They are also not informed about other important aspect of their consumption such as the proportion of electricity that was generated through renewable resources .
One of the goals of the smart grid is to offer consumers real-time data and analytics about their energy use .
Smart appliances and energy management systems will automate homes and businesses according to consumer preferences , such as cost savings or by making sure more renewable energy is consumed .
To achieve these objectives , the major initiatives associated with the smart grid are the advanced metering infrastructure , demand response , transmission and distribution automation , distributed energy resources , and the integration of electric vehicles .
While modernising the power grid will bring many advantages , it can also create new threat vectors .
Smart grid technologies can be used to infer the location and behaviour of users including if they are at home , the amount of energy that they consume , and the type of devices they own [ 1645 , 1646 ] ) .
In addition to new privacy threats , another potential new attack has been referred to as loadaltering attack .
Demand-response programs provide a new mechanism for controlling the demand of electricity to improve power grid stability and energy efﬁciency .
Currently , these programs are mostly used by large commercial consumers and government agencies managing large campuses and buildings , and their operation is based on informal incentive signals via phone calls by the utility or by the demand-response provider ( e.g .
As these programs become more widespread ( targeting residential consumers ) and automated ( giving utilities or demand-response companies the ability to directly control the load of their customers remotely ) the attack surface for load-altering attacks will increase .
The attacks proposed consider that the adversary has gained access to the company controlling remote loads and can change a large amount of the load to affect the power system and cause either inefﬁciencies to the system , economic proﬁts for the attacker , or potentially cause enough load changes to change the frequency of the power grid and cause large-scale blackouts .
Demand-response systems can be generalised by transactive energy markets , where prosumers ( consumers with energy generation and storage capabilities ) can trade energy with each other , bringing their own privacy and security challenges [ 1653 ] .
[ 1655 ] showed that creating a system blackout—which would require a black start period of several days to restart the grid—or even a blackout of a large percentage of the bulk power grid can be very difﬁcult in part because the power grid has several protections to load changes , including under-frequency load shedding .
Modern functionalities include Trafﬁc ﬂow control with ramp metering at freeway on-ramps and signal timing plans at signalised intersections to reduce congestion ; Demand management which focuses on reducing the excess trafﬁc during peak hours ; Incident management which targets resources to alleviate incident hot spots ; and Traveler information which is used to reduce traveler buffer time , i.e .
While this large-scale collection of sensor data can enable various societal advantages , it also raises signiﬁcant privacy concerns .
Although privacy is an important concern for these systems , it is unfortunately not the only one .
[ 1664 ] showed that attackers can inject false data in crowdsourced services to cause false trafﬁc congestion alarms and fake accidents , triggering the services to automatically reroute trafﬁc .
Similar problems can be found on commercial ﬂights .
Not only are airplanes being modernised while introducing potentially new attack vectors by attempting to attack avionic systems through the entertainment network [ 1666 ] but air trafﬁc systems might also be vulnerable to attacks .
ADS-B consists of airplanes sharing their GPS coordinates with each other and with air trafﬁc control systems , but these systems are currently unauthenticated and unencrypted , posing security and privacy problems [ 1667 ] .
19.3.3.1 Ground , Air , and Sea Vehicles Software problems in the sensors of vehicles can cause notorious failures , as the Ariane 5 rocket accident [ 1668 ] , which was caused by software in the inertial navigation system shut down causing incorrect signals to be sent to the engines .
With advances in manufacturing and modern sensors , we are starting to see the proliferation of Unmanned Vehicles ( UVs ) in the consumer market as well as across other industries .
Devices that were only available to government agencies have diversiﬁed their applications ranging from agricultural management to aerial mapping and freight transportation [ 1669 ] .
The expansion of unmanned aerial vehicles has increased security and privacy concerns .
UVs have multiple sensors that aid them to assess their physical environments such as accelerometers , gyroscopes , barometers , GPS and cameras .
While reliance on sensor data without any form of validation has proven to be an effective trade-off in order to maintain the efﬁciency demands of real-time systems , it is not a sustainable practice as UVs become more pervasive .
ICAS are generally installed with connections to external Programmable Logic Controllers ( PLCs ) , which are used in Supervisory Control and Data Acquisition ( SCADA ) systems to direct the movement of control equipment that performs actual manipulation of physical devices in the ship such as propulsion and steering ( rudder ) devices [ 1676 , 1677 ] .
Therefore , the secure operation of ships is highly related to the security of industrial control systems .
For ground vehicles , one of the areas of interest is the security of the Controller Area Network ( CAN ) .
The CAN system is a serial broadcast bus designed by Bosch in 1983 to enable the communication of Electrical Control Units ( ECUs ) in cars .
Examples of ECUs include brake systems , the central timing module , telematic control units , gear control , and engine control .
KA Cyber-Physical Systems Security | October 2019 Page 631 The Cyber Security Body Of Knowledge www.cybok.org 19.3.4 Robotics and Advanced Manufacturing Security in manufacturing has been for many years a part of critical infrastructure security but , as the manufacturing process became more sophisticated , the threats have increased .
They also mention that quality control techniques traditionally used in the manufacturing industry can be leveraged to detect attacks .
Robotic systems in automated assembly lines can also be used to create damaged parts or cause safety problems [ 1685 ] .
Singer , the Ford worker might have been the ﬁrst , but he would be far from the last , as robots have killed various other people [ 1686 ] .
We will discuss later in this document how new advances in CPSs may change the way nations wage future wars .
19.3.5 Medical Devices Due to their safety and privacy risks , embedded medical devices are another CPS domain that has received signiﬁcant attention in the literature .
While not an attack , the software error of the Therac-25 is one of the most well-known classical examples of how software problems can harm and even kill people .
Our concern here is if these problems are not accidental but malicious ?
These devices can usually be queried and reprogrammed by a doctor , but this also opens these devices up to security and privacy threats , in particular when an attacker can impersonate the device used by the doctor to modify the settings of IMDs . ) .
, and the use of an external wearable device that allows or denies access to the medical device depending on whether this extra wearable device is present .
In addition to prevention , they also discuss attack detection by observing patterns to distinguish between safe and unsafe behaviour .
The basic idea is that the patient has a biometric signal ( such as the time between heart beats ) that should only be available to other devices KA Cyber-Physical Systems Security | October 2019 Page 632 The Cyber Security Body Of Knowledge www.cybok.org in direct contact with the patient .
This “ secret ” information is then used by the programmer and the IMD as a fuzzy password to bootstrap their security association .
A key challenge is to make sure that the biometric signal being used to give access via touchto-access , is not remotely observable .
As healthcare computer and software infrastructure introduces new technology , the industry will need to increase its security efforts .
19.3.6 The Internet of Things Consumer Internet of Things ( IoT ) devices are found everywhere : in our houses as voiceassistant devices , home automation smart devices , smart appliances , and surveillance systems ; in healthcare as wearable technology including ﬁtness devices and health-monitoring devices ; in education including Internet-connected educational children toys ; and for entertainment including remote controlled Wi-Fi devices .
As our lives become more dependent on these systems , their security has become an important , growing concern .
The security of these devices depends on the integrity of the software and ﬁrmware they execute and the security mechanisms they implement .
Internet-connected cameras have given rise to multiple reports of unauthorised access by attackers [ 1695 ] , and video feeds of multiple cameras are openly available online and discoverable through IoT web indexing platforms like Shodan [ 1696 ] , potentially compromising the privacy of consumers who do not check the default conﬁguration mechanisms .
The threats to IoT go beyond privacy fears and DDoS attacks .
Vulnerabilities in consumer IoT products including drones , IoT cameras , smart toys for children , and intimate devices can lead not only to privacy invasions but also to physical damages ( drones being used to harm people ) , abuse , and harassment [ 1697 ] .
Understanding the consequences of these new type of physical and mental abuses will require the involvement of more social scientists and legal scholars to help us deﬁne a framework on how to reason about them .
An area that has attracted signiﬁcant attention from the research community is the security of voice-activated digital assistants .
For example the consumer might want to open the application “ Capital One ” , but an attacker can make an application available called “ Capital Won ” and the voice-controlled personal assistant might open the second functionality .
In the “ voice masquerading ” attack , an attacker application might remain in control of the system and pretend to be following the consumer ’ s commands to open other functionalities , while in reality it is impersonating the desired functionalities .
KA Cyber-Physical Systems Security | October 2019 Page 633 The Cyber Security Body Of Knowledge www.cybok.org Several of the security solutions for consumer IoT have proposed the idea of having a centralised IoT secure hub that mediates the communications between IoT devices in a home , and the Internet [ 1699 ] .
One of the problems of relying on an external device to mediate IoT communications is that the connections between IoT device and the cloud servers may be encrypted , and therefore this hub will need to make security decisions with encrypted trafﬁc [ 1700 ] .
On the other hand , end-to-end encrypted communications can also prevent consumers from auditing their IoT devices to make sure they are not violating their privacy expectations .
One option to address this problem is to ask the vendor of the IoT device to disclose their key ( and rotate their key ) to a trusted third party ( called “ auditor ” ) that can decrypt and show the results to the owners of the data [ 1701 ] .
In short , the proliferation of vulnerable IoT devices is raising new security and privacy concerns , while making IoT devices attractive to attackers .
, devices that have backdoors for troubleshooting ) to their inability to apply software updates to patch vulnerable ﬁrmware .
One of the biggest problems for improving the security of IoT and CPSs is that market forces do not incentivise vendors to compete for better security .
In the next section we will discuss the causes of this lack of security and some potential solutions .
19.4 POLICY AND POLITICAL ASPECTS OF CPS SECURITY [ 1686 , 1702 , 1703 ] In this ﬁnal section of the paper we summarise some of the industry- and government-led efforts to try to improve the security of CPSs , and how to leverage the new ﬁeld of CPS security for attacks and wars .
19.4.1 Incentives and Regulation Most industries in the CPS domain have rarely seen attacks sabotaging their physical process , in part because CPS attacks are hard to monetise by criminals .
” In summary , market incentives alone are insufﬁcient to improve the security posture of CPSs , and as a result , our CPS infrastructures remain fairly vulnerable to computer attacks and with security practices that are decades behind the current security best practices used in enterprise IT domains .
Regulation : Mandating cyber security standards that the CPS industries have to follow is a possible government intervention , and there is some precedent for this idea .
, mandating compliance to speciﬁc security standards ) will stiﬂe innovation , and that more regulation tends to create a culture of compliance instead of a culture of security .
KA Cyber-Physical Systems Security | October 2019 Page 634 The Cyber Security Body Of Knowledge www.cybok.org Some states in the US are starting to take regulation into their hands ; for example , the recently proposed California Senate Bill SB-327 will make California the ﬁrst state in the US with an IoT cyber security law—starting in 2020 , any manufacturer of a device that connects “ directly or indirectly ” to the Internet must equip it with “ reasonable ” security features , designed to prevent unauthorised access , modiﬁcation , or information disclosure .
The European Union Agency for cyber security proposed the EU Network and Information Security directive [ 1708 ] as the ﬁrst piece of EU-wide cyber security legislation , where operators of essential services such as those outlined in this KA have to comply with these new sets of standards .
Another alternative to imposing regulation broadly , is to use the governments ’ “ power of the purse ” by mandating cyber security standards only to companies that want to do business with the government .
The goal would be that once the best security practices are developed to meet the standards for working with the government , then they will spread to other markets and products .
This approach is a reasonable balance between incentives and regulation .
Only CPS and IoT vendors working with the Federal government will have to follow speciﬁc security standards , but once they are implemented , the same security standards will beneﬁt other markets where they reuse the technologies .
One of the notable exceptions to the lack of regulation is the nuclear energy industry .
Because of the highly safety-critical nature of this industry , nuclear energy is highly regulated in general , and in cyber security standards in particular , with processes such as the Ofﬁce for Nuclear Regulation ( ONR ) Security Assessment Principles in the UK [ 1709 ] .
Incentives : A complementary way to nudge companies to improve their cyber security posture is for governments to nurture a cyber-insurance market for CPS protection .
The idea is that premiums charged by the insurance companies would reﬂect the cyber security posture of CPS companies ; if a company follows good cyber security practices , the insurance premiums would be low , otherwise , the premiums would be very expensive ( and this would in principle incentivise the company to invest more in cyber security protections ) .
It is not clear if this cyber-insurance market will grow organically , or if it would need to be mandated by the government .
It is unclear if government incentives to improve security in CPSs will require ﬁrst a catastrophic cyber-attack , but it appears that , in the future , the choice will no longer be between government regulation and no government regulation , but between smart government regulation and stupid regulation [ 1702 ] .
Cybercriminals compromise computers anywhere they can ﬁnd them ( even in control systems ) .
, they do not have the intention of harming control systems ) , but may cause negative side effects : control systems infected with malware may operate inappropriately .
The most famous non-targeted attack on control systems occurred in 2003 , when the Slammer worm affected the computerised safety monitoring system at the Davis-Besse nuclear power plant in the US .
More recently , ransomware has also been used to attack CPSs , like the attack on the Austrian hotel [ 1522 ] , where guests were unable to get their room keys activated until the hotel paid the ransom .
These attacks are important from a security point of view because they are caused by insiders : individuals with authorised access to computers and networks used by control systems .
So , even if the systems had proper authentication and authorisation , as well as little information publicly available about them , attacks by insiders would still be possible .
Because disgruntled employees generally act alone , the potential consequences of their attacks may not be as damaging as the potential harm caused by larger organised groups such as terrorists and nation states .
Terrorists , and activists are another potential threat to control systems .
While there is no concrete evidence that terrorists or activists have targeted control systems via cyber-attacks , there is a growing threat of such an attack in the future .
Nation states are establishing military units with computer security expertise for any future conﬂicts .
In addition to land , air , sea and space , cyberspace is now considered by many nations as an additional theatre of conﬂict .
International treaties have developed public international law concerning two main principles in the law of war ( 1 ) jus ad bellum the right to wage a war , and ( 2 ) jus in bellum acceptable wartime conduct .
The Tallinn manual is a non-binding study by NATO ’ s cooperative cyber-defence center of excellence , on how the law of war applies to cyber conﬂicts , and the Koh Speech was a speech given by Harold Koh , a US State Department legal advisor , which explained how the US interprets international law applied to cyberspace .
The argument is that the effects of any of these attacks are similar to what a missile strike from an enemy would look like .
In contrast , when there is no physical harm , the problem of determining when a cyber-attack can be considered a use of force by the enemy is unresolved , so cyber-attacks to the ﬁnancial , or election infrastructure of a nation may not clear the bar to be considered an act of war .
Once nations are engaged in war , the question is how to leverage computer attacks in a way that is consistent with acceptable wartime conduct ( jus in bellum ) .
The conventional norm is that attacks must distinguish between military and non-military objectives .
The problem in attacking critical infrastructures is that some of the infrastructures supporting these efforts are in dual-use by the military as well as by the civilian population .
For example , a large percentage of military communications in the US use civilian networks at some stage , and the power grid supports military as well as civilian infrastructures .
Another factor to consider in designing CPS attacks is that the “ law of war ” in general prohibits uncontrollable or unpredictable attacks , in particular those that deny the civilian population of indispensable objects , such as food or water .
While physical weapons have a limited geographical area of impact , cyberweapons can have more uncontrollable side-effects ; for example , worms can replicate and escape their intended target network and infect civilian infrastructures .
Therefore , nations will have to extensively test any cyberweapon to minimise unpredictable consequences .
In short , any future conﬂict in the physical world will have enabling technologies in the cyberworld , and computer attacks may be expected to play an integral part in future conﬂicts .
There is a large grey area regarding what types of computer attacks can be considered an act of force , and a future challenge will be to design cyber-attacks that only target military objectives and minimise civilian side effects .
At the same time , attack attribution in cyber-space will be harder , and nation-states might be able to get away with sabotage operations without facing consequences .
It is a responsibility of the international community to design new legal frameworks to cover cyber-conﬂicts , and for nation states to outline new doctrines covering how to conduct cyber-operations with physical side effects .
Finally , cyberwar is also related to the discussion in the last section about cyber-insurance .
For example , after the NotPetya cyberattack in 2017 [ 1718 ] , several companies who had purchased cyber-insurance protections sought to get help from their insurance companies to cover part of their loses .
However , some insurance companies denied the claims citing a war exclusion which protects insurers from being saddled with costs related to damage from war .
Since then insurers have been applying the war exemption to avoid claims related to digital attacks 2 .
This type of collateral damage from cyber-attacks might be more common in the future , and presents a challenge for insurance industries in their quest to quantify the risk of correlated large-scale events .
2 https : //www.nytimes.com/2019/04/15/technology/cyberinsurance-notpetya-attack.html KA Cyber-Physical Systems Security | October 2019 Page 637 The Cyber Security Body Of Knowledge www.cybok.org 19.4.3 Industry Practices and Standards We ﬁnalise the CPS Security KA by referencing various industry and government efforts for improving the security of CPSs .
There are several industrial and government-led efforts to improve the security of control systems .
One of the most important security standards in this space started with the Instruction Set Architecture ( ISA ) standard ISA 99 , which later became a US standard with ANSI 62443 and ﬁnally an international cyber security standard for control systems known as IEC 62443 [ 1719 ] .
The US National Institute of Standards and Technology ( NIST ) has guidelines for security best practices for general IT in Special Publication 800-53 .
US Federal agencies must meet NIST SP 800-53 , but industry in general ( and industry dealing with the US government in particular ) uses these recommendations as a basis for their security posture .
Although these recommendations are not enforceable , they can provide guidance for analysing the security of most utility companies .
A more recent effort is the NIST cyber security framework for protecting critical infrastructure , which was initiated by an Executive Order from then US President Obama [ 1721 ] , as an effort to improve the security posture of critical infrastructures .
NERC is authorised to enforce compliance to these standards , and it is expected that all electric utilities operating the bulk power system in North America are fully compliant with these standards .
All of these standards are general and ﬂexible .
In addition to these general security standards for control systems , the industries that develop and maintain speciﬁc industrial control protocols , such as those used for SCADA , e.g .
Recall that most of these industrial protocols were developed before security was a pressing concern for industrial control systems , therefore the communication links were not authenticated or encrypted .
The new standard IEC 62351 is meant to guide asset owners on how to deploy a secure network to authenticate and encrypt network links , and other organisations have released similar support , such as , providing security extensions for PROFINET3 .
Instead ( or in addition ) to using these end-toend application layer security recommendations , some operators might prefer to use lowerlayer security protections of IP networks , including TLS and IPSec .
In the IoT domain , ETSI , the European Standards Organisation developed the ﬁrst globallyapplicable security standard for consumer IoT .
The goal of this standard is to automate the creation of network white lists , which are used by network administrators to block any unauthorised connection by the device .
For the most part industry efforts for protecting CPSs are based on the same technical principles from general Information Technology systems .
Therefore , industry best practices are behind general IT security best practices and the most recent CPS security research discussed in this KA .
We hope that in the next decade CPS security research becomes mature enough to start having an impact on industry practices .
CONCLUSIONS As technology continues to integrate computing , networking , and control elements in new cyber-physical systems , we also need to train a new generation of engineers , computer scientists , and social scientists to be able to capture the multidisciplinary nature of CPS security , like transduction attacks .
In addition , as the technologies behind CPS security mature , some of them will become industry-accepted best practices while others might be forgotten .
Several start-up companies in the US , Europe , and Israel offer services for proﬁling and characterising industrial networks , to help operators better understand what is allowed and what should be blocked .
On the other hand , there are other CPS security research areas that are just starting to be analysed , like the work on attack mitigation , and in particular , the response to alerts from intrusion detection systems .
We are only at the starting point for CPS security research , and the decades to come will bring new challenges as we continue to integrate physical things with computing capabilities .
The physical phenomenon utilized by the techniques presented in this Knowledge Area is the radiation of electromagnetic waves .
The frequencies considered hereinafter consist of the entire spectrum that ranges from a few Hertz to frequencies beyond those of visible light ( optical spectrum ) .
This Knowledge Area covers concepts and techniques that exploit the way these signals propagate through the air and other transmission media .
It is organised into sections that describe security mechanisms for wireless communication methods as well as some implications of unintended radio frequency emanations .
Since most frequencies used for wireless communication reside in the radio frequency spectrum and follow the well-understood laws of radio propagation theory , the majority of this Knowledge Area is dedicated to security concepts based on physical aspects of radio frequency transmission .
The chapter therefore starts with an explanation of the fundamental concepts and main techniques that were developed to make use of the wireless communication layer for conﬁdentiality , integrity , access control and covert communication .
These techniques mainly use properties of physical layer modulations and signal propagation to enhance the security of systems .
After having presented schemes to secure the wireless channel , the Knowledge Area continues with a review of security issues related to the wireless physical layer , focusing on those aspects that make wireless communication systems different from wired systems .
Following this , the chapter continues to present approaches for performing secure distance measurements and secure positioning based on electromagnetic waves .
Protocols for distance measurements and positioning are designed in order to thwart threats on the physical layer as well as the logical layer .
Those attack vectors are covered in detail , together with defense strategies and the requirements for secure position veriﬁcation .
Then , the Knowledge Area covers unintentional wireless emanations from devices such as from computer displays and summarises wireless side-channel attacks studied in literature .
This is followed by a review on spooﬁng of analogue sensors .
Unintentional emissions are in their nature different from wireless communication systems , especially because these interactions are not structured .
Finally , after having treated the fundamental concepts of wireless physical security , this Knowledge Area presents a selection of existing communication technologies and discusses their security mechanisms .
It explains design choices and highlights potential shortcomings while referring to the principles described in the earlier sections .
Included are examples from near-ﬁeld communication and wireless communication in the aviation industry , followed by the security considerations of cellular networks .
Security of global navigation systems and of terrestrial positioning systems is covered last since the security goals of such systems are different from communication systems and are mainly related to position spooﬁng resilience .
The channel response , as measured at the receiver , can therefore be modelled as having frequency and position dependent random components .
In addition , within the short time span and in the absence of interference , communicating parties will measure highly correlated channel responses .
These responses can therefore be used as shared randomness , unavailable to the adversary , and form a basis of secure communication .
It should be noted that modern-day cryptography provides many different protocols to assure the conﬁdentiality , integrity and authenticity of data transmitted using radio signals .
If the communicating parties are associated with each other or share a mutual secret , cryptographic protocols can effectively establish secure communication by making use of cryptographic keying material .
, in a positioning system ) , or if no pre-shared secrets are available , cryptographic protocols operating at higher layers of the protocol stack are not sufﬁcient and physical-layer constructs can be viable solutions .
The main physical layer schemes are presented in the following sections .
20.1.1 Key Establishment based on Channel Reciprocity The physical-layer randomness of a wireless channel can be used to derive a shared secret .
One of the main security assumptions of physical-layer key establishment schemes is that the attacker is located at least half a wavelength away from the communicating parties .
According to wireless communication theory , it can be assumed that the attacker ’ s channel measurements will be de-correlated from those computed by the communicating parties if they are at least half a wavelength apart .
The attacker will therefore likely not have access to the measured secret randomness .
If the attacker injects signals during the key generation , the signal that it transmits will , due to channel distortions , be measured differently at communicating parties , resulting in key disagreement .
Physical layer key establishment schemes operate as follows .
Each party then measures the channel response over the received packets .
The key agreement is then typically executed in three phases .
Quantisation Phase : Alice and Bob create a time series of channel properties that are measured over the received packets .
Example properties include RSSI and the CIR .
Any property that is believed to be non-observable by the attacker can be used .
The measured time series are then quantised by both parties independently .
This quantisation is typically based on ﬁxed or dynamic thresholds .
KA Physical Layer Security and Telecommunications | October 2019 Page 643 The Cyber Security Body Of Knowledge www.cybok.org Information Reconciliation Phase : Since the quantisation phase is likely to result in disagreeing sequences at Alice and Bob , they need to reconcile their sequences to correct for any errors .
This is typically done leveraging error correcting codes and privacy ampliﬁcation techniques .
Most schemes use simple level-crossing algorithms for quantisation and do not use coding techniques .
However , if the key derivation uses methods based on channel states whose distributions are not necessarily symmetric , more sophisticated quantisation methods , such as approximating the channel fading phenomena as a Gaussian source , or ( multilevel ) coding is needed [ 1727 ] .
Key Veriﬁcation Phase : In this last phase , communicating parties conﬁrm that they established a shared secret key .
If this step fails , the parties need to restart key establishment .
Most of the research in physical-layer techniques has been concerned with the choice of channel properties and of the quantisation technique .
Even if physical-layer key establishment techniques seem attractive , many of them have been shown to be vulnerable to active , physically distributed and multi-antenna adversaries .
However , in a number of scenarios where the devices are mobile , and where the attacker is restricted , they can be a valuable replacement or enhancement to traditional public-key key establishment techniques .
However , with the emergence of MIMO devices and beam-forming , researchers have proposed to leverage these new capabilities to further secure communication .
Two basic techniques that were proposed in this context are orthogonal blinding and zero forcing .
Both of these techniques aim to enable the transmitter to wirelessly send conﬁdential data to the intended receiver , while preventing the co-located attacker from receiving this data .
Although this might seem infeasible , since as well as the intended receiver , the attacker can receive all transmitted packets .
For beam-forming to be effective , the transmitter needs to know some channel information for the channels from its antennas to the antennas of the receiver .
In Zero-Forcing , the transmitter knows the channels to the intended receiver as well as to the attacker .
This allows the transmitter to encode the data such that it can be measured at the receiver , whereas the attacker measures nothing related to the data .
In many scenarios , assuming the knowledge of the channel to the attackers is unrealistic .
In Orthogonal Blinding , the transmitter doesn ’ t know the channel to the attacker , but knows the channels to the receiver .
The transmitter then encodes the data in the way that the receiver can decode the data , whereas the attacker will receive data mixed with random noise .
The attacker therefore can not decode the data .
In order to communicate securely , the transmitter and the receiver do not need to share any secrets .
Instead , the transmitter only needs to know ( or measure ) the channels to the intended receivers .
Like physical-layer key establishment techniques , these techniques have been show to be vulnerable to multi-antenna and physically distributed attackers .
They were further shown to be vulnerable to known-plaintext attacks .
KA Physical Layer Security and Telecommunications | October 2019 Page 644 The Cyber Security Body Of Knowledge www.cybok.org 20.1.3 Secrecy Capacity Secrecy capacity is an information-theoretical concept that attempts to determine the maximal rate at which a wireless channel can be used to transmit conﬁdential information without relying on higher-layer encryption , even if there is an eavesdropper present .
This means it is possible to convey a secret message without leaking any information to an eavesdropper .
Researchers have managed to derive explicit mathematical expressions and bounds even when taking into account complex phenomena such as fading which is present in wireless channels [ 1734 ] .
A practical implementation of the concept of secrecy capacity can mainly be achieved using the two methods described above .
Either the communicating parties establish a secret key by extracting features from the wireless channel ( see 20.1.1 ) or they communicate with each other using intelligent coding and transmission strategies possibly relying on multiple antennas ( see 20.1.2 ) .
Therefore , the study of secrecy capacity can be understood as the information-theoretical framework for key establishment and MIMO-supported security mechanisms in the context of wireless communication .
20.1.4 Friendly Jamming Similar to Orthogonal Blinding , Friendly Jamming schemes use signal interference generated by collaborating devices to either prevent an attacker from communicating with the protected device , or to prevent the attacker from eavesdropping on messages sent by protected devices .
Friendly Jamming can therefore be used for both conﬁdentiality and access control .
Unlike Orthogonal Blinding , Friendly Jamming doesn ’ t leverage the knowledge of the channel to the receiver .
, the friendly jammer ) wants to prevent unauthorised communication with the protected device it will jam the receiver of the protected device .
If it wants to prevent eavesdropping , it will transmit jamming signals in the vicinity of the protected device .
Preventing communication with a protected device requires no special assumptions on the location of the collaborating devices .
However , protecting against eavesdropping requires that the eavesdropper is unable to separate the signals from the protected device from those originating at the collaborating device .
For this to hold , the channel from the protected device to the attacker should not be correlated to the channel from the collaborating device to the attacker .
To ensure this , the protected device and the collaborating device need to be typically placed less than half a carrier wavelength apart .
This assumption is based on the fact that , in theory , an attacker with multiple antennas who tries to tell apart the jamming signal from the target signal requires the two transmitters to be separated by more than half a wavelength .
However , signal deterioration is gradual and it has been shown that under some conditions , a multi-antenna attacker will be able to separate these signals and recover the transmitted messages .
Friendly jamming was originally proposed for the protection of those medical implants ( e.g .
, KA Physical Layer Security and Telecommunications | October 2019 Page 645 The Cyber Security Body Of Knowledge www.cybok.org already implanted pacemakers ) that have no abilities to perform cryptographic operations .
This device would then simultaneously receive and jam all communication from the implant .
The shield would then be able to forward the received messages to any other authorised device using standard cryptographic techniques .
20.1.5 Using Physical Layer to Protect Data Integrity Research into the use of physical layer for security is not only limited to the protection of data conﬁdentiality .
Physical layer can also be leveraged to protect data integrity .
This is illustrated by the following scenario .
, shared keys or authenticated public keys ) , how can the messages exchanged between these entities be authenticated and how can their integrity be preserved in the presence of an attacker ?
Here , by message integrity , we mean that the message must be protected against any malicious modiﬁcation , and by message authentication we mean that it should be clear who is the sender of the message .
One basic technique that was proposed in this context is integrity codes , a modulation scheme that provides a method of ensuring the integrity ( and a basis for authentication ) of a message transmitted over a public channel .
Integrity codes rely on the observation that , in a mobile setting and in a multi-path rich environment , it is hard for the attacker to annihilate randomly chosen signals .
Integrity codes assume a synchronised transmission between the transmitter and a receiver , as well as the receiver being aware that it is in the range of the transmitter .
This encoded message is then transmitted using on-off keying , such that each 0 is transmitted as an absence of signal and each 1 as a random signal .
To decode the message and check its integrity , the receiver simply measures the energy of the signal .
If the ratio of bits 1 and 0 corresponds to the encoding scheme , the integrity of the message is validated .
Integrity codes assume that the receiver knows when the transmitter is transmitting .
This means that their communication needs to be scheduled or the transmitter needs to always be transmitting .
20.1.6 Low Probability of Intercept and Covert Communication LPI signals are such signals that are difﬁcult to detect for the unintended recipient .
The simplest form of LPI is communication at a reduced power and with high directionality .
Since such communication limits the range and the direction of communication , more sophisticated techniques were developed : Frequency Hopping , Direct Sequence Spread Spectrum and Chirping .
In Frequency Hopping the sender and the receiver hop between different frequency channels thus trying to avoid detection .
In Direct Sequence Spread Spectrum the information signal is modulated with a high rate ( and thus high bandwidth ) digital signal , thus spreading across a wide frequency band .
Finally , Chirps are high speed frequency sweeps that carry information .
The hopping sequence or chirp sequence constitute a secret shared between receiver and transmitter .
This allows the legitimate receiver to recombine the signal while an eavesdropper is unable to do so .
KA Physical Layer Security and Telecommunications | October 2019 Page 646 The Cyber Security Body Of Knowledge www.cybok.org Covert communication is parasitic and leverages legitimate and expected transmissions to enable unobservable communication .
Typically , such communication hides within the expected and tolerated deviations of the signal from its nominal form .
One prominent example is embedding of communicated bits within the modulation errors .
It happens when the jammer injects a signal which , when combined with the legitimate transmission , prevents the receiver from extracting the information contained in the legitimate transmission .
Jamming can be surgical and affect only the message preamble thus preventing decoding , or can be comprehensive and aim to affect every symbol in the transmission .
Depending on their behaviour , jammers can be classiﬁed as constant or reactive .
Constant jammers transmit permanently , irrespective of the legitimate transmission .
Reactive jammers are most agile as they sense for transmission and then jam .
This allows them to save energy as well as to stay undetected .
Jammer strength is typically expressed in terms of their output power and their effectiveness as the jamming-to-signal ratio at the receiver .
Beyond a certain jamming-to-signal ratio , the receiver will not be able to decode the information contained in the signal .
This ratio is speciﬁc to particular receivers and communication schemes .
The main parameters that inﬂuence the success of jamming are transmission power of the jammer and benign transmitter , their antenna gains , communication frequency , and their respective distances to the benign receiver .
Countermeasures against jamming involve concealing from the adversary which frequencies are used for communication at which time .
This uncertainty forces the adversary to jam a wider portion of the spectrum and therefore weakens their impact on the legitimate transmission , effectively reducing the jamming-to-signal ratio .
20.2.1 Coordinated Spread Spectrum Techniques Coordinated Spread Spectrum techniques are prevalent jamming countermeasures in a number of civilian and military applications .
They are used not only to increase resilience to jamming , but also to cope with interference from neighboring devices .
Spread spectrum techniques are typically effective against jammers that can not cover the entire communication spectrum at all times .
These techniques make a sender spread a signal over the entire available band of radio frequencies , which might require a considerable amount of energy .
This gain is the ratio by which interference can be suppressed relative to the original signal , and is computed as a ratio of the spread signal radio frequency bandwidth to the un-spread information ( baseband ) band22 width .
Spread-spectrum techniques use randomly generated sequences to spread information signals over a wider band of frequencies .
The resulting signal is transmitted and then de-spread at the receivers by correlating it with the spreading sequence .
For this to work , it is essential that the transmitter and receiver share the same secret spreading sequence .
In FHSS , this sequence is the set of central frequencies and the order in which the transmitter and receiver switch between them in synchrony .
In DSSS , the data signal is modulated with the spreading sequence ; this process effectively mixes the carrier signal with the spreading sequence , thus increasing the frequency bandwidth of the transmitted signal .
This process allows for both narrow band and wide band jamming to be suppressed at the receiver .
Unless the jammer can guess the spreading code , its jamming signal will be spread at the receiver , whereas the legitimate transmission will be de-spread , allowing for its detection .
The secrecy of the spreading codes is therefore crucial for the jamming resilience of spread spectrum systems .
This is why a number of civilian systems that use spreading with public spreading codes , such as the GPS and 802.11b , remain vulnerable to jamming .
20.2.2 Uncoordinated Spread Spectrum Techniques In broadcast applications and in applications in which communication can not be anticipated as scheduled , there is still a need to protect such communication from jamming .
To address such scenarios , uncoordinated spread spectrum techniques were proposed : UFH and UDSSS .
Uncoordinated Frequency Hopping relies on the fact that even if the sender hops in a manner that is not coordinated with the receiver , the throughput of this channel will be non-zero .
In fact , if the receiver is broadband , it can recover all the messages transmitted by the sender .
Given that the sender and the receiver are not synchronised , and short message fragments transmitted within each hop are not authenticated , the attacker can inject fragments that make the reassembly of the packets infeasible .
To prevent this , UFH includes fragment linking schemes that make this reassembly possible even under poisoning .
UDSSS follows the principle of DSSS in terms of spreading the data using spreading sequences .
However , in contrast to anti-jamming DSSS where the spreading sequence is secret and shared exclusively by the communication partners , in UDSSS , a public set of spreading sequences is used by the sender and the receivers .
To transmit a message , the sender repeat- KA Physical Layer Security and Telecommunications | October 2019 Page 648 The Cyber Security Body Of Knowledge www.cybok.org edly selects a fresh , randomly selected spreading sequence from the public set and spreads the message with this sequence .
Hence , UDSSS neither requires message fragmentation at the sender nor message reassembly at the receivers .
The receivers record the signal on the channel and despread the message by applying sequences from the public set , using a trial-and-error approach .
The receivers are not synchronised to the beginning of the sender ’ s message and thus record for ( at least ) twice the message transmission time .
After the sampling , the receiver tries to decode the data in the buffer by using code sequences from the set and by applying a sliding-window protocol .
20.2.3 Signal Annihilation and Overshadowing Unlike jamming where the primary goal of the attacker is to prevent information from being decoded at the receiver , signal annihilation suppresses the signal at the receiver by introducing destructive interference .
This typically means that the attacker will generate a signal identical to the legitimate transmission only with a different polarity .
Jamming attacks typically increase the energy on the channel and thus are more easily detected than signal annihilation which reduces the energy typically below the threshold of signal detection .
The goal of overshadowing is similar to jamming and signal annihilation in the sense that the attacker aims to prevent the receiver from decoding a legitimate signal .
However , instead of interfering with the signal by adding excessive noise to the channel or cancelling out the signal ( i.e .
, signal annihilation ) , the attacker emits their own signal at the same time and overshadows the legitimate signal .
As a result , the receiver only registers the adversarial signal which is often orders of magnitude higher in amplitude than the legitimate signal .
Malicious signal overshadowing can not only deceive the receiver into decoding different data than intended , it can also be used to alter any physical properties the receiver may extract during signal reception , such as angle of arrival or time of arrival .
Overshadowing attacks have been shown to be particularly effective against systems that rely on physical layer properties including positioning and ranging systems .
More precisely , physical-layer device identiﬁcation is the process of ﬁngerprinting the analogue circuitry of a device by analysing the device ’ s communication at the physical layer for the purpose of identifying a device or a class of devices .
This type of identiﬁcation is possible due to hardware imperfections in the analogue circuitry introduced at the manufacturing process .
These imperfections are remotely measurable as they appear in the transmitted signals .
While more precise manufacturing and quality control could minimise such artefacts , it is often impractical due to signiﬁcantly higher production costs .
Physical-layer device identiﬁcation systems aim at identifying ( or verifying the identity of ) KA Physical Layer Security and Telecommunications | October 2019 Page 649 The Cyber Security Body Of Knowledge www.cybok.org devices or their afﬁliation classes , such as their manufacturer .
Such systems can be viewed as pattern recognition systems typically composed of : an acquisition setup to acquire signals from devices under identiﬁcation , also referred to as identiﬁcation signals , a feature extraction module to obtain identiﬁcation-relevant information from the acquired signals , also referred to as ﬁngerprints , and a ﬁngerprint matcher for comparing ﬁngerprints and notifying the application system requesting the identiﬁcation of the comparison results .
Typically , there are two modules in an identiﬁcation system : one for enrollment and one for identiﬁcation .
Fingerprints obtained from the feature extraction module are then stored in a database ( each ﬁngerprint may be linked with some form of unique ID representing the associated device or class ) .
During identiﬁcation , ﬁngerprints obtained from the devices under identiﬁcation are compared with reference ﬁngerprints stored during enrollment .
The identiﬁcation module uses statistical methods to perform the matching of the ﬁngerprints .
These methods are classiﬁers trained with Machine Learning techniques during the enrollment phase .
It tries to verify a newly acquired signal against a stored reference pattern established during enrollment .
Often , these classiﬁers are designed to return a list of candidates ranked according to a similarity metric or likelihood that denotes the conﬁdence for a match .
20.3.1 Device under Identiﬁcation Physical-layer device identiﬁcation is based on ﬁngerprinting the analogue circuitry of devices by observing their radio communication .
Consequently , any device that uses radio communication may be subject to physical-layer identiﬁcation .
Although what enables a device or a class of devices to be uniquely identiﬁed among other devices or classes of devices is known to be due to imperfections introduced at the manufacturing phase of the analogue circuitry , the actual device ’ s components causing these have not always been clearly identiﬁed in all systems .
For example , VHF identiﬁcation systems are based on the uniqueness of transmitters ’ frequency synthesisers ( local oscillators ) , while in RFID systems some studies only suggested that the proposed identiﬁcation system may rely on imperfections caused by the RFID device ’ s antennas and charge pumps .
Identifying the exact components may become more difﬁcult when considering relatively-complex devices .
For example , IEEE 802.11 transceivers were identiﬁed considering modulation-related features ; the cause of hardware artefacts can be then located in the modulator subcircuit of the transceivers .
Knowing the components that make devices uniquely identiﬁable may have relevant implications for both attacks and applications , which makes the investigation of such components an important open problem and research direction .
KA Physical Layer Security and Telecommunications | October 2019 Page 650 The Cyber Security Body Of Knowledge www.cybok.org 20.3.2 Identiﬁcation Signals Considering devices communicating through radio signals , that is , sending data according to some deﬁned speciﬁcation and protocol , identiﬁcation at the physical layer aims at extracting unique characteristics from the transmitted radio signals and to use those characteristics to distinguish among different devices or classes of devices .
We deﬁne identiﬁcation signals as the signals that are collected for the purpose of identiﬁcation .
Signal characteristics are mainly based on observing and extracting information from the properties of the transmitted signals , like amplitude , frequency , or phase over a certain period of time .
These time-windows can cover different parts of the transmitted signals .
Non-data-related parts of signals are not associated with data transmission .
The characteristics extracted from identiﬁcation signals are called features .
Those can be predeﬁned or inferred .
Speciﬁcations are used for quality control and describe error tolerances .
Examples of in-speciﬁcation characteristics include modulation errors such as frequency offset , I/Q origin offset , magnitude and phase errors , as well as time-related parameters such as the duration of the response .
Examples of out-speciﬁcation characteristics include clock skew and the duration of the turn-on transient .
Differently from predeﬁned features , where the considered characteristics are known in advance prior to recording of the signals , we say that features are inferred when they are extracted from signals , for example , by means of some spectral transformations such as Fast Fourier Transform ( FFT ) or Discrete Wavelet Transform ( DWT ) , without a-priori knowledge of a speciﬁc signal characteristic .
The Fourier transformation has also been used to extract features from the turn-on transient and other technologyspeciﬁc device responses .
Both predeﬁned and inferred features can be subject to further statistical analysis in order to improve their quality and distinguishing power .
20.3.3 Device Fingerprints Fingerprints are sets of features ( or combinations of features , that are used to identify devices .
The properties that ﬁngerprints need to present in order to achieve practical implementations are ( similar to those of biometrics ) : 1 .
No two devices should have the same ﬁngerprints .
The obtained ﬁngerprints should be invariant over time .
It should be possible to capture the identiﬁcation signals with existing ( available ) equipments .
Fingerprints should not be subject , or at least , they should be evaluated with respect to external environmental aspects that directly inﬂuence the collected signal like radio interference due to other radio signals , surrounding materials , signal reﬂections , absorption , etc .
, as well as positioning aspects like the distance and orientation between the devices under identiﬁcation and the identiﬁcation system .
Many types of robustness can be acceptable for a practical identiﬁcation system .
Generally , obtaining robust features helps in building more reliable identiﬁcation systems .
This dependency has particularly interesting implications if the ﬁngerprints can be associated with both devices and data transmitted by those devices .
This might strengthen authentication and help prevent replay attacks .
20.3.4 Attacks on Physical Layer Identiﬁcation The large majority of research works have focused on exploring feature extraction and matching techniques for physical-layer device identiﬁcation .
Only recently the security of these techniques started being addressed .
Different studies showed that their identiﬁcation system may be vulnerable to hill-climbing attacks if the set of signals used for building the device ﬁngerprint is not carefully chosen .
This attack consists of repeatedly sending signals to the device identiﬁcation system with modiﬁcations that gradually improve the similarity score between these signals and a target genuine signal .
They also demonstrated that transientbased approaches could easily be disabled by jamming the transient part of the signal while still enabling reliable communication .
Furthermore , impersonation attacks on modulationbased identiﬁcation techniques were developed and showed that low-cost software-deﬁned radios as well as high end signal generators could be used to reproduce modulation features and impersonate a target device with a success rate of 50-75 % .
Modulation-based techniques are vulnerable to impersonation with high accuracy , while transient-based techniques are likely to be compromised only from the location of the target device .
The authors pointed out that this is mostly due to presence of wireless channel effects in the considered device ﬁngerprints ; therefore , the channel needed to be taken into consideration for successful impersonation .
The attacker does not modify the captured identiﬁcation signals , that is , the analogue signal and the data payload are preserved .
This attack is similar to message replay in the Dolev-Yao model in which an attacker can observe and manipulate information currently in the air at will .
Unlike in signal replay attacks , where the goal of the attack is to reproduce the captured identiﬁcation signals in their entirety , feature replay attack creates , modiﬁes or composes identiﬁcation signals that reproduce only the features considered by the identiﬁcation system .
The analogue representation of the forged signals may be different , but the features should be the same ( or at the least very similar ) .
Their use is broad and ranges from the prevention of relay attacks to enabling secure positioning .
Securing distance measurement requires secure protocols on the logical layer and a distance measurement technique resilient to physical layer attacks .
To attack distance measurement , an attacker can exploit both data-layer as well as physical-layer weaknesses of distance measurement techniques and protocols .
However , physical-layer attacks are of signiﬁcant concern as they can be executed independently of any higher-layer cryptographic primitive that is implemented .
20.4.1 Distance Bounding Protocols Secure distance measurement protocols aim at preventing distance shortening and enlargement attacks .
When they only prevent distance shortening , they are also called distance bounding protocols , where at the end of the protocol a secure upper bound on the distance is calculated .
These protocols are typically executed with different trust assumptions .
Devices measuring the distance ( typically named veriﬁer and prover ) can be mutually trusted , in which case the protocol aims at preventing distance manipulation by an external attacker .
If one of the devices , the prover , is untrusted , it will try to manipulate the measured distance .
Other scenarios include the untrusted prover being helped by third parties to cheat on its distance .
Distance bounding literature describes four main types of attacks ’ frauds ’ corresponding to the above scenarios : distance fraud , maﬁa fraud , terrorist fraud and distance hijacking .
These protocols , as well as many that followed , are designed as cryptographic challenge-response protocols with RTT of ﬂight measurements .
One of the key insights of Brands and Chaum was to minimise the processing at the prover so that the prover can not cheat on its distance to the veriﬁer .
Namely , this protocol requires that the prover only computes single bit XOR during the time-critical phase of the protocol .
This translates into strong security guarantees as long as the prover can not implement a faster XOR than assumed by the veriﬁer .
This design reduces the number of protocols steps by allowing the veriﬁer and the prover to pre-agree on the nonces that will be used in the protocol exchange .
Many protocols followed these two designs , notably addressing other types of frauds ( especially terrorist fraud ) , as well as the robustness to message loss , performance in terms of protocol execution time , and privacy of distance measurement .
KA Physical Layer Security and Telecommunications | October 2019 Page 653 The Cyber Security Body Of Knowledge www.cybok.org 20.4.2 Distance Measurement Techniques Establishing proximity requires estimating the physical distance between two or more wireless entities .
, amplitude , phase ) that occur as the signal propagates or by estimating the time taken for the signal to travel between the entities .
A radio signal experiences a loss in its signal strength as it travels through the medium .
The amount of loss or attenuation in the signal ’ s strength is proportional to the square of the distance travelled .
The distance between the transmitter and the receiver can therefore be calculated based on the free space path loss equation .
In reality , the signal experiences additional losses due to its interaction with the objects in the environment which are difﬁcult to account for accurately .
This directly affects the accuracy of the computed distance and therefore advanced models such as the Rayleigh fading and log-distance path loss models are typically used to improve the distance estimation accuracy .
, Apple iBeacon and Passive Keyless Entry and Start Systems ) use the strength of the received Bluetooth signal also referred to as the Received Signal Strength Indicator ( RSSI ) value as a measure of proximity .
Alternatively , the devices can measure the distance between them by estimating the phase difference between a received continuous wave signal and a local reference signal .
The need for keeping track of the number of whole cycles elapsed is eliminated by using signals of different frequencies typically referred to as multi-carrier phase-based ranging .
Due to their low complexity and low power consumption , phase based ranging is used in several commercial products .
Finally , the time taken for the radio waves to travel from one point to another can be used to measure the distance between the devices .
One way time-of-ﬂight measurement requires the clocks of the measuring entities to be tightly synchronised .
The precise distance measurement largely depends on the system ’ s ability to estimate the time of arrival and the physical characteristics of the radio frequency signal itself .
The ranging precision is roughly proportional to the bandwidth of the ranging signal .
There are a number of commercially available wireless systems that use chirp and UWB round-trip time-of-ﬂight for distance measurement today .
This means that the attacker has full control of the wireless communication channel and therefore is capable of manipulating all messages transmitted between the two entities .
In RSSI-based distance estimation , an attacker can manipulate the measured distance by manipulating the received signal strength at the veriﬁer .
The attacker can simply amplify the signal transmitted by the prover before relaying it to the veriﬁer .
This will result in an incorrect distance estimation at the veriﬁer .
Commercially available solutions claim to secure against relay attacks by simply reducing or attenuating the power of the transmitted signal .
However , an attacker can trivially circumvent such countermeasures by using higher gain ampliﬁers and receiving antennas .
Similarly , an attacker can also manipulate the estimated distance between the veriﬁer and the prover in systems that use the phase or frequency property of the radio signal .
For instance , the attacker can exploit the maximum measurable property of phase or frequency-based distance measurement systems and execute distance reduction attacks .
, the largest value of distance dmax that can be estimated using a phasebased proximity system , directly depends on the maximum measurable phase .
Given that the phase value ranges from 0 to 2π and then rolls over , the maximum measurable distance also rolls over after a certain value .
An attacker can leverage this maximum measurable distance property of the system in order to execute the distance decreasing relay attack .
The attacker then receives the prover ’ s response signal and forwards it to the veriﬁer , however with a time delay .
The attacker chooses the time delay such that the measured phase differences reaches its maximum value of 2 and rolls over .
In other words , the attacker was able to prove to the veriﬁer that the prover is in close proximity ( e.g .
In Time of Flight ( ToF ) based ranging systems , the distance is estimated based on the time elapsed between the veriﬁer transmitting a ranging packet and receiving an acknowledgement back from the prover .
In order to reduce the distance measured , an attacker must decrease the signal ’ s round trip time of ﬂight .
Based on the implementation , an attacker can reduce the estimated distance in a time-of-ﬂight based ranging system in more than one way .
The ﬁrst type of attack on time-of-ﬂight ranging leverages the predictable nature of the data contained in the ranging and the acknowledgement packets .
A number of time-of-ﬂight ranging systems use pre-deﬁned data packets for ranging , making it trivial for an attacker to predict and generate their own ranging or acknowledgment signal .
An attacker can transmit the acknowledgment packet even before receiving the challenge ranging packet .
Several works have shown that the de-facto standard for IR-UWB , IEEE 802.15.4a does not automatically provide security against distance decreasing attacks .
In [ 1749 ] it was shown that an attacker can potentially decrease the measured distance by as much as 140 meters by predicting the preamble and payload data with more than 99 % accuracy even before receiving the entire symbol .
This degrades the performance of energy detection based receivers , resulting in reduction of the distance measurements .
In order to prevent such attacks it is KA Physical Layer Security and Telecommunications | October 2019 Page 655 The Cyber Security Body Of Knowledge www.cybok.org important to avoid predeﬁned or ﬁxed data during the time critical phase of the distance estimation scheme .
In addition to having the response packet dependent on the challenge signal , the way in which these challenge and response data are encoded in the radio signals affects the security guarantees provided by the ranging or localisation system .
An attacker can predict the bit ( early detect ) even before receiving the symbol completely .
Furthermore , the attacker can leverage the robustness property of modern receivers and transmit arbitrary signal until the correct symbol is predicted .
In such a scenario , the attacker needn ’ t wait for the entire series of pulses to be received before detecting the data being transmitted .
After just a time period , the attacker would be able to correctly predict the symbol .
Due to their long symbol lengths , both implementations have been shown to be vulnerable to early-detect and late-commit attacks .
Thus , it is clear that in order to guarantee proximity and secure a wireless proximity system against early detect and late-commit attacks , it is necessary to keep the symbol length as short as possible .
Design of a physical layer for secure distance measurement remains an open topic .
However , research so far has yielded some guiding principles for its design .
Only radio RTT with singlepulse or multi-pulse UWB modulation has been shown to be secure against physical layer attacks .
As a result , the IEEE 802.15.4z working group started the standardization of a new physical layer for UWB secure distance measurement .
The ﬁrst attempt at formalizing the requirements for secure distance measurement based on the Time of Arrival ( ToA ) of transmitted messages can be found in [ 1747 ] .
Said work presents a formal deﬁnition of Message Time of Arrival Codes ( MTACs ) , the core primitive in the construction of systems for secure ToA measurement .
If implemented correctly , MTACs provide the ability to withstand reduction and enlargement attacks on distance measurements .
It is shown that systems based on UWB modulation can be implemented such that the stated security requirements are met and therefore constitute examples of MTAC schemes .
To spoof the position of prover inside the triangle , the attacker would need to reduce at least one of the distance bounds .
20.4.4 Secure Positioning Secure positioning systems allow positioning anchors ( also called veriﬁers ) to compute the correct position of a node ( also called the prover ) or allow the prover to determine its own position correctly despite manipulations by the attacker .
This means that the attacker can not convince the veriﬁers or the prover that the prover is at a position that is different from its true position .
A related property is the one of secure position veriﬁcation which means that the veriﬁers can verify the position of an untrusted prover .
It is generally assumed that the veriﬁers are trusted .
No restrictions are posed on the attacker as it fully controls the communication channel between the provers and the veriﬁers .
The analysis of broadcast positioning techniques , such as GNSS has shown that such techniques are vulnerable to spooﬁng if the attacker controls the signals at the antenna of the GNSS receiver .
These type of approaches have been proposed to address this issue : Veriﬁable Multilateration and Secure Positioning based on Hidden Stations .
Veriﬁable Multilateration relies on secure distance measurement / distance bounding .
It consists of distance bound measurements to the prover from at least three veriﬁers ( in 2D ) and four veriﬁers ( in 3D ) and of subsequent computations performed by the veriﬁers or by a central system .
Veriﬁable Multilateration has been proposed to address both secure positioning and position veriﬁcation .
In the case of secure positioning , the prover is trusted and maﬁafraud-resilient distance bounding is run between the prover and each of the veriﬁers .
For the attacker to spoof a prover from position P to P ’ within a triangle/pyramid , the attacker would need to reduce at least one of the distance bounds that are measured to P. This follows from the geometry of the triangle/pyramid .
Since Distance bounding prevents distance reduction attacks , Veriﬁable Multilateration prevents spooﬁng attacks within the triangle/pyramid .
The attacker can only spoof P to P ’ that is outside of the triangle/pyramid , causing the prover and the veriﬁers to reject the computed position .
Namely , the veriﬁers and the prover only accept the positions that are within the area of coverage , deﬁned as the area covered by the veriﬁcation triangles/pyramids .
Given this , when the prover is trusted , Veriﬁable Multilateration is resilient to all forms of spoofing by the attacker .
Additional care needs to be given to the management of errors and the computation of the position when distance measurement errors are taken into account .
When used for position veriﬁcation , Veriﬁable Multilateration is run with an untrusted prover .
Based on the obtained distance bounds , the veriﬁers compute the provers ’ position .
If this position KA Physical Layer Security and Telecommunications | October 2019 Page 657 The Cyber Security Body Of Knowledge www.cybok.org ( within some distance and position error bounds ) falls within the veriﬁcation triangle/pyramid , the veriﬁers accept it as valid .
Given that the prover is untrusted , it can enlarge any of the measured distances , but can not reduce them since this is prevented by the use of distance bounding protocols .
Like in the case of secure positioning , the geometry of the triangle/pyramid then prevents the prover from claiming a false position .
Unlike in the case of secure positioning , position veriﬁcation is vulnerable to cloning attacks , in which the prover shares its key to its clones .
These clones can then be strategically placed to the veriﬁers and fake any position by enlarging distances to each individual veriﬁer .
This attack can be possibly addressed by tamper resistant hardware or device ﬁngerprinting .
Another approach to secure positioning and position veriﬁcation is to prevent the attacker from deterministically spooﬁng the computed position by making the positions of the veriﬁers unpredictable for the attacker ( either a malicious prover or an external attacker ) .
Veriﬁer positions can therefore be hidden or the veriﬁers can be mobile .
When the veriﬁers are hidden they should only listen to the beacons sent by the nodes to not disclose their positions .
Upon receiving the beacons , the base stations compute the nodes location with TDOA and check if this location is consistent with the time differences .
Such emanations , or more generally referred to as side channels , are prevalent and have been extensively studied .
Instead of eavesdropping on electromagnetic leakage , an attacker injects signals that spoof the value measured by a sensor or receiver and thereby ( adversely ) affects the system relying on the sensor readings and measurements .
This is particularly critical in autonomous and other cyber-physical systems that have direct consequences on the safety of the surrounding people and infrastructure .
20.5.1 Compromising Emanations In the military context , techniques for exploiting and protecting against unwanted emission in communication systems date back to World War II and have over the time have been collected in an umbrella-term called TEMPEST .
This attack demonstrated that information displayed on CRT monitors can be successfully eavesdropped from a distance of hundreds of meters .
This demonstration prompted research into the sources of such emanations as well as into protective measures .
It also highlighted that not only radio emissions leak information .
Detailed studies of the sources and features that lead to such compromises have been carried out over the years , and on multiple occasions , it was demonstrated that compromising emanations from analogue and digital displays resulted from information being transmitted KA Physical Layer Security and Telecommunications | October 2019 Page 658 The Cyber Security Body Of Knowledge www.cybok.org through analogue video cables and through high-speed Digital Serial Interface ( DVI ) cables .
However , more recent works show that such emanations are not restricted to cables and , to aggravate the situation , compromising emissions are not necessarily caused by analogue or digital displays only .
Some attacks described in research showed that high-frequency sounds caused by vibration of electronic components ( capacitors and coils ) in the computer ’ s voltage regulation circuit can be used to infer prime factors and therefore derive RSA encryption keys .
Sounds emanating from key presses on a keyboard were used to infer what a user is typing .
The resulting vibrations can , for instance , be sensed by the accelerometer of a phone located nearby .
Finally , reﬂections from different objects in the vicinity of computer screens , such as spoons , bottles and user ’ s retina were used to infer information show on a display .
The increasing availability of phones that integrate high quality sensors , such as cameras , microphones and accelerometers makes it easier to mount successful attacks since no dedicated sensor equipment needs to be covertly put in place .
To avoid unwanted signal emissions , devices can be held at a distance , can be shielded and signals that are transmitted should be ﬁltered in order to remove high-frequency components that might reﬂect switching activity in the circuitry .
Moreover , it is generally advised to place a return wire close to the transmission wire in order to avoid exploitation of the return current .
20.5.2 Sensor Compromise Analogue sensors have been shown to be particularly vulnerable to spooﬁng attacks .
Similar to compromising emanations , sensor spooﬁng depends on the type of the physical phenomena the sensor captures .
Nowadays , many electronic devices , including self-driving cars , medical devices and closedloop control systems , feature analogue sensors that help observe the environment and make decisions in a fully autonomous way .
These systems are equipped with sophisticated protection mechanisms to prevent unauthorised access or compromise via the device ’ s communication interfaces , such as encryption , authentication and access control .
Unfortunately , when it comes to data gathered by sensors , the same level of protection is often not available or difﬁcult to achieve since adversarial interactions with a sensor can be hard to model and predict .
As a result , unintentional and especially intentional EMI targeted at analogue sensors can pose a realistic threat to any system that relies on readings obtained from an affected sensor .
EMI has been used to manipulate the output of medical devices as well as to compromise ultrasonic ranging systems .
Research has shown that consumer electronic devices equipped with microphones are especially vulnerable to the injection of fabricated audio signals [ 1560 ] .
Ultrasonic signals were used to inject silent voice commands , and acoustic waves were used to affect the output of MEMS accelerometers .
System designers therefore have to take great care and protect analogue sensors from adversarial input as an attacker might trigger a critical decision on the application layer of such a device by exposing it to intentional EMI .
Potential de- KA Physical Layer Security and Telecommunications | October 2019 Page 659 The Cyber Security Body Of Knowledge www.cybok.org fence strategies include , for example , ( analogue ) shielding of the devices , measuring signal contamination using various metrics , or accommodating dedicated EMI monitors to detect and ﬂag suspicious sensor readings .
A promising strategy that follows the approach of quantifying signal contamination to detect EMI sensor spooﬁng is presented in [ 1755 ] .
The sensor output can be turned on and off according to a pattern unknown to the attacker .
Adversarial EMI in the wires between sensor and the circuitry converting the reading to a digital value , i.e .
, the ADC , can be detected during the times the sensor is off since the sensor output should be at a known level .
In case there are ﬂuctuations in the readings , an attack is detected .
Such an approach is thought to be especially effective when used to protect powered or non-powered passive sensors .
It has been demonstrated to successfully thwart EMI attacks against a microphone and a temperature sensor system .
The only modiﬁcation required is the addition of an electronic switch that can be operated by the control unit or microcontroller to turn the sensor on and off .
An active sensor often has an emitting element and a receiving element .
The emitter releases a signal that is reﬂected and captured by the receiver .
Based on the properties of the received signal , the sensor can infer information about the entity or the object that reﬂected the signal .
The emitter can be turned off randomly and during that time the receiver should not be able to register any incoming signal .
Otherwise , an attack is detected and the sensor reading is discarded .
The main focus is on physical-layer security constructs as well as any lack thereof .
The communication techniques that are discussed in detail are near-ﬁeld communication , air trafﬁc communication networks , cellular networks and global navigation satellite systems .
The standard is used for contact-less payment and mobile payment systems in general .
NFC-enabled devices can also exchange identity information , such as keycards , for access control , and negotiate parameters to establish a subsequent high-bandwidth wireless connection using more capable protocols .
NFC is designed to only transmit and receive data to a distance of up to a few centimeters .
Even if higher-layer cryptographic protocols are used , vanilla NFC protocols do not offer secure communication and can not guarantee that two communicating devices are indeed only a short distance apart .
Even nowadays , standard NFC is deployed in security-critical contexts due to the assumption that communicating devices are in close proximity .
Research has shown , however , that this KA Physical Layer Security and Telecommunications | October 2019 Page 660 The Cyber Security Body Of Knowledge www.cybok.org assumption can not be veriﬁed reliably using NFC protocols .
The distance can be made almost arbitrarily large by relaying messages between NFC-enabled devices .
The attack works as follows : The benign NFC devices are made to believe that they are communicating with each other , but they are actually exchanging data with a modiﬁed smartphone .
An adversary can strategically place a smartphone next to each benign NFC device while the smartphones themselves use a communication method that can cover long distances , such as WiFi .
They simply forward the messages the benign devices are sending to each other .
Such an attack is also referred to as a wormhole attack where communicating parties are tricked into assuming that they are closer than they actually are .
This is a problem that can not be solved using techniques on the logical layer or on the data layer .
Obviously , most of the described attacks can be mitigated by shielding the NFC devices or enhance the protocol with two-factor authentication , for example .
Such mechanisms unfortunately transfer security-relevant decisions to the user of an NFC system .
Countermeasures that do not impose user burden can roughly be categorised into physical layer methods and the augmentation with context- or device-speciﬁc identiﬁers [ 1758 ] .
Protocol augmentation entails context-aware NFC devices that incorporate location information into the NFC system to verify proximity .
The location sensing can be implemented with the help of a variety of different services , each with its own accuracy and granularity .
Conceivable are , for instance , GNSS/GPS based proximity veriﬁcation or leveraging the cell-ID of the base station to which the NFC device is currently closest in order to infer a notion of proximity .
Physical layer methods that have been suggested in research literature are timing restrictions and distance bounding .
Enforcing strict timing restraints on the protocol messages can be understood as a crude form of distance bounding .
As discussed in Section 4.1 , distance bounding determines an upper bound on the physical distance between two communicating devices .
While distance bounding is considered the most effective approach , it still remains to be shown if secure distance bounding can be implemented in practice for small NFC-enabled devices .
20.6.2 Air Trafﬁc Communication Networks Throughout different ﬂight phases commercial and non-commercial aviation uses several wireless communication technologies to exchange information with aviation authorities on the ground as well as between airborne vehicles .
Often legacy systems are still in use and security has never been part of the design of such systems .
While new proposals suggest to overhaul these systems and to tightly integrate security measures into the data layer , such as encryption and message authentication , air trafﬁc communication networks are not only used for information transmission , but also to extract physical layer features from the signal in order to perform aircraft location positioning .
It is , for instance , possible to prevent an aircraft ’ s location from being tracked by Air Trafﬁc Control ( ATC ) by simply jamming the respective messages .
Similarly , an adversary could create ghost planes by emitting fabricated KA Physical Layer Security and Telecommunications | October 2019 Page 661 The Cyber Security Body Of Knowledge www.cybok.org transponder messages .
A sophisticated attacker could even fully distort the view ATC has on its airspace .
Multilateration ( MLAT ) can be seen as a technology that mitigates some of the shortcomings of unauthenticated ADS-B and is therefore usually deployed in conjunction with ADS-B .
MLAT does not rely on the transmitted information encapsulated in the message , but makes use of the physical and geometrical constellation between the transmitter ( i.e .
MLAT systems extract physical layer properties from the received messages .
The time of arrival of a message is recorded at different co-located receivers and , using the propagation speed of the signal , the location of the aircraft ’ s transponder can be estimated .
Multilateration techniques infer the aircraft ’ s location even if the contents of the ADS-B messages are incorrect and thus MLAT provides a means to crosscheck the location information disseminated by the aircraft ’ s transponder .
Although MLAT offers additional security based on physical layer properties , a distributed adversary can still manipulate ADS-B messages .
In addition to altering the location information , an attacker can modify or inject signals that affect the time-of-arrival measurement at the receivers .
If the attacker has access to multiple distributed antennas and is able to coordinate adversarial signal emission precisely , attacks similar to those on standard ADS-B are feasible .
However , the more receivers used to record the signals , the more difﬁcult such attacks become .
Unfortunately , MLAT is not always an effective solution in aviation as strategic receiver placement is crucial and time of arrival calculations can be susceptible to multi-path interference [ 1759 ] .
20.6.3 Cellular Networks Cellular networks provide voice , data and messaging communication through a network of base stations , each covering one or more cells .
The security provisions of these networks are mainly governed by the standards that were adopted in the GSM Association and later in the Third Generation Partnership Plan ( 3GPP ) .
Further development of email and web services resulted in a need for enhanced speeds and services 3GPP improved 2G GSM standard with packet switched data service , resulting in the General Packet Radio Service ( GPRS ) .
Like GSM , GPRS made use of the Home Location Register ( HLR ) , a component that was responsible for subscriber key management and authentication .
However , GPRS enhanced GSM by adding the Serving GPRS Support Node ( SGSN ) for data trafﬁc routing and mobility management for better data trafﬁc delivery .
One of the main security properties that cellular networks aim to protect is the conﬁdentiality of the communication of the link between the mobile station , and the base station and correct billing .
The security of cellular networks has evolved with network generations , but all generations have the same overarching concept .
Subscribers are identiﬁed via their ( Universal ) KA Physical Layer Security and Telecommunications | October 2019 Page 662 The Cyber Security Body Of Knowledge www.cybok.org Subscriber Identity Modules their International Mobile Subscriber Identity ( IMSI ) number and its related secret key .
IMSI and the keys are used to authenticate subscribers as well as to generate the necessary shared secrets to protect the communication to the cellular network .
2G security focused on the conﬁdentiality of the wireless link between the mobile station and the base station .
This protocol is executed each time when a mobile station initiates a billable operation .
2G AKA achieved authentication based on a long term key Ki shared between the subscriber SIM card and the network .
This key is used by the network to authenticate the subscriber and to derive a session key Kc .
This is done within in a challenge response protocol , executed between the SGSN and the mobile station .
Before the execution of the protocol , SGSN receives from the HLR the Kc , a random value RAN D and an expected response XRES .
Both Kc and XRES are generated within the HLR based on RAN D and Ki .
When the mobile station attempts to authenticate to the network it is sent RAN D. To authenticate , the mobile station combines its long term key Ki ( stored on its SIM card ) with the received RAN D to generate RES and Kc .
The mobile station sends RES to the SGSN which compares it to XRES .
If the two values match , the mobile station is authenticated to the network .
The SGSN then sends the Kc to the base station to which the mobile station is connected in order to protect the mobile to base station wireless link .
Furthermore , AKA was designed to provide only one-way authentication of the mobile station to the network .
Since the network did not authenticate to the mobile stations this enabled attacks by fake base stations violating users location privacy and conﬁdentiality of their communication .
3G AKA replaced the weak cryptographic algorithms that were used in 2G and provided mutual authentication between the network and the mobile stations .
Like in 2G , the goal of the protocol is the authentication ( now mutual ) of the network and the mobile station .
The input into the protocol is a secret key K shared between the HLR and the subscriber .
The outcome of the protocol are two keys , the encryption/conﬁdentiality key CK and the integrity key IK .
The generation of two keys allows the network and the mobile station to protect the integrity and conﬁdentiality of their communication using two different keys , in line with common security practices .
CK and IK are each 128 bits long which is considered adequate .
The authentication and key derivation is performed as follows .
The HLR ﬁrst generates the random challenge RAN D , from it the expected response XRES , the keys CK and IK and the authentication token AU T N .
It then sends these values to the SGSN .
The SGSN sends the RAN D as well as the AU T N to the mobile station ( also denoted as User Equipment ( UE ) ) , which will then use its long term key K to generate the response RES and to verify if AU T N was generated by the HLR .
The AU T N is from the shared key and the counter maintained by both the HLR and the mobile station .
Upon receiving the RES from the mobile station , SGSN will compare it with the XRES and if they match , will forward the CK and IK to the base station .
The base and mobile station can now use these keys to protect their communication .
CK and IK are transmitted between different entities in the network .
They are transmitted between SGSN and the associated base station as well as between different base stations during mo- KA Physical Layer Security and Telecommunications | October 2019 Page 663 The Cyber Security Body Of Knowledge www.cybok.org bility .
This allows network attackers to record these keys and therefore eavesdrop on wireless connections .
4G ( LTE ) security architecture preserved many of the core elements of 2G and 3G networks , but aimed to address the shortcomings of 3G in terms of the protection of the in-network trafﬁc through the protection of network links and redistribution of different roles .
For example , the long term key storage was moved from the HLR to the Home Subscriber Server ( HSS ) .
Mobility management was moved from the SGSN to the Mobility Management Engine ( MME ) .
20.6.4 GNSS Security and Spooﬁng Attacks GNSS such as GPS and Galileo provide global navigation service through satellites that are orbiting the earth approximately 20,000km above the ground .
Satellites are equipped with high-precision atomic clocks which allows the satellites to remain synchronised .
Direct Sequence Spreading is used to enable acquisition and to protect the signals carrying those messages from spooﬁng and jamming attacks .
Civilian codes are public and therefore do not offer such protection , whereas military and special interest codes are kept conﬁdential .
Navigation messages carry data including satellite clock information , the ephemeris ( information related to the satellite orbit ) and the almanac ( the satellite orbital and clock information ) .
Satellite messages are broadcasted and the reception of messages from four of more satellites will allow a receiver to calculate its position .
This position calculation is based on trilateration .
The receiver measures the times of arrival of the satellite signals , converts them into distances ( pseudoranges ) , and then calculates its position as well as its clock offset with respect to the satellite clocks .
A GPS signal spooﬁng attack is a physical-layer attack in which an attacker transmits specially crafted radio signals that are identical to authentic satellite signals .
Civilian GPS is easily vulnerable to signal spooﬁng attacks .
This is due to the lack of any signal authentication and the publicly known spreading codes for each satellite , modulation schemes , and data structure .
Due to the low power of the legitimate satellite signal at the receiver , the attacker ’ s spooﬁng signals can trivially overshadow the authentic signals .
The attacker can manipulate the receiver time of arrival by temporally shifting the navigation message signals while transmitting the spooﬁng signals .
We can classify spoofing attacks based on how synchronous ( in time ) and consistent ( with respect to the contents of the navigation messages ) the spooﬁng signals are in comparison to the legitimate GPS signals currently being received at the receiver ’ s true location .
The spooﬁng aligns its signal with the legitimate signal and slowly increase the transmit power .
are both unsynchronised and contain different navigation message data in comparison to the authentic signals .
Attackers who use GPS signal generators to execute the spooﬁng attack typically fall under this category .
An attacker with a little know-how can execute a spoofing attack using these simulators due to their low complexity , portability and ease of use .
Some advanced GPS signal generators are even capable of recording and replaying signals , however not in real-time .
In other words , the attacker uses the simulator to record at one particular time in a given location and later replays it .
Since they are replayed at a later time , the attacker ’ s signals are not coherent and contain different navigation message data than the legitimate signals currently being received .
Non-Coherent but Unmodiﬁed Message Contents : In this type of attack , the navigation message contents of the transmitted spooﬁng signals are identical to the legitimate GPS signals currently being received .
However , the attacker temporally shifts the spooﬁng signal thereby manipulating the spooﬁng signal time of arrival at the target receiver .
For example , attackers capable of real-time recording and replaying of GPS signals fall under this category as they will have the same navigation contents as that of the legitimate GPS signals , however shifted in time .
The location or time offset caused by such an attack on the target receiver depends on the time delay introduced both by the attacker and due to the propagation time of the relayed signal .
The attacker can precompute these delays and successfully spoof a receiver to a desired location .
Coherent but Modiﬁed Message Contents : The attacker generates spooﬁng signals that are synchronised to the authentic GPS signals .
However , the contents of the navigation messages are not the same as that of the currently seen authentic signals .
For instance , PhaseCoherent Signal Synthesisers are capable of generating spooﬁng signals with the same code phase as the legitimate GPS signal that the target receiver is currently locked on to .
Additionally , the attacker modiﬁes the contents of the navigation message in real-time ( and with minimal delay ) and replays it to the target receiver .
A variety of commercial GPS receivers were shown to be vulnerable to this attack and in some cases , it even caused permanent damage to the receivers .
Coherent and Unmodiﬁed Message Contents : Here , the attacker does not modify the contents of the navigation message and is completely synchronised to the authentic GPS signals .
Even though the receiver locks on to the attacker ’ s spooﬁng signals ( due to the higher power ) , there is no change in the location or time computed by the target receiver .
Therefore , this is not an attack in itself but is an important ﬁrst step in executing the seamless takeover attack .
The seamless takeover attack is considered one of the strongest attacks in literature .
In a majority of applications , the target receiver is already locked on to the legitimate GPS satel- KA Physical Layer Security and Telecommunications | October 2019 Page 665 The Cyber Security Body Of Knowledge www.cybok.org lite signals .
The goal of an attacker is to force the receiver to stop tracking the authentic GPS signals and lock onto the spooﬁng signals without causing any signal disruption or data loss .
This is because the target receiver can potentially detect the attack based on the abrupt loss of GPS signal .
In a seamless takeover attack , ﬁrst , the attacker transmits spooﬁng signals that are synchronised with the legitimate satellite signals and are at a power level lower than the received satellite signals .
The receiver is still locked on to the legitimate satellite signals due to the higher power and hence there is no change in the ships route .
The attacker then gradually increases the power of the spoofing signals until the target receiver stops tracking the authentic signal and locks on to the spooﬁng signals .
Note that during this takeover , the receiver does not see any loss of lock , in other words , the takeover was seamless .
Even though the target receiver is now locked on to the attacker , there is still no change in the route as the spooﬁng signals are both coherent with the legitimate satellite signals as well as there is no modiﬁcation to the contents of the navigation message itself .
Now , the attacker begins to manipulate the spooﬁng signal such that the receiver computes a false location and begins to alter its course .
The attacker can either slowly introduce a temporal shift from the legitimate signals or directly manipulate the navigation message contents to slowly deviate the course of the ship to a hostile destination .
However , if the attack is remote , and the attacker can not fully control the signals at the receiver , anomaly detection techniques can be used to detect spooﬁng .
Particularly interesting are techniques based on tracking and analysis of autocorrelation peaks that are used for the detection of GNSS signals .
Distortion , the number and the behaviour over time of these peaks can be used to detect even the most sophisticated seamless takeover attacks .
The detection of GNSS spooﬁng can be improved if spooﬁng signals are simultaneously received by several receivers .
This can be used for the detection of spooﬁng as well as for spoofer localisation .
, are placed at ﬁxed distances ) , the spoofer needs to preserve those distances when performing the spooﬁng attack .
When a single spoofer broadcasts its signals , it will result in all receivers being spoofed to the same position , therefore enabling detection .
This basic detection technique can be generalised to several receivers , allowing even the detection of distributed spoofers .
Finally , GNSS spooﬁng can be made harder through the authentication and hiding of GNSS signals .
Although currently civilian GNSS systems do not support authentication , digital signatures as well as hash-based signatures such as TESLA can be added to prevent the attacker from generating GNSS signals .
This would , however , not prevent all spooﬁng attacks since the attacker can still selectively delay navigation messages and therefore modify the computed position .
This attack can be prevented by the use of spreading with delayed key disclosure .
Even this approach still does not fully prevent against spooﬁng by broadband receivers that are able to relay full GNSS frequency band between locations .
Military GPS signals are authenticated , and try to achieve low-probability of intercept as well as jamming resilience via the use of secret spreading codes .
This approach prevents some of the spooﬁng attacks , but still fails to fully prevent record-and-relay attacks .
In addition , this approach does not scale well since secret spreading codes need to be distributed to all intended receivers , increasing the likelihood of their leakage and reducing usability .
In conclusion , although newly proposed and deployed countermeasures make it more dif- KA Physical Layer Security and Telecommunications | October 2019 Page 666 The Cyber Security Body Of Knowledge www.cybok.org ﬁcult for the attacker to spoof GNS systems like GPS , currently no measure fully prevents spooﬁng under strong attacker models .
This is an area of active research .
CONCLUSION As we have shown in this knowledge area , the wireless physical layer presents both challenges and opportunities .
Challenges typically come from the broadcast nature of wireless communication and from it not being protected against conﬁdentiality and integrity violations .
Physical layer is typically application agnostic .
Opportunities stem from the stochastic nature of the channel as well as from its robustness to ﬁne-grained manipulations .
Under different attacker models , physical layer can support both highly usable and secure solutions .
CROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL The table below lists the reference material that serves as the basis for for this chapter and explains how it relates to the different topics .
Thanks to Aanjhan Ranganathan , Davide Zanetti , Boris Danev , Christina Popper , Kasper Rasmussen and Nils Tippenhauer for allowing the reproduction of selected text and ﬁgures from their publications within this document .
Security and Usability : Designing secure systems that people can use .
Available : https : //www.lawfareblog.com/why-eu-has-issued-relatively-few-data-protectionadequacydeterminations-reply [ 173 ] “ Directive ( EU ) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention , investigation , detection or prosecution of criminal offences or the execution of criminal penalties , and on the free movement of such data , and repealing Council Framework Decision 2008/977/JHA , ” Ofﬁcial Journal of the European Union , vol .
Child Sex Abuse Images and Exploitation Materials .
Seaman , “ The DTSA at One : An Empirical Study of the First Year of Litigation Under the Defend Trade Secrets Act , ” Wake Forest Law Review , vol .
Advanced code evolution techniques and computer virus generator kits .
1991 IEEE Computer Society Symposium on Research in Security and Privacy .
on the insecurity of whitelists and the future of content security policy , ” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security .
: The impact of password meters on password selection , ” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ser .
The Morgan Kaufmann Series in Computer Architecture and Design .
A. Cardenas , “ Understanding security threats in consumer drones Bibliography | October 2019 Page 770 The Cyber Security Body Of Knowledge www.cybok.org through the lens of the discovery quadcopter family , ” in Proceedings of the 2017 Workshop on Internet of Things Security and Privacy .
: Combining attestation and measurements inspection to handle malicious data injections in WSNs , ” in Proceedings of the 10th ACM Conference on Security and Privacy in Wireless and Mobile Networks .
Special Issue on Advances and Applications in the Internet of Things and Cloud Computing , 2017 .
AEAD Authenticated Encryption with Associated Data .
CAPEC Common Attack Pattern Enumeration and Classiﬁcation .
CAPTCHA Completely Automated Public Turing test to tell Computers and Humans Apart .
CCMP Cipher Block Chaining Message Authentication Code Protocol .
CHERI Capability Hardware Enhanced RISC Instructions .
CRTM Core Root of Trust for Measurements .
CSIRT Computer Security Incident Response Team .
CyBOK Cyber Security Body of Knowledge .
DARPA Defence Advanced Research Projects Agency .
DPA Differential and Higher Order Power Analysis .
EAPoL Extensible Authentication Protocol over LAN .
ECIES Elliptic Curve Integrated Encryption Scheme .
ENISA European Union Agency for Cybersecurity .
FIRST Forum of Incident Response and Security Teams .
FUSE File System in User Space .
GSM Global System for Mobile Communications .
HACMS High Assurance Cyber Military Systems .
HIPAA Health Insurance Portability and Accountability Act .
IDMEF Intrusion Detection Message Exchange Format .
IDPS Intrusion Detection and Prevention System .
IODEF Incident Object Description Exchange Format .
ISAC Information Sharing and Analysis Center .
ISAKMP Internet Security Association and Key Management Protocol .
MASVS OWASP Mobile Application Security Veriﬁcation Standard .
MTAC Message Time of Arrival Code .
NERC North American Electric Reliability Corporation .
NICE National Institute for Cybersecurity Education .
NIST National Institute of Standards and Technology .
OWASP Open Web Application Security Project .
PCI DSS Payment Card Industry Data Security Standard .
RAID Redundant Array of Inexpensive Disks .
RTM Root of Trust for Measurement .
RTR Root of Trust for Reporting .
RTS Root of Trust for Storage .
SCADA Supervisory Control and Data Acquisition .
SIEM Security Information and Event Management .
SMIME Secure Multipurpose Internet Mail Extensions .
SOIM Security Operations and Incident Management .
SWEBOK Software Engineering Body of Knowledge .
SWIFT Society for Worldwide Interbank Financial Telecommunication .
taLEA Topology Aware Localised Eclipse Attacks .
TCSEC Trusted Computer System Evaluation Criteria .
TOCTOU Time Of Check Time Of Use .
TOGAF The Open Group Architectural Framework .
XACML eXtensible Access Control Markup Language .
access control the process of denying or granting access requests .
Actuator An actuator is a device that moves or controls some mechanism .
An actuator turns a control signal into mechanical action such as an electric motor .
Actuators may be based on hydraulic , pneumatic , electric , thermal or mechanical means , but are increasingly being driven by software .
advance fee fraud a crime in which the victim is promised a reward , but in order to obtain it has to ﬁrst pay a small fee to the fraudster .
advanced persistent threat An attack to an organization that continues its activities and yet remains undetected for an extended period of time .
ALARA A method to reduce risk to levels As Low As Reasonably Allowable .
ALARP A method to reduce risk to levels As Low As Reasonably Possible .
In the SOIM context , an alert should refer to an event , or group of events , of interest from a security perspective , representing either an attack symptom or consequence .
An alert is necessarily the outcome of an analysis process performed by an Intrusion Detection System sensor on event traces .
anonymity The state of being not identiﬁable within a set of subjects , the anonymity set .
817 The Cyber Security Body Of Knowledge www.cybok.org appiﬁcation The replacement of websites with applications that run on mobile devices.. ASIC Application Speciﬁc Integrated Circuit is one class on integrated circuits , where the circuit is tuned to a speciﬁc application or set of applications .
attack An attempt to gain unauthorised access to an Information System services , resources , or information , or an attempt to compromise system integrity .
attack surface The set of entry points where an attacker can attempt unauthorised access .
Security approaches endeavor to keep the attack surface as small as possible .
authentication The process of verifying the identity of an individual or entity .
botnet A network of compromised computers ( or , bots ) that is controlled by an attacker to launch coordinated malicious activities .
bulletproof hosting service providers providers that are well known not to comply with law enforcement takedown requests .
This is made possible by either being located in countries with lax cybercrime legislation , or by the service provider operators actively bribing local law enforcement .
card skimming the practice of installing devices on ATM that allow for the cloning of the cards that are being inserted .
carving ( File/data content carving ) The process of recovering and reconstructing ﬁle content directly from block storage without using the ﬁlesystem metadata .
More generally , data ( structure ) carving is the process of reconstructing logical objects ( such as ﬁles and database records ) from a bulk data capture ( disk/RAM image ) without using metadata that describes the location and layout of the artifacts .
Data carvers use knowledge of the data formats to identify and validate the extracted content.. certiﬁcate a digitally signed data structure binding an entity ( called subject ) to some attribute .
click fraud the practice of using malware to generate fake clicks on websites .
CMOS Complementary Metal Oxide Semiconductor technology is the most popular silicon technology to make integrated circuits .
It consitst of complementary PMOS and NMOS transistors .
Its main advantages are that it has a very low static power consumption and relative robust operation .
Hence it made it possible to integrate a large number of transistors ( millions to billions ) into one integrated circuit .
compromise Disclosure of information to unauthorised persons , or a violation of the security policy of a system in which unauthorised intentional or unintentional Glossary | October 2019 Page 818 The Cyber Security Body Of Knowledge www.cybok.org disclosure , modiﬁcation , destruction , or loss of an object may have occurred .
conﬁdentiality The property that ensures that information is not made available or disclosed to unauthorised individuals , entities , or processes .
consensus Consensus ( and similarly for Consistency ) refers to mechanisms and the property of achieving varied types of agreement on values or coordination of state/entities , typically in the presence of speciﬁed failures .
consumer In the context of a given transaction , a natural person who enters into a transaction other than for business or professional purposes .
This deﬁnition is far from universal .
coordination schema The mechanisms that help orchestrate the actions of the involved entities .
Covert Channel Attack An attack that results in the unauthorised capability to glean or transfer information between entities that are not speciﬁed to be able to communicate as per the security policy .
CPU Central Processing Unit is a general purpose integrated circuit made to execute a program .
It typically consists of an arithmetic unit , a program control unit , a bus structure and storage for code and data .
One SOC could contain one or more CPU cores with peripherals , extra memory , etc .
credential an input presented for authentication .
cryptocurrency mining the practice of generating cryptocurrencies by solving cryptographic tasks .
cyber-dependent crime crime that can only be committed with the use of computers or technology devices .
cyber-enabled crime crime that has an increased reach compared to its ofﬂine counterpart through the use of technology .
cyberbullying sending or posting harmful material or engaging in other forms of social aggression using the Internet or other digital technologies .
cyberspace A global domain within the information environment consisting of an interdependent network of information system infrastructures including the Internet , telecommunications networks , computer systems , and embedded processors and controllers [ 360 ] .
cyberstalking the practice of using electronic means to stalk another person .
CyBOK Refers to the Cyber Security Body of Knowledge .
delegation the act of granting access rights one holds to another principal .
Denial of Service The prevention of authorised access to resources or the delaying of time-critical operations .
digital ( forensic ) trace An explicit , or implicit , record that testiﬁes to the execution of speciﬁc computations , or the communication and/or storage of speciﬁc data.. digital forensics The process of identifying and reconstructing the relevant sequence of events that have led to the currently observable state of a target IT system or ( digital ) artifacts .
Distributed Denial of Service A Denial of Service technique that uses numerous hosts to perform the attack .
doxing an attack where the victim ’ s private information is publicly released online .
DRAM DRAM is Dynamic Random Access Memory .
Very popular because of its high density .
It requires only one transistor and one small capacitance to store one bit of data .
It looses its value when the power supply is turned off .
drive-by download attack an attack in which a webpage tries to exploit a software vulnerability in the victim ’ s browser with the goal of installing malware .
encryption The process of transforming information ( commonly referred to as plaintext/data ) using an algorithm ( called cipher ) to make it unreadable to anyone except those possessing special knowledge , commonly referred to as a cryptographic key .
In the SOIM context , this is a piece of evidence logged that an activity was performed in the monitored system .
Events are acquired sequentially by sensors to obtain a trace of the activity on a computer or network , to ﬁnd indicator of compromise .
exploit Software or data that takes advantage of a vulnerability in a system to cause unintended consequences .
exploit kit a tool that collects a large number of vulnerabilities and are sold on the black market for other criminals to use .
ﬁle system ( ﬁlesystem ) An operating system subsystem that is responsible for the persistent storage and organisation of user and system ﬁles on a partition/volume .
ﬁrewall A gateway that limits access between networks in accordance with local security policy .
forensics The practice of gathering , retaining , and analysing computer-related data for investigative purposes in a manner that maintains the integrity of the data .
FPGA A Field Programmable Gate Array or FPGA is a specialized integrated circuit that contains conﬁgurable logic , which can still be programmed after fabrication .
Programming is done by loading a bitstream which conﬁgures each of the programmable logic gates individually .
fullz stolen credit card records that also contain billing information .
GPU Graphics Processing Unit is a specialized programmable integrated circuit .
hacktivism the act of computer crime motivated by a political goal .
HDL A Hardware Description Language is a special language to describe digital hardware at the register transfer level .
Most well known languages are VHDL and Verilog .
homomorphic encryption A form of encryption that when computing on ciphertexts , generates an encrypted result which , when decrypted , matches the result of the computation as if it had been performed on the plaintext .
In the context of SOIM , honeypots can be operated locally as an additional detection method supplementing IDS sensors , or by an external CTI service provider .
IC An Integrated Circuit is an electronic device that contains a large amount of electronic components , mostly transistors integrated into one piece of semiconductor material , usually CMOS silicon .
impact The magnitude of harm that can be expected to result from the consequences of unauthorised disclosure of information , unauthorised modiﬁcation of information , unauthorised destruction of information , or loss of information or information system availability ( Source = NIST IR 7298r2 ) .
In the context of SOIM , this is the extent of damage caused by the attack to either the ICT infrastructure , or to business processes .
incident Actions taken through using computer networks that result in an actual or potentially adverse effect on an information system and/or the information residing therein .
In the SOIM context , an incident is described as a set of alerts that are considered evidence of a cybersecurity breach , generally a successful attack ( although serious attempts , or attempts against critical systems , may also be considered incidents .
indicator of compromise Recognised action , speciﬁc , generalized , or theoretical , that an adversary might be expected to take in preparation for an attack .
Industrial Control Systems General term that encompasses several types of control systems , including supervisory control and data acquisition ( SCADA ) systems , distributed control systems ( DCS ) , and other control system conﬁgurations such as Programmable Logic Controllers ( PLC ) often found in the industrial sectors and critical infrastructures .
Industry 4.0 Industry 4.0 refers to the modernization of manufacturing with Internet of Things services , which provide the basis for the fourth industrial revolution .
The ﬁrst industrial revolution was enabled by the introduction of mechanical production facilities powered by water and steam , the second revolution was enabled by mass production powered by electrical energy , and the third revolution was enabled by the introduction of electronics and information technology [ 1836 ] .
In the SOIM context , it designs the ICT infrastructure to detect possible attacks .
integrity The property that ensures that data is real , accurate and safeguarded from unauthorised user modiﬁcation .
Internet of Things Network of physical objects or “ things ” embedded with electronics , software , sensors , and connectivity to enable objects to exchange data with the manufacturer , operator and/or other connected devices .
The IoT refers to devices , that are often constrained in communication and computation capabilities , now becoming more commonly connected to the Internet , and to various services that are built on top of the capabilities these devices jointly provide1 .
Intrusion Detection System ( IDS ) Hardware or software product that gathers and analyses information from various areas within a computer or a network to identify possible security breaches , which include both intrusions ( attacks from outside organisations ) and misuse ( attacks from inside the organisations . ) .
Intrusion Prevention System ( IDPS ) Intrusion Detection System with the additional capability to take immediate and local action to block the detected attack .
This implies two differences , the positioning of the device as an interceptor through which all requests , malicious or benign , will pass , and the ability to diagnose the malicious behaviour with certainty .
See also Intrusion Detection System and sensor .
jurisdiction See the discussion in Section 3.2. key-logger A virus or physical device that logs keystrokes to secretly capture private information such as passwords or credit card details .
leader election Following the replacement of an existing leader , on failure of a leader or for fairness or load balancing , the process of electing a new entity to perform the leadership activities of coordination .
legal action The process by which a person brings a legal claim to a tribunal for adjudication or to enforce the results of a prior adjudication .
This is the method used to enforce a right of action .
legal person An entity vested with sufﬁcient characteristics of personhood to merit a legal identity separate from its constituent members .
These characteristics include : the right to commence or respond to legal action in the entity ’ s name ; the right to own assets in the entity ’ s name ; and the right to enter into obligations in the entity ’ s name .
Likelihood A measure capturing the degree of possibility that a threat will exploit a vulnerability , and therefore produce an undesirable outcome .
1 https : //www.ietf.org/topics/iot/ Glossary | October 2019 Page 823 The Cyber Security Body Of Knowledge www.cybok.org logical acquisition The process of obtaining the data relies on one or more software layers as intermediaries to acquire the data from the storage device .
logical volume A collection of physical volumes presented and managed as a single unit .
macro virus A virus that attaches itself to documents and uses the macro programming capabilities of the document ’ s application to execute and propagate .
malware analysis The process of analyzing malware code and understanding its intended functionalities .
malware detection The process of detecting the presence of malware in a system .
metamorphic malware Malware of which each iteration or instance has different code from the preceding one .
The code changes make it difﬁcult to recognize the different iterations are the same malware ( contrast with polymorphic malware ) .
meterpreter A tool that allows an attacker to control a victim ’ s computer by running an invisible shell and establishing a communication channel back to the attacking machine .
middleware A software layer between the Operating System and the Application Layer designed to facilitate the interconnection and interaction between distributed components .
money mule a person who is recruited by a criminal to perform money laundering .
object the entity accessed by an access operation .
obligation operation to be performed in conjunction with an access request that had been granted .
They also underpin complex manufacturing systems where processes are too heavy-duty , monotonous , or dangerous for human involvement .
Operational Technology Hardware and software that detects or causes a change through the direct monitoring and/or control of physical devices , processes and events in the enterprise [ 1837 ] .
overlay Refers to the overlay network in peer-to-peer systems that is a virtual network linking a speciﬁed set of nodes as built on top of the nodes of the physical network .
Glossary | October 2019 Page 824 The Cyber Security Body Of Knowledge www.cybok.org packed malware Packed malware is obfuscated malware in which the malicious program is compressed and can not be analysed statically .
passive dns A mechanism to collect large amounts of DNS data by storing DNS responses from servers .
PCB A Printed Circuit Board is a specialized board which holds the different integrated circuits .
It is made of an insulated material with copper wiring to connect the pins of different integrated circuits with each other and the outside .
phishing a fraud that lures users into giving away access credentials to online services to a criminal .
phishing kit a programme that can be installed on a server and will produce an appropriately-looking web page for many popular services .
physical acquisition The process of obtaining the data directly from hardware media , without the mediation of any ( untrusted ) third-party software .
polymorphic malware Malware that changes each instance to avoid detection .
It typically has two parts : the decryptor and the encrypted program body .
Each instance can encrypt the malware program differently and hence has a different decryptor ; however , once decrypted , the same malware code is executed .
potentially unwanted program A program that may not be wanted by a user and is often downloaded along with a program that the user wants .
principal in policies , the active entity in an access request .
Programmable Logic Controller ( PLC ) An industrially hardened computer-based unit that performs discrete or continuous control functions in a variety of processing plant and factory environments .
It was originally intended as a relay replacement equipment for the automotive industry .
proof See the discussion in Section 3.1.4. prove See the discussion in Section 3.1.4 .
RAM RAM is Random Access Memory .
It is memory on an integrated circuit to store values ( data or code ) .
Glossary | October 2019 Page 825 The Cyber Security Body Of Knowledge www.cybok.org ransomware Malicious software that makes data or systems unusable until the victim makes a payment .
reference monitor the abstract component that mediates all accesses to objects .
replication The aspect of adding physical or logical copies of a resource .
reshipping mule a person who is recruited by a criminal to send goods purchased with stolen credit cards abroad .
right of action A right arising in law for one person to take legal action against another .
safety In the context of malware analysis , a requirement that malware should be prevented from causing damage to the connected systems and networks while it runs in the analysis environment .
Side Channel attacks can be mounted based on monitoring data or key dependent variations in execution time , power consumption or electromagnetic radiation of integrated circuits .
signature A characteristic byte pattern used in malicious code or an indicator , or set of indicators , that allows the identiﬁcation of malicious network activities .
sinkholing A technique used by a DNS server to give out false information to prevent the use of a domain name .
slack space The difference between the allocated storage for a data object , such as ﬁle , or a volume , and the storage in actual use .
SOC System-on-chip is a very large integrated circuit that combines multiple large components , which in previous generations might have consisted of multiple chips on one circuit board .
spam The abuse of electronic messaging systems to indiscriminately send unsolicited bulk messages .
Glossary | October 2019 Page 826 The Cyber Security Body Of Knowledge www.cybok.org spyware Software that is secretly or surreptitiously installed into an information system to gather information on individuals or organizations without their knowledge ; a type of malicious code .
SRAM SRAM is Static Random Access Memory , a type of memory that makes it easy to address each individual bit , requiring typically 6 transistors per bit .
SRAM looses its values when the power supply is turned off .
In the context of pubic international law and diplomacy , conﬁrming the status of an entity as a ’ state ’ is a decision normally made individually by other states through proclamation , exchange of ambassadors , etc .
Supervisory Control and Data Acquisition A supervisory control system that integrates remote data acquisition systems with data transmission systems and Human-Machine Interface ( HMI ) software to provide a centralised monitoring and control system for numerous process inputs and outputs .
SCADA systems are designed to collect ﬁeld information , transfer it to a central computer facility , and display the information to the operator graphically or textually , thereby allowing the operator to monitor or control an entire system from a central location in near real time .
This is the case for electric power control , although the electric power generation facility is controlled by a DCS , the DCS must communicate with the SCADA system to coordinate production output with transmission and distribution demands [ 1609 ] .
token a data structure encoding the result of an access decision .
trace Ordered set of events , generally of the same type , gathered in a container for easy sequential access .
The order is not necessarily chronological , but is ﬁxed at the time of writing the trace .
triage Triage is a partial forensic examination conducted under ( signiﬁcant ) time and resource constraints.. Glossary | October 2019 Page 827 The Cyber Security Body Of Knowledge www.cybok.org trojan A computer program that appears to have a useful function , but also has a hidden and potentially malicious function that evades security mechanisms , sometimes by exploiting legitimate authorizations of a system entity that invokes the program .
Trusted Computing Base The Trusted Computing Base ( TCB ) is the typical root of trust for a computer system .
It contains all hardware and software components , that need to be trusted and of which the trustworthiness can not be explicitly veriﬁed .
If security vulnerabilities occur in the TCB , then the security of the entire computer system might be at risk .
Trusted Platform Module A Trusted Platform Module is a functional component that can perform cryptographic operations , manage keys , and provide remote attestation services .
When implemented as a cryptographic co-processor and embedded on a personal computer platform , it provides roots of trust so that the platform can identify itself , its current conﬁguration , and running software.. unlinkability The property of two ( or more ) items in a system that ensures that these items are no more and no less related than they are related concerning the a-priori knowledge of the adversary .
A virus can not run by itself ; it requires that its host program be run to make the virus active .
VLSI Very Large Scale Integration is a collection of electronic design automation techniques to translate a HDL description into the actual polygons required for the maskmaking of an integrated circuit .
The VLSI tools made it possible to manage the complexity of designing large integrated circuits .
vulnerability Something open to attack or misuse that could lead to an undesirable outcome .
webiﬁcation The process of using web technologies to display and transfer content on the web and mobile devices.. WiFi A family of radio technologies that is used for the wireless local area networking ( WLAN ) .
worm A computer program that can run independently , can propagate a complete working version of itself onto other hosts on a network , and may consume computer resources destructively .
YARA YARA is a tool primarily used in malware analysis .
It describes malware families using textual or binary patterns .